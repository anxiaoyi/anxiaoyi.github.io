'use strict';(function(){const indexCfg={cache:true};indexCfg.doc={id:'id',field:['title','content'],store:['title','href'],};const index=FlexSearch.create('balance',indexCfg);window.bookSearchIndex=index;index.add({'id':0,'href':'/docs/rocketmq/rocketmq-send-message-flow/','title':"RocketMQ 消息发送流程",'content':"RocketMQ 消息发送流程 本文讲述 RocketMQ 发送一条普通消息的流程。\n一、服务器启动 我们可以参考官方文档来启动服务:\n 启动 Name 服务器:  sh bin/mqnamesrv  启动 Broker 服务器:  sh bin/mqbroker -n localhost:9876 二、构建消息体 一条消息体最少需要指定两个值:\n 所属话题 消息内容  如下就是创建了一条话题为 “Test”，消息体为 “Hello World” 的消息:\nMessage msg = new Message( \u0026#34;Test\u0026#34;, \u0026#34;Hello World\u0026#34;.getBytes() ); 三、启动 Producer 准备发送消息 如果我们想要发送消息呢，我们还需要再启动一个 DefaultProducer (生产者) 类来发消息:\nDefaultMQProducer producer = new DefaultMQProducer(); producer.start(); 现在我们所启动的服务如下所示:\n四、Name 服务器的均等性 注意我们上述开启的是单个服务，也即一个 Broker 和一个 Name 服务器，但是实际上使用消息队列的时候，我们可能需要搭建的是一个集群，如下所示:\n在 RocketMQ 的设计中，客户端需要首先询问 Name 服务器才能确定一个合适的 Broker 以进行消息的发送:\n然而这么多 Name 服务器，客户端是如何选择一个合适的 Name 服务器呢?\n首先，我们要意识到很重要的一点，Name 服务器全部都是处于相同状态的，保存的都是相同的信息。在 Broker 启动的时候，其会将自己在本地存储的话题配置文件 (默认位于 $HOME/store/config/topics.json 目录) 中的所有话题加载到内存中去，然后会将这些所有的话题全部同步到所有的 Name 服务器中。与此同时，Broker 也会启动一个定时任务，默认每隔 30 秒来执行一次话题全同步:\n五、选择 Name 服务器 由于 Name 服务器每台机器存储的数据都是一致的。因此我们客户端任意选择一台服务器进行沟通即可。\n其中客户端一开始选择 Name 服务器的源码如下所示:\npublic class NettyRemotingClient extends NettyRemotingAbstract implements RemotingClient { private final AtomicInteger namesrvIndex = new AtomicInteger(initValueIndex()); private static int initValueIndex() { Random r = new Random(); return Math.abs(r.nextInt() % 999) % 999; } private Channel getAndCreateNameserverChannel() throws InterruptedException { // ...  for (int i = 0; i \u0026lt; addrList.size(); i++) { int index = this.namesrvIndex.incrementAndGet(); index = Math.abs(index); index = index % addrList.size(); String newAddr = addrList.get(index); this.namesrvAddrChoosed.set(newAddr); Channel channelNew = this.createChannel(newAddr); if (channelNew != null) return channelNew; } // ...  } } 以后，如果 namesrvAddrChoosed 选择的服务器如果一直处于连接状态，那么客户端就会一直与这台服务器进行沟通。否则的话，如上源代码所示，就会自动轮寻下一台可用服务器。\n六、寻找话题路由信息 当客户端发送消息的时候，其首先会尝试寻找话题路由信息。即这条消息应该被发送到哪个地方去。\n客户端在内存中维护了一份和话题相关的路由信息表 topicPublishInfoTable，当发送消息的时候，会首先尝试从此表中获取信息。如果此表不存在这条话题的话，那么便会从 Name 服务器获取路由消息。\npublic class DefaultMQProducerImpl implements MQProducerInner { private TopicPublishInfo tryToFindTopicPublishInfo(final String topic) { TopicPublishInfo topicPublishInfo = this.topicPublishInfoTable.get(topic); if (null == topicPublishInfo || !topicPublishInfo.ok()) { this.topicPublishInfoTable.putIfAbsent(topic, new TopicPublishInfo()); this.mQClientFactory.updateTopicRouteInfoFromNameServer(topic); topicPublishInfo = this.topicPublishInfoTable.get(topic); } // ...  } } 当尝试从 Name 服务器获取路由信息的时候，其可能会返回两种情况:\n(1) 新建话题 这个话题是新创建的，Name 服务器不存在和此话题相关的信息：\n(2) 已存话题 话题之前创建过，Name 服务器存在此话题信息：\n服务器返回的话题路由信息包括以下内容:\n“broker-1”、”broker-2” 分别为两个 Broker 服务器的名称，相同名称下可以有主从 Broker，因此每个 Broker 又都有 brokerId 。默认情况下，BrokerId 如果为 MixAll.MASTER_ID （值为 0） 的话，那么认为这个 Broker 为 MASTER 主机，其余的位于相同名称下的 Broker 为这台 MASTER 主机的 SLAVE 主机。\npublic class MQClientInstance { public String findBrokerAddressInPublish(final String brokerName) { HashMap\u0026lt;Long/* brokerId */, String/* address */\u0026gt; map = this.brokerAddrTable.get(brokerName); if (map != null \u0026amp;\u0026amp; !map.isEmpty()) { return map.get(MixAll.MASTER_ID); } return null; } } 每个 Broker 上面可以绑定多个可写消息队列和多个可读消息队列，客户端根据返回的所有 Broker 地址列表和每个 Broker 的可写消息队列列表会在内存中构建一份所有的消息队列列表。之后客户端每次发送消息，都会在消息队列列表上轮循选择队列 (我们假设返回了两个 Broker，每个 Broker 均有 4 个可写消息队列):\npublic class TopicPublishInfo { public MessageQueue selectOneMessageQueue() { int index = this.sendWhichQueue.getAndIncrement(); int pos = Math.abs(index) % this.messageQueueList.size(); if (pos \u0026lt; 0) pos = 0; return this.messageQueueList.get(pos); } } 七、给 Broker 发送消息 在确定了 Master Broker 地址和这个 Broker 的消息队列以后，客户端才开始真正地发送消息给这个 Broker，也是从这里客户端才开始与 Broker 进行交互:\n这里我们暂且先忽略消息体格式的具体编/解码过程，因为我们并不想一开始就卷入这些繁枝细节中，现在先从大体上了解一下整个消息的发送流程，后续会写专门的文章来说明。\n八、Broker 检查话题信息 刚才说到，如果话题信息在 Name 服务器不存在的话，那么会使用默认话题信息进行消息的发送。然而一旦这条消息到来之后，Broker 端还并没有这个话题。所以 Broker 需要检查话题的存在性:\npublic abstract class AbstractSendMessageProcessor implements NettyRequestProcessor { protected RemotingCommand msgCheck(final ChannelHandlerContext ctx, final SendMessageRequestHeader requestHeader, final RemotingCommand response) { // ...  TopicConfig topicConfig = this.brokerController .getTopicConfigManager() .selectTopicConfig(requestHeader.getTopic()); if (null == topicConfig) { // ...  topicConfig = this.brokerController .getTopicConfigManager() .createTopicInSendMessageMethod( ... ); } } } 如果话题不存在的话，那么便会创建一个话题信息存储到本地，并将所有话题再进行一次同步给所有的 Name 服务器:\npublic class TopicConfigManager extends ConfigManager { public TopicConfig createTopicInSendMessageMethod(final String topic, /** params **/) { // ...  topicConfig = new TopicConfig(topic); this.topicConfigTable.put(topic, topicConfig); this.persist(); // ...  this.brokerController.registerBrokerAll(false, true); return topicConfig; } } 话题检查的整体流程如下所示:\n九、消息存储 当 Broker 对消息的一些字段做过一番必要的检查之后，便会存储到磁盘中去:\n十、整体流程 发送消息的整体流程:\n"});index.add({'id':1,'href':'/docs/rocketmq/','title':"RocketMQ 源码分析",'content':"RocketMQ RocketMQ 是阿里巴巴集团开源的一款分布式消息中间件，其采用纯 Java 语言编写，本博客基于 RocketMQ 4.2.0 版本，为大家分析和讲解其内部几个关键模块的运行原理。\n"});index.add({'id':2,'href':'/docs/tomcat/tomcat-architecture/','title':"Tomcat 主体架构",'content':"Tomcat 主体架构 本篇讲述 Tomcat 的主体架构，在描述架构之前，会首先向大家介绍 Servlet 是什么，以及 Servlet 容器又是什么等相关概念。\nServlet 是什么 一句话：Servlet 是一个实现了 javax.servlet.Servlet 接口的类，该类由 Servlet 容器进行统一管理。在该接口中，其定义了所有 Servlet 实现类必须实现的几个方法：\n init(ServletConfig config) service(ServletRequest request, ServletResponse response) destroy() getServletConfig() getServletInfo()  Servlet 是 Java 为 Web 开发者们所制定的一套标准，一个规范，其当前已经发展到了最新的 3.0 版本。从 Servlet 接口中，我们可以看出，service 方法提供了 request 对象和 response 对象，该方法是用来处理客户端逻辑的核心方法，客户端发送过来的请求信息会被封装到 request 对象中，开发者在该方法内，可以通过 response 对象，将想要输出给客户端的信息发送出去。\nServlet 容器是什么 Servlet 容器是一个可以用来管理多个 Servlet 对象的可以处理用户请求的容器。其根据 Servlet 标准规范，来决定如何解析用户请求，何时调用某个 Servlet 的 init、service、destroy 等方法，以及如何支持 HTTP 协议等。更进一步，其通常需要设计和支持的功能至少包含如下几个点：\n 管理每一个 Servlet 的生命周期 解析 HTTP 请求的头部、参数、请求路径、编码等 为 Servlet 提供访问资源、存取参数等信息、虚拟主机等方法 请求路径映射 为响应提供 Buffer、重定向、如何添加头等 登录校验、缓存校验、数据格式校验等请求过滤器 Session 信息管理 注解能力 分发请求、转发请求、错误处理等 事件监听等 安全校验  Tomcat 整体架构 如图一个 Tomcat 实例，内部包含一个 Server 示例，这个 Server 又可以添加多个 Service，每一个 Service 包含一组 Connector 和一个 Container。\nServer 是用来启动和关闭整个容器的，当其启动的时候，会默认添加一个 Service：\n// org.apache.catalina.startup.Tomcat.java server = new StandardServer(); Service service = new StandardService(); service.setName(\u0026#34;Tomcat\u0026#34;); server.addService(service); Service 是用来维护 Connector 和 Container 的，你可以将其想象为一个名为 XXXManager 这样的类。\nConnector 是用来解析 HTTP 协议请求的，不同的 HTTP 协议（如 HTTP 和 HTTPS）有不同的请求头，需要不同的解析方式。另外是使用 Java 中的 NIO 方式还是 NIO2 的方式去接受、建立、响应 Socket 连接，在速度和性能上这也是不同的。因此基于协议的不同和 Java IO 模型选择的不同，会有多种不同的 Connector 实现。\n参考  Java Servlet Specification 3.0  "});index.add({'id':3,'href':'/docs/books/beauty_of_mathematics/','title':"数学之美",'content':"数学之美 2000多年前，古埃及人在罗塞塔石碑上，用三种文字记录了托勒密五世登基的诏书，这帮助后人破解了古埃及的象形文字，让我们了解了5000年前古埃及的历史。可见信息冗余是信息安全的保障，这对于信息编码具有重要指导意义。\n犹太人为了避免抄错《圣经》，发明了一种校验码的方法，他们把每一个希伯来字母对应于一个数字，这样每行文字加起来便得到一个特殊的数字，这样的数字变成为了这一行的校验码。\n隐含马尔可夫链成功应用在机器翻译、拼写纠错、手写体识别、图像处理、基因序列分析、股票预测和投资等方面。\n如何准确的识别出一个快递地址，写一个分析器去分析这些描述恐怕是不行的，因为地址是比较复杂的上下文有关的文法。答案是使用有限状态机。当用户输入的地址不太标准或有错别字的时候，有限状态机会束手无措，因为有限状态机是严格匹配的，所以科学家提出了基于概率的有限状态机。\n2002 年，Google 想要做一个全新的中、日、韩搜索算法，吴军写的算法比较简单，但是占用内存比较多，Google 服务器数量还没有那么多。辛格提出，用一个拟合函数替换很耗内存的语言模型，无需增加任何服务器，但是搜索质量会降到 80%。辛格指出，这样可以提早两个月将这个新算法提供给中国的用户，用户体验会有质的提高。辛格做事情的哲学，先帮助用户解决 80% 的问题，再慢慢解决剩下的 20% 的问题，是在工业界成功的秘诀之一。\n新闻分类的关键在于计算出两篇新闻的相似度，每篇新闻变成一个向量，最后余弦定理可以计算出来相似度。但两两计算的迭代次数太多，如何一次性就把所有新闻的相关性计算出来呢？答案是矩阵运算中的奇异值分解。\n如何判断两个集合是否相同？一种答案是双层 for 循环一一比较，复杂度 O(N^2)；稍好一点的办法是对集合进行排序，然后顺序比较，时间复杂度 O(NlogN)；还可以将一个集合的元素放到散列表里面，另外一个与之一一对比，时间复杂度 O(N)，但是额外使用了 O(N) 的空间，不完美；最完美的是计算这两个集合的指纹，对一个集合中的元素分别计算指纹，然后一一相加。\n如何判断两个集合基本相同？答案是 Simhash。判断两个网页是否重复，也没有必要完全从头比到尾，只需要每个网页挑选出几个词 (IDF 最大的几个词)，构成特征词，然后计算信息指纹即可。判断一篇文章是否抄袭另外一篇文章，每篇文章切成小的片段，挑选特征词，并计算指纹。YouTuBe 如何从上百万视频中找出一个视频是否另外一个视频的盗版？其核心在于关键帧的提取和特征的提取。关键帧对于视频的重要性，就如同主题词对于新闻的重要性一样。\n最大熵原理指出，对一个随机事件的概率分布进行预测时，我们的预测应当满足全部已知的条件，而对未知的情况不要做任何主观假设，这种情况下，概率分布最均匀，预测的风险最小。例如拼音输入法，Wang-Xiao-Bo 转换为王晓波和王小波，唯一确定用户需要的是哪一个，非常难。\n"});index.add({'id':4,'href':'/docs/javascript/understand-this-keyword/','title':"理解 This 关键字",'content':"理解 This 关键字 JavaScript 中的 this 所指向的对象，取决于上下文以及函数被调用的方式，本文列举了几种常见的情况，帮助大家理解。\n一、全局上下文 当直接在一个全局的上下文中，使用 this 指针的时候，this 指针会指向到全局对象上。例如在浏览器的调试工具栏中直接打印 this 指针，其指向的是 Window 对象：\n在 node 中打印 this 指针，其指向的是 node 提供的全局对象，其中包含了进程信息等：\n二、Function 上下文 在 Function 上下文中，this 的值取决于 function 是如何被调用的。\n(1) Function 调用 当 this 指针定义在一个 function 中，那么此 this 仍然会指向全局对象：\nfunction foo() { console.log(this) } foo(); // Window {parent: Window, postMessage: ƒ, blur: ƒ, focus: ƒ, close: ƒ, …} (2) 严格模式下的 Function 调用 如果在严格模式下定义的 function 的话，this 指针的值将会是 undefined：\nfunction foo() { \u0026#39;use strict\u0026#39;; console.log(this) } foo(); // undefined (3) Method 调用 Method 调用指的是，function 作为一个对象的属性而存在。当 this 指针被定义在一个对象内的时候，那么其将会指向紧紧包裹自己的这个对象。\nvar obj = { name: \u0026#39;outerObj\u0026#39;, innerObj: { name: \u0026#39;innerObj\u0026#39;, foo: function() { console.log(this.name) } } }; console.log(obj.innerObj.foo()) // innerObj (4) 构造器调用 当 function 被用于构造器的时候，那么定义在构造器内部的 this 指针将会指向此构造器新 new 出来的实例对象。\nfunction Person(name) { this.name = name console.log(this) } console.log(new Person(\u0026#34;Tom\u0026#34;)) // Person {name: \u0026#34;Tom\u0026#34;} (5) call()、apply()、bind() 调用 这三个函数最大的特点就是，你可以通过参数为他们指定 this 指针所需要指向的对象：\nfunction add(inc1, inc2) { var value = this.a + inc1 + inc2; console.log(this) return value; } var o = { a : 4 }; console.log(add.call(o, 5, 6)) // {a: 4} console.log(add.apply(o, [5, 6])) // {a: 4}  var g = add.bind(o, 5, 6) console.log(g()) // {a: 4} (6) ES6 箭头函数调用 当你使用 ES6 箭头函数的时候，this 指针返回的总是箭头函数定义所在位置的上一级的函数作用域的 this 对象，是箭头函数被 function() { } 包裹的作用域中的 this 对象。如下面示例，this 指向的是 log() 函数内部的 this 指针的值：\nclass Student { log() { // 这个地方的 this 的值  setTimeout(() =\u0026gt; console.log(this === student), 100) } } const student = new Student() student.log() // true 但是如果上一级并不是位于函数作用域中，而是位于 Object 对象嵌套层级中，则需要继续向上找函数作用域，因为 Object 嵌套层级不构成单独的作用域。如下所示 this 指针指向的是 Window 对象，而非 o 对象：\nvar o = { b: () =\u0026gt; { console.log(\u0026#39;this is\u0026#39;, this); // this is Window  } } o.b(); 三、参考  How does the “this” keyword work? Gentle Explanation of \u0026ldquo;this\u0026rdquo; in JavaScript MDN this 箭头函数this的指向问题  "});index.add({'id':5,'href':'/docs/javascript/','title':"JavaScript 专栏",'content':"JavaScript 专栏 本专栏用于整理在 JavaScript 中最常使用的、必知必会的基础知识点，方便大家温故而知新。\n"});index.add({'id':6,'href':'/docs/javascript/javascript-array/','title':"JavaScript 数组",'content':"JavaScript 数组 使用 JavaScript 在编程的时候，我们有很大一部分时间都是在与数组打交道，因此对数组常见的方法做到灵活的运用至关重要。本文整理了和 JavaScript 数组相关的，日常经常需要的功能和使用技巧，供大家参阅。\n从数组中移除指定元素 查阅 JavaScript 的数组 API，发现其并没有提供一个像 remove(obj) 或 removeAll(obj) 此类的方法，供我们方便的删除对象，因此我们需要通过使用其它的 API 来达到我们移出元素的目的。\n(1) 使用 splice 方法 splice 方法可以从指定索引处，向数组中添加元素或者删除元素，其会直接在原数组上改变，因此通过此方法可以达到我们的目的。但是在移除元素之前，我们必须首先通过 indexOf 方法找到我们的元素在数组中处于的索引位置。\nconst array = [2, 5, 9]; const index = array.indexOf(5); if (index \u0026gt; -1) { array.splice(index, 1); // 1 代表删除 1 个元素 } console.log(array) 当然，如果你不想使用 indexOf 的话，也可以直接从后向前遍历整个数组，对每个符合要求的元素都使用 splice 方法：\nconst array = [2, 5, 9]; for (var i = array.length; i--; ) { if (array[i] === 5) { array.splice(i, 1) } } console.log(array) 之所以需要从后向前移除，是因为在移除过程中，数组的 length 和 index 索引都是会改变的。\n(2) 使用 filter 方法 在 ES6 中，你可以使用 filter 函数遍历数组，对不符合元素值的对象进行过滤。filter 方法会返回一个新的数组，并不会直接在原数组上进行操作。\nlet value = 3; let array = [1, 2, 3, 4, 5, 3]; console.log(array.filter(item =\u0026gt; item !== value)) 如何遍历数组元素 JavaScript 数组提供了非常多的方法，这些方法都可以用来遍历数组：\n(1) 使用 forEach 方法 var a = [\u0026#34;a\u0026#34;, \u0026#34;b\u0026#34;, \u0026#34;c\u0026#34;]; a.forEach(function(entry) { console.log(entry) }) (2) 使用 for 遍历 var a = [\u0026#34;a\u0026#34;, \u0026#34;b\u0026#34;, \u0026#34;c\u0026#34;]; for (var index = 0; index \u0026lt; a.length; ++index) { console.log(a[index]) } (3) 使用 for 反向遍历 for (var i = array.length; i--; ) { // ... } 上述反向遍历的原理是：i-- 是属于测试条件的一部分，在每一次开始执行方法体之前，i 的值已经提前执行了 -- 这个操作了。当最后一次迭代，发现 i 等于 0 的时候，这个循环自然会停下来。\n(4) 使用 for-of 遍历 ES6 添加了迭代器的概念，当你使用 for-of 遍历的时候，其实已经隐形的在使用迭代器了：\nvar a = [\u0026#34;a\u0026#34;, \u0026#34;b\u0026#34;, \u0026#34;c\u0026#34;]; for (const val of a) { console.log(val); } (5) 不要使用 for-in 遍历 你或许听到过一些其它人的观点告诉你，使用 for-in 同样可以做到遍历数组。但是 for-in 是为了遍历对象用的，它并不保证按照数组的索引顺序来一一地遍历元素。所以在遍历数组的时候不推荐使用这种做法。\nfor (key in obj) { if (obj.hasOwnProperty(key)) { // ...  } } 如何清空数组 (1) 直接赋值一个空数组 如果你确实不在使用这个数组的话，也能保证其它地方没有引用这个数组，那么完全可以通过为其赋上一个新的空数组，从而置位空。\narr = [] (2) 将长度置为 0 arr.length = 0 (3) 使用 splice 方法 arr.splice(0, arr.length) (4) 使用 pop 方法 一一将元素 pop 出去，可能是最慢的一个方法了。\nwhile (arr.length) { arr.pop(); } 从头部插入元素 (1) 使用 unshift 方法  unshift 方法从头部插入一个元素到数组中 shift 方法从头部删除一个元素 push 方法从尾部插入一个元素到数组中 pop 方法从尾部删除一个元素  JavaScript 提供的从头部删除元素的方法名叫做 unshift，而不是叫做 insertAtHead 之类的，的确是在用到的时候不太容易想到这个名称。之所以这样命名，是因为 JavaScript 的数组的命名方式参考了 C 语言的栈的命名方式:\n array_unshift() array_shift() array_push() array_pop()  (2) 使用 concat 方法 concat() 方法可以用来连接两个数组：\nvar arr = [1, 2, 3, 4, 5, 6, 7]; console.log([0].concat(arr)); (3) 使用 Spread 操作符 在 ES6 中，可以使用 Spread 操作符 \u0026hellip; 来新增元素：\nvar arr = [23, 45, 12, 67]; arr = [34, ...arr]; 提前 break 数组循环 (1) 使用 Exception 对于 forEach 而言，使用 break 是不管用的，需要抛出异常强制终止循环，最好的建议是如果你需要 break 循环，在这种情况下就不要使用 forEach 来循环数组了：\nvar BreakException = {}; try { [1, 2, 3].forEach(function(el) { console.log(el); if (el === 2) throw BreakException; }); } catch (e) { if (e !== BreakException) throw e; } (2) 使用 for-of for (const [index, el] of arr.entries()) { if ( index === 5 ) break; } (3) 使用普通的循环 var array = [1, 2, 3]; for (var i = 0; i \u0026lt; array.length; i++) { if (array[i] === 1){ break; } } 数组去重 (1) 使用 filter 方法 var myArray = [\u0026#39;a\u0026#39;, 1, \u0026#39;a\u0026#39;, 2, \u0026#39;1\u0026#39;]; var unique = myArray.filter((value, index, arr) =\u0026gt; arr.indexOf(value) === index); (2) 使用 Set 构造器 var myArray = [\u0026#39;a\u0026#39;, 1, \u0026#39;a\u0026#39;, 2, \u0026#39;1\u0026#39;]; // unique = Array.from(new Set(myArray)) let unique = [...new Set(myArray)]; 参考  How do I remove a particular element from an array in JavaScript For-each over an array in JavaScript How do I empty an array in JavaScript How can I add new array elements at the beginning of an array in Javascript? Short circuit Array.forEach like calling break Get all unique values in a JavaScript array  "});index.add({'id':7,'href':'/docs/rocketmq/rocketmq-message-store-flow/','title':"RocketMQ 消息存储流程",'content':"RocketMQ 消息存储流程 本文讲述 RocketMQ 存储一条消息的流程。\n一、存储位置 当有一条消息过来之后，Broker 首先需要做的是确定这条消息应该存储在哪个文件里面。在 RocketMQ 中，这个用来存储消息的文件被称之为 MappedFile。这个文件默认创建的大小为 1GB。\n一个文件为 1GB 大小，也即 1024 * 1024 * 1024 = 1073741824 字节，这每个文件的命名是按照总的字节偏移量来命名的。例如第一个文件偏移量为 0，那么它的名字为 00000000000000000000；当当前这 1G 文件被存储满了之后，就会创建下一个文件，下一个文件的偏移量则为 1GB，那么它的名字为 00000000001073741824，以此类推。\n默认情况下这些消息文件位于 $HOME/store/commitlog 目录下，如下图所示:\n二、文件创建 当 Broker 启动的时候，其会将位于存储目录下的所有消息文件加载到一个列表中:\n当有新的消息到来的时候，其会默认选择列表中的最后一个文件来进行消息的保存:\npublic class MappedFileQueue { public MappedFile getLastMappedFile() { MappedFile mappedFileLast = null; while (!this.mappedFiles.isEmpty()) { try { mappedFileLast = this.mappedFiles.get(this.mappedFiles.size() - 1); break; } catch (IndexOutOfBoundsException e) { //continue;  } catch (Exception e) { log.error(\u0026#34;getLastMappedFile has exception.\u0026#34;, e); break; } } return mappedFileLast; } } 当然如果这个 Broker 之前从未接受过消息的话，那么这个列表肯定是空的。这样一旦有新的消息需要存储的时候，其就得需要立即创建一个 MappedFile 文件来存储消息。\nRocketMQ 提供了一个专门用来实例化 MappedFile 文件的服务类 AllocateMappedFileService。在内存中，也同时维护了一张请求表 requestTable 和一个优先级请求队列 requestQueue 。当需要创建文件的时候，Broker 会创建一个 AllocateRequest 对象，其包含了文件的路径、大小等信息。然后先将其放入 requestTable 表中，再将其放入优先级请求队列 requestQueue 中:\npublic class AllocateMappedFileService extends ServiceThread { public MappedFile putRequestAndReturnMappedFile(String nextFilePath, String nextNextFilePath, int fileSize) { // ...  AllocateRequest nextReq = new AllocateRequest(nextFilePath, fileSize); boolean nextPutOK = this.requestTable.putIfAbsent(nextFilePath, nextReq) == null; if (nextPutOK) { // ...  boolean offerOK = this.requestQueue.offer(nextReq); } } } 服务类会一直等待优先级队列是否有新的请求到来，如果有，便会从队列中取出请求，然后创建对应的 MappedFile，并将请求表 requestTable 中 AllocateRequest 对象的字段 mappedFile 设置上值。最后将 AllocateRequest 对象上的 CountDownLatch 的计数器减 1 ，以标明此分配申请的 MappedFile 已经创建完毕了:\npublic class AllocateMappedFileService extends ServiceThread { public void run() { // 一直运行  while (!this.isStopped() \u0026amp;\u0026amp; this.mmapOperation()) { } } private boolean mmapOperation() { req = this.requestQueue.take(); if (req.getMappedFile() == null) { MappedFile mappedFile; // ...  mappedFile = new MappedFile(req.getFilePath(), req.getFileSize()); // 设置上值  req.setMappedFile(mappedFile); } // ...  // 计数器减 1  req.getCountDownLatch().countDown(); // ...  return true; } } 其上述整体流程如下所示:\n等待 MappedFile 创建完毕之后，其便会从请求表 requestTable 中取出并删除表中记录:\npublic class AllocateMappedFileService extends ServiceThread { public MappedFile putRequestAndReturnMappedFile(String nextFilePath, String nextNextFilePath, int fileSize) { // ...  AllocateRequest result = this.requestTable.get(nextFilePath); if (result != null) { // 等待 MappedFile 的创建完成  boolean waitOK = result.getCountDownLatch().await(waitTimeOut, TimeUnit.MILLISECONDS); if (!waitOK) { return null; } else { // 从请求表中删除  this.requestTable.remove(nextFilePath); return result.getMappedFile(); } } } } 然后再将其放到列表中去:\npublic class MappedFileQueue { public MappedFile getLastMappedFile(final long startOffset, boolean needCreate) { MappedFile mappedFile = null; if (this.allocateMappedFileService != null) { // 创建 MappedFile  mappedFile = this.allocateMappedFileService .putRequestAndReturnMappedFile(nextFilePath, nextNextFilePath, this.mappedFileSize); } if (mappedFile != null) { // ...  // 添加至列表中  this.mappedFiles.add(mappedFile); } return mappedFile; } } 至此，MappedFile 已经创建完毕，也即可以进行下一步的操作了。\n三、文件初始化 在 MappedFile 的构造函数中，其使用了 FileChannel 类提供的 map 函数来将磁盘上的这个文件映射到进程地址空间中。然后当通过 MappedByteBuffer 来读入或者写入文件的时候，磁盘上也会有相应的改动。采用这种方式，通常比传统的基于文件 IO 流的方式读取效率高。\npublic class MappedFile extends ReferenceResource { public MappedFile(final String fileName, final int fileSize) throws IOException { init(fileName, fileSize); } private void init(final String fileName, final int fileSize) throws IOException { // ...  this.fileChannel = new RandomAccessFile(this.file, \u0026#34;rw\u0026#34;).getChannel(); this.mappedByteBuffer = this.fileChannel.map(MapMode.READ_WRITE, 0, fileSize); // ...  } } 四、消息文件加载 前面提到过，Broker 在启动的时候，会加载磁盘上的文件到一个 mappedFiles 列表中。但是加载完毕后，其还会对这份列表中的消息文件进行验证 (恢复)，确保没有错误。\n验证的基本想法是通过一一读取列表中的每一个文件，然后再一一读取每个文件中的每个消息，在读取的过程中，其会更新整体的消息写入的偏移量，如下图中的红色箭头 (我们假设最终读取的消息的总偏移量为 905):\n当确定消息整体的偏移量之后，Broker 便会确定每一个单独的 MappedFile 文件的各自的偏移量，每一个文件的偏移量是通过取余算法确定的:\npublic class MappedFileQueue { public void truncateDirtyFiles(long offset) { for (MappedFile file : this.mappedFiles) { long fileTailOffset = file.getFileFromOffset() + this.mappedFileSize; if (fileTailOffset \u0026gt; offset) { if (offset \u0026gt;= file.getFileFromOffset()) { // 确定每个文件的各自偏移量  file.setWrotePosition((int) (offset % this.mappedFileSize)); file.setCommittedPosition((int) (offset % this.mappedFileSize)); file.setFlushedPosition((int) (offset % this.mappedFileSize)); } else { // ...  } } } // ...  } } 在确定每个消息文件各自的写入位置的同时，其还会删除起始偏移量大于当前总偏移量的消息文件，这些文件可以视作脏文件，或者也可以说这些文件里面一条消息也没有。这也是上述文件 1073741824 被打上红叉的原因:\npublic void truncateDirtyFiles(long offset) { List\u0026lt;MappedFile\u0026gt; willRemoveFiles = new ArrayList\u0026lt;MappedFile\u0026gt;(); for (MappedFile file : this.mappedFiles) { long fileTailOffset = file.getFileFromOffset() + this.mappedFileSize; if (fileTailOffset \u0026gt; offset) { if (offset \u0026gt;= file.getFileFromOffset()) { // ...  } else { // 总偏移量 \u0026lt; 文件起始偏移量  // 加入到待删除列表中  file.destroy(1000); willRemoveFiles.add(file); } } } this.deleteExpiredFile(willRemoveFiles); } 五、写入消息 一旦我们获取到 MappedFile 文件之后，我们便可以往这个文件里面写入消息了。写入消息可能会遇见如下两种情况，一种是这条消息可以完全追加到这个文件中，另外一种是这条消息完全不能或者只有一小部分只能存放到这个文件中，其余的需要放到新的文件中。我们对于这两种情况分别讨论:\n(1) 文件可以完全存储消息 MappedFile 类维护了一个用以标识当前写位置的指针 wrotePosition，以及一个用来映射文件到进程地址空间的 mappedByteBuffer:\npublic class MappedFile extends ReferenceResource { protected final AtomicInteger wrotePosition = new AtomicInteger(0); private MappedByteBuffer mappedByteBuffer; } 由这两个数据结构我们可以看出来，单个文件的消息写入过程其实是非常简单的。首先获取到这个文件的写入位置，然后将消息内容追加到 byteBuffer 中，然后再更新写入位置。\npublic class MappedFile extends ReferenceResource { public AppendMessageResult appendMessagesInner(final MessageExt messageExt, final AppendMessageCallback cb) { // ...  int currentPos = this.wrotePosition.get(); if (currentPos \u0026lt; this.fileSize) { ByteBuffer byteBuffer = writeBuffer != null ? writeBuffer.slice() : this.mappedByteBuffer.slice(); // 更新 byteBuffer 位置  byteBuffer.position(currentPos); // 写入消息内容  // ...  // 更新 wrotePosition 指针的位置  this.wrotePosition.addAndGet(result.getWroteBytes()); return result; } } } 示例流程如下所示:\n(2) 文件不可以完全存储消息 在写入消息之前，如果判断出文件已经满了的情况下，其会直接尝试创建一个新的 MappedFile:\npublic class CommitLog { public PutMessageResult putMessage(final MessageExtBrokerInner msg) { // 文件为空 || 文件已经满了  if (null == mappedFile || mappedFile.isFull()) { mappedFile = this.mappedFileQueue.getLastMappedFile(0); } // ...  result = mappedFile.appendMessage(msg, this.appendMessageCallback); } } 如果文件未满，那么在写入之前会先计算出消息体长度 msgLen，然后判断这个文件剩下的空间是否有能力容纳这条消息。在这个地方我们还需要介绍下每条消息的存储方式。\n每条消息的存储是按照一个 4 字节的长度来做界限的，这个长度本身就是整个消息体的长度，当读完这整条消息体的长度之后，下一次再取出来的一个 4 字节的数字，便又是下一条消息的长度:\n围绕着一条消息，还会存储许多其它内容，我们在这里只需要了解前两位是 4 字节的长度和 4 字节的 MAGICCODE 即可:\nMAGICCODE 的可选值有:\n CommitLog.MESSAGE_MAGIC_CODE CommitLog.BLANK_MAGIC_CODE  当这个文件有能力容纳这条消息体的情况下，其便会存储 MESSAGE_MAGIC_CODE 值；当这个文件没有能力容纳这条消息体的情况下，其便会存储 BLANK_MAGIC_CODE 值。所以这个 MAGICCODE 是用来界定这是空消息还是一条正常的消息。\n当判定这个文件不足以容纳整个消息的时候，其将消息体长度设置为这个文件剩余的最大空间长度，将 MAGICCODE 设定为这是一个空消息文件 (需要去下一个文件去读)。由此我们可以看出消息体长度 和 MAGICCODE 是判别一条消息格式的最基本要求，这也是 END_FILE_MIN_BLANK_LENGTH 的值为 8 的原因:\n// CommitLog.java class DefaultAppendMessageCallback implements AppendMessageCallback { // File at the end of the minimum fixed length empty  private static final int END_FILE_MIN_BLANK_LENGTH = 4 + 4; public AppendMessageResult doAppend(final long fileFromOffset, final ByteBuffer byteBuffer, final int maxBlank, final MessageExtBrokerInner msgInner) { // ...  if ((msgLen + END_FILE_MIN_BLANK_LENGTH) \u0026gt; maxBlank) { // ...  // 1 TOTALSIZE  this.msgStoreItemMemory.putInt(maxBlank); // 2 MAGICCODE  this.msgStoreItemMemory.putInt(CommitLog.BLANK_MAGIC_CODE); // 3 The remaining space may be any value  byteBuffer.put(this.msgStoreItemMemory.array(), 0, maxBlank); return new AppendMessageResult(AppendMessageStatus.END_OF_FILE, /** other params **/ ); } } } 由上述方法我们看出在这种情况下返回的结果是 END_OF_FILE。当检测到这种返回结果的时候，CommitLog 接着又会申请创建新的 MappedFile 并尝试写入消息。追加方法同 (1) 相同，不再赘述:\n 注: 在消息文件加载的过程中，其也是通过判断 MAGICCODE 的类型，来判断是否继续读取下一个 MappedFile 来计算整体消息偏移量的。\n 六、消息刷盘策略 当消息体追加到 MappedFile 以后，这条消息实际上还只是存储在内存中，因此还需要将内存中的内容刷到磁盘上才算真正的存储下来，才能确保消息不丢失。一般而言，刷盘有两种策略: 异步刷盘和同步刷盘。\n(1) 异步刷盘 当配置为异步刷盘策略的时候，Broker 会运行一个服务 FlushRealTimeService 用来刷新缓冲区的消息内容到磁盘，这个服务使用一个独立的线程来做刷盘这件事情，默认情况下每隔 500ms 来检查一次是否需要刷盘:\nclass FlushRealTimeService extends FlushCommitLogService { public void run() { // 不停运行  while (!this.isStopped()) { // interval 默认值是 500ms  if (flushCommitLogTimed) { Thread.sleep(interval); } else { this.waitForRunning(interval); } // 刷盘  CommitLog.this.mappedFileQueue.flush(flushPhysicQueueLeastPages); } } } 在追加消息完毕之后，通过唤醒这个服务立即检查以下是否需要刷盘:\npublic class CommitLog { public void handleDiskFlush(AppendMessageResult result, PutMessageResult putMessageResult, MessageExt messageExt) { // Synchronization flush  if (FlushDiskType.SYNC_FLUSH == this.defaultMessageStore.getMessageStoreConfig().getFlushDiskType()) { // ...  } // Asynchronous flush  else { if (!this.defaultMessageStore.getMessageStoreConfig().isTransientStorePoolEnable()) { // 消息追加成功后，立即唤醒服务  flushCommitLogService.wakeup(); } else { // ...  } } } } (2) 同步刷盘 当配置为同步刷盘策略的时候，Broker 运行一个叫做 GroupCommitService 服务。在这个服务内部维护了一个写请求队列和一个读请求队列，其中这两个队列每隔 10ms 就交换一下“身份”，这么做的目的其实也是为了读写分离:\n在这个服务内部，每隔 10ms 就会检查读请求队列是否不为空，如果不为空，则会将读队列中的所有请求执行刷盘，并清空读请求队列:\nclass GroupCommitService extends FlushCommitLogService { private void doCommit() { // 检查所有读队列中的请求  for (GroupCommitRequest req : this.requestsRead) { // 每个请求执行刷盘  CommitLog.this.mappedFileQueue.flush(0); req.wakeupCustomer(flushOK); } this.requestsRead.clear(); } } 在追加消息完毕之后，通过创建一个请求刷盘的对象，然后通过 putRequest() 方法放入写请求队列中，这个时候会立即唤醒这个服务，写队列和读队列的角色会进行交换，交换角色之后，读请求队列就不为空，继而可以执行所有刷盘请求了。而在这期间，Broker 会一直阻塞等待最多 5 秒钟，在这期间如果完不成刷盘请求的话，那么视作刷盘超时:\npublic class CommitLog { public void handleDiskFlush(AppendMessageResult result, PutMessageResult putMessageResult, MessageExt messageExt) { // Synchronization flush  if (FlushDiskType.SYNC_FLUSH == this.defaultMessageStore.getMessageStoreConfig().getFlushDiskType()) { // ...  if (messageExt.isWaitStoreMsgOK()) { GroupCommitRequest request = new GroupCommitRequest(result.getWroteOffset() + result.getWroteBytes()); service.putRequest(request); // 等待刷盘成功  boolean flushOK = request.waitForFlush(this.defaultMessageStore.getMessageStoreConfig().getSyncFlushTimeout()); if (!flushOK) { // 刷盘超时  putMessageResult.setPutMessageStatus(PutMessageStatus.FLUSH_DISK_TIMEOUT); } } else { // ...  } } // Asynchronous flush  else { // ...  } } } 通过方法 putRequest 放入请求后的服务执行流程:\n七、消息刷盘理念 我们在这里已经知道消息刷盘有同步刷盘和异步刷盘策略，对应的是 GroupCommitService 和 FlushRealTimeService 这两种不同的服务。\n这两种服务都有定时请求刷盘的机制，但是机制背后最终调用的刷盘方式全部都集中在 flush 这个方法上:\npublic class MappedFileQueue { public boolean flush(final int flushLeastPages) { // ...  } } 再继续向下分析这个方法之前，我们先对照着这张图说明一下使用 MappedByteBuffer 来简要阐述读和写文件的简单过程：\n操作系统为了能够使多个进程同时使用内存，又保证各个进程访问内存互相独立，于是为每个进程引入了地址空间的概念，地址空间上的地址叫做虚拟地址，而程序想要运行必须放到物理地址上运行才可以。地址空间为进程营造出了一种假象：”整台计算机只有我一个程序在运行，这台计算机内存很大”。一个地址空间内包含着这个进程所需要的全部状态信息。通常一个进程的地址空间会按照逻辑分成好多段，比如代码段、堆段、栈段等。为了进一步有效利用内存，每一段又细分成了不同的页 (page)。与此相对应，计算机的物理内存被切成了页帧 (page frame)，文件被分成了块 (block)。既然程序实际运行的时候还是得依赖物理内存的地址，那么就需要将虚拟地址转换为物理地址，这个映射关系是由**页表 (page table)**来完成的。\n另外在操作系统中，还有一层磁盘缓存 (disk cache)的概念，它主要是用来减少对磁盘的 I/O 操作。磁盘缓存是以页为单位的，内容就是磁盘上的物理块，所以又称之为页缓存 (page cache)。当进程发起一个读操作 （比如，进程发起一个 read() 系统调用），它首先会检查需要的数据是否在页缓存中。如果在，则放弃访问磁盘，而直接从页缓存中读取。如果数据没在缓存中，那么内核必须调度块 I/O 操作从磁盘去读取数据，然后将读来的数据放入页缓存中。系统并不一定要将整个文件都缓存，它可以只存储一个文件的一页或者几页。\n如图所示，当调用 FileChannel.map() 方法的时候，会将这个文件映射进用户空间的地址空间中，注意，建立映射不会拷贝任何数据。我们前面提到过 Broker 启动的时候会有一个消息文件加载的过程，当第一次开始读取数据的时候:\n// 首次读取数据 int totalSize = byteBuffer.getInt(); 这个时候，操作系统通过查询页表，会发现文件的这部分数据还不在内存中。于是就会触发一个缺页异常 (page faults)，这个时候操作系统会开始从磁盘读取这一页数据，然后先放入到页缓存中，然后再放入内存中。在第一次读取文件的时候，操作系统会读入所请求的页面，并读入紧随其后的少数几个页面（不少于一个页面，通常是三个页面），这时的预读称为同步预读 (如下图所示，红色部分是需要读取的页面，蓝色的那三个框是操作系统预先读取的):\n当然随着时间推移，预读命中的话，那么相应的预读页面数量也会增加，但是能够确认的是，一个文件至少有 4 个页面处在页缓存中。当文件一直处于顺序读取的情况下，那么基本上可以保证每次预读命中:\n下面我们来说文件写，正常情况下，当尝试调用 writeInt() 写数据到文件里面的话，其写到页缓存层，这个方法就会返回了。这个时候数据还没有真正的保存到文件中去，Linux 仅仅将页缓存中的这一页数据标记为“脏”，并且被加入到脏页链表中。然后由一群进程（flusher 回写进程）周期性将脏页链表中的页写会到磁盘，从而让磁盘中的数据和内存中保持一致，最后清理“脏”标识。在以下三种情况下，脏页会被写回磁盘:\n 空闲内存低于一个特定阈值 脏页在内存中驻留超过一个特定的阈值时 当用户进程调用 sync() 和 fsync() 系统调用时  可见，在正常情况下，即使不采用刷盘策略，数据最终也是会被同步到磁盘中去的:\n但是，即便有 flusher 线程来定时同步数据，如果此时机器断电的话，消息依然有可能丢失。RocketMQ 为了保证消息尽可能的不丢失，为了最大的高可靠性，做了同步和异步刷盘策略，来手动进行同步:\n八、消息刷盘过程 在介绍完上述消息刷盘背后的一些机制和理念后，我们再来分析刷盘整个过程。首先，无论同步刷盘还是异步刷盘，其线程都在一直周期性的尝试执行刷盘，在真正执行刷盘函数的调用之前，Broker 会检查文件的写位置是否大于 flush 位置，避免执行无意义的刷盘：\n其次，对于异步刷盘来讲，Broker 执行了更为严格的刷盘限制策略，当在某个时间点尝试执行刷盘之后，在接下来 10 秒内，如果想要继续刷盘，那么脏页面数量必须不小于 4 页，如下图所示:\n下面是执行刷盘前最后检查的刷盘条件：\npublic class MappedFile extends ReferenceResource { private boolean isAbleToFlush(final int flushLeastPages) { int flush = this.flushedPosition.get(); int write = getReadPosition(); if (this.isFull()) { return true; } if (flushLeastPages \u0026gt; 0) { // 计算当前脏页面算法  return ((write / OS_PAGE_SIZE) - (flush / OS_PAGE_SIZE)) \u0026gt;= flushLeastPages; } // wrotePosition \u0026gt; flushedPosition  return write \u0026gt; flush; } } 当刷盘完毕之后，首先会更新这个文件的 flush 位置，然后再更新 MappedFileQueue 的整体的 flush 位置:\n当刷盘完毕之后，便会将结果通知给客户端，告知发送消息成功。至此，整个存储过程完毕。\n"});index.add({'id':8,'href':'/docs/rocketmq/rocketmq-message-receive-flow/','title':"RocketMQ 消息接受流程",'content':"RocketMQ 消息接受流程 本篇讲述 RocketMQ 消息接受流程\n一、消费者注册 生产者负责往服务器 Broker 发送消息，消费者则从 Broker 获取消息。消费者获取消息采用的是订阅者模式，即消费者客户端可以任意订阅一个或者多个话题来消费消息:\npublic class Consumer { public static void main(String[] args) throws InterruptedException, MQClientException { /* * 订阅一个或者多个话题 */ consumer.subscribe(\u0026#34;TopicTest\u0026#34;, \u0026#34;*\u0026#34;); } } 当消费者客户端启动以后，其会每隔 30 秒从命名服务器查询一次用户订阅的所有话题路由信息:\npublic class MQClientInstance { private void startScheduledTask() { this.scheduledExecutorService.scheduleAtFixedRate(new Runnable() { @Override public void run() { // 从命名服务器拉取话题信息  MQClientInstance.this.updateTopicRouteInfoFromNameServer(); } }, 10, this.clientConfig.getPollNameServerInterval(), TimeUnit.MILLISECONDS); } } 我们由 RocketMQ 消息发送流程 这篇文章知道 RocketMQ 在发送消息的时候，每条消息会以轮循的方式均衡地分发的不同 Broker 的不同队列中去。由此，消费者客户端从服务器命名服务器获取下来的便是话题的所有消息队列:\n在获取话题路由信息的时候，客户端还会将话题路由信息中的所有 Broker 地址保存到本地:\npublic class MQClientInstance { public boolean updateTopicRouteInfoFromNameServer(final String topic, boolean isDefault, DefaultMQProducer defaultMQProducer) { // ...  if (changed) { TopicRouteData cloneTopicRouteData = topicRouteData.cloneTopicRouteData(); // 更新 Broker 地址列表  for (BrokerData bd : topicRouteData.getBrokerDatas()) { this.brokerAddrTable.put(bd.getBrokerName(), bd.getBrokerAddrs()); } return true; } // ...  } } 当消费者客户端获取到了 Broker 地址列表之后，其便会每隔 30 秒给服务器发送一条心跳数据包，告知所有 Broker 服务器这台消费者客户端的存在。在每次发送心跳包的同时，其数据包内还会捎带这个客户端消息订阅的一些组信息，比如用户订阅了哪几个话题等，与此相对应，每台 Broker 服务器会在内存中维护一份当前所有的消费者客户端列表信息:\npublic class ConsumerManager { private final ConcurrentMap\u0026lt;String/* Group */, ConsumerGroupInfo\u0026gt; consumerTable = new ConcurrentHashMap\u0026lt;String, ConsumerGroupInfo\u0026gt;(1024); } 消费者客户端与 Broker 服务器进行沟通的整体流程如下图所示：\n二、消息队列负载均衡 我们知道无论发送消息还是接受消息都需要指定消息的话题，然而实际上消息在 Broker 服务器上并不是以话题为单位进行存储的，而是采用了比话题更细粒度的队列来进行存储的。当你发送了 10 条相同话题的消息，这 10 条话题可能存储在了不同 Broker 服务器的不同队列中。由此，我们说 RocketMQ 管理消息的单位不是话题，而是队列。\n当我们讨论消息队列负载均衡的时候，就是在讨论服务器端的所有队列如何给所有消费者消费的问题。在 RocketMQ 中，客户端有两种消费模式，一种是广播模式，另外一种是集群模式。\n我们现在假设总共有两台 Broker 服务器，假设用户使用 Producer 已经发送了 8 条消息，这 8 条消息现在均衡的分布在两台 Broker 服务器的 8 个队列中，每个队列中有一个消息。现在有 3 台都订阅了 Test 话题的消费者实例，我们来看在不同消费模式下，不同的消费者会收到哪几条消息。\n(1) 广播模式 广播模式是指所有消息队列中的消息都会广播给所有的消费者客户端，如下图所示，每一个消费者都能收到这 8 条消息:\n(2) 集群模式 集群模式是指所有的消息队列会按照某种分配策略来分给不同的消费者客户端，比如消费者 A 消费前 3 个队列中的消息，消费者 B 消费中间 3 个队列中的消息等等。我们现在着重看 RocketMQ 为我们提供的三个比较重要的消息队列分配策略:\n1. 平均分配策略 平均分配策略下，三个消费者的消费情况如下所示：\n Consumer-1 消费前 3 个消息队列中的消息 Consumer-2 消费中间 3 个消息队列中的消息 Consumer-3 消费最后 2 个消息队列中的消息  2. 平均分配轮循策略 平均分配轮循策略下，三个消费者的消费情况如下所示：\n Consumer-1 消费 1、4、7消息队列中的消息 Consumer-2 消费 2、5、8消息队列中的消息 Consumer-3 消费 3、6消息队列中的消息  3. 一致性哈希策略 一致性哈希算法是根据这三台消费者各自的某个有代表性的属性(我们假设就是客户端ID)来计算出三个 Hash 值，此处为了减少由于 Hash 函数选取的不理想的情况， RocketMQ 算法对于每个消费者通过在客户端ID后面添加 1、2、3 索引来使每一个消费者多生成几个哈希值。那么现在我们需要哈希的就是九个字符串:\n Consumer-1-1 Consumer-1-2 Consumer-1-3 Consumer-2-1 Consumer-2-2 Consumer-2-3 Consumer-3-1 Consumer-3-2 Consumer-3-3  计算完这 9 个哈希值以后，我们按照从小到大的顺序来排列成一个环 (如图所示)。这个时候我们需要一一对这 8 个消息队列也要计算一下 Hash 值，当 Hash 值落在两个圈之间的时候，我们就选取沿着环的方向的那个节点作为这个消息队列的消费者。如下图所示 (注意: 图只是示例，并非真正的消费情况):\n在一致性哈希策略下，三个消费者的消费情况如下所示：\n Consumer-1 消费 1、2、3、4消息队列中的消息 Consumer-2 消费 5、8消息队列中的消息 Consumer-3 消费 6、7消息队列中的消息  消息队列的负载均衡是由一个不停运行的均衡服务来定时执行的:\npublic class RebalanceService extends ServiceThread { // 默认 20 秒一次  private static long waitInterval = Long.parseLong(System.getProperty(\u0026#34;rocketmq.client.rebalance.waitInterval\u0026#34;, \u0026#34;20000\u0026#34;)); @Override public void run() { while (!this.isStopped()) { this.waitForRunning(waitInterval); // 重新执行消息队列的负载均衡  this.mqClientFactory.doRebalance(); } } } 接着往下看，会知道在广播模式下，当前这台消费者消费和话题相关的所有消息队列，而集群模式会先按照某种分配策略来进行消息队列的分配，得到的结果就是当前这台消费者需要消费的消息队列:\npublic abstract class RebalanceImpl { private void rebalanceByTopic(final String topic, final boolean isOrder) { switch (messageModel) { // 广播模式  case BROADCASTING: { // 消费这个话题的所有消息队列  Set\u0026lt;MessageQueue\u0026gt; mqSet = this.topicSubscribeInfoTable.get(topic); if (mqSet != null) { // ...  } break; } // 集群模式  case CLUSTERING: { // ...  // 按照某种负载均衡策略进行消息队列和消费客户端之间的分配  // allocateResult 就是当前这台消费者被分配到的消息队列  allocateResult = strategy.allocate( this.consumerGroup, this.mQClientFactory.getClientId(), mqAll, cidAll); // ...  } break; } } } 三、Broker 消费队列文件 现在我们再来看 Broker 服务器端。首先我们应该知道，消息往 Broker 存储就是在向 CommitLog 消息文件中写入数据的一个过程。在 Broker 启动过程中，其会启动一个叫做 ReputMessageService 的服务，这个服务每隔 1 秒会检查一下这个 CommitLog 是否有新的数据写入。ReputMessageService 自身维护了一个偏移量 reputFromOffset，用以对比和 CommitLog 文件中的消息总偏移量的差距。当这两个偏移量不同的时候，就代表有新的消息到来了:\nclass ReputMessageService extends ServiceThread { private volatile long reputFromOffset = 0; private boolean isCommitLogAvailable() { // 看当前有没有新的消息到来  return this.reputFromOffset \u0026lt; DefaultMessageStore.this.commitLog.getMaxOffset(); } @Override public void run() { while (!this.isStopped()) { try { Thread.sleep(1); this.doReput(); } catch (Exception e) { DefaultMessageStore.log.warn(this.getServiceName() + \u0026#34; service has exception. \u0026#34;, e); } } } } 在有新的消息到来之后，doReput() 函数会取出新到来的所有消息，每一条消息都会封装为一个 DispatchRequest 请求，进而将这条请求分发给不同的请求消费者，我们在这篇文章中只会关注利用消息创建消费队列的服务 CommitLogDispatcherBuildConsumeQueue:\nclass ReputMessageService extends ServiceThread { // ... 部分代码有删减  private void doReput() { SelectMappedBufferResult result = DefaultMessageStore.this.commitLog.getData(reputFromOffset); if (result != null) { this.reputFromOffset = result.getStartOffset(); for (int readSize = 0; readSize \u0026lt; result.getSize() \u0026amp;\u0026amp; doNext; ) { // 读取一条消息，然后封装为 DispatchRequest  DispatchRequest dispatchRequest = DefaultMessageStore.this.commitLog.checkMessageAndReturnSize(result.getByteBuffer(), false, false); int size = dispatchRequest.getMsgSize(); if (dispatchRequest.isSuccess()) { // 分发这个 DispatchRequest 请求  DefaultMessageStore.this.doDispatch(dispatchRequest); this.reputFromOffset += size; readSize += size; } // ...  } } } } CommitLogDispatcherBuildConsumeQueue 服务会根据这条请求按照不同的队列 ID 创建不同的消费队列文件，并在内存中维护一份消费队列列表。然后将 DispatchRequest 请求中这条消息的消息偏移量、消息大小以及消息在发送时候附带的标签的 Hash 值写入到相应的消费队列文件中去。\n消费队列文件的创建与消息存储 CommitLog 文件的创建过程是一致的，只是路径不同，这里不再赘述。\n寻找消费队列的代码如下:\npublic class DefaultMessageStore implements MessageStore { private final ConcurrentMap\u0026lt;String/* topic */, ConcurrentMap\u0026lt;Integer/* queueId */, ConsumeQueue\u0026gt;\u0026gt; consumeQueueTable; public void putMessagePositionInfo(DispatchRequest dispatchRequest) { ConsumeQueue cq = this.findConsumeQueue(dispatchRequest.getTopic(), dispatchRequest.getQueueId()); cq.putMessagePositionInfoWrapper(dispatchRequest); } } 向消费队列文件中存储数据的代码如下:\npublic class ConsumeQueue { private boolean putMessagePositionInfo(final long offset, final int size, final long tagsCode, final long cqOffset) { // 存储偏移量、大小、标签码  this.byteBufferIndex.flip(); this.byteBufferIndex.limit(CQ_STORE_UNIT_SIZE); this.byteBufferIndex.putLong(offset); this.byteBufferIndex.putInt(size); this.byteBufferIndex.putLong(tagsCode); // 获取消费队列文件  final long expectLogicOffset = cqOffset * CQ_STORE_UNIT_SIZE; MappedFile mappedFile = this.mappedFileQueue.getLastMappedFile(expectLogicOffset); if (mappedFile != null) { // ...  return mappedFile.appendMessage(this.byteBufferIndex.array()); } return false; } } 以上阐述了消费队列创建并存储消息的一个过程，但是消费队列文件中的消息是需要持久化到磁盘中去的。持久化的过程是通过后台服务 FlushConsumeQueueService 来定时持久化的:\nclass FlushConsumeQueueService extends ServiceThread { private void doFlush(int retryTimes) { // ...  ConcurrentMap\u0026lt;String, ConcurrentMap\u0026lt;Integer, ConsumeQueue\u0026gt;\u0026gt; tables = DefaultMessageStore.this.consumeQueueTable; for (ConcurrentMap\u0026lt;Integer, ConsumeQueue\u0026gt; maps : tables.values()) { for (ConsumeQueue cq : maps.values()) { boolean result = false; for (int i = 0; i \u0026lt; retryTimes \u0026amp;\u0026amp; !result; i++) { // 刷新到磁盘  result = cq.flush(flushConsumeQueueLeastPages); } } } // ...  } } 上述过程体现在磁盘文件的变化如下图所示，commitLog 文件夹下面存放的是完整的消息，来一条消息，向文件中追加一条消息。同时，根据这一条消息属于 TopicTest 话题下的哪一个队列，又会往相应的 consumequeue 文件下的相应消费队列文件中追加消息的偏移量、消息大小和标签码:\n总流程图如下所示:\n四、消息队列偏移量 Broker 服务器存储了各个消费队列，客户端需要消费每个消费队列中的消息。消费模式的不同，每个客户端所消费的消息队列也不同。那么客户端如何记录自己所消费的队列消费到哪里了呢？答案就是消费队列偏移量。\n针对同一话题，在集群模式下，由于每个客户端所消费的消息队列不同，所以每个消息队列已经消费到哪里的消费偏移量是记录在 Broker 服务器端的。而在广播模式下，由于每个客户端分配消费这个话题的所有消息队列，所以每个消息队列已经消费到哪里的消费偏移量是记录在客户端本地的。\n下面分别讲述两种模式下偏移量是如何获取和更新的:\n(1) 集群模式 在集群模式下，消费者客户端在内存中维护了一个 offsetTable 表:\npublic class RemoteBrokerOffsetStore implements OffsetStore { private ConcurrentMap\u0026lt;MessageQueue, AtomicLong\u0026gt; offsetTable = new ConcurrentHashMap\u0026lt;MessageQueue, AtomicLong\u0026gt;(); } 同样在 Broker 服务器端也维护了一个偏移量表:\npublic class ConsumerOffsetManager extends ConfigManager { private ConcurrentMap\u0026lt;String/* topic@group */, ConcurrentMap\u0026lt;Integer, Long\u0026gt;\u0026gt; offsetTable = new ConcurrentHashMap\u0026lt;String, ConcurrentMap\u0026lt;Integer, Long\u0026gt;\u0026gt;(512); } 在消费者客户端，RebalanceService 服务会定时地 (默认 20 秒) 从 Broker 服务器获取当前客户端所需要消费的消息队列，并与当前消费者客户端的消费队列进行对比，看是否有变化。对于每个消费队列，会从 Broker 服务器查询这个队列当前的消费偏移量。然后根据这几个消费队列，创建对应的拉取请求 PullRequest 准备从 Broker 服务器拉取消息，如下图所示:\n当从 Broker 服务器拉取下来消息以后，只有当用户成功消费的时候，才会更新本地的偏移量表。本地的偏移量表再通过定时服务每隔 5 秒同步到 Broker 服务器端:\npublic class MQClientInstance { private void startScheduledTask() { this.scheduledExecutorService.scheduleAtFixedRate(new Runnable() { @Override public void run() { MQClientInstance.this.persistAllConsumerOffset(); } }, 1000 * 10, this.clientConfig.getPersistConsumerOffsetInterval(), TimeUnit.MILLISECONDS); } } 而维护在 Broker 服务器端的偏移量表也会每隔 5 秒钟序列化到磁盘中:\npublic class BrokerController { public boolean initialize() throws CloneNotSupportedException { this.scheduledExecutorService.scheduleAtFixedRate(new Runnable() { @Override public void run() { BrokerController.this.consumerOffsetManager.persist(); } }, 1000 * 10, this.brokerConfig.getFlushConsumerOffsetInterval(), TimeUnit.MILLISECONDS); } } 保存的格式如下所示：\n上述整体流程如下所示，红框框住的是这个话题下面的队列的 ID，箭头指向的分别是每个队列的消费偏移量：\n(2) 广播模式 对于广播模式而言，每个消费队列的偏移量肯定不能存储在 Broker 服务器端，因为多个消费者对于同一个队列的消费可能不一致，偏移量会互相覆盖掉。因此，在广播模式下，每个客户端的消费偏移量是存储在本地的，然后每隔 5 秒将内存中的 offsetTable 持久化到磁盘中。当首次从服务器获取可消费队列的时候，偏移量不像集群模式下是从 Broker 服务器读取的，而是直接从本地文件中读取的:\npublic class LocalFileOffsetStore implements OffsetStore { @Override public long readOffset(final MessageQueue mq, final ReadOffsetType type) { if (mq != null) { switch (type) { case READ_FROM_STORE: { // 本地读取  offsetSerializeWrapper = this.readLocalOffset(); // ...  } } } // ...  } } 当消息消费成功后，偏移量的更新也是持久化到本地，而非更新到 Broker 服务器中。这里提一下，在广播模式下，消息队列的偏移量默认放在用户目录下的 .rocketmq_offsets 目录下:\npublic class LocalFileOffsetStore implements OffsetStore { @Override public void persistAll(Set\u0026lt;MessageQueue\u0026gt; mqs) { // ...  String jsonString = offsetSerializeWrapper.toJson(true); MixAll.string2File(jsonString, this.storePath); // ...  } } 存储格式如下：\n简要流程图如下：\n五、拉取消息 在客户端运行着一个专门用来拉取消息的后台服务 PullMessageService，其接受每个队列创建 PullRequest 拉取消息请求，然后拉取消息:\npublic class PullMessageService extends ServiceThread { @Override public void run() { while (!this.isStopped()) { PullRequest pullRequest = this.pullRequestQueue.take(); if (pullRequest != null) { this.pullMessage(pullRequest); } } } } 每一个 PullRequest 都关联着一个 MessageQueue 和一个 ProcessQueue，在 ProcessQueue 的内部还维护了一个用来等待用户消费的消息树，如下代码所示:\npublic class PullRequest { private MessageQueue messageQueue; private ProcessQueue processQueue; } public class ProcessQueue { private final TreeMap\u0026lt;Long, MessageExt\u0026gt; msgTreeMap = new TreeMap\u0026lt;Long, MessageExt\u0026gt;(); } 当真正尝试拉取消息之前，其会检查当前请求的内部缓存的消息数量、消息大小、消息阈值跨度是否超过了某个阈值，如果超过某个阈值，则推迟 50 毫秒重新执行这个请求:\npublic class DefaultMQPushConsumerImpl implements MQConsumerInner { public void pullMessage(final PullRequest pullRequest) { // ...  final ProcessQueue processQueue = pullRequest.getProcessQueue(); long cachedMessageCount = processQueue.getMsgCount().get(); long cachedMessageSizeInMiB = processQueue.getMsgSize().get() / (1024 * 1024); // 缓存消息数量阈值，默认为 1000  if (cachedMessageCount \u0026gt; this.defaultMQPushConsumer.getPullThresholdForQueue()) { this.executePullRequestLater(pullRequest, PULL_TIME_DELAY_MILLS_WHEN_FLOW_CONTROL); return; } // 缓存消息大小阈值，默认为 100 MB  if (cachedMessageSizeInMiB \u0026gt; this.defaultMQPushConsumer.getPullThresholdSizeForQueue()) { this.executePullRequestLater(pullRequest, PULL_TIME_DELAY_MILLS_WHEN_FLOW_CONTROL); return; } if (!this.consumeOrderly) { // 最小偏移量和最大偏移量的阈值跨度，默认为 2000 偏移量，消费速度不能太慢  if (processQueue.getMaxSpan() \u0026gt; this.defaultMQPushConsumer.getConsumeConcurrentlyMaxSpan()) { this.executePullRequestLater(pullRequest, PULL_TIME_DELAY_MILLS_WHEN_FLOW_CONTROL); return; } } // ...  } } 当执行完一些必要的检查之后，客户端会将用户指定的过滤信息以及一些其它必要消费字段封装到请求信息体中，然后才开始从 Broker 服务器拉取这个请求从当前偏移量开始的消息，默认一次性最多拉取 32 条，服务器返回的响应会告诉客户端这个队列下次开始拉取时的偏移量。客户端每次都会注册一个 PullCallback 回调，用以接受服务器返回的响应信息，根据响应信息的不同状态信息，然后修正这个请求的偏移量，并进行下次请求:\npublic void pullMessage(final PullRequest pullRequest) { PullCallback pullCallback = new PullCallback() { @Override public void onSuccess(PullResult pullResult) { if (pullResult != null) { // ...  switch (pullResult.getPullStatus()) { case FOUND: // ...  break; case NO_NEW_MSG: // ...  break; case NO_MATCHED_MSG: // ...  break; case OFFSET_ILLEGAL: // ...  break; default: break; } } } @Override public void onException(Throwable e) { // ...  } }; } 上述是客户端拉取消息时的一些机制，现在再说一下 Broker 服务器端与此相对应的逻辑。\n服务器在收到客户端的请求之后，会根据话题和队列 ID 定位到对应的消费队列。然后根据这条请求传入的 offset 消费队列偏移量，定位到对应的消费队列文件。偏移量指定的是消费队列文件的消费下限，而最大上限是由如下算法来进行约束的:\nfinal int maxFilterMessageCount = Math.max(16000, maxMsgNums * ConsumeQueue.CQ_STORE_UNIT_SIZE); 有了上限和下限，客户端便会开始从消费队列文件中取出每个消息的偏移量和消息大小，然后再根据这两个值去 CommitLog 文件中寻找相应的完整的消息，并添加到最后的消息队列中，精简过的代码如下所示：\npublic class DefaultMessageStore implements MessageStore { public GetMessageResult getMessage(final String group, final String topic, final int queueId, final long offset, final int maxMsgNums, final MessageFilter messageFilter) { // ...  ConsumeQueue consumeQueue = findConsumeQueue(topic, queueId); if (consumeQueue != null) { // 首先根据消费队列的偏移量定位消费队列  SelectMappedBufferResult bufferConsumeQueue = consumeQueue.getIndexBuffer(offset); if (bufferConsumeQueue != null) { try { status = GetMessageStatus.NO_MATCHED_MESSAGE; // 最大消息长度  final int maxFilterMessageCount = Math.max(16000, maxMsgNums * ConsumeQueue.CQ_STORE_UNIT_SIZE); // 取消息  for (; i \u0026lt; bufferConsumeQueue.getSize() \u0026amp;\u0026amp; i \u0026lt; maxFilterMessageCount; i += ConsumeQueue.CQ_STORE_UNIT_SIZE) { long offsetPy = bufferConsumeQueue.getByteBuffer().getLong(); int sizePy = bufferConsumeQueue.getByteBuffer().getInt(); // 根据消息的偏移量和消息的大小从 CommitLog 文件中取出一条消息  SelectMappedBufferResult selectResult = this.commitLog.getMessage(offsetPy, sizePy); getResult.addMessage(selectResult); status = GetMessageStatus.FOUND; } // 增加下次开始的偏移量  nextBeginOffset = offset + (i / ConsumeQueue.CQ_STORE_UNIT_SIZE); } finally { bufferConsumeQueue.release(); } } } // ...  } } 客户端和 Broker 服务器端完整拉取消息的流程图如下所示：\n六、消费消息 依赖于用户指定的消息回调函数的不同，消息的消费分为两种: 并发消费和有序消费。\n并发消费没有考虑消息发送的顺序，客户端从服务器获取到消息就会直接回调给用户。而有序消费会考虑每个队列消息发送的顺序，注意此处并不是每个话题消息发送的顺序，一定要记住 RocketMQ 控制消息的最细粒度是消息队列。当我们讲有序消费的时候，就是在说对于某个话题的某个队列，发往这个队列的消息，客户端接受消息的顺序与发送的顺序完全一致。\n下面我们分别看这两种消费模式是如何实现的。\n(1) 并发消费 当用户注册消息回调类的时候，如果注册的是 MessageListenerConcurrently 回调类，那么就认为用户不关心消息的顺序问题。我们在上文提到过每个 PullRequest 都关联了一个处理队列 ProcessQueue，而每个处理队列又都关联了一颗消息树 msgTreeMap。当客户端拉取到新的消息以后，其先将消息放入到这个请求所关联的处理队列的消息树中，然后提交一个消息消费请求，用以回调用户端的代码消费消息:\npublic class DefaultMQPushConsumerImpl implements MQConsumerInner { public void pullMessage(final PullRequest pullRequest) { PullCallback pullCallback = new PullCallback() { @Override public void onSuccess(PullResult pullResult) { if (pullResult != null) { switch (pullResult.getPullStatus()) { case FOUND: // 消息放入处理队列的消息树中  boolean dispathToConsume = processQueue .putMessage(pullResult.getMsgFoundList()); // 提交一个消息消费请求  DefaultMQPushConsumerImpl.this .consumeMessageService .submitConsumeRequest( pullResult.getMsgFoundList(), processQueue, pullRequest.getMessageQueue(), dispathToConsume); break; } } } }; } } 当提交一个消息消费请求后，对于并发消费，其实现如下:\npublic class ConsumeMessageConcurrentlyService implements ConsumeMessageService { class ConsumeRequest implements Runnable { @Override public void run() { // ...  status = listener.consumeMessage(Collections.unmodifiableList(msgs), context); // ...  } } } 我们可以看到 msgs 是直接从服务器端拿到的最新消息，直接喂给了客户端进行消费，并未做任何有序处理。当消费成功后，会从消息树中将这些消息再给删除掉:\npublic class ConsumeMessageConcurrentlyService implements ConsumeMessageService { public void processConsumeResult(final ConsumeConcurrentlyStatus status, /** 其它参数 **/) { // 从消息树中删除消息  long offset = consumeRequest.getProcessQueue().removeMessage(consumeRequest.getMsgs()); if (offset \u0026gt;= 0 \u0026amp;\u0026amp; !consumeRequest.getProcessQueue().isDropped()) { this.defaultMQPushConsumerImpl.getOffsetStore() .updateOffset(consumeRequest.getMessageQueue(), offset, true); } } } (2) 有序消费 RocketMQ 的有序消费主要依靠两把锁，一把是维护在 Broker 端，一把维护在消费者客户端。Broker 端有一个 RebalanceLockManager 服务，其内部维护了一个 mqLockTable 消息队列锁表:\npublic class RebalanceLockManager { private final ConcurrentMap\u0026lt;String/* group */, ConcurrentHashMap\u0026lt;MessageQueue, LockEntry\u0026gt;\u0026gt; mqLockTable = new ConcurrentHashMap\u0026lt;String, ConcurrentHashMap\u0026lt;MessageQueue, LockEntry\u0026gt;\u0026gt;(1024); } 在有序消费的时候，Broker 需要确保任何一个队列在任何时候都只有一个客户端在消费它，都在被一个客户端所锁定。当客户端在本地根据消息队列构建 PullRequest 之前，会与 Broker 沟通尝试锁定这个队列，另外当进行有序消费的时候，客户端也会周期性地 (默认是 20 秒) 锁定所有当前需要消费的消息队列:\npublic class ConsumeMessageOrderlyService implements ConsumeMessageService { public void start() { if (MessageModel.CLUSTERING.equals(ConsumeMessageOrderlyService.this.defaultMQPushConsumerImpl.messageModel())) { this.scheduledExecutorService.scheduleAtFixedRate(new Runnable() { @Override public void run() { ConsumeMessageOrderlyService.this.lockMQPeriodically(); } }, 1000 * 1, ProcessQueue.REBALANCE_LOCK_INTERVAL, TimeUnit.MILLISECONDS); } } } 由上述这段代码也能看出，只在集群模式下才会周期性地锁定 Broker 端的消息队列，因此在广播模式下是不支持进行有序消费的。\n而在 Broker 这端，每个客户端所锁定的消息队列对应的锁项 LogEntry 有一个上次锁定时的时间戳，当超过锁的超时时间 (默认是 60 秒) 后，也会判定这个客户端已经不再持有这把锁，以让其他客户端能够有序消费这个队列。\n在前面我们说到过 RebalanceService 均衡服务会定时地依据不同消费者数量分配消费队列。我们假设 Consumer-1 消费者客户端一开始需要消费 3 个消费队列，这个时候又加入了 Consumer-2 消费者客户端，并且分配到了 MessageQueue-2 消费队列。当 Consumer-1 内部的均衡服务检测到当前消费队列需要移除 MessageQueue-2 队列，这个时候，会首先解除 Broker 端的锁，确保新加入的 Consumer-2 消费者客户端能够成功锁住这个队列，以进行有序消费。\npublic abstract class RebalanceImpl { private boolean updateProcessQueueTableInRebalance(final String topic, final Set\u0026lt;MessageQueue\u0026gt; mqSet, final boolean isOrder) { while (it.hasNext()) { // ...  if (mq.getTopic().equals(topic)) { // 当前客户端不需要处理这个消息队列了  if (!mqSet.contains(mq)) { pq.setDropped(true); // 解锁  if (this.removeUnnecessaryMessageQueue(mq, pq)) { // ...  } } // ...  } } } } 消费者客户端每一次拉取消息请求，如果有发现新的消息，那么都会将这些消息封装为 ConsumeRequest 来喂给消费线程池，以待消费。如果消息特别多，这样一个队列可能有多个消费请求正在等待客户端消费，用户可能会先消费偏移量大的消息，后消费偏移量小的消息。所以消费同一队列的时候，需要一把锁以消费请求顺序化:\npublic class ConsumeMessageOrderlyService implements ConsumeMessageService { class ConsumeRequest implements Runnable { @Override public void run() { final Object objLock = messageQueueLock.fetchLockObject(this.messageQueue); synchronized (objLock) { // ...  } } } } RocketMQ 的消息树是用 TreeMap 实现的，其内部基于消息偏移量维护了消息的有序性。每次消费请求都会从消息树中拿取偏移量最小的几条消息 (默认为 1 条)给用户，以此来达到有序消费的目的:\npublic class ConsumeMessageOrderlyService implements ConsumeMessageService { class ConsumeRequest implements Runnable { @Override public void run() { // ...  final int consumeBatchSize = ConsumeMessageOrderlyService.this .defaultMQPushConsumer .getConsumeMessageBatchMaxSize(); List\u0026lt;MessageExt\u0026gt; msgs = this.processQueue.takeMessags(consumeBatchSize); } } } "});index.add({'id':9,'href':'/docs/tomcat/','title':"Tomcat 源码分析",'content':""});index.add({'id':10,'href':'/docs/books/','title':"书籍",'content':"书籍  书籍是人类进步的阶梯。\u0026ndash; 高尔基\n "});index.add({'id':11,'href':'/docs/rocketmq/rocketmq-message-filter-flow/','title':"RocketMQ 消息过滤流程",'content':"RocketMQ 消息过滤流程 讲述 RocketMQ 消息过滤流程\n一、消息过滤类型 Producer 在发送消息的时候可以指定消息的标签类型，还可以为每一个消息添加一个或者多个额外的属性:\n// 指定标签 Message msg = new Message(\u0026#34;TopicTest\u0026#34;, \u0026#34;TagA\u0026#34;, (\u0026#34;Hello RocketMQ\u0026#34;).getBytes(RemotingHelper.DEFAULT_CHARSET)); // 添加属性 a msg.putUserProperty(\u0026#34;a\u0026#34;, 5); 根据标签和属性的不同，RocketMQ 客户端在消费消息的时候有三种消息过滤类型:\n(1) 标签匹配 consumer.subscribe(\u0026#34;TopicTest\u0026#34;, \u0026#34;TagA | TagB | TagC\u0026#34;); (2) SQL 匹配 consumer.subscribe(\u0026#34;TopicTest\u0026#34;, MessageSelector.bySql( \u0026#34;(TAGS is not null and TAGS in (\u0026#39;TagA\u0026#39;, \u0026#39;TagB\u0026#39;))\u0026#34; + \u0026#34;and (a is not null and a between 0 3)\u0026#34;)); (3) 自定义匹配 客户端实现 MessageFilter 类，自定义过滤逻辑:\nClassLoader classLoader = Thread.currentThread().getContextClassLoader(); File classFile = new File(classLoader.getResource(\u0026#34;MessageFilterImpl.java\u0026#34;).getFile()); String filterCode = MixAll.file2String(classFile); consumer.subscribe(\u0026#34;TopicTest\u0026#34;, \u0026#34;org.apache.rocketmq.example.filter.MessageFilterImpl\u0026#34;,filterCode); 对于 MessageFilter 类实现 match 方法即可:\npublic class MessageFilterImpl implements MessageFilter { @Override public boolean match(MessageExt msg, FilterContext context) { String property = msg.getProperty(\u0026#34;SequenceId\u0026#34;); if (property != null) { int id = Integer.parseInt(property); if (((id % 10) == 0) \u0026amp;\u0026amp; (id \u0026gt; 100)) { return true; } } return false; } } 下面我们一一讲解各自背后的机制与实现原理。\n二、标签匹配 当为消息指定消息标签类型的时候，实际上所指定的标签例如 TagA 是作为一个属性放入到了这条消息中的:\npublic class Message implements Serializable { public void setTags(String tags) { this.putProperty(MessageConst.PROPERTY_TAGS, tags); } } 当这条消息到达 Broker 服务器端后，用户设置的标签会计算为标签码，默认的计算方式采用的标签字符串的 hashCode() 作为计算结果的:\npublic class CommitLog { public DispatchRequest checkMessageAndReturnSize(java.nio.ByteBuffer byteBuffer, final boolean checkCRC, final boolean readBody) { // ...  String tags = propertiesMap.get(MessageConst.PROPERTY_TAGS); if (tags != null \u0026amp;\u0026amp; tags.length() \u0026gt; 0) { tagsCode = MessageExtBrokerInner .tagsString2tagsCode(MessageExt.parseTopicFilterType(sysFlag), tags); } // ...  } } 当计算出来标签码之后，这条消息的标签码会被存放至消费队列文件中，用来与消费者客户端消费队列的标签码进行匹配。消费者客户端订阅消费话题的时候，会指定想要匹配的标签类型:\nconsumer.subscribe(\u0026#34;TopicTest\u0026#34;, \u0026#34;TagA | TagB | TagC\u0026#34;); 这段代码在内部实现中利用 FilterAPI 构建了一个 SubscriptionData 对象:\npublic class DefaultMQPushConsumerImpl implements MQConsumerInner { public void subscribe(String topic, String subExpression) throws MQClientException { SubscriptionData subscriptionData = FilterAPI .buildSubscriptionData(this.defaultMQPushConsumer.getConsumerGroup(), topic, subExpression); // ...  } } 当用户未指定标签或者指定为星号标签的时候，则代表用户接受所有标签的消息。如果用户指定了一个或者多个标签，那么会将每一个标签取其 hashCode() 放入到 codeSet 中。SubscriptionData 还有一个 expressionType 字段，在使用标签匹配的时候，其不会设置这个这个字段的值，因此其保留为 null。在这些信息设置好以后，当客户端发送心跳包的时候，会将这些话题的注册信息一并上传至 Broker 服务器端，方便在 Broker 端进行匹配。\npublic class SubscriptionData implements Comparable\u0026lt;SubscriptionData\u0026gt; { public final static String SUB_ALL = \u0026#34;*\u0026#34;; private Set\u0026lt;String\u0026gt; tagsSet = new HashSet\u0026lt;String\u0026gt;(); private Set\u0026lt;Integer\u0026gt; codeSet = new HashSet\u0026lt;Integer\u0026gt;(); private String expressionType; } 当 Broker 端服务器在取消息的时候，每取出来一条消息，都会执行两道过滤机制:\n ConsumeQueue 文件匹配 CommitLog 文件匹配  任一检查没有通过后，绝不会放行这条消息给客户端:\npublic class DefaultMessageStore implements MessageStore { public GetMessageResult getMessage(final String group, /** 其他参数 **/) { for (; i \u0026lt; bufferConsumeQueue.getSize() \u0026amp;\u0026amp; i \u0026lt; maxFilterMessageCount; i += ConsumeQueue.CQ_STORE_UNIT_SIZE) { // ConsumeQueue 文件匹配  if (messageFilter != null \u0026amp;\u0026amp; !messageFilter.isMatchedByConsumeQueue(isTagsCodeLegal ? tagsCode : null, extRet ? cqExtUnit : null)) { if (getResult.getBufferTotalSize() == 0) { status = GetMessageStatus.NO_MATCHED_MESSAGE; } continue; } // CommitLog 文件匹配  if (messageFilter != null \u0026amp;\u0026amp; !messageFilter.isMatchedByCommitLog(selectResult.getByteBuffer().slice(), null)) { if (getResult.getBufferTotalSize() == 0) { status = GetMessageStatus.NO_MATCHED_MESSAGE; } // release...  selectResult.release(); continue; } } } } 消息过滤器的默认实现是 ExpressionMessageFilter ，消息过滤的默认实现策略就是看这个话题的标签码集合中是否包括当前这条消息的标签码:\npublic class ExpressionMessageFilter implements MessageFilter { @Override public boolean isMatchedByConsumeQueue(Long tagsCode, ConsumeQueueExt.CqExtUnit cqExtUnit) { // ...  if (ExpressionType.isTagType(subscriptionData.getExpressionType())) { if (tagsCode == null) { return true; } if (subscriptionData.getSubString().equals(SubscriptionData.SUB_ALL)) { return true; } return subscriptionData.getCodeSet().contains(tagsCode.intValue()); } // ...  return true; } @Override public boolean isMatchedByCommitLog(ByteBuffer msgBuffer, Map\u0026lt;String, String\u0026gt; properties) { if (ExpressionType.isTagType(subscriptionData.getExpressionType())) { return true; } // ...  } } 下图是一幅标签匹配的简要流程图:\n三、SQL 匹配 在发送消息的时候，可以为每一条消息附带一个或者多个属性值，SQL 匹配指的就是依据这些属性值和 TAG 标签 是否满足一定的 SQL 语句条件，来过滤消息。用户如果想要开启 SQL 匹配，那么需要在 Broker 启动的时候，启用如下几个配置信息:\nbrokerConfig.setEnablePropertyFilter(true); brokerConfig.setEnableCalcFilterBitMap(true); messageStoreConfig.setEnableConsumeQueueExt(true); (1) 注册过滤信息 我们在消费者如何接受消息一文中提到过，消费者启动之后，会通过心跳包定时给 Broker 服务器汇报自己的信息。而 Broker 服务器在收到消费者的心跳包之后，会产生一个注册事件，如下所示:\npublic class ConsumerManager { public boolean registerConsumer(final String group, /** 其他参数 **/) { // ...  this.consumerIdsChangeListener.handle(ConsumerGroupEvent.REGISTER, group, subList); // ...  } } DefaultConsumerIdsChangeListener 是默认的消费者列表注册事件通知器的实现类，其在收到注册事件以后，会将用户在消费者端订阅的话题信息注册到 ConsumerFilterManager 中:\npublic class DefaultConsumerIdsChangeListener implements ConsumerIdsChangeListener { @Override public void handle(ConsumerGroupEvent event, String group, Object... args) { switch (event) { case REGISTER: Collection\u0026lt;SubscriptionData\u0026gt; subscriptionDataList = (Collection\u0026lt;SubscriptionData\u0026gt;) args[0]; this.brokerController.getConsumerFilterManager().register(group, subscriptionDataList); break; // ...  } } } ConsumerFilterData 中包含了消费者客户端注册的 SQL 表达式，由上图我们可以看到对于每一个话题所对应的 FilterDataMapByTopic ，可以注册多个 SQL 表达式。但是这里需要注意的是，这多个 SQL 表达式是按照组来做区分的，就是说一个组只能有一个 SQL 表达式，客户端如果在一个组中注册了多个不同的 SQL 表达式，那么后注册的会覆盖掉前注册的。因此，如果想要对同一个组使用不同的 SQL 语句来过滤自己想要的信息，这些不同的 SQL 语句必须划分到不同的组里面才可行。\n(2) 生成 BloomFilterData 布隆过滤器 (BloomFilter) 是一种空间效率很高的数据结构，其可以用来判断某个元素是否可能存在于某个集合中。当判断结果返回 true 的时候，表示可能存在，当返回 false 的时候，表示这个元素一定不存在于这个集合中。\n它的原理是当一个元素被加入集合时，通过 k 个 Hash 函数将这个元素映射成一个长度为 m 位数组（Bit array）中的 k 个点，把它们置为 1。检索时，我们只要看看这些点是不是都是 1 就（大约）知道集合中有没有它了：\n 如果这些点有任何一个 0，则被检索元素一定不在。 如果都是 1， 则被检索元素很可能在。  如下是一个采用位数组长度为 m=18 以及哈希函数个数为 k=3 实现的布隆过滤器，”x,y,z” 每一个字母都需要经过 3 次哈希函数的计算，然后映射到 3 个不同的槽中。由于字母 “w” 在经过 3 次哈希函数计算后，其中一次产生的哈希值并未命中已有的槽，因此可以确定的是 “w” 肯定不存在于这个集合中。\n在 RocketMQ 的实现中，其有四个最关键的值:\npublic class BloomFilter { // 最大错误率  private int f; // 可能插入 n 个元素  private int n; // k 个哈希函数  private int k; // 数组总共 m 位  private int m; } RocketMQ 实现的布隆过滤器是根据错误率 f 和可能插入的元素数量 n 计算出来的 k 和 m，在默认配置情况下，即如下 n = 32 和 f = 20，计算出来需要 k = 3 个哈希函数和 m = 112 位的数组。\npublic class BrokerConfig { // Expect num of consumers will use filter.  private int expectConsumerNumUseFilter = 32; // Error rate of bloom filter, 1~100.  private int maxErrorRateOfBloomFilter = 20; } 我们这里大致了解以下布隆过滤器的一个基本想法即可，具体算法比较复杂，也不在讨论范畴以内。当客户端注册过滤信息的时候，其会根据 “组#话题” 这个字符串计算出相应的位映射数据，也即这个字符串经过布隆过滤器中的若干个哈希函数得到的几个不同的哈希值:\npublic class ConsumerFilterManager extends ConfigManager { public boolean register(final String topic, /** 其它参数 **/) { // ...  BloomFilterData bloomFilterData = bloomFilter.generate(consumerGroup + \u0026#34;#\u0026#34; + topic); // ...  } } ConsumerFilterManager 中的话题过滤信息数据，每隔 10 秒进行一次磁盘持久化:\npublic class BrokerController { public boolean initialize() throws CloneNotSupportedException { this.scheduledExecutorService.scheduleAtFixedRate(new Runnable() { @Override public void run() { BrokerController.this.consumerFilterManager.persist(); } }, 1000 * 10, 1000 * 10, TimeUnit.MILLISECONDS); } } 磁盘文件 consumerFilter.json 中保存的数据信息如下示例:\n上述大致流程图如下所示：\n(3) 编译 SQL 语句 JavaCC (Java Compiler Compiler) 是一个能生成语法和词法分析器的生成程序，它通过阅读一个自定义的语法标准文件 (通常以 jj 为后缀名) ，然后就能生成能够解析该语法的扫描器和解析器的代码。\n通过执行 javacc SelectorParser.jj 命令以后，其会生成如下七个 Java 文件，用以解析 SQL 语法:\n过滤器工厂 FilterFactory 在初次使用的时候，会注册一个 SqlFilter 类，这个类能够将消费者端指定的 SQL 语句编译解析为 Expression 表达式对象，方便后续消息的快速匹配与过滤。\npublic class SqlFilter implements FilterSpi { @Override public Expression compile(final String expr) throws MQFilterException { return SelectorParser.parse(expr); } } (4) 计算位映射 当 Broker 服务器接收到新的消息到来之后，一直在后台运行的 ReputMessageService 会负责将这条消息封装为一个 DispatchRequest 分发请求，这个请求会传递给提前构建好的分发请求链。在 DefaultMessageStore 的构造函数中，我们看到依次添加了构建消费队列和构建索引的分发请求服务:\npublic class DefaultMessageStore implements MessageStore { public DefaultMessageStore(final MessageStoreConfig messageStoreConfig, /** 其它参数 **/) throws IOException { this.dispatcherList = new LinkedList\u0026lt;\u0026gt;(); this.dispatcherList.addLast(new CommitLogDispatcherBuildConsumeQueue()); this.dispatcherList.addLast(new CommitLogDispatcherBuildIndex()); } } 而在 Broker 初始化的时候，我们看到其又添加了计算位映射的分发请求服务，并且将此分发服务放在链表的第一个位置:\npublic class BrokerController { public boolean initialize() throws CloneNotSupportedException { this.messageStore.getDispatcherList() .addFirst(new CommitLogDispatcherCalcBitMap(this.brokerConfig, this.consumerFilterManager)); } } 由此，在每次收到新的消息之后，分发请求的需要经过如下三个分发请求服务进行处理:\n我们在这部分只介绍计算位映射的服务类实现。如下，dispatch 方法用来分发请求里面的消息，对于这每一条消息，首先根据话题取得所有的消费过滤数据。这每一条数据代表的就是一条 SQL 过滤语句信息。我们在这个地方，需要一一遍历这些过滤信息，从而完成计算位服务的需求:\npublic class CommitLogDispatcherCalcBitMap implements CommitLogDispatcher { @Override public void dispatch(DispatchRequest request) { Collection\u0026lt;ConsumerFilterData\u0026gt; filterDatas = consumerFilterManager.get(request.getTopic()); Iterator\u0026lt;ConsumerFilterData\u0026gt; iterator = filterDatas.iterator(); while (iterator.hasNext()) { ConsumerFilterData filterData = iterator.next(); // ...  } } } 在拿到 ConsumerFilterData 信息之后，其会根据这条信息内的 SQL 语句编译后的表达式来对这条消息进行检查匹配 (evaluate)，看这条消息是否满足 SQL 语句所设置的条件。如果满足，那么会将先前在客户端注册阶段计算好的 BloomFilterData 中的映射位信息设置到 filterBitMap 中，即将相应的位数组 BitsArray 中的相应位设置为 1 。在验证完所有的 SQL 语句之后，会将这些所有的字节数组放置到 request 请求之中，以便交由下一个请求分发服务进行使用:\n@Override public void dispatch(DispatchRequest request) { BitsArray filterBitMap = BitsArray.create(this.consumerFilterManager.getBloomFilter().getM()); while (iterator.hasNext()) { ConsumerFilterData filterData = iterator.next(); MessageEvaluationContext context = new MessageEvaluationContext(request.getPropertiesMap()); Object ret = filterData.getCompiledExpression().evaluate(context); // eval true  if (ret != null \u0026amp;\u0026amp; ret instanceof Boolean \u0026amp;\u0026amp; (Boolean) ret) { consumerFilterManager .getBloomFilter() .hashTo(filterData.getBloomFilterData(), filterBitMap); } } request.setBitMap(filterBitMap.bytes()); } (5) 存储位映射 MessageStore 在开启扩展消费队列的配置之后，每一个消费队列在创建的时候，都会额外创建一个扩展消费队列。每一个扩展消费队列文件的大小默认为 48MB:\npublic class ConsumeQueue { public ConsumeQueue(final String topic, /** 其它参数 **/) { // ...  if (defaultMessageStore.getMessageStoreConfig().isEnableConsumeQueueExt()) { this.consumeQueueExt = new ConsumeQueueExt(topic, /** 其它参数 **/); } } } 在计算位映射一节中，计算好位字节数组之后，我们这里需要通过第二个分发请求服务 CommitLogDispatcherBuildConsumeQueue 来存储这些字节信息。通过如下代码，我们知道它将请求中的位映射信息、消息存储时间、标签码这三条信息封装为 ConsumeQueueExt.CqExtUnit ，然后放入到扩展消费队列文件中。\npublic class ConsumeQueue { public void putMessagePositionInfoWrapper(DispatchRequest request) { long tagsCode = request.getTagsCode(); if (isExtWriteEnable()) { ConsumeQueueExt.CqExtUnit cqExtUnit = new ConsumeQueueExt.CqExtUnit(); cqExtUnit.setFilterBitMap(request.getBitMap()); cqExtUnit.setMsgStoreTime(request.getStoreTimestamp()); cqExtUnit.setTagsCode(request.getTagsCode()); long extAddr = this.consumeQueueExt.put(cqExtUnit); if (isExtAddr(extAddr)) { tagsCode = extAddr; } } } } 我们注意到在上述代码中，put 函数返回的是一个 long 类型的扩展地址，当这个数值满足 isExtAddr 要求后，其会将当前的标签码设置为刚才返回的扩展地址。那么这是为什么呢?\n我们首先来看 ConsumeQueueExt 文件在存放数据成功后是如何返回信息的:\npublic class ConsumeQueueExt { public static final long MAX_ADDR = Integer.MIN_VALUE - 1L; public long put(final CqExtUnit cqExtUnit) { if (mappedFile.appendMessage(cqExtUnit.write(this.tempContainer), 0, size)) { return decorate(wrotePosition + mappedFile.getFileFromOffset()); } return 1; } public long decorate(final long offset) { if (!isExtAddr(offset)) { return offset + Long.MIN_VALUE; } return offset; } public static boolean isExtAddr(final long address) { return address \u0026lt;= MAX_ADDR; } } MAX_ADDR 是一个很小很小的值，为 -2147483649， 即写入位置如果不小于这个值，那么我们就认定为它不是扩展地址。需要将修正后的 写入偏移量 + Long.MIN_VALUE 确定为扩展地址。当读取信息的时候，其先读取 ConsumeQueue 文件中的最后的 Hash 标签码值，如果其通过 isExtAddr() 函数返回的是 true，那么我们就可以使用这个地址，再通过一个叫做 unDecorate() 函数将其修正为正确的 ConsumeQueueExt 文件的写入地址，从而接着读取想要的信息:\npublic long unDecorate(final long address) { if (isExtAddr(address)) { return address - Long.MIN_VALUE; } return address; } 这个地方，我们发现 ConsumeQueue 中的最后一个 long 型数值，可能存储的是标签 Hash 码，也可能存储的是扩展消费队列的写入地址，所以需要通过 isExtAddr() 来分情况判断。\n下图为 ConsumeQueue 文件和 ConsumeQueueExt 文件中存取信息的不同:\n(6) 消息过滤 在上小节我们提到了有关扩展消费队列地址和标签 Hash 码存储的不同，所以当在取消息的时候，先得从消费队列文件中取出 tagsCode，然后检查是否是扩展消费队列地址，如果是，那么就需要从扩展消费队列文件中读取正确的标签 Hash 码，如下代码所示：\npublic class DefaultMessageStore implements MessageStore { public GetMessageResult getMessage(final String group, /** 其它参数 **/) { ConsumeQueueExt.CqExtUnit cqExtUnit = new ConsumeQueueExt.CqExtUnit(); for (; i \u0026lt; bufferConsumeQueue.getSize() \u0026amp;\u0026amp; i \u0026lt; maxFilterMessageCount; i += ConsumeQueue.CQ_STORE_UNIT_SIZE) { long tagsCode = bufferConsumeQueue.getByteBuffer().getLong(); boolean extRet = false, isTagsCodeLegal = true; if (consumeQueue.isExtAddr(tagsCode)) { extRet = consumeQueue.getExt(tagsCode, cqExtUnit); if (extRet) { tagsCode = cqExtUnit.getTagsCode(); } else { isTagsCodeLegal = false; } } } } } 当获取到这条消息在扩展消费队列文件中存取的信息后，就会和标签匹配一节所讲述的一致，会进行两道过滤机制。我们先来看第一道 ConsumeQueue 文件匹配:\npublic class ExpressionMessageFilter implements MessageFilter { @Override public boolean isMatchedByConsumeQueue(Long tagsCode, ConsumeQueueExt.CqExtUnit cqExtUnit) { byte[] filterBitMap = cqExtUnit.getFilterBitMap(); BloomFilter bloomFilter = this.consumerFilterManager.getBloomFilter(); BitsArray bitsArray = BitsArray.create(filterBitMap); return bloomFilter.isHit(consumerFilterData.getBloomFilterData(), bitsArray); } } ExpressionMessageFilter 依据 CqExtUnit 中存储的位数组重新创建了比特数组 bitsArray，这个数组信息中已经存储了不同 SQL 表达式是否匹配这条消息的结果。isHit() 函数会一一检查 BloomFilterData 中存储的位信息是否映射在 BitsArray 中。只要有任何一位没有映射，那么就可以立刻判断出这条消息肯定不符合 SQL 语句的条件。\n因为布隆过滤器有一定的错误率，其只能精确的判断消息是否一定不在集合中，返回成功的只能确定为消息可能在集合中。因此通过布隆过滤器检查后还需要经过第二道过滤机制，即 SQL 编译后的表达式亲自验证是否匹配:\npublic class ExpressionMessageFilter implements MessageFilter { @Override public boolean isMatchedByCommitLog(ByteBuffer msgBuffer, Map\u0026lt;String, String\u0026gt; properties) { MessageEvaluationContext context = new MessageEvaluationContext(tempProperties); Object ret = realFilterData.getCompiledExpression().evaluate(context); if (ret == null || !(ret instanceof Boolean)) { return false; } return (Boolean) ret; } } 通过在验证 SQL 表达式是否满足之前，提前验证是否命中布隆过滤器，可以有效的避免许多不必要的验证:\n四、自定义匹配 消息的自定义匹配需要开启过滤服务器、上传过滤类、过滤服务器委托过滤消息等步骤，下面我们一一进行说明。\n(1) 过滤服务器 在启动 Broker 服务器的时候，如果指定了下面一行设置:\nbrokerConfig.setFilterServerNums(int filterServerNums); 即将过滤服务器的数量设定为大于 0，那么 Broker 服务器在启动的时候，将会启动 filterServerNums 个过滤服务器。过滤服务器是通过调用 shell 命令的方式，启用独立进程进行启动的。\npublic class FilterServerManager { public void createFilterServer() { int more = this.brokerController.getBrokerConfig().getFilterServerNums() - this.filterServerTable.size(); String cmd = this.buildStartCommand(); for (int i = 0; i \u0026lt; more; i++) { FilterServerUtil.callShell(cmd, log); } } } 过滤服务器在初始化的时候，会启动定时器每隔 10 秒注册一次到 Broker 服务器:\npublic class FiltersrvController { public boolean initialize() { this.scheduledExecutorService.scheduleAtFixedRate(new Runnable() { @Override public void run() { FiltersrvController.this.registerFilterServerToBroker(); } }, 3, 10, TimeUnit.SECONDS); } } Broker 服务器在收到来自过滤服务器的注册信息之后，会把过滤服务器的地址信息、注册时间等放到过滤服务器表中:\npublic class FilterServerManager { private final ConcurrentMap\u0026lt;Channel, FilterServerInfo\u0026gt; filterServerTable = new ConcurrentHashMap\u0026lt;Channel, FilterServerInfo\u0026gt;(16); } 同样，Broker 服务器也需要定时将过滤服务器地址信息同步给所有 Namesrv 命名服务器，上述整个流程如下图所示:\n(2) 过滤类 当消费者通过使用自定义匹配过滤消息的时候，这个时候会将存储订阅信息的 SubscriptionData 中的 filterClassSource 设置为 true，以表征这个客户端需要过滤类来进行消息的匹配和过滤。\n消费者客户端在启动过程中，还会定时地上传本地的过滤类源码到过滤服务器:\npublic class MQClientInstance { private void startScheduledTask() { this.scheduledExecutorService.scheduleAtFixedRate(new Runnable() { @Override public void run() { MQClientInstance.this.sendHeartbeatToAllBrokerWithLock(); } }, 1000, this.clientConfig.getHeartbeatBrokerInterval(), TimeUnit.MILLISECONDS); } public void sendHeartbeatToAllBrokerWithLock() { // ...  this.uploadFilterClassSource(); } } 其中过滤服务器的地址列表是在从 Namesrv 服务器获取话题路由信息的时候取得的，话题路由信息不光存储了消息队列数据，还存储了各个 Broker 所关联的过滤服务器列表:\npublic class TopicRouteData extends RemotingSerializable { // ...  private HashMap\u0026lt;String/* brokerAddr */, List\u0026lt;String\u0026gt;/* Filter Server */\u0026gt; filterServerTable; } 当过滤服务器接收到来自消费者客户端的源码之后，其会首先首先生成一个键为 话题@组 的字符串来查阅过滤类信息是否已经存在于内存里面的 filterClassTable 表中且文件通过 CRC 校验。如果没有存在或校验失败，那么就需要先编译并加载这个类:\npublic class DynaCode { public void compileAndLoadClass() throws Exception { String[] sourceFiles = this.uploadSrcFile(); this.compile(sourceFiles); this.loadClass(this.loadClass.keySet()); } } 默认情况下，编译后的类存放于 $HOME/rocketmq_filter_class/$PID 目录下，类的源文件和类的字节码文件名也会相应的加上当前时间戳来确定:\n上述流程图如下:\n(3) 过滤消息 当消费者客户端启用自定义匹配过滤消息后，发往服务器的数据中也包含了过滤标志位，这样每次拉取消息的服务器也由原来的 Broker 服务器变更为 Filtersrv 过滤服务器，其中过滤服务器地址的选择是随机确定的:\npublic class PullAPIWrapper { public PullResult pullKernelImpl(final MessageQueue mq, /** 其它参数 **/) throws Exception { // ...  if (findBrokerResult != null) { if (PullSysFlag.hasClassFilterFlag(sysFlagInner)) { // 从过滤服务器拉取消息  brokerAddr = computPullFromWhichFilterServer(mq.getTopic(), brokerAddr); } // ...  } } } 过滤服务器在启动的时候，内部还启动了一个 PullConsumer 客户端，用以从 Broker 服务器拉取消息:\npublic class FiltersrvController { private final DefaultMQPullConsumer defaultMQPullConsumer = new DefaultMQPullConsumer(MixAll.FILTERSRV_CONSUMER_GROUP); public void start() throws Exception { this.defaultMQPullConsumer.start(); // ...  } } 当过滤服务器收到真正的消费者发来的消费消息的请求之后，其会委托内部的 PullConsumer 使用包含在请求体内的偏移量去 Broker 服务器拉取所有消息，此时这些消息是完全没有过滤的：\npublic class DefaultRequestProcessor implements NettyRequestProcessor { private RemotingCommand pullMessageForward(final ChannelHandlerContext ctx, final RemotingCommand request) throws Exception { MessageQueue mq = new MessageQueue(); mq.setTopic(requestHeader.getTopic()); mq.setQueueId(requestHeader.getQueueId()); mq.setBrokerName(this.filtersrvController.getBrokerName()); // 设置偏移量和最大数量  long offset = requestHeader.getQueueOffset(); int maxNums = requestHeader.getMaxMsgNums(); // 委托内部消费者从 Broker 服务器拉取消息  pullConsumer.pullBlockIfNotFound(mq, null, offset, maxNums, pullCallback); } } 过滤服务器从 Broker 服务器获取到完整的消息列表之后，会遍历消息列表，然后使用过滤类一一进行匹配，最终将匹配成功的消息列表返回给客户端:\npublic class DefaultRequestProcessor implements NettyRequestProcessor { private RemotingCommand pullMessageForward(final ChannelHandlerContext ctx, final RemotingCommand request) throws Exception { final PullCallback pullCallback = new PullCallback() { @Override public void onSuccess(PullResult pullResult) { switch (pullResult.getPullStatus()) { case FOUND: List\u0026lt;MessageExt\u0026gt; msgListOK = new ArrayList\u0026lt;MessageExt\u0026gt;(); for (MessageExt msg : pullResult.getMsgFoundList()) { // 使用过滤类过滤消息  boolean match = findFilterClass.getMessageFilter().match(msg, filterContext); if (match) { msgListOK.add(msg); } } break; // ...  } } }; // ...  } } 上述流程如下图所示:\n"});index.add({'id':12,'href':'/docs/rocketmq/rocketmq-message-indexing-flow/','title':"RocketMQ 消息索引流程",'content':"RocketMQ 消息索引流程 讲述 RocketMQ 消息索引服务\n一、消息查询方式 对于 Producer 发送到 Broker 服务器的消息，RocketMQ 支持多种方式来方便地查询消息:\n(1) 根据键查询消息 如下所示，在构建消息的时候，指定了这条消息的键为 “OrderID001”:\nMessage msg = new Message(\u0026#34;TopicTest\u0026#34;, \u0026#34;TagA\u0026#34;, \u0026#34;OrderID001\u0026#34;, // Keys  \u0026#34;Hello world\u0026#34;.getBytes(RemotingHelper.DEFAULT_CHARSET)); 那么，当这条消息发送成功后，我们可以使用 queryMsgByKey 命令查询到这条消息的详细信息:\nMQAdminStartup.main(new String[] { \u0026#34;queryMsgByKey\u0026#34;, \u0026#34;-n\u0026#34;, \u0026#34;localhost:9876\u0026#34;, \u0026#34;-t\u0026#34;, \u0026#34;TopicTest\u0026#34;, \u0026#34;-k\u0026#34;, \u0026#34;OrderID001\u0026#34; }); (2) 根据ID(偏移量)查询消息 消息在发送成功之后，其返回的 SendResult 类中包含了这条消息的唯一偏移量 ID (注意此处指的是 offsetMsgId):\n用户可以使用 queryMsgById 命令查询这条消息的详细信息:\nMQAdminStartup.main(new String[] { \u0026#34;queryMsgById\u0026#34;, \u0026#34;-n\u0026#34;, \u0026#34;localhost:9876\u0026#34;, \u0026#34;-i\u0026#34;, \u0026#34;0A6C73D900002A9F0000000000004010\u0026#34; }); (3) 根据唯一键查询消息 消息在发送成功之后，其返回的 SendResult 类中包含了这条消息的唯一 ID:\n用户可以使用 queryMsgByUniqueKey 命令查询这条消息的详细信息:\nMQAdminStartup.main(new String[] { \u0026#34;queryMsgByUniqueKey\u0026#34;, \u0026#34;-n\u0026#34;, \u0026#34;localhost:9876\u0026#34;, \u0026#34;-i\u0026#34;, \u0026#34;0A6C73D939B318B4AAC20CBA5D920000\u0026#34;, \u0026#34;-t\u0026#34;, \u0026#34;TopicTest\u0026#34; }); (4) 根据消息队列偏移量查询消息 消息发送成功之后的 SendResult 中还包含了消息队列的其它信息，如消息队列 ID、消息队列偏移量等信息:\nSendResult [sendStatus=SEND_OK, msgId=0A6C73D93EC518B4AAC20CC4ACD90000, offsetMsgId=0A6C73D900002A9F000000000000484E, messageQueue=MessageQueue [topic=TopicTest, brokerName=zk-pc, queueId=3], queueOffset=24] 根据这些信息，使用 queryMsgByOffset 命令也可以查询到这条消息的详细信息:\nMQAdminStartup.main(new String[] { \u0026#34;queryMsgByOffset\u0026#34;, \u0026#34;-n\u0026#34;, \u0026#34;localhost:9876\u0026#34;, \u0026#34;-t\u0026#34;, \u0026#34;TopicTest\u0026#34;, \u0026#34;-b\u0026#34;, \u0026#34;zk-pc\u0026#34;, \u0026#34;-i\u0026#34;, \u0026#34;3\u0026#34;, \u0026#34;-o\u0026#34;, \u0026#34;24\u0026#34; }); 二、ID (偏移量) 查询 (1) 生成 ID ID (偏移量) 是在消息发送到 Broker 服务器存储的时候生成的，其包含如下几个字段：\n Broker 服务器 IP 地址 Broker 服务器端口号 消息文件 CommitLog 写偏移量  public class CommitLog { class DefaultAppendMessageCallback implements AppendMessageCallback { public AppendMessageResult doAppend(final long fileFromOffset, /** 其它参数 **/) { String msgId = MessageDecoder .createMessageId(this.msgIdMemory, msgInner.getStoreHostBytes(hostHolder), wroteOffset); // ...  } } } (2) 使用 ID 查询 Admin 端查询的时候，首先对 msgId 进行解析，取出 Broker 服务器的 IP 、端口号和消息偏移量:\npublic class MessageDecoder { public static MessageId decodeMessageId(final String msgId) throws UnknownHostException { byte[] ip = UtilAll.string2bytes(msgId.substring(0, 8)); byte[] port = UtilAll.string2bytes(msgId.substring(8, 16)); // offset  byte[] data = UtilAll.string2bytes(msgId.substring(16, 32)); // ...  } } 获取到偏移量之后，Admin 会对 Broker 服务器发送一个 VIEW_MESSAGE_BY_ID 的请求命令，Broker 服务器在收到请求后，会依据偏移量定位到 CommitLog 文件中的相应位置,然后取出消息，返回给 Admin 端:\npublic class DefaultMessageStore implements MessageStore { @Override public SelectMappedBufferResult selectOneMessageByOffset(long commitLogOffset) { SelectMappedBufferResult sbr = this.commitLog .getMessage(commitLogOffset, 4); // 1 TOTALSIZE  int size = sbr.getByteBuffer().getInt(); return this.commitLog.getMessage(commitLogOffset, size); } } 三、消息队列偏移量查询 根据队列偏移量查询是最简单的一种查询方式，Admin 会启动一个 PullConsumer ，然后利用用户传递给 Admin 的队列 ID、队列偏移量等信息，从服务器拉取一条消息过来:\npublic class QueryMsgByOffsetSubCommand implements SubCommand { @Override public void execute(CommandLine commandLine, Options options, RPCHook rpcHook) throws SubCommandException { // 根据参数构建 MessageQueue  MessageQueue mq = new MessageQueue(); mq.setTopic(topic); mq.setBrokerName(brokerName); mq.setQueueId(Integer.parseInt(queueId)); // 从 Broker 服务器拉取消息  PullResult pullResult = defaultMQPullConsumer.pull(mq, \u0026#34;*\u0026#34;, Long.parseLong(offset), 1); } } 四、消息索引服务 在继续讲解剩下两种查询方式之前，我们必须先介绍以下 Broker 端的消息索引服务。\n在之前提到过，每当一条消息发送过来之后，其会封装为一个 DispatchRequest 来下发给各个转发服务，而 CommitLogDispatcherBuildIndex 构建索引服务便是其中之一:\nclass CommitLogDispatcherBuildIndex implements CommitLogDispatcher { @Override public void dispatch(DispatchRequest request) { if (DefaultMessageStore.this.messageStoreConfig.isMessageIndexEnable()) { DefaultMessageStore.this.indexService.buildIndex(request); } } } (1) 索引文件结构 消息的索引信息是存放在磁盘上的，文件以时间戳命名的，默认存放在 $HOME/store/index 目录下。由下图来看，一个索引文件的结构被分成了三部分:\n 前 40 个字节存放固定的索引头信息，包含了存放在这个索引文件中的消息的最小/大存储时间、最小/大偏移量等状况 中间一段存储了 500 万个哈希槽位，每个槽内部存储的是索引文件的地址 (索引槽) 最后一段存储了 2000 万个索引内容信息，是实际的索引信息存储的地方。每一个槽位存储了这条消息的键哈希值、存储偏移量、存储时间戳与下一个索引槽地址  RocketMQ 在内存中还维护了一个索引文件列表，对于每一个索引文件，前一个文件的最大存储时间是下一个文件的最小存储时间，前一个文件的最大偏移量是下一个文件的最大偏移量。每一个索引文件都索引了在某个时间段内、某个偏移量段内的所有消息，当文件满了，就会用前一个文件的最大偏移量和最大存储时间作为起始值，创建下一个索引文件:\n(2) 添加消息 当有新的消息过来后，构建索引服务会取出这条消息的键，然后对字符串 “话题#键” 构建索引。构建索引的步骤如下:\n 找出哈希槽: 生成字符串哈希码，取余落到 500W 个槽位之一，并取出其中的值，默认为 0 找出索引槽: IndexHeader 维护了 indexCount，实际存储的索引槽就是直接依次顺延添加的 存储索引内容: 找到索引槽后，放入键哈希值、存储偏移量、存储时间戳与下一个索引槽地址。下一个索引槽地址就是第一步哈希槽中取出的值，0 代表这个槽位是第一次被索引，而不为 0 代表这个槽位之前的索引槽地址。由此，通过索引槽地址可以将相同哈希槽的消息串联起来，像单链表那样。 更新哈希槽: 更新原有哈希槽中存储的值  我们以实际例子来说明。假设我们需要依次为键的哈希值为 “{16,29,29,8,16,16}” 这几条消息构建索引，我们在这个地方忽略了索引信息中存储的存储时间和偏移量字段，只是存储键哈希和下一索引槽信息，那么:\n 放入 16: 将 “16|0” 存储在第 1 个索引槽中，并更新哈希槽为 16 的值为 1，即哈希槽为 16 的第一个索引块的地址为 1 放入 29: 将 “29|0” 存储在第 2 个索引槽中，并更新哈希槽为 29 的值为 2，即哈希槽为 29 的第一个索引块的地址为 2 放入 29: 取出哈希槽为 29 中的值 2，然后将 “29|2” 存储在第 3 个索引槽中，并更新哈希槽为 29 的值为 3，即哈希槽为 29 的第一个索引块的地址为 3。而在找到索引块为 3 的索引信息后，又能取出上一个索引块的地址 2，构成链表为： “[29]-\u0026gt;3-\u0026gt;2” 放入 8: 将 “8|0” 存储在第 4 个索引槽中，并更新哈希槽为 8 的值为 4，即哈希槽为 8 的第一个索引块的地址为 4 放入 16: 取出哈希槽为 16 中的值 1，然后将 “16|1” 存储在第 5 个索引槽中，并更新哈希槽为 16 的值为 5。构成链表为: “[16]-\u0026gt;5-\u0026gt;1” 放入 16: 取出哈希槽为 16 中的值 5，然后将 “16|5” 存储在第 6 个索引槽中，并更新哈希槽为 16 的值为 6。构成链表为: “[16]-\u0026gt;6-\u0026gt;5-\u0026gt;1”  整个过程如下图所示:\n(3) 查询消息 当需要根据键来查询消息的时候，其会按照倒序回溯整个索引文件列表，对于每一个在时间上能够匹配用户传入的 begin 和 end 时间戳参数的索引文件，会一一进行消息查询：\npublic class IndexService { public QueryOffsetResult queryOffset(String topic, String key, int maxNum, long begin, long end) { // 倒序  for (int i = this.indexFileList.size(); i \u0026gt; 0; i--) { // 位于时间段内  if (f.isTimeMatched(begin, end)) { // 消息查询  } } } } 而具体到每一个索引文件，其查询匹配消息的过程如下所示:\n 确定哈希槽: 根据键生成哈希值，定位到哈希槽 定位索引槽: 哈希槽中的值存储的就是链表的第一个索引槽地址 遍历索引槽: 沿着索引槽地址，依次取出下一个索引槽地址，即沿着链表遍历，直至遇见下一个索引槽地址为非法地址 0 停止 收集偏移量: 在遇到匹配的消息之后，会将相应的物理偏移量放到列表中，最后根据物理偏移量，从 CommitLog 文件中取出消息  public class DefaultMessageStore implements MessageStore { @Override public QueryMessageResult queryMessage(String topic, String key, int maxNum, long begin, long end) { for (int m = 0; m \u0026lt; queryOffsetResult.getPhyOffsets().size(); m++) { long offset = queryOffsetResult.getPhyOffsets().get(m); // 根据偏移量从 CommitLog 文件中取出消息  } } } 以查询哈希值 16 的消息为例，图示如下:\n五、唯一键查询消息 (1) 构建键 消息的唯一键是在客户端发送消息前构建的:\npublic class DefaultMQProducerImpl implements MQProducerInner { private SendResult sendKernelImpl(final Message msg, /** 其它参数 **/) throws XXXException { // ...  if (!(msg instanceof MessageBatch)) { MessageClientIDSetter.setUniqID(msg); } } } 创建唯一 ID 的算法:\npublic class MessageClientIDSetter { public static String createUniqID() { StringBuilder sb = new StringBuilder(LEN * 2); sb.append(FIX_STRING); sb.append(UtilAll.bytes2string(createUniqIDBuffer())); return sb.toString(); } } 唯一键是根据客户端的进程 ID、IP 地址、ClassLoader 哈希码、时间戳、计数器这几个值来生成的一个唯一的键，然后作为这条消息的附属属性发送到 Broker 服务器的:\npublic class MessageClientIDSetter { public static void setUniqID(final Message msg) { if (msg.getProperty(MessageConst.PROPERTY_UNIQ_CLIENT_MESSAGE_ID_KEYIDX) == null) { msg.putProperty(MessageConst.PROPERTY_UNIQ_CLIENT_MESSAGE_ID_KEYIDX, createUniqID()); } } } (2) 索引键 当服务器收到客户端发送过来的消息之后，索引服务便会取出客户端生成的 uniqKey 并为之建立索引，放入到索引文件中:\npublic class IndexService { public void buildIndex(DispatchRequest req) { // ...  if (req.getUniqKey() != null) { indexFile = putKey(indexFile, msg, buildKey(topic, req.getUniqKey())); } // ...  } } (3) 使用键查询 客户端在生成消息唯一键的时候，在 ByteBuffer 的第 11 位到第 14 位放置的是当前的时间与当月第一天的时间的毫秒差:\npublic class MessageClientIDSetter { private static byte[] createUniqIDBuffer() { long current = System.currentTimeMillis(); if (current \u0026gt;= nextStartTime) { setStartTime(current); } // 时间差 [当前时间 - 这个月 1 号的时间]  // putInt 占据的是第 11 位到第 14 位  buffer.putInt((int) (System.currentTimeMillis() - startTime)); } private synchronized static void setStartTime(long millis) { Calendar cal = Calendar.getInstance(); cal.setTimeInMillis(millis); cal.set(Calendar.DAY_OF_MONTH, 1); cal.set(Calendar.HOUR_OF_DAY, 0); cal.set(Calendar.MINUTE, 0); cal.set(Calendar.SECOND, 0); cal.set(Calendar.MILLISECOND, 0); // 开始时间设置为这个月的 1 号  startTime = cal.getTimeInMillis(); // ...  } } 我们知道消息索引服务的查询需要用户传入 begin 和 end 这连个时间值，以进行这段时间内的匹配。所以 RocketMQ 为了加速消息的查询，于是在 Admin 端对特定 ID 进行查询的时候，首先取出了这段时间差值，然后与当月时间进行相加得到 begin 时间值:\npublic class MessageClientIDSetter { public static Date getNearlyTimeFromID(String msgID) { ByteBuffer buf = ByteBuffer.allocate(8); byte[] bytes = UtilAll.string2bytes(msgID); buf.put((byte) 0); buf.put((byte) 0); buf.put((byte) 0); buf.put((byte) 0); // 取出第 11 位到 14 位  buf.put(bytes, 10, 4); buf.position(0); // 得到时间差值  long spanMS = buf.getLong(); Calendar cal = Calendar.getInstance(); long now = cal.getTimeInMillis(); cal.set(Calendar.DAY_OF_MONTH, 1); cal.set(Calendar.HOUR_OF_DAY, 0); cal.set(Calendar.MINUTE, 0); cal.set(Calendar.SECOND, 0); cal.set(Calendar.MILLISECOND, 0); long monStartTime = cal.getTimeInMillis(); if (monStartTime + spanMS \u0026gt;= now) { cal.add(Calendar.MONTH, -1); monStartTime = cal.getTimeInMillis(); } // 设置为这个月(或者上个月) + 时间差值  cal.setTimeInMillis(monStartTime + spanMS); return cal.getTime(); } } 由于发送消息的客户端和查询消息的 Admin 端可能不在一台服务器上，而且从函数的命名 getNearlyTimeFromID 与上述实现来看，Admin 端的时间戳得到的是一个近似起始值，它尽可能地加速用户的查询。而且太旧的消息(超过一个月的消息)是查询不到的。\n当 begin 时间戳确定以后，Admin 便会将其它必要的信息如话题、Key等信息封装到 QUERY_MESSAGE 的包中，然后向 Broker 服务器传递这个请求，来进行消息的查询。Broker 服务器在获取到这个查询消息的请求后，便会根据 Key 从索引文件中查询符合的消息，最终返回到 Admin 端。\n六、键查询消息 (1) 构建键 我们提到过，在发送消息的时候，可以填充一个 keys 的值，这个值将会作为消息的一个属性被发送到 Broker 服务器上:\npublic class Message implements Serializable { public void setKeys(String keys) { this.putProperty(MessageConst.PROPERTY_KEYS, keys); } } (2) 索引键 当服务器收到客户端发送过来的消息之后，索引服务便会取出这条消息的 keys 并将其用空格进行分割，分割后的每一个字符串都会作为一个单独的键，创建索引，放入到索引文件中:\npublic class IndexService { public void buildIndex(DispatchRequest req) { // ...  if (keys != null \u0026amp;\u0026amp; keys.length() \u0026gt; 0) { // 使用空格进行分割  String[] keyset = keys.split(MessageConst.KEY_SEPARATOR); for (int i = 0; i \u0026lt; keyset.length; i++) { String key = keyset[i]; if (key.length() \u0026gt; 0) { indexFile = putKey(indexFile, msg, buildKey(topic, key)); } } } } } 由此我们也可以得知，keys 键的设置通过使用空格分割字符串，一条消息可以指定多个键。\n(3) 使用键查询 keys 键查询的方式也是通过将参数封装为 QUERY_MESSAGE 请求包中去请求服务器返回相应的信息。由于键本身不能和时间戳相关联，因此 begin 值设置的是 0，这是和第五节的不同之处:\npublic class QueryMsgByKeySubCommand implements SubCommand { private void queryByKey(final DefaultMQAdminExt admin, final String topic, final String key) throws MQClientException, InterruptedException { // begin: 0  // end: Long.MAX_VALUE  QueryResult queryResult = admin.queryMessage(topic, key, 64, 0, Long.MAX_VALUE); } } "});index.add({'id':13,'href':'/docs/rocketmq/rocketmq-timing-message-and-retry-message/','title':"RocketMQ 定时消息和重试消息",'content':"RocketMQ 定时消息和重试消息 讲述 RocketMQ 定时消息和重试消息\n一、定时消息概述 RocketMQ 支持 Producer 端发送定时消息，即该消息被发送之后，到一段时间之后才能被 Consumer 消费者端消费。但是当前开源版本的 RocketMQ 所支持的定时时间是有限的、不同级别的精度的时间，并不是任意无限制的定时时间。因此在每条消息上设置定时时间的 API 叫做 setDelayTimeLevel，而非 setDelayTime 这样的命名:\nMessage msg = new Message(\u0026#34;TopicTest\u0026#34; /* Topic */, \u0026#34;TagA\u0026#34; /* Tag */, (\u0026#34;Hello RocketMQ \u0026#34; + i).getBytes(RemotingHelper.DEFAULT_CHARSET) /* Message body */); msg.setDelayTimeLevel(i + 1); 默认 Broker 服务器端有 18 个定时级别:\npublic class MessageStoreConfig { private String messageDelayLevel = \u0026#34;1s 5s 10s 30s 1m 2m 3m 4m 5m 6m 7m 8m 9m 10m 20m 30m 1h 2h\u0026#34;; } 这 18 个定时级别在服务器端启动的时候，会被解析并放置到表 delayLevelTable 中。解析的过程就是上述字符串按照空格拆分开，然后根据时间单位的不同再进一步进行计算，得到最终的毫秒时间。级别就是根据这些毫秒时间的顺序而确定的，例如上述 1s 延迟就是级别 1， 5s 延迟就是级别 2，以此类推:\npublic class ScheduleMessageService extends ConfigManager { public boolean parseDelayLevel() { for (int i = 0; i \u0026lt; levelArray.length; i++) { // ...  int level = i + 1; long delayTimeMillis = tu * num; // 级别:延迟时间  this.delayLevelTable.put(level, delayTimeMillis); } } } 二、定时消息预存储 客户端在为某条消息设置上定时级别的时候，实际上级别这个字段会被作为附属属性放到消息中:\npublic class Message implements Serializable { public void setDelayTimeLevel(int level) { this.putProperty(MessageConst.PROPERTY_DELAY_TIME_LEVEL, String.valueOf(level)); } } 我们先前的文章提到过，发送到 Broker 服务器的消息会被存储到 CommitLog 消息文件中。那么在此处即使是定时消息也不例外，将定时消息存储下来是为了保证消息最大程度地不丢失。然而毕竟和普通消息不同，在遇到定时消息后，CommitLog 会将这条消息的话题和队列 ID 替换成专门用于定时的话题和相应的级别对应的队列 ID。真实的话题和队列 ID 会作为属性放置到这条消息中。\npublic class CommitLog { public PutMessageResult putMessage(final MessageExtBrokerInner msg) { // Delay Delivery  if (msg.getDelayTimeLevel() \u0026gt; 0) { topic = ScheduleMessageService.SCHEDULE_TOPIC; queueId = ScheduleMessageService.delayLevel2QueueId(msg.getDelayTimeLevel()); // Backup real topic, queueId  MessageAccessor.putProperty(msg, MessageConst.PROPERTY_REAL_TOPIC, msg.getTopic()); MessageAccessor.putProperty(msg, MessageConst.PROPERTY_REAL_QUEUE_ID, String.valueOf(msg.getQueueId())); msg.setPropertiesString(MessageDecoder.messageProperties2String(msg.getProperties())); // 替换 Topic 和 QueueID  msg.setTopic(topic); msg.setQueueId(queueId); } } } 随后，这条消息会被存储在 CommitLog 消息文件中。而我们知道后台重放消息服务 ReputMessageService 会一直监督 CommitLog 文件是否添加了新的消息。当有了新的消息后，重放消息服务会取出消息并封装为 DispatchRequest 请求，然后将其分发给不同的三个分发服务，建立消费队列文件服务就是这其中之一。而此处当取消息封装为 DispatchRequest 的时候，当遇到定时消息时，又多做了一些额外的事情。\n当遇见定时消息时，CommitLog 计算 tagsCode 标签码与普通消息不同。对于定时消息，tagsCode 值设置的是这条消息的投递时间，即建立消费队列文件的时候，文件中的 tagsCode 存储的是这条消息未来在什么时候被投递:\npublic class CommitLog { public DispatchRequest checkMessageAndReturnSize(java.nio.ByteBuffer byteBuffer, final boolean checkCRC, final boolean readBody) { // Timing message processing  { String t = propertiesMap.get(MessageConst.PROPERTY_DELAY_TIME_LEVEL); if (ScheduleMessageService.SCHEDULE_TOPIC.equals(topic) \u0026amp;\u0026amp; t != null) { int delayLevel = Integer.parseInt(t); if (delayLevel \u0026gt; 0) { tagsCode = this.defaultMessageStore.getScheduleMessageService() .computeDeliverTimestamp(delayLevel,storeTimestamp); } } } } } 如下是，发送了 10 条定时级别分别为 1-10 的消息以后，$HOME/store/consumequeue 文件下的消费队列文件的分布情况:\n不同的定时级别对应于不同的队列 ID，定时级别减 1 得到的就是队列 ID 的值。因此级别 1-10 对应的是 0-9 的队列 ID:\npublic class ScheduleMessageService extends ConfigManager { public static int delayLevel2QueueId(final int delayLevel) { return delayLevel - 1; } } 三、定时消息再存储 Broker 启动的时候，会开启一个调度消息服务，此服务会监控所有定时消息队列，每一个消息队列会创建一个专门的延时消息投递任务用以到达规定时间后投递此消息:\npublic class ScheduleMessageService extends ConfigManager { public void start() { for (Map.Entry\u0026lt;Integer, Long\u0026gt; entry : this.delayLevelTable.entrySet()) { Integer level = entry.getKey(); Long timeDelay = entry.getValue(); Long offset = this.offsetTable.get(level); if (timeDelay != null) { this.timer.schedule(new DeliverDelayedMessageTimerTask(level, offset), FIRST_DELAY_TIME); } } } } 每个消息队里的消息投递任务，会检查自己跟踪的消息队列，并从此消息队列所对应的定时级别的偏移量中检查是否有新的定时消息到来。其中定时级别的偏移量是维护在内存中的偏移量表 offsetTable 中。每隔 10 秒钟，这个表会被持久化到磁盘上的 delayOffset.json 文件中一次:\npublic class ScheduleMessageService extends ConfigManager { private final ConcurrentMap\u0026lt;Integer /* level */, Long/* offset */\u0026gt; offsetTable = new ConcurrentHashMap\u0026lt;Integer, Long\u0026gt;(32); public void start() { // 每隔 10 秒钟持久化一次  this.timer.scheduleAtFixedRate(new TimerTask() { @Override public void run() { ScheduleMessageService.this.persist(); } }, 10000, this.defaultMessageStore.getMessageStoreConfig().getFlushDelayOffsetInterval()); } } delayOffset.json 文件中存储的示例信息如下所示：\nDeliverDelayedMessageTimerTask 任务会从消费任务队列文件中取出最新的定时消息的 tagsCode ，并计算出的当前是否已经到了这条消息投递的时间。如果到了，即 countdown \u0026lt; 0，那么便会从 CommitLog 文件中取出消息，修正消息的话题和队列 ID 等信息，然后重新存储此条消息。如果还没有到，那么便会重新执行一个定时时间设置为 countdown 毫秒的定时任务。在完成之后，会更新当前的偏移量表，为下一次做准备:\nclass DeliverDelayedMessageTimerTask extends TimerTask { public void executeOnTimeup() { // ...  for (; i \u0026lt; bufferCQ.getSize(); i += ConsumeQueue.CQ_STORE_UNIT_SIZE) { // 是否到时间  long countdown = deliverTimestamp - now; if (countdown \u0026lt;= 0) { // 取出消息  MessageExt msgExt = ScheduleMessageService.this.defaultMessageStore.lookMessageByOffset(offsetPy, sizePy); // 修正消息，设置上正确的话题和队列 ID  MessageExtBrokerInner msgInner = this.messageTimeup(msgExt); // 重新存储消息  PutMessageResult putMessageResult = ScheduleMessageService.this.defaultMessageStore .putMessage(msgInner); } else { // countdown 后投递此消息  ScheduleMessageService.this .timer .schedule(new DeliverDelayedMessageTimerTask(this.delayLevel, nextOffset), countdown); // 更新偏移量  } } // end of for  // 更新偏移量  } } 四、消息重试概述 消息重试分为消息发送重试和消息接受重试，消息发送重试是指消息从 Producer 端发送到 Broker 服务器的失败以后的重试情况，消息接受重试是指 Consumer 在消费消息的时候出现异常或者失败的重试情况。\nProducer 端通过配置如下这两个两个 API 可以分别配置在同步发送和异步发送消息失败的时候的重试次数:\nDefaultMQProducer producer = new DefaultMQProducer(\u0026#34;please_rename_unique_group_name\u0026#34;); producer.setRetryTimesWhenSendAsyncFailed(3); producer.setRetryTimesWhenSendFailed(3); Consumer 端在消费的时候，如果接收消息的回调函数出现了以下几种情况:\n 抛出异常 返回 NULL 状态 返回 RECONSUME_LATER 状态 超时 15 分钟没有响应  那么 Consumer 便会将消费失败的消息重新调度直到成功消费:\nconsumer.registerMessageListener(new MessageListenerConcurrently() { @Override public ConsumeConcurrentlyStatus consumeMessage(List\u0026lt;MessageExt\u0026gt; msgs, ConsumeConcurrentlyContext context) { // 抛出异常  // 返回 NULL 或者 RECONSUME_LATER 状态  return ConsumeConcurrentlyStatus.RECONSUME_LATER; } }); 五、Producer 消息发送重试 发送失败的重试方式，主要表现在发送消息的时候，会最多尝试 getRetryTimesWhenSendFailed() 次发送，当成功发送以后，会直接返回发送结果给调用者。当发送失败以后，会继续进行下一次发送尝试，核心代码如下所示：\npublic class DefaultMQProducerImpl implements MQProducerInner { private SendResult sendDefaultImpl(Message msg, /** 其他参数 **/) throws MQClientException, RemotingException, MQBrokerException, InterruptedException { int timesTotal = communicationMode == CommunicationMode.SYNC ? 1 + this.defaultMQProducer.getRetryTimesWhenSendFailed() : 1; int times = 0; for (; times \u0026lt; timesTotal; times++) { // 尝试发送消息，发送成功 return，发送失败 continue  } } } 六、Consumer 消息接受重试 (1) 订阅重试话题 Consumer 在启动的时候，会执行一个函数 copySubscription() ，当用户注册的消息模型为集群模式的时候，会根据用户指定的组创建重试组话题并放入到注册信息中:\npublic class DefaultMQPushConsumerImpl implements MQConsumerInner { public synchronized void start() throws MQClientException { switch (this.serviceState) { case CREATE_JUST: // ...  this.copySubscription(); // ...  this.serviceState = ServiceState.RUNNING; break; } } private void copySubscription() throws MQClientException { switch (this.defaultMQPushConsumer.getMessageModel()) { case BROADCASTING: break; case CLUSTERING: // 重试话题组  final String retryTopic = MixAll.getRetryTopic(this.defaultMQPushConsumer.getConsumerGroup()); SubscriptionData subscriptionData = FilterAPI.buildSubscriptionData(this.defaultMQPushConsumer.getConsumerGroup(), retryTopic, SubscriptionData.SUB_ALL); this.rebalanceImpl.getSubscriptionInner().put(retryTopic, subscriptionData); break; default: break; } } } 假设用户指定的组为 “ORDER”，那么重试话题则为 “%RETRY%ORDER”，即前面加上了 “%RETRY%” 这个字符串。\nConsumer 在一开始启动的时候，就为用户自动注册了订阅组的重试话题。即用户不单单只接受这个组的话题的消息，也接受这个组的重试话题的消息。这样一来，就为下文用户如何重试接受消息奠定了基础。\n(2) 失败消息发往重试话题 当 Consumer 客户端在消费消息的时候，抛出了异常、返回了非正确消费的状态等错误的时候，这个时候 ConsumeMessageConcurrentlyService 会收集所有失败的消息，然后将每一条消息封装进 CONSUMER_SEND_MSG_BACK 的请求中，并将其发送到 Broker 服务器:\npublic class ConsumeMessageConcurrentlyService implements ConsumeMessageService { public void processConsumeResult(final ConsumeConcurrentlyStatus status, /** 其他参数 **/) { switch (this.defaultMQPushConsumer.getMessageModel()) { case BROADCASTING: // ...  break; case CLUSTERING: for (int i = ackIndex + 1; i \u0026lt; consumeRequest.getMsgs().size(); i++) { MessageExt msg = consumeRequest.getMsgs().get(i); // 重新将消息发往 Broker 服务器  boolean result = this.sendMessageBack(msg, context); } // ...  break; default: break; } } } 当消费失败的消息重新发送到服务器后，Broker 会为其指定新的话题重试话题，并根据当前这条消息的已有的重试次数来选择定时级别，即将这条消息变成定时消息投放到重试话题消息队列中。可见消息消费失败后并不是立即进行新的投递，而是有一定的延迟时间的。延迟时间随着重试次数的增加而增加，也即投递的时间的间隔也越来越长:\npublic class SendMessageProcessor extends AbstractSendMessageProcessor implements NettyRequestProcessor { private RemotingCommand consumerSendMsgBack(final ChannelHandlerContext ctx, final RemotingCommand request) throws RemotingCommandException { // 指定为重试话题  String newTopic = MixAll.getRetryTopic(requestHeader.getGroup()); int queueIdInt = Math.abs(this.random.nextInt() % 99999999) % subscriptionGroupConfig.getRetryQueueNums(); // 指定为延时信息，设定延时级别  if (0 == delayLevel) { delayLevel = 3 + msgExt.getReconsumeTimes(); } msgExt.setDelayTimeLevel(delayLevel); // 重试次数增加  msgInner.setReconsumeTimes(msgExt.getReconsumeTimes() + 1); // 重新存储  PutMessageResult putMessageResult = this.brokerController.getMessageStore().putMessage(msgInner); // ...  } } 当然，消息如果一直消费不成功，那也不会一直无限次的尝试重新投递的。当重试次数大于最大重试次数 (默认为 16 次) 的时候，该消息将会被送往死信话题队列，认定这条话题投递无门:\npublic class SendMessageProcessor extends AbstractSendMessageProcessor implements NettyRequestProcessor { private RemotingCommand consumerSendMsgBack(final ChannelHandlerContext ctx, final RemotingCommand request) throws RemotingCommandException { // 重试次数大于最大重试次数  if (msgExt.getReconsumeTimes() \u0026gt;= maxReconsumeTimes || delayLevel \u0026lt; 0) { // 死信队列话题  newTopic = MixAll.getDLQTopic(requestHeader.getGroup()); queueIdInt = Math.abs(this.random.nextInt() % 99999999) % DLQ_NUMS_PER_GROUP; } // ...  } } 上述客户端消费失败信息的流程图如下所示:\n"});index.add({'id':14,'href':'/docs/rocketmq/rocketmq-master-slave-sync/','title':"RocketMQ 主备同步",'content':"RocketMQ 主备同步 介绍 RocketMQ 的主备同步机制\n一、简介 RocketMQ 通过 Master-Slave 主备机制，来实现整个系统的高可用，具体表现在:\n Master 磁盘坏掉，Slave 依然保存了一份 Master 宕机，不影响消费者继续消费  二、搭建环境 我们在一台机器上搭建一个 Master 一个 Slave 的环境:\n为了能够将 Master 和 Slave 搭建在同一台计算机上，我们除了需要将 Broker 的角色设置为 SLAVE ，还需要为其指定单独的 brokerId、 storePathRootDir、 storePathCommitLog。\n// SLAVE 角色 messageStoreConfig.setBrokerRole(BrokerRole.SLAVE); // 一个机器如果要启动多个 Broker，那么每个 Broker 的 store 根目录必须不同 messageStoreConfig.setStorePathRootDir(storePathRootDir); // 一个机器如果要启动多个 Broker，那么每个 Broker 的 storePathCommitLog 根目录必须不同 messageStoreConfig.setStorePathCommitLog(storePathCommitLog); // 设置 Slave 的 Master HA 地址 messageStoreConfig.setHaMasterAddress(\u0026#34;localhost:10912\u0026#34;); // SLAVE 角色的 brokerId 必须大于 0 brokerConfig.setBrokerId(1); 注意 Slave 和 Master 的 brokerName 必须一致，即它们必须处于同一个 BrokerData 数据结构里面。实际上在做了如上的修改之后， Slave 和 Master 依旧不能同时运行在同一台机器上，因为 Slave 本身也可以称为 Master，接受来自其他 Slave 的请求，因此当运行 Slave 的时候，需要将 HAService 里面的启动 AcceptSocketService 运行的相关方法注释掉。\n三、建立连接 当一个 Broker 在启动的时候，会调用 HAService 的 start() 方法:\npublic class HAService { public void start() throws Exception { this.acceptSocketService.beginAccept(); this.acceptSocketService.start(); this.groupTransferService.start(); this.haClient.start(); } } AcceptSocketService 服务的功能是 Master 等待接受来自其它客户端 Slave 的连接，当成功建立连接后，会将这条连接 HAConnection 放入到 connectionList 连接列表里面。而 HAClient 服务的功能是 Slave 主动发起同其它 Master 的连接。\n四、数据传输 当启动 HAService 之后，一旦 Master 发现和 Slave 不同步，那么Master 会自动开始同步消息到 Slave，无需其它的触发机制。\n(1) 消息异步传输 如果 Master Broker 的角色是 ASYNC_MASTER，那么消息等待从 Master 同步到 Slave 的方式是异步传输的方式。这意味当一条消息发送到 Master Broker 的时候，Master Broker 在存储完这条消息到本地之后，并不会等待消息同步到 Slave Broker 才返回。这种方式会缩短发送消息的响应时间。\n(2) 消息同步传输 如果 Master Broker 的角色是 SYNC_MASTER，那么消息等待从 Master 同步到 Slave 的方式是同步传输的方式。除此之外，进入同步方式还得满足另外两个条件：\n 消息体的 PROPERTY_WAIT_STORE_MSG_OK 属性值为 true，即这条消息允许等待 Slave 相比 Master 落下的同步进度不能超过 256MB  public class CommitLog { public void handleHA(AppendMessageResult result, PutMessageResult putMessageResult, MessageExt messageExt) { if (BrokerRole.SYNC_MASTER == this.defaultMessageStore.getMessageStoreConfig().getBrokerRole()) { HAService service = this.defaultMessageStore.getHaService(); // 消息是否允许等待同步  if (messageExt.isWaitStoreMsgOK()) { // Slave 是否没有落下 Master 太多  if (service.isSlaveOK(result.getWroteOffset() + result.getWroteBytes())) { // 等待同步完成  // ...  } // Slave problem  else { // Tell the producer, slave not available  putMessageResult.setPutMessageStatus(PutMessageStatus.SLAVE_NOT_AVAILABLE); } } } } } 其中 isSlaveOK 方法就是用来检测 Slave 和 Master 落下的同步进度是否太大的:\npublic class HAService { public boolean isSlaveOK(final long masterPutWhere) { boolean result = this.connectionCount.get() \u0026gt; 0; result = result \u0026amp;\u0026amp; ((masterPutWhere - this.push2SlaveMaxOffset.get()) \u0026lt; this.defaultMessageStore .getMessageStoreConfig() .getHaSlaveFallbehindMax()); // 默认 256 * 1024 * 1024 = 256 MB  return result; } } 如果上面两个条件不满足的话，那么 Master 便不会再等待消息同步到 Slave 之后再返回，能尽早返回便尽早返回了。\n消息等待是否同步到 Slave 是借助 CountDownLatch 来实现的。当消息需要等待的时候，便会构建一个 GroupCommitRequest ，每个请求在其内部都维护了一个 CountDownLatch ，然后通过调用 await(timeout) 方法来等待消息同步到 Slave 之后，或者超时之后自动返回。\npublic static class GroupCommitRequest { private final CountDownLatch countDownLatch = new CountDownLatch(1); public void wakeupCustomer(final boolean flushOK) { this.flushOK = flushOK; this.countDownLatch.countDown(); } public boolean waitForFlush(long timeout) { try { this.countDownLatch.await(timeout, TimeUnit.MILLISECONDS); return this.flushOK; } catch (InterruptedException e) { log.error(\u0026#34;Interrupted\u0026#34;, e); return false; } } } 我们再重点来看几个循环体和唤醒点:\n GroupTransferService 服务的是否处理请求的循环体和唤醒点:  class GroupTransferService extends ServiceThread { public synchronized void putRequest(final CommitLog.GroupCommitRequest request) { // ...  // 放入请求，唤醒  if (hasNotified.compareAndSet(false, true)) { waitPoint.countDown(); // notify  } } public void run() { // 循环体  while (!this.isStopped()) { try { // putRequest 会提前唤醒这句话  this.waitForRunning(10); this.doWaitTransfer(); } catch (Exception e) { log.warn(this.getServiceName() + \u0026#34; service has exception. \u0026#34;, e); } } } }  HAConnection 的是否进行消息传输的循环体和唤醒点：  class WriteSocketService extends ServiceThread { @Override public void run() { // 循环体  while (!this.isStopped()) { SelectMappedBufferResult selectResult = HAConnection.this.haService.getDefaultMessageStore().getCommitLogData(this.nextTransferFromWhere); if (selectResult != null) { // 传输（写入）消息  } else { // 等待 100 毫秒或者提前被唤醒  HAConnection.this.haService.getWaitNotifyObject().allWaitForRunning(100); } } } } public class CommitLog { public void handleHA(AppendMessageResult result, PutMessageResult putMessageResult, MessageExt messageExt) { GroupCommitRequest request = new GroupCommitRequest(result.getWroteOffset() + result.getWroteBytes()); service.putRequest(request); // 提前唤醒 WriteSocketService  service.getWaitNotifyObject().wakeupAll(); } }  Slave 汇报进度唤醒 GroupTransferService， 等待同步完成唤醒 GroupCommitRequest 的 CountDownLatch:  class ReadSocketService extends ServiceThread { private boolean processReadEvent() { // 唤醒 GroupTransferService  HAConnection.this.haService.notifyTransferSome(HAConnection.this.slaveAckOffset); } } class GroupTransferService extends ServiceThread { // 被唤醒  public void notifyTransferSome() { this.notifyTransferObject.wakeup(); } private void doWaitTransfer() { for (CommitLog.GroupCommitRequest req : this.requestsRead) { boolean transferOK = HAService.this.push2SlaveMaxOffset.get() \u0026gt;= req.getNextOffset(); // 5 次重试  for (int i = 0; !transferOK \u0026amp;\u0026amp; i \u0026lt; 5; i++) { // 等待被唤醒或者超时  this.notifyTransferObject.waitForRunning(1000); transferOK = HAService.this.push2SlaveMaxOffset.get() \u0026gt;= req.getNextOffset(); } // 唤醒 GroupCommitRequest 的 CountDownLatch  req.wakeupCustomer(transferOK); } } } public static class GroupCommitRequest { // 被唤醒  public void wakeupCustomer(final boolean flushOK) { this.flushOK = flushOK; this.countDownLatch.countDown(); } } 下图是上图一个完整的消息唤醒链:\n五、主备消费 当消费者在消费的时候，如果 Master 突然宕机，那么消费者会自动切换到 Slave 机器上继续进行消费。\n六、消费建议 RocketMQ 提供了自动从 Slave 读取老数据的功能。这个功能主要由 slaveReadEnable 这个参数控制。默认是关的（slaveReadEnable = false）。推荐把它打开，主从都要开。这个参数打开之后，在客户端消费数据时，会判断，当前读取消息的物理偏移量跟最新的位置的差值，是不是超过了内存容量的一个百分比（accessMessageInMemoryMaxRatio = 40 by default）。如果超过了，就会告诉客户端去备机上消费数据。如果采用异步主从，也就是 brokerRole 等于 ASYNC_AMSTER 的时候，你的备机 IO 打爆，其实影响不太大。但是如果你采用同步主从，那还是有影响。所以这个时候，最好挂两个备机。因为 RocketMQ 的主从同步复制，只要一个备机响应了确认写入就可以了，一台 IO 打爆，问题不大。参考自阿里中间件团队博客。\n七、异常处理 Q: Master(Slave) 读取来自 Slave(Master) 的消息异常 (IOException、 read() 返回 -1 等) 的时候怎么处理? A: 打印日志 + 关闭这条连接\nQ: Master(Slave) 长时间没有收到来自 Slave(Master) 的进度汇报怎么处理? A: 每次读取之后更新 lastReadTimestamp 或者 lastWriteTimestamp，一旦发现在 haHousekeepingInterval 间隔内 (默认 20秒) 这个时间戳都没有改变的话，关闭这条连接\nQ: Slave 检测到来自 Master 汇报的本次传输偏移量和本地的传输偏移量不同时怎么处理? A: 打印日志 + 关闭这条连接\nQ: Master 如何知道 Slave 是否真正的存储了刚才发送过去的消息? A: Slave 存储完毕之后，通过向 Master 汇报进度来完成。相当于 TCP 的 ACK 机制。\nQ: Master 宕掉 A: 无论 Maser 是主动关闭 Mater，还是 Master 因为异常而退出，Slave 都会每隔 5 秒重连一次 Master\n"});index.add({'id':15,'href':'/categories/','title':"Categories",'content':""});index.add({'id':16,'href':'/docs/','title':"Docs",'content':""});index.add({'id':17,'href':'/tags/','title':"Tags",'content':""});index.add({'id':18,'href':'/','title':"首页",'content':"赵坤的个人网站 本博客将致力于整理、分析 Java、前端 等开发者生态圈的开源项目的教程、源码等，我会参阅大量书籍，一一对这些基础知识点抽丝剥茧，并匹配大量图表，为大家呈现出它们最本质的面目。\n通过阅读和分析开源项目等，可以增长自己的工程实践能力，可以让自己从代码中汲取养分，也可以学习到他人的设计权衡之道，其对于自己成长的重要性不言而喻！\n对于在博客中遇到的问题或其它事项，欢迎通过微信 top-axy 或邮箱 igozhaokun@163.com 与我联系，谢谢！\n"});})();