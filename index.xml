<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>首页 on 赵坤的个人网站</title>
    <link>https://kunzhao.org/</link>
    <description>Recent content in 首页 on 赵坤的个人网站</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-cn</language>
    <lastBuildDate>Sun, 31 May 2020 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="https://kunzhao.org/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>如何维持缓存的一致性？</title>
      <link>https://kunzhao.org/posts/maintaining-cache-consistency/</link>
      <pubDate>Sun, 31 May 2020 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/posts/maintaining-cache-consistency/</guid>
      <description>&lt;p&gt;Phil Karlton 曾经说过，“计算机科学中只有两件困难的事情：缓存失效和命名问题。” 这句话还有其他很好的举例。我个人最喜欢 Jeff Atwood 的一句话：“计算机科学中有两件困难的事情：缓存失效、命名和一个错误就关闭。”显然，缓存是困难的。就像分布式系统中的几乎所有东西一样，它甚至可能一眼就看不清。我将介绍分布式系统中几种常见的缓存方法，这些方法应该涵盖您将使用的绝大多数缓存系统。具体来说，我将关注如何维护缓存一致性。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>如何改进 NGINX 配置文件节省带宽？</title>
      <link>https://kunzhao.org/posts/help-the-world-by-healing-your-nginx-configuration/</link>
      <pubDate>Sun, 24 May 2020 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/posts/help-the-world-by-healing-your-nginx-configuration/</guid>
      <description>&lt;p&gt;2014年，Admiral William H. McRaven 在得克萨斯大学发表了著名的演讲，他说，如果你想改变世界，就从整理床铺开始。有时候小事情会有很大的影响——不管是在早上整理床铺，还是对网站的HTTP服务器配置做一些更改。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Best Time to Buy and Sell Stock</title>
      <link>https://kunzhao.org/docs/programmer-interview/algorithm/best-time-to-buy-and-sell-stock/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/programmer-interview/algorithm/best-time-to-buy-and-sell-stock/</guid>
      <description>Best Time to Buy and Sell Stock 题目 LeetCode 地址：Best Time to Buy and Sell Stock
有一个数组，第 i 个元素的值代表第 i 天的股票价格，如果你最多只能进行一次交易（某天买入一支股票，然后过几天卖掉），请问你能收获的最大利润是多少？
分析 这道题有两个简单做法：状态机和动态规划。
使用状态机的做法的好处是，这种思路可以延续到其它几个买卖股票的问题上。关键是要想清楚，某一天有几种状态，在这道题是三种：
 状态 s0: 不买也不卖，无操作。s0 的值只能有一个来源，就是和昨天保持一致，不买也不卖 状态 s1: 买入了股票。s1 的值有两个来源：1. 与昨天一致，即已经买入了，且只能买一次，所以不能再买了，s1 = s1；2. 买入今天的股票，花了 price[i] 钱，s1 = s0 - price[i] 状态 s2: 卖出了股票。s2 的值有两个来源：1. 之前已经卖出了，所以维持卖出状态，不能再次卖了，s2 = s1；2. 卖出之前买入的股票，挣 price[i] 钱，s2 = s1 + price[i]  所以，我们可以得到如下状态转移关系：
 s0 = s0 s1 = s1 s1 = s0 - price[i] s2 = s2 s2 = s1 + price[i]  在这整个过程中，我们都要保证每一天的 s0、s1、s2 都是 max 状态，s2 是最终卖完后的收益，所以返回这个结果就行。</description>
    </item>
    
    <item>
      <title>B站高可用架构实践</title>
      <link>https://kunzhao.org/docs/cloud-plus-bbs/bilibili-high-availability/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/cloud-plus-bbs/bilibili-high-availability/</guid>
      <description>B站高可用架构实践 流量洪峰下要做好高服务质量的架构是一件具备挑战的事情，从Google SRE的系统方法论以及实际业务的应对过程中出发，分享一些体系化的可用性设计。对我们了解系统的全貌上下游的联防有更进一步的了解。
负载均衡 BFE 就是指边缘节点，BFE 选择下游 IDC 的逻辑权衡：
 离 BFE 节点比较近的 基于带宽的调度策略 某个 IDC 的流量已经过载，选择另外一个 IDC  当流量走到某个 IDC 时，这个流量应该如何进行负载均衡？
问题：RPC 定时发送的 ping-pong，也即 healthcheck，占用资源也非常多。服务 A 需要与账号服务维持长连接发送 ping-pong，服务 B 也需要维持长连接发送 ping-pong。这个服务越底层，一般依赖和引用这个服务的资源就越多，一旦有任何抖动，那么产生的这个故障面是很大的。那么应该如何解决？
解决：以前是一个 client 跟所有的 backend 建立连接，做负载均衡。现在引入一个新的算法，子集选择算法，一个 client 跟一小部分的 backend 建立连接。图片中示例的算法，是从《Site Reliability Engineering》这本书里看的。
如何规避单集群抖动带来的问题？多集群。
如上述图片所示，如果采用的是 JSQ 负载均衡算法，那么对于 LBA 它一定是选择 Server Y 这个节点。但如果站在全局的视角来看，就肯定不会选择 Server Y 了，因此这个算法缺乏一个全局的视角。
如果微服务采用的是 Java 语言开发，当它处于 GC 或者 FullGC 的时候，这个时候发一个请求过去，那么它的 latency 肯定会变得非常高，可能会产生过载。
新启动的节点，JVM 会做 JIT，每次新启动都会抖动一波，那么就需要考虑如何对这个节点做预热？
如上图所示，采用 &amp;ldquo;the choice-of-2&amp;rdquo; 算法后，各个机器的 CPU 负载趋向于收敛，即各个机器的 CPU 负载都差不多。Client 如何拿到后台的 Backend 的各项负载？是采用 Middleware 从 Rpc 的 Response 里面获取的，有很多 RPC 也支持获取元数据信息等。</description>
    </item>
    
    <item>
      <title>fastjson 又现高危漏洞！</title>
      <link>https://kunzhao.org/docs/it-zone/2020-06/fastjson-high-risk-vulnerability/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/it-zone/2020-06/fastjson-high-risk-vulnerability/</guid>
      <description>fastjson 又现高危漏洞！ 日期：2020-06-01
 5 月 28 日，据 360 网络安全响应中心发布《Fastjson远程代码执行漏洞通告》显示，由阿里巴巴开源的 fastjson 库 又现高危漏洞，该漏洞可导致不法分子远程执行服务器命令等严重后果。
fastjson 是阿里巴巴的开源JSON解析库，它可以解析JSON格式的字符串，支持将Java Bean序列化为JSON字符串，也可以从JSON字符串反序列化到 JavaBean。
fastjson 存在远程代码执行漏洞，autotype 开关的限制可以被绕过，链式的反序列化攻击者精心构造反序列化利用链，最终达成远程命令执行的后果。此漏洞本身无法绕过 fastjson 的黑名单限制，需要配合不在黑名单中的反序列化利用链才能完成完整的漏洞利用。
该漏洞影响的版本：&amp;lt;= 1.2.68
该漏洞修复建议：
 升级到 fastjson 1.2.69/1.2.70 版本，下载地址为 Releases · alibaba/fastjson 或者通过配置以下参数开启 SafeMode 来防护攻击：ParserConfig.getGlobalInstance().setSafeMode(true);（safeMode 会完全禁用 autotype，无视白名单，请注意评估对业务影响）  </description>
    </item>
    
    <item>
      <title>Git 配置用户名和邮箱</title>
      <link>https://kunzhao.org/docs/tutorial/git/config-user-and-email/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/tutorial/git/config-user-and-email/</guid>
      <description>Git 配置用户名和邮箱 假设你的用户名是 zk，邮箱账号是 xxx@163.com，那么需要提前配置 Git 的用户名和邮箱帐号：
git config --global user.name &amp;#34;zk&amp;#34; git config --global user.email &amp;#34;xxx@163.com&amp;#34; Git 需要知道谁对代码做出了变更，对代码做出变更的这个人的邮件联系方式是什么，以方便追踪。
Git Config 有三个作用域：
 git config --local：只对某个仓库有效 git config --global：对当前用户所有仓库有效 git config --system：对系统所有登录的用户有效  如何查看当前设置的 Git 配置？
git config --list --local git config --list --global git config --list --system  --local 针对的是某个仓库，配置 --local 作用域的时候，需要进入到项目所在的目录才能配置或显示。
 </description>
    </item>
    
    <item>
      <title>grep</title>
      <link>https://kunzhao.org/docs/tutorial/unix-command/grep/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/tutorial/unix-command/grep/</guid>
      <description>grep grep 命令如何使用？grep 命令的常见用法？
简介 grep 命令用于搜索文本。它在给定文件中搜索包含与给定字符串或单词匹配的行。它是 Linux 和类 Unix 系统中最有用的命令之一。让我们看看如何在 Linux 或类 Unix 系统上使用 grep。
grep 命令是一个包含 grep、egrep 和 fgrep 命令的大家族，都用于搜索文本。
常见用法 下面是一些标准的 grep 命令，通过示例说明了如何在Linux、macOS和Unix上使用 grep：
（1）在文件 foo.txt 中搜索单词 word
grep &amp;#39;word&amp;#39; foo.txt （2）在文件 foo.txt 中搜索单词 word，并且忽略大小写
grep -i &amp;#39;word&amp;#39; foo.txt 上述命令会把位于 foo.txt 文件中的 WORD、Word、word 等忽略大小写的 word 全部搜索出来。
（3）在当前目录以及所有子目录中查找单词 word
grep -R &amp;#39;word&amp;#39; .  注意：最后面有一个点，代表当前目录。-r 命令也是递归搜索，只是 -r 不会搜索符号链接文件。
 （4）搜索并显示单词 word 出现的次数
grep -c &amp;#39;word&amp;#39; foo.txt （5）只匹配单词 word</description>
    </item>
    
    <item>
      <title>RocketMQ 消息发送流程</title>
      <link>https://kunzhao.org/docs/rocketmq/rocketmq-send-message-flow/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/rocketmq/rocketmq-send-message-flow/</guid>
      <description>RocketMQ 消息发送流程 本文讲述 RocketMQ 发送一条普通消息的流程。
一、服务器启动 我们可以参考官方文档来启动服务:
 启动 Name 服务器:  sh bin/mqnamesrv  启动 Broker 服务器:  sh bin/mqbroker -n localhost:9876 二、构建消息体 一条消息体最少需要指定两个值:
 所属话题 消息内容  如下就是创建了一条话题为 “Test”，消息体为 “Hello World” 的消息:
Message msg = new Message( &amp;#34;Test&amp;#34;, &amp;#34;Hello World&amp;#34;.getBytes() ); 三、启动 Producer 准备发送消息 如果我们想要发送消息呢，我们还需要再启动一个 DefaultProducer (生产者) 类来发消息:
DefaultMQProducer producer = new DefaultMQProducer(); producer.start(); 现在我们所启动的服务如下所示:
四、Name 服务器的均等性 注意我们上述开启的是单个服务，也即一个 Broker 和一个 Name 服务器，但是实际上使用消息队列的时候，我们可能需要搭建的是一个集群，如下所示:
在 RocketMQ 的设计中，客户端需要首先询问 Name 服务器才能确定一个合适的 Broker 以进行消息的发送:</description>
    </item>
    
    <item>
      <title>VUE 面试题</title>
      <link>https://kunzhao.org/docs/programmer-interview/front-end/vue/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/programmer-interview/front-end/vue/</guid>
      <description>VUE 面试题 整理 VUE 相关的常见面试题
介绍一下 VUE 介绍一下 VUEX VUE 2.X 和 3.0 的区别 （1）数据监听方式变化
VUE 2.X 使用 ES5 的 Object.defineProperty() 的 get() 和 set(newValue) 实现，VUE 3.0 基于 Proxy 监听实现，同时更为强大：
 可以检测属性的新增和删除 可以检测数组索引的变化和 length 的变化 支持 Map、Set、WeakMap 和 WeakSet   优点：速度加倍，内存占用减半。
 （2）体积更小
支持 Tree Shaking，内置组件、内置指令按需引入。
（3）速度更快
参考：vue3.0和vue2.x的区别、Vue 3.0 和 Vue 2.0的对比以及Vue 2.0精讲以及Vue全家桶精讲
VUE 的生命周期 VUE 数据双向绑定原理 VUE 采用发布者-订阅者模式的方式来实现双向绑定。
（1）视图更新数据：
input 标签监听 input 事件即可。
（2）数据更新视图：
Object.defineProperty() 监听数据变化，通过消息订阅器发布消息，订阅者收到消息执行相应的操纵 DOM 的函数，从而更新视图。</description>
    </item>
    
    <item>
      <title>图片优化</title>
      <link>https://kunzhao.org/docs/tutorial/front-end-optimization-guide/image-optimization/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/tutorial/front-end-optimization-guide/image-optimization/</guid>
      <description>图片优化 图片在网页数据的传输中占据了非常大的流量，如何优化图片，对于前端页面加载的性能极其重要。本文讲述了比较常见的几种优化图片的技巧。
图片格式介绍 （1）JPEG
JPEG 是 Joint Photographic Experts Group 的缩写，不支持透明度，常用于网站的 Banner 图。JPEG 使用的是一种有损图像质量的压缩算法，压缩的越狠，图片的质量损失也就越大，图片的尺寸也就越小。根据你网站所能忍受的图片质量，来相应的选择压缩比：
（2）PNG
支持透明度，支持无损压缩，一般图片的尺寸都比较大。
（3）GIF
适合放动画图片。
（4）WebP
🔥Google 2010 年提出的新的图像压缩格式算法，在 2013 年又推出 Animated WebP，即支持动画的 Webp。优点：更优的图像数据压缩算法、拥有肉眼识别无差异的图像质量、具备了无损和有损的压缩模式、Alpha 透明以及动画的特性。
PNG、JPG、WebP 压缩对比：
GIF 和 WebP 对比：
不同网络环境，加载不同尺寸图片 如下是京东网站首页占据 C 位的宣传图：
它的 URL 地址如下，你任意改变这张图片的 URL 里面的宽、高，放到浏览器里面重新进行请求，就可以得到相应大小的图片：
响应式图片 不同平台设备加载不同大小、甚至不同内容的图片！
CSS 媒体查询 @media all and (max-width: 600px) { img { width: 300px; } } @media all and (min-width: 600px) and (max-width: 1200px) { img { width: 900px; } } srcset、sizes、picture 和 source （1）srcset 属性</description>
    </item>
    
    <item>
      <title>数学之美</title>
      <link>https://kunzhao.org/docs/books/beauty_of_mathematics/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/books/beauty_of_mathematics/</guid>
      <description>数学之美 2000多年前，古埃及人在罗塞塔石碑上，用三种文字记录了托勒密五世登基的诏书，这帮助后人破解了古埃及的象形文字，让我们了解了5000年前古埃及的历史。可见信息冗余是信息安全的保障，这对于信息编码具有重要指导意义。
犹太人为了避免抄错《圣经》，发明了一种校验码的方法，他们把每一个希伯来字母对应于一个数字，这样每行文字加起来便得到一个特殊的数字，这样的数字变成为了这一行的校验码。
隐含马尔可夫链成功应用在机器翻译、拼写纠错、手写体识别、图像处理、基因序列分析、股票预测和投资等方面。
如何准确的识别出一个快递地址，写一个分析器去分析这些描述恐怕是不行的，因为地址是比较复杂的上下文有关的文法。答案是使用有限状态机。当用户输入的地址不太标准或有错别字的时候，有限状态机会束手无措，因为有限状态机是严格匹配的，所以科学家提出了基于概率的有限状态机。
2002 年，Google 想要做一个全新的中、日、韩搜索算法，吴军写的算法比较简单，但是占用内存比较多，Google 服务器数量还没有那么多。辛格提出，用一个拟合函数替换很耗内存的语言模型，无需增加任何服务器，但是搜索质量会降到 80%。辛格指出，这样可以提早两个月将这个新算法提供给中国的用户，用户体验会有质的提高。辛格做事情的哲学，先帮助用户解决 80% 的问题，再慢慢解决剩下的 20% 的问题，是在工业界成功的秘诀之一。
新闻分类的关键在于计算出两篇新闻的相似度，每篇新闻变成一个向量，最后余弦定理可以计算出来相似度。但两两计算的迭代次数太多，如何一次性就把所有新闻的相关性计算出来呢？答案是矩阵运算中的奇异值分解。
如何判断两个集合是否相同？一种答案是双层 for 循环一一比较，复杂度 O(N^2)；稍好一点的办法是对集合进行排序，然后顺序比较，时间复杂度 O(NlogN)；还可以将一个集合的元素放到散列表里面，另外一个与之一一对比，时间复杂度 O(N)，但是额外使用了 O(N) 的空间，不完美；最完美的是计算这两个集合的指纹，对一个集合中的元素分别计算指纹，然后一一相加。
如何判断两个集合基本相同？答案是 Simhash。判断两个网页是否重复，也没有必要完全从头比到尾，只需要每个网页挑选出几个词 (IDF 最大的几个词)，构成特征词，然后计算信息指纹即可。判断一篇文章是否抄袭另外一篇文章，每篇文章切成小的片段，挑选特征词，并计算指纹。YouTuBe 如何从上百万视频中找出一个视频是否另外一个视频的盗版？其核心在于关键帧的提取和特征的提取。关键帧对于视频的重要性，就如同主题词对于新闻的重要性一样。
最大熵原理指出，对一个随机事件的概率分布进行预测时，我们的预测应当满足全部已知的条件，而对未知的情况不要做任何主观假设，这种情况下，概率分布最均匀，预测的风险最小。例如拼音输入法，Wang-Xiao-Bo 转换为王晓波和王小波，唯一确定用户需要的是哪一个，非常难。</description>
    </item>
    
    <item>
      <title>理解 This 关键字</title>
      <link>https://kunzhao.org/docs/javascript/understand-this-keyword/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/javascript/understand-this-keyword/</guid>
      <description>理解 This 关键字 JavaScript 中的 this 所指向的对象，取决于上下文以及函数被调用的方式，本文列举了几种常见的情况，帮助大家理解。
一、全局上下文 当直接在一个全局的上下文中，使用 this 指针的时候，this 指针会指向到全局对象上。例如在浏览器的调试工具栏中直接打印 this 指针，其指向的是 Window 对象：
在 node 中打印 this 指针，其指向的是 node 提供的全局对象，其中包含了进程信息等：
二、Function 上下文 在 Function 上下文中，this 的值取决于 function 是如何被调用的。
(1) Function 调用 当 this 指针定义在一个 function 中，那么此 this 仍然会指向全局对象：
function foo() { console.log(this) } foo(); // Window {parent: Window, postMessage: ƒ, blur: ƒ, focus: ƒ, close: ƒ, …} (2) 严格模式下的 Function 调用 如果在严格模式下定义的 function 的话，this 指针的值将会是 undefined：
function foo() { &amp;#39;use strict&amp;#39;; console.</description>
    </item>
    
    <item>
      <title>信息的半衰期</title>
      <link>https://kunzhao.org/posts/half-life-of-information/</link>
      <pubDate>Sat, 16 May 2020 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/posts/half-life-of-information/</guid>
      <description>&lt;p&gt;今天，我想与您讨论一下信息能存活多久的问题，这个问题又会如何影响我们工作的方式。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Best Time to Buy and Sell Stock Ⅱ</title>
      <link>https://kunzhao.org/docs/programmer-interview/algorithm/best-time-to-buy-and-sell-stock-2/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/programmer-interview/algorithm/best-time-to-buy-and-sell-stock-2/</guid>
      <description>Best Time to Buy and Sell Stock Ⅱ 题目 LeetCode 地址：Best Time to Buy and Sell Stock Ⅱ
有一个数组，第 i 个元素的值代表第 i 天的股票价格，如果你可以进行无限次交易（某天买入一支股票，然后过几天卖掉），请问你能收获的最大利润是多少？
分析 这道题就一个想法，只要今天 price[i] 比昨天 price[i - 1] 的价格涨了，就可以算作是有效的利润，累加到最后的结果中。
答案 // 假设有一个数组，它的第i个元素是一个给定的股票在第i天的价格。 // 设计一个算法来找到最大的利润。你可以完成尽可能多的交易(多次买卖股票)。 // 然而,你不能同时参与多个交易(你必须在再次购买前出售股票)。 // // https://www.lintcode.com/problem/best-time-to-buy-and-sell-stock-ii/description public class BestTimetoBuyandSellStockII { public int maxProfit(int[] prices) { int max = 0; for (int i = 1; i &amp;lt; prices.length; i++) { int diff = prices[i] - prices[i - 1]; if (diff &amp;gt; 0) { max += diff; } } return max; } } 扫描下面二维码，在手机上阅读这篇文章：</description>
    </item>
    
    <item>
      <title>find</title>
      <link>https://kunzhao.org/docs/tutorial/unix-command/find/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/tutorial/unix-command/find/</guid>
      <description>find find 命令的常见用法有哪些？find 命令的例子。
简介 Linux Find命令是类Unix操作系统中最重要、最常用的命令行实用程序之一。find 命令可以，根据不同的查找条件，来查询匹配不同的文件或目录列表。
find 可用于根据各种条件查找，例如您可以按权限、用户、组、文件类型、日期、大小和其他可能的条件查找文件。
通过本文，我们将以示例的形式分享我们的日常Linux find命令体验及其使用。
格式 find [path...] [test...] [action...]  path：find 命令的第一件事，查看每个路径 test：对于遇到的每个文件，find 应用测试条件 action：一旦搜索完成，find 对每个文件执行相应的操作  路径示例：
 find /usr/bin find / find . find ~  测试示例：
 -name pattern：包含 pattern 的文件名 -iname pattern：包含 pattern 的文件名（忽略大小写） -type [df]：文件类型，d 代表目录，f 代表文件 -perm mode：设置为 mode 的文件权限 -user userid：用户为 userid -group groupid：组为 groupid -size [-+]n[cbkMG]：大小为 n[字符(字节)、块、千字节、兆字节、吉字节] -empty：空文件 -amin [-+]n：n 分钟之前访问 -anewer file：file 文件之后访问 -atime [-+]n：n 天之前访问 -cmin [-+]n：n 分钟之前状态改变 -cnewer file：file 文件之后状态改变 -ctime [-+]n：n 天状态之前改变 -mmin [-+]n：n 分钟之前修改 -mtime [-+]n：n 天之前修改 -newer file：file 文件之后修改   - 代表：小于，+ 代表：大于</description>
    </item>
    
    <item>
      <title>HTML 优化</title>
      <link>https://kunzhao.org/docs/tutorial/front-end-optimization-guide/html-optimization/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/tutorial/front-end-optimization-guide/html-optimization/</guid>
      <description>HTML 优化 本文通过一些案例讲述了常见的优化 HTML 的几种小技巧：减少 DOM 树、精简 HTML 文件大小等。
优化 DOM 节点树 去除页面除首屏外的对于用户不可见的信息区块，可以让页面的 DOM 节点数更少，DOM 树结构更简单，然后再使用懒加载异步化请求，去动态加载这些不可见的信息区块。
在《大型网站性能优化实战》这本书中，作者为了优化搜索页面的渲染瓶颈问题，将首屏以下的 33 各搜索结果对应的 HTML 代码放到 &amp;lt;textarea&amp;gt; 节点中，当该区域处于可见状态时，再从 TextArea 中取出 HTML 代码，恢复到 DOM 树中进行渲染。这样一来，页面首次渲染的 DOM 树所包含的节点数大幅度减少，从而有效提高了首次渲染速度。
多个空格合并为一个空格 通过将多个空格合并为一个空格，可以减少 HTML 的大小，从而缩短传输 HTML 文件所需的时间。通常在编写 HTML 文件的时候，总是倾向于格式化它，以方便我们人类阅读，所以这个文件中填充了许多空格，但这些空格对于浏览器来说是用不到的。在替换空格的时候，需要保留 &amp;lt;pre&amp;gt;、&amp;lt;textarea&amp;gt;、&amp;lt;script&amp;gt;、&amp;lt;style&amp;gt; 中的空格。
不过，如果你的网页中使用了 white-space: pre 这个 CSS 属性就要小心了，这个属性可以避免让多个空格压缩为一个，在实际开发网站的时候，其实也很少用到这个属性。如果确实需要，那么就放弃把 HTML 的多个空格合并为一个空格吧。
&amp;lt;html&amp;gt; &amp;lt;head&amp;gt; &amp;lt;title&amp;gt;Hello, world! &amp;lt;/title&amp;gt; &amp;lt;script&amp;gt; var x = &amp;#39;Hello, world!&amp;#39;;&amp;lt;/script&amp;gt; &amp;lt;/head&amp;gt; &amp;lt;body&amp;gt; Hello, World! &amp;lt;pre&amp;gt; Hello, World! &amp;lt;/pre&amp;gt; &amp;lt;/body&amp;gt; &amp;lt;/html&amp;gt; 转为：</description>
    </item>
    
    <item>
      <title>JavaScript 数组</title>
      <link>https://kunzhao.org/docs/javascript/javascript-array/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/javascript/javascript-array/</guid>
      <description>JavaScript 数组 使用 JavaScript 在编程的时候，我们有很大一部分时间都是在与数组打交道，因此对数组常见的方法做到灵活的运用至关重要。本文整理了和 JavaScript 数组相关的，日常经常需要的功能和使用技巧，供大家参阅。
从数组中移除指定元素 查阅 JavaScript 的数组 API，发现其并没有提供一个像 remove(obj) 或 removeAll(obj) 此类的方法，供我们方便的删除对象，因此我们需要通过使用其它的 API 来达到我们移出元素的目的。
(1) 使用 splice 方法 splice 方法可以从指定索引处，向数组中添加元素或者删除元素，其会直接在原数组上改变，因此通过此方法可以达到我们的目的。但是在移除元素之前，我们必须首先通过 indexOf 方法找到我们的元素在数组中处于的索引位置。
const array = [2, 5, 9]; const index = array.indexOf(5); if (index &amp;gt; -1) { array.splice(index, 1); // 1 代表删除 1 个元素 } console.log(array) 当然，如果你不想使用 indexOf 的话，也可以直接从后向前遍历整个数组，对每个符合要求的元素都使用 splice 方法：
const array = [2, 5, 9]; for (var i = array.length; i--; ) { if (array[i] === 5) { array.</description>
    </item>
    
    <item>
      <title>RocketMQ 消息存储流程</title>
      <link>https://kunzhao.org/docs/rocketmq/rocketmq-message-store-flow/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/rocketmq/rocketmq-message-store-flow/</guid>
      <description>RocketMQ 消息存储流程 本文讲述 RocketMQ 存储一条消息的流程。
一、存储位置 当有一条消息过来之后，Broker 首先需要做的是确定这条消息应该存储在哪个文件里面。在 RocketMQ 中，这个用来存储消息的文件被称之为 MappedFile。这个文件默认创建的大小为 1GB。
一个文件为 1GB 大小，也即 1024 * 1024 * 1024 = 1073741824 字节，这每个文件的命名是按照总的字节偏移量来命名的。例如第一个文件偏移量为 0，那么它的名字为 00000000000000000000；当当前这 1G 文件被存储满了之后，就会创建下一个文件，下一个文件的偏移量则为 1GB，那么它的名字为 00000000001073741824，以此类推。
默认情况下这些消息文件位于 $HOME/store/commitlog 目录下，如下图所示:
二、文件创建 当 Broker 启动的时候，其会将位于存储目录下的所有消息文件加载到一个列表中:
当有新的消息到来的时候，其会默认选择列表中的最后一个文件来进行消息的保存:
public class MappedFileQueue { public MappedFile getLastMappedFile() { MappedFile mappedFileLast = null; while (!this.mappedFiles.isEmpty()) { try { mappedFileLast = this.mappedFiles.get(this.mappedFiles.size() - 1); break; } catch (IndexOutOfBoundsException e) { //continue;  } catch (Exception e) { log.</description>
    </item>
    
    <item>
      <title>Rust 语言首次进入 Tiobe 前 20 名</title>
      <link>https://kunzhao.org/docs/it-zone/2020-06/rust-enter-top-20/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/it-zone/2020-06/rust-enter-top-20/</guid>
      <description>Rust 语言首次进入 Tiobe 前 20 名 日期：2020-06-02
 Rust 在 Tiobe 上的排名已大大提高，从去年的38位上升到今天的20位。Tiobe 的索引基于主要搜索引擎上对某种语言的搜索，因此这并不意味着更多的人正在使用 Rust，但是它表明更多的开发人员正在搜索有关该语言的信息。
在 Stack Overflow 的2020年调查中， Rust 被开发人员连续第五年票选为最受欢迎的编程语言。今年，有86％的开发人员表示他们热衷于使用Rust，但只有5％的开发人员实际将其用于编程。
另一方面，由于Microsoft已公开预览其针对Windows运行时（WinRT）的 Rust 库，因此它可能会得到更广泛的使用 ，这使开发人员可以更轻松地在Rust中编写Windows，跨平台应用程序和驱动程序。
Tiobe软件首席执行官Paul Jansen说，Rust的崛起是因为它是一种“正确的”系统编程语言。
然而，Rust 项目的2020年开发人员调查发现，由于其陡峭的学习曲线以及很少有公司使用它，用户难以采用该语言。 Google 在新的Fuchsia OS 排除了 Rust 语言，因为很少有开发人员对此感到熟悉。</description>
    </item>
    
    <item>
      <title>上帝掷骰子吗</title>
      <link>https://kunzhao.org/docs/books/history_of_quantum_physics/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/books/history_of_quantum_physics/</guid>
      <description>上帝掷骰子吗-量子物理史话 1887年德国，赫兹在实验室证实了电磁波的存在，也证实了光其实是电磁波的一种，两者具有共同的波的特性，古老的光学终于可以被完全包容于新兴的电磁学里面。1901年，赫兹死后的第 7 年，无线电报已经可以穿越大西洋，实现两地的实时通讯了。
赫兹铜环接收器的缺口之间不停地爆发着电火花，明白无误地昭示着电磁波的存在。但偶然间，赫兹又发现了一个奇怪的现象：当有光照射到这个缺口上的时候，似乎火花就出现得更容易一些。
 量子就是能量的最小单位，就是能量里的一美分。一切能量的传输，都只能以这个量为单位来进行，它可以传输一个量子，两个量子，任意整数个量子，但却不能传输1 又1/2 个量子，那个状态是不允许的，就像你不能用现钱支付1 又1/2 美分一样。这个值，现在已经成为了自然科学中最为 重要的常数之一，以它的发现者命名，称为“普朗克常数”，用 h 来表示。
在后来十几年的时间里，普朗克一直认为量子的假设并不是一个物理真实，而纯粹是一个为了方便而引入的假设而已。他不断地告诫人们，在引用普朗克常数 h 的时候，要尽量小心谨慎，不到万不得已千万不要胡思乱想。</description>
    </item>
    
    <item>
      <title>创建 Git 仓库</title>
      <link>https://kunzhao.org/docs/tutorial/git/create-repository/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/tutorial/git/create-repository/</guid>
      <description>创建 Git 仓库 （1）已有项目使用 Git 管理
假设你的项目所在文件夹叫做：abc_project
cd abc_project git init （2）新建项目直接使用 Git 管理
假设新建的项目名为 xxx_project
git init xxx_project </description>
    </item>
    
    <item>
      <title>穗康小程序口罩预约前后端架构及产品设计</title>
      <link>https://kunzhao.org/docs/cloud-plus-bbs/suikang-mini-program-design/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/cloud-plus-bbs/suikang-mini-program-design/</guid>
      <description>穗康小程序口罩预约前后端架构及产品设计 在战“疫”期间，腾讯与广州市政府合作，在小程序“穗康”上，2天内上线了全国首款口罩预约功能，上线首日访问量1.7亿，累计参与口罩预约人次1400万+。那么，它是如何在2天内开发上线，扛住了超大并发量呢？其背后的前后端架构是怎样的？
无损服务设计 整个流程下来需要 3 个实时接口：
 药店当前口罩的库存情况 哪个时间段有名额 提交预约实时返回结果  有损服务设计 结果，口罩预约关注度远超预期：
下面展示的 UI 的设计：
为什么有 “损” 平衡的理论就是 CAP 理论、BASE 最终一致性：
牺牲强一致换取高可用 两个机房需要同步，并发性差。以下是优化后的代码，引入计时器：
降低了专线依赖。
怎么 &amp;ldquo;损&amp;rdquo;  放弃绝对一致，追求高可用和快速响应 万有一失，用户重试 伸缩调度，降级服务  （1）穗康小程序 引入消息队列，最终一致：
（2）QQ 相册负载高 选择扩容？带宽和存储成本高。
（3）转账 用户重试极少量消息。再想一下微信的红色感叹号，点一下重新发送。
（4）穗康的预约重试 （5）QQ 相册降级 </description>
    </item>
    
    <item>
      <title>分布式系统一致性问题</title>
      <link>https://kunzhao.org/posts/consistency-problem-of-the-distrubuted-system/</link>
      <pubDate>Fri, 22 Jun 2018 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/posts/consistency-problem-of-the-distrubuted-system/</guid>
      <description>&lt;p&gt;描述解决分布式系统一致性问题的典型思路!&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Best Time to Buy and Sell Stock Ⅲ</title>
      <link>https://kunzhao.org/docs/programmer-interview/algorithm/best-time-to-buy-and-sell-stock-3/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/programmer-interview/algorithm/best-time-to-buy-and-sell-stock-3/</guid>
      <description>Best Time to Buy and Sell Stock Ⅲ 题目 LeetCode 地址：Best Time to Buy and Sell Stock Ⅲ
有一个数组，第 i 个元素的值代表第 i 天的股票价格，如果你最多只能进行两次交易（某天买入一支股票，然后过几天卖掉），请问你能收获的最大利润是多少？
分析 参考 Best Time to Buy and Sell Stock 思路上状态机，状态机应用两次即可。
答案 // 最多两次交易 // 且不能同时持有，必须卖掉这个，然后持有另外一个 // https://leetcode.com/problems/best-time-to-buy-and-sell-stock-iii/ // public class BestTimetoBuyandSellStockIII { // Buy Sell Buy Sell  // s0 ----&amp;gt; s1 -----&amp;gt; s2 -----&amp;gt; s3 ------&amp;gt; s4 (end)  // ↑___| ↑__| ↑____| ↑___|  //  public int maxProfit(int[] prices) { if (prices == null || prices.</description>
    </item>
    
    <item>
      <title>CSS 优化</title>
      <link>https://kunzhao.org/docs/tutorial/front-end-optimization-guide/css-optimization/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/tutorial/front-end-optimization-guide/css-optimization/</guid>
      <description>CSS 优化 本文讲述在实际工作中如何优化 CSS，提升页面加载的性能！
避免使用 @import @import url(&amp;#34;base.css&amp;#34;); @import url(&amp;#34;layout.css&amp;#34;); @import url(&amp;#34;carousel.css&amp;#34;); 由于 @import 属性允许相互之间嵌套引入，因此浏览器必须串行的去下载每一个 @import 引入的文件，因此会增加下载 CSS 文件的时间，而使用 &amp;lt;link&amp;gt; 就可以并行下载 CSS 文件，可有效提升 CSS 加载的性能：
&amp;lt;link rel=&amp;#34;stylesheet&amp;#34; href=&amp;#34;base.css&amp;#34;&amp;gt; &amp;lt;link rel=&amp;#34;stylesheet&amp;#34; href=&amp;#34;layout.css&amp;#34;&amp;gt; &amp;lt;link rel=&amp;#34;stylesheet&amp;#34; href=&amp;#34;carousel.css&amp;#34;&amp;gt; 简化 CSS 选择器 浏览器是从右向左逐步解析选择器表达式的，例如 #id .class &amp;gt; ul a 。首先找到页面上所有匹配 a 的节点，然后找到所有 ul 元素，并且将 a 元素恰好是 ul 元素子节点的元素过滤出来，直至解析到最左侧的选择器 #id 。
如下是在网站上针对 50000 个元素使用不同 CSS 选择器选择元素的时间对比：
   选择器 查询时间(ms)     div 4.8740   .</description>
    </item>
    
    <item>
      <title>Git 查看文件差异</title>
      <link>https://kunzhao.org/docs/tutorial/git/check-file-diff/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/tutorial/git/check-file-diff/</guid>
      <description>Git 查看文件差异 Git 三个区 Git 有三个区：工作区、Stage 区（暂存区）、版本库。这意味着，一个文件可能在这三个区都有所不同。如下图所示，一个文件使用 git add 命令之后，这个文件就转移到了暂存区，继续使用 git commit 之后就转移到了版本库。git diff 使用不同的命令参数可以查看文件在这三个区域中的两两对比的差异。
本地代码（工作区）与暂存区中的差异 git diff 示例结果如下所示：
diff 输出的格式介绍 下面解释上述 git diff 输出的格式：
 第一行，展示了使用什么命令做的比较 第二行，100644 代表这是一个普通文件 --- 表示原始文件，即这个文件没有修改前的内容 +++ 表示新文件，即这个文件修改后的内容 -1,5 中的 - 表示原始文件，1,5 表示从第 1 行到第 4 行做了改动 +1,5 中的 + 表示新文件，1,5 表示从第 1 行到第 4 行做了改动 @@ -1,5 +1,5 @@ 表示这个文件的第 1 行到第 4 行，变更为了新文件的第 1 行到第 4 行  本地代码（工作区）和版本库的差异 git diff HEAD  HEAD 指：当前工作分支的版本库</description>
    </item>
    
    <item>
      <title>ls</title>
      <link>https://kunzhao.org/docs/tutorial/unix-command/ls/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/tutorial/unix-command/ls/</guid>
      <description>ls ls 命令教程，ls 命令的常见使用方法介绍。
简介 ls 命令是一个命令行实用程序，用于列出通过标准输入提供给它的一个或多个目录的内容。它将结果写入标准输出。ls 命令支持显示关于文件的各种信息、对一系列选项进行排序和递归列表。
示例 （1）显示目录中的文件
ls /home/zk （2）显示隐藏的文件和文件夹
ls -a /home/zk 结果：
ls -a /home/george . .goobook .tmux.conf .. .goobook_auth.json .urlview .asoundrc .inputrc .vim .asoundrc.asoundconf .install.sh .viminfo .asoundrc.asoundconf.bak .irbrc .viminfo.tmp ... （3）列出来的文件，标识上文件的类型
ls -F 显示结果如下所示：
bin@ dotfiles/ file.txt irc/ src/ code/ Downloads/ go/ logs/ 不同文件类型显示的后缀不同：
 /：目录 @：symbolic link |：FIFO =：socket &amp;gt;：door 什么也不显示，代表正常文件  （4）显示更多信息
ls -l 显示结果：
-rwxrw-r-- 10 root root 2048 Jan 13 07:11 afile.</description>
    </item>
    
    <item>
      <title>RocketMQ 消息接受流程</title>
      <link>https://kunzhao.org/docs/rocketmq/rocketmq-message-receive-flow/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/rocketmq/rocketmq-message-receive-flow/</guid>
      <description>RocketMQ 消息接受流程 本篇讲述 RocketMQ 消息接受流程
一、消费者注册 生产者负责往服务器 Broker 发送消息，消费者则从 Broker 获取消息。消费者获取消息采用的是订阅者模式，即消费者客户端可以任意订阅一个或者多个话题来消费消息:
public class Consumer { public static void main(String[] args) throws InterruptedException, MQClientException { /* * 订阅一个或者多个话题 */ consumer.subscribe(&amp;#34;TopicTest&amp;#34;, &amp;#34;*&amp;#34;); } } 当消费者客户端启动以后，其会每隔 30 秒从命名服务器查询一次用户订阅的所有话题路由信息:
public class MQClientInstance { private void startScheduledTask() { this.scheduledExecutorService.scheduleAtFixedRate(new Runnable() { @Override public void run() { // 从命名服务器拉取话题信息  MQClientInstance.this.updateTopicRouteInfoFromNameServer(); } }, 10, this.clientConfig.getPollNameServerInterval(), TimeUnit.MILLISECONDS); } } 我们由 RocketMQ 消息发送流程 这篇文章知道 RocketMQ 在发送消息的时候，每条消息会以轮循的方式均衡地分发的不同 Broker 的不同队列中去。由此，消费者客户端从服务器命名服务器获取下来的便是话题的所有消息队列:</description>
    </item>
    
    <item>
      <title>代码整洁之道</title>
      <link>https://kunzhao.org/docs/books/clean_code/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/books/clean_code/</guid>
      <description>代码整洁之道 勒布朗法则：Later equals never.
随着混乱的增加，团队生产力也持续下降，趋近于零。生产力下降的时候，管理层只能增加更多的人手，期望提高生产力。
什么是整洁代码  我喜欢优雅和高效的代码。代码逻辑应当直截了当，叫缺陷难以隐藏；尽量减少依赖关系，使之便于维护；依据某种分层战略完善错误处理代码；性能调至最优，省得引诱别人做没规矩的优化，搞出一堆混乱来。整洁的代码只做好一件事。&amp;mdash; Bjarne Stroustrup，C++ 语言发明者
  整洁的代码应可由作者之外的开发者阅读和增补。它应有单元测试和验收测试。它使用有意义的命名。它只提供一种而非多种做一件事的途径。它只有尽量少的依赖关系，且要明确地定义和提供清晰、尽量少的 API。代码应通过其表面表达含义，因为不同的语言导致并非所有必需信息均可通过代码自身清晰表达。&amp;mdash; Dave Thomas, OTI 公司创始人
  整洁的代码总是看起来像是某位特别在意它的人写的。几乎没有改进的余地，代码作者什么都想到了。&amp;mdash; 《修改代码的艺术》作者
 有意义的命名 对于变量，如果其需要注释来补充，那就不算是名副其实。比如你需要定义一个变量，这个变量存储的是消逝的时间，其单位是天，那么下面是一些比较好的命名：
int elapsedTimeInDays; int daysSinceCreation; int daysSinceModification; int fileAgeInDays; 别用 accountList 来指一组账号，除非它真的是 List 类型，List 一词对于程序员有特殊意义，所以用 accountGroup 或 bunchOfAcounts，甚至用 accounts 都会好一些。
别说废话，废话都是冗余。假如你有一个 Product 类，如果还有一个 ProductInfo 或 ProductData 类，它们虽然名称不同，意思却无区别。Info 和 Data 就像 a、an 和 the 一样，是意义含混的废话。下面三个函数的命名，我们怎么知道应该调用哪个呢？
getActiveAccount(); getActiveAccounts(); getActiveAccountInfo(); 使用常量，WORK_DAYS_PER_WEEK 比数字 5 要好找的多。
 对于类名，其应该是名词或名词短语，如 Customer、WikiPage、Account 和 AddressParser，避免使用 Manager、Processor、Data 或 Info 这样的类名。类名不应当是动词。</description>
    </item>
    
    <item>
      <title>谷歌修改 Chromium 源码中的“黑白名单”术语</title>
      <link>https://kunzhao.org/docs/it-zone/2020-06/chrome-change-blacklist-to-blocklist/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/it-zone/2020-06/chrome-change-blacklist-to-blocklist/</guid>
      <description>谷歌修改 Chromium 源码中的“黑白名单”术语 日期：2020-06-09
 【为了种族中立，谷歌修改 Chromium 源码中的“黑白名单”术语】
国外正在进行的 Black Lives Matter 运动，谷歌已表态支持。
据外媒报道，Google 在修改 Chromium 源码中的有种族歧视色彩的术语，来消除微妙的种族主义形式。
 blacklist 改成 blocklist， whitelist 改成 allowlist；
 2019 年 10 月，Chromium 开源项目的官方代码风格指南中，新增了如何编写种族中立代码的内容。其中明确指出，Chrome 和 Chromium 开发人员应避免使用“黑名单”和“白名单”一词，而应使用中性术语“阻止名单”和“允许名单”。
其实早在 2018 年 5 月，Google 已开始着手删除普通用户在 Chrome 浏览器中能看到的“黑名单”和“白名单”。
但普通用户看不到的 Chrome / Chromium 源码中，还有很多很多，据统计约 2000 多处。</description>
    </item>
    
    <item>
      <title>Java 并发 - 锁</title>
      <link>https://kunzhao.org/posts/java-lock/</link>
      <pubDate>Sat, 13 May 2017 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/posts/java-lock/</guid>
      <description>&lt;p&gt;Java 世界中都有哪些锁？锁的分类？如何减少锁的竞争等问题。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>JVM 性能调优</title>
      <link>https://kunzhao.org/posts/jvm-optimization/</link>
      <pubDate>Tue, 02 May 2017 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/posts/jvm-optimization/</guid>
      <description>&lt;p&gt;JVM 如何进行性能调优？&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Best Time to Buy and Sell Stock Ⅳ</title>
      <link>https://kunzhao.org/docs/programmer-interview/algorithm/best-time-to-buy-and-sell-stock-4/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/programmer-interview/algorithm/best-time-to-buy-and-sell-stock-4/</guid>
      <description>Best Time to Buy and Sell Stock Ⅳ 题目 LeetCode 地址：Best Time to Buy and Sell Stock Ⅳ
有一个数组，第 i 个元素的值代表第 i 天的股票价格，如果你最多只能进行K次交易（某天买入一支股票，然后过几天卖掉），请问你能收获的最大利润是多少？
分析 参考 Best Time to Buy and Sell Stock 思路上状态机，状态机应用K次即可。
答案 // 最多交易 k 次 // https://leetcode.com/problems/best-time-to-buy-and-sell-stock-iv/ // public class BestTimetoBuyandSellStockIV { public int maxProfit(int k, int[] prices) { if (prices == null || prices.length &amp;lt;= 1 || k &amp;lt;= 0) { return 0; } if (k &amp;gt;= prices.</description>
    </item>
    
    <item>
      <title>Git 重置</title>
      <link>https://kunzhao.org/docs/tutorial/git/git-reset/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/tutorial/git/git-reset/</guid>
      <description>Git 重置 git reset 命令是 Git 最危险最容易误用的命令之一！一定要慎用，要清除地知道你自己在做什么！
Git reset 命令格式 git reset [--soft | --mixed | --hard] [&amp;lt;commit&amp;gt;] Git 提交历史记录 cat .git/refs/heads/master 显示的就是当前版本库的最新的 commitid
Git 重置与版本变化关系图 上述图，
 1 代表更新引用指向，即引用指向新的 commit 2 代表暂存区的内容与版本库保持一致 3 代表工作区的内容与暂存区保持一致  使用不同的参数，执行的操作不一样：
 --hard 参数，上图 1、2、3 这三步全部执行 --soft 参数，上图 1 执行 --mixed 参数，上图 1、2 执行 不使用参数，等同于使用了 --mixed 参数  根据上述解释，我们来看几个例子：
彻底回退到上一次提交 git reset --hard HEAD^  HEAD^ 指：HEAD 的父提交，即上一次提交。注意 --hard 选项会将本地工作区的内容也恢复为上一次提交，且不可恢复，所以此命令慎用！！！
 彻底回退到某一次 commit 根据 commit id 回退到某一次的提交：</description>
    </item>
    
    <item>
      <title>JS 优化</title>
      <link>https://kunzhao.org/docs/tutorial/front-end-optimization-guide/js-optimization/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/tutorial/front-end-optimization-guide/js-optimization/</guid>
      <description>JS 优化 本文介绍常见的优化 JS、提升 JS 加载性能的优化方法！
提升加载性能 script 放入到 body 中 &amp;lt;script&amp;gt; 标签经常以下面的这种方式引入：
&amp;lt;script src=&amp;#34;script.js&amp;#34;&amp;gt;&amp;lt;/script&amp;gt; 当 HTML 解析器看到这一行代码时，就会请求获取脚本，并执行脚本。一旦这个过程完成，解析就可以继续，剩下的 HTML 也可以被分析。所以你可以想象，这个操作会对页面的加载时间产生多么大的影响。如果脚本加载的时间比预期的稍长，例如，如果网络有点慢，或者如果您在移动设备上，并且网速特别慢，则在加载和执行脚本之前，访问者可能会看到一个空白页。
所以推荐将 script 标签从 &amp;lt;head&amp;gt; 位置挪到 &amp;lt;/body&amp;gt; 标签前。如果你这样做了，脚本在所有页面都被解析和加载之后才会加载和执行，这是对 &amp;lt;head&amp;gt; 替代方案的巨大改进。
&amp;lt;script defer src=&amp;#34;script.js&amp;#34;&amp;gt;&amp;lt;/script&amp;gt; Async 和 Defer 如果不考虑兼容旧浏览器，那么 async 和 defer 这两个布尔属性值，会是提升页面加载速度的更好选择：
&amp;lt;script async src=&amp;#34;script.js&amp;#34;&amp;gt;&amp;lt;/script&amp;gt; &amp;lt;script defer src=&amp;#34;script.js&amp;#34;&amp;gt;&amp;lt;/script&amp;gt; 这两个属性都可以达到异步加载和执行 script 标签的目的，如果同时指定了两个，那么 async 优先级高一点，老一点的浏览器不支持 async 会降级到 defer。这些属性只有在页面的 &amp;lt;head&amp;gt; 部分使用 &amp;lt;script&amp;gt; 时才有意义，如果像我们上面看到的那样将脚本放在 &amp;lt;body&amp;gt; 中，则这些属性是无用的。
使用 async 会阻塞 HTML 的解析：
使用 defer 并不会阻塞 HTML 的解析：</description>
    </item>
    
    <item>
      <title>RocketMQ 消息过滤流程</title>
      <link>https://kunzhao.org/docs/rocketmq/rocketmq-message-filter-flow/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/rocketmq/rocketmq-message-filter-flow/</guid>
      <description>RocketMQ 消息过滤流程 讲述 RocketMQ 消息过滤流程
一、消息过滤类型 Producer 在发送消息的时候可以指定消息的标签类型，还可以为每一个消息添加一个或者多个额外的属性:
// 指定标签 Message msg = new Message(&amp;#34;TopicTest&amp;#34;, &amp;#34;TagA&amp;#34;, (&amp;#34;Hello RocketMQ&amp;#34;).getBytes(RemotingHelper.DEFAULT_CHARSET)); // 添加属性 a msg.putUserProperty(&amp;#34;a&amp;#34;, 5); 根据标签和属性的不同，RocketMQ 客户端在消费消息的时候有三种消息过滤类型:
(1) 标签匹配 consumer.subscribe(&amp;#34;TopicTest&amp;#34;, &amp;#34;TagA | TagB | TagC&amp;#34;); (2) SQL 匹配 consumer.subscribe(&amp;#34;TopicTest&amp;#34;, MessageSelector.bySql( &amp;#34;(TAGS is not null and TAGS in (&amp;#39;TagA&amp;#39;, &amp;#39;TagB&amp;#39;))&amp;#34; + &amp;#34;and (a is not null and a between 0 3)&amp;#34;)); (3) 自定义匹配 客户端实现 MessageFilter 类，自定义过滤逻辑:
ClassLoader classLoader = Thread.currentThread().getContextClassLoader(); File classFile = new File(classLoader.</description>
    </item>
    
    <item>
      <title>ssh</title>
      <link>https://kunzhao.org/docs/tutorial/unix-command/ssh/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/tutorial/unix-command/ssh/</guid>
      <description>ssh 本文展示了一些常见的 ssh 命令，了解一些 ssh 技巧将有利于任何系统管理员、网络工程师或安全专业人员。
连接远程主机 localhost:~$ ssh -v -p 22 -C neo@remoteserver  -v：打印 debug 日志信息，用于打印连接时候的一些日志。 -p 22：指定连接远程主机的哪个端口，默认情况下，不用指定，因为 ssh 默认端口就是 22。编辑 sshd_config 文件，可以修改默认的 ssh 的监听端口。 -C：传输数据的时候，是否对数据启用压缩。 neo@remoteserver：neo 代表远程主机的用户名，remoteserver 代表远程主机的 IP 或者域名。添加 -4 选项，可以只连接 IPv4 连接；添加 -6 选项，只连接 IPv6 连接。  拷贝文件到远程服务器 远程拷贝文件的命令 scp 建立在 ssh 命令之上：
localhost:~$ scp mypic.png neo@remoteserver:/media/data/mypic_2.png  mypic.png：代表本地电脑上的图片 /media/data/mypic_2.png：代表你想把图片拷贝到远程主机的哪个路径  流量代理 SSH 代理特性被放在第1位是有充分理由的。它的功能比许多用户意识到的要强大得多，它允许您使用几乎任何应用程序访问远程服务器可以访问的任何系统。ssh客户机可以仅用一行代码，就可以使用SOCKS代理服务器在连接隧道上通信。
localhost:~$ ssh -D 8888 user@remoteserver localhost:~$ netstat -pan | grep 8888 tcp 0 0 127.</description>
    </item>
    
    <item>
      <title>企业 IT 架构转型之道</title>
      <link>https://kunzhao.org/docs/books/the_transformation_of_enterprise_it_architecture/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/books/the_transformation_of_enterprise_it_architecture/</guid>
      <description>企业 IT 架构转型之道 共享服务体系搭建 SOA 的主要特性：
 面向服务的分布式计算。 服务间松散耦合。 支持服务的组装。 服务注册和自动发现。 以服务契约方式定义服务交互方式。  基于 “中心化” 的 ESB 服务调用方式  “去中心化” 服务架构调用方式   数据拆分实现数据库能力线性扩展 数据库的读写分离 读写分离基本原理是让主数据库处理事务性增、改、删（INSERT、UPDATE、DELETE）操作，而从数据库专门负责处理查询（SELECT）操作，在数据库的后台会把事务性操作导致的主数据库中的数据变更同步到集群中的从数据库。
数据库分库分表 采用分库分表的方式将业务数据拆分后，如果每一条SQL语句中都能带有分库分表键，SQL语句的执行效率最高：
但不是所有的业务场景在进行数据库访问时每次都能带分库分表键的。比如在买家中心的界面中，要显示买家test1过去三个月的订单列表信息。此时就出现了我们所说的全表扫描，一条SQL语句同时被推送到后端所有数据库中运行。如果是高并发情况下同时请求的话，为了数据库整体的扩展能力，则要考虑下面描述的异构索引手段来避免这样的情况发生。对于在内存中要进行大数据量聚合操作和计算的SQL请求，如果这类SQL的不是大量并发或频繁调用的话，平台本身的性能影响也不会太大，如果这类SQL请求有并发或频繁访问的要求，则要考虑采用其他的平台来满足这一类场景的要求，比如Hadoop这类做大数据量离线分析的产品，如果应用对请求的实时性要求比较高，则可采用如内存数据库或HBase这类平台。
所谓“异构索引表”，就是采用异步机制将原表内的每一次创建或更新，都换另一个维度保存一份完整的数据表或索引表。本质上这是互联网公司很多时候都采用的一个解决思路：“拿空间换时间”。也就是应用在创建或更新一条按照订单ID为分库分表键的订单数据时，也会再保存一份按照买家ID为分库分表键的订单索引数据。
基于订单索引表实现买家订单列表查看流程示意：
实现对数据的异步索引创建有多种实现方式，其中一种就是从数据库层采用 binlog 数据复制的方式实现。
采用数据异构索引的方式在实战中基本能解决和避免90%以上的跨join或全表扫描的情况，是在分布式数据场景下，提升数据库服务性能和处理吞吐能力的最有效技术手段。但在某些场景下，比如淘宝商品的搜索和高级搜索，因为商品搜索几乎是访问淘宝用户都会进行的操作，所以调用非常频繁，如果采用SQL语句的方式在商品数据库进行全表扫描的操作，则必然对数据库的整体性能和数据库连接资源带来巨大的压力。面对此类场景，我们不建议采用数据库的方式提供这样的搜索服务，而是采用专业的搜索引擎平台来行使这样的职能，如Lucene、Solr、ElasticSearch 等。
异步化与缓存原则 业务流程异步化 以淘宝的交易订单为例，目前淘宝的订单创建流程需要调用超过200个服务，就算所有服务的调用时间都控制在20ms内返回结果，整个订单创建的时间也会超过4s：
以异步化方式将上述交易创建过程中，对于有严格先后调用关系的服务保持顺序执行，对于能够同步执行的所有服务均采用异步化方式处理。阿里巴巴内部使用消息中间件的方式实现了业务异步化，提高了服务的并发处理，从而大大减少整个业务请求处理所花的时间。
数据库事务异步化 扣款是一个要求事务一致性的典型场景，稍微数据不一致带来的后果都可能是成百上千（可能在某些借款项目中达到上百万的金额）的金额差异。所以在传统的实现方式中，整个扣款的逻辑代码都是在一个大的事务中，通过数据库的事务特性来实现这样一个稍显复杂的业务一致性。
数据库事务的异步化：通俗来说，就是将大事务拆分成小事务，降低数据库的资源被长时间事务锁占用而造成的数据库瓶颈，就能大大提升平台的处理吞吐量和事务操作的响应时间。
在实际的改造方案中，同样基于消息服务提供的异步机制，将整个还款流程进行异步化的处理：
事务与柔性事务 不管是业务流程异步化，还是数据库事务异步化，其实都面临一个如何保证业务事务一致性的问题。面对这个问题目前并没有完美的解决方案，本节会介绍淘宝是如何对订单创建场景实现业务一致的实践，以及近一两年来我们在分布式事务上所作出的创新尝试，供各技术同行在解决此类问题时借鉴和参考。
关于数据库事务，核心是体现数据库ACID（原子性、一致性、隔离性和持久性）属性，即作为一个事务中包含的所有逻辑处理操作在作用到数据库上时，只有这个事务中所有的操作都成功，对数据库的修改才会永久更新到数据库中，任何一个操作失败，对于数据库之前的修改都会失效。在分布式领域，基于CAP理论和在其基础上延伸出的BASE理论，有人提出了“柔性事务”的概念。
（1）CAP理论
一个分布式系统最多只能同时满足一致性（Consistency）、可用性（Availability）和分区容错性（Partition tolerance）这三项中的两项。“一致性”指更新操作成功并返回客户端完成后，所有节点在同一时间的数据完全一致。“可用性”指用户在访问数据时可以得到及时的响应。“分区容错性”指分布式系统在遇到某节点或网络分区故障的时候，仍然能够对外提供满足一致性和可用性的服务。
CAP定理并不意味着所有系统的设计都必须抛弃三个要素之中的一个。CAP三者可以在一定程度上衡量，并不是非黑即白的，例如可用性从0%到100%有不同等级。
（2）BASE理论
BASE理论是对CAP理论的延伸，核心思想是即使无法做到强一致性（Strong Consistency, CAP的一致性就是强一致性），但应用可以采用适合的方式达到最终一致性（EventualConsitency）。BASE是指基本可用（Basically Available）、柔性状态（Soft State）、最终一致性（Eventual Consistency）。
  “基本可用”是指分布式系统在出现故障的时候，允许损失部分可用性，即保证核心可用。电商大促时，为了应对访问量激增，部分用户可能会被引导到降级页面，服务层也可能只提供降级服务。这就是损失部分可用性的体现。
  “柔性状态”是指允许系统存在中间状态，而该中间状态不会影响系统整体可用性。分布式存储中一般一份数据至少会有三个副本，允许不同节点间副本同步的延时就是柔性状态的体现。MySQLReplication的异步复制也是一种柔性状态体现。
  “最终一致性”是指系统中的所有数据副本经过一定时间后，最终能够达到一致的状态。弱一致性和强一致性相反，最终一致性是弱一致性的一种特殊情况。
  对于如何实现高可用，我们认为：</description>
    </item>
    
    <item>
      <title>Best Time to Buy and Sell Stock With Cooldown</title>
      <link>https://kunzhao.org/docs/programmer-interview/algorithm/best-time-to-buy-and-sell-stock-with-cooldown/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/programmer-interview/algorithm/best-time-to-buy-and-sell-stock-with-cooldown/</guid>
      <description>Best Time to Buy and Sell Stock With Cooldown 题目 LeetCode 地址：Best Time to Buy and Sell Stock With Cooldown
有一个数组，第 i 个元素的值代表第 i 天的股票价格，如果你最多只能进行任意次交易（某天买入一支股票，然后过几天卖掉），你卖出一只股票后，接下来的一天不能买，必须要到后天才能买。也就是说有冷静期1天。请问你能收获的最大利润是多少？
答案 // https://leetcode.com/problems/best-time-to-buy-and-sell-stock-with-cooldown/ // 交易任意多次，只不过 buy sell 之后的第二天必须 cooldown 隔天才能再次 buy // // https://leetcode.com/problems/best-time-to-buy-and-sell-stock-with-cooldown/discuss/240277/Java-solution-in-Chinese public class BestTimetoBuyandSellStockwithCooldown { public int maxProfit(int[] prices) { if (prices == null || prices.length &amp;lt;= 1) { return 0; } // 买入只能是从前天买入 buy[i] = sell[i - 2] - prices[i];  // 卖出可以昨天卖出 sell[i] = buy[i - 1] + prices[i];  int[] sell = new int[prices.</description>
    </item>
    
    <item>
      <title>Git checkout</title>
      <link>https://kunzhao.org/docs/tutorial/git/git-checkout/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/tutorial/git/git-checkout/</guid>
      <description>Git checkout git checkout 检出命令，可以用来切换分支、查看某个 commit 的代码等。
detached HEAD 当你执行 git checkout [commitId] 时，你会看到下面的文件警告：
Note: switching to &#39;467dd6520&#39;. You are in &#39;detached HEAD&#39; state. You can look around, make experimental changes and commit them, and you can discard any commits you make in this state without impacting any branches by switching back to a branch. If you want to create a new branch to retain commits you create, you may do so (now or later) by using -c with the switch command.</description>
    </item>
    
    <item>
      <title>Redis 5 设计与源码分析</title>
      <link>https://kunzhao.org/docs/books/redis_5_source_code/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/books/redis_5_source_code/</guid>
      <description>Redis 5 设计与源码分析 Redis 5.0 新特性  新增Streams数据类型，这是 Redis 5.0 最重要的改进之一。可以把Streams当作消息队列。 新的模块API、定时器、集群及字典。 RDB中持久化存储LFU和LRU的信息。 将集群管理功能完全用C语言集成到redis-cli中，Redis 3.x 和 Redis4.x 的集群管理是通过Ruby脚本实现的。 有序集合新增命令ZPOPMIN/ZPOPMAX。 改进HyperLogLog的实现。 新增Client Unblock和Client ID。 新增LOLWUT命令。 Redis主从复制中的从不再称为Slave，改称Replicas。 Redis 5.0引入动态哈希，以平衡CPU的使用率和相应性能，可以通过配置文件进行配置。Redis 5.0默认使用动态哈希。 Redis核心代码进行了部分重构和优化。  简单动态字符串 （1） 长度小于 32 的短字符串
struct __attribute__ ((__packed__))sdshdr5 { unsigned char flags; // 低 3 位存储类型，高 5 位存储长度  char buf[]; // 柔性数组 } 结构如下：
（2） 长度大于 31 的字符串
此处仅展示一个示例：
struct __attribute__ ((__packed__))sdshdr8 { uint8_t len; // 已使用长度  uint8_t alloc; // 已分配的字节总长度  unsigned char flags; // 低 3 位存储类型  char buf[]; // 柔性数组 } SDS 读操作的复杂度多为O(1)，直接读取成员变量；涉及修改的写操作，则可能会触发扩容。</description>
    </item>
    
    <item>
      <title>RocketMQ 消息索引流程</title>
      <link>https://kunzhao.org/docs/rocketmq/rocketmq-message-indexing-flow/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/rocketmq/rocketmq-message-indexing-flow/</guid>
      <description>RocketMQ 消息索引流程 讲述 RocketMQ 消息索引服务
一、消息查询方式 对于 Producer 发送到 Broker 服务器的消息，RocketMQ 支持多种方式来方便地查询消息:
(1) 根据键查询消息 如下所示，在构建消息的时候，指定了这条消息的键为 “OrderID001”:
Message msg = new Message(&amp;#34;TopicTest&amp;#34;, &amp;#34;TagA&amp;#34;, &amp;#34;OrderID001&amp;#34;, // Keys  &amp;#34;Hello world&amp;#34;.getBytes(RemotingHelper.DEFAULT_CHARSET)); 那么，当这条消息发送成功后，我们可以使用 queryMsgByKey 命令查询到这条消息的详细信息:
MQAdminStartup.main(new String[] { &amp;#34;queryMsgByKey&amp;#34;, &amp;#34;-n&amp;#34;, &amp;#34;localhost:9876&amp;#34;, &amp;#34;-t&amp;#34;, &amp;#34;TopicTest&amp;#34;, &amp;#34;-k&amp;#34;, &amp;#34;OrderID001&amp;#34; }); (2) 根据ID(偏移量)查询消息 消息在发送成功之后，其返回的 SendResult 类中包含了这条消息的唯一偏移量 ID (注意此处指的是 offsetMsgId):
用户可以使用 queryMsgById 命令查询这条消息的详细信息:
MQAdminStartup.main(new String[] { &amp;#34;queryMsgById&amp;#34;, &amp;#34;-n&amp;#34;, &amp;#34;localhost:9876&amp;#34;, &amp;#34;-i&amp;#34;, &amp;#34;0A6C73D900002A9F0000000000004010&amp;#34; }); (3) 根据唯一键查询消息 消息在发送成功之后，其返回的 SendResult 类中包含了这条消息的唯一 ID:
用户可以使用 queryMsgByUniqueKey 命令查询这条消息的详细信息:</description>
    </item>
    
    <item>
      <title>top</title>
      <link>https://kunzhao.org/docs/tutorial/unix-command/top/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/tutorial/unix-command/top/</guid>
      <description>top 本文介绍 top 命令的常见例子！top 可以显示系统运行的进程和资源等情况的有用信息。
基础展示 top 上述命令将会显示：
 红色区域：系统的统计信息 蓝色区域：系统所有的进程列表信息  默认情况下，top 命令每隔 3 秒刷新一次。
 红色区域
 第一行展示的是：时间、电脑运行多久了、多少人登录着电脑、过去 1、5、15 分钟电脑的平均负载。 第二行展示的是，任务的总数量，以及各个状态的任务数量。 第三行展示的是 CPU 的一些信息。  CPU 信息的每一列的含义：
 us：用户态 CPU 占用处理器的总时间 sy：内核态 CPU 占用处理器的总时间 ni：使用手动设置的 nice 值执行进程所花费的时间。 id：CPU空闲时间的数量。 wa：CPU等待I/O完成所花费的时间。 hi：维护硬件中断所花费的时间。 si：维护软件中断所花费的时间。 st：由于运行虚拟机而损失的时间（“窃取时间”）。  第四行显示物理内存的总量（以kibibytes为单位），以及空闲、使用、缓冲或缓存的内存量。 第五行显示交换内存的总量（也以kibibytes为单位），以及空闲、使用和可用的内存量。后者包括预期可以从缓存中恢复的内存。
 蓝色区域的，进程列表中的各个列的信息如下：
 PID：进程ID。 USER：进程的所有者。 PR：流程优先级。 NI：这个过程很有价值。 VIRT：进程使用的虚拟内存量。 RES：进程使用的常驻内存量。 SHR：进程使用的共享内存量。 S： 进程的状态。（有关此字段可以采用的值，请参见下面的列表）。 %CPU：自上次更新以来进程使用的CPU时间的份额。 %MEM：使用的物理内存份额。 TIME+：任务使用的总CPU时间（以百分之一秒为单位）。 COMMAND：命令名或命令行（名称+选项）。  内存值以kibibytes为单位显示。进程的状态可以是以下之一：
 D： 不间断睡眠 R： 跑步 S： 睡觉 T： 跟踪（停止） Z： 僵尸  按 Q 退出 top 命令。</description>
    </item>
    
    <item>
      <title>cat</title>
      <link>https://kunzhao.org/docs/tutorial/unix-command/cat/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/tutorial/unix-command/cat/</guid>
      <description>cat cat 命令的常见用法！
查看文件内容 要使用 cat 显示文件的内容，只需传递要查看的一个或多个文件的名称。文件内容将打印到标准输出并在终端中可见。下面的示例假设文件foo.txt 文件只有一行“Hello World”。
cat foo.txt Hello world 如果文件的内容很长，则全部内容将写入终端。在这种情况下，很难找到文件的某些部分。在寻找特定内容时，grep 可能是一个更好的选择。
将一个文件的内容写入到另外一个文件 使用cat工具结合重定向，可以将文件内容写入新的文件。下面的示例假设文件foo.txt文件只有一行“Hello World”并将其写入bar.txt文件.
cat foo.txt &amp;gt; bar.txt cat bar.txt Hello world 如果 bar.txt 文件不存在，那么 cat 工具会自动创建 bar.txt 文件。
将一个文件的内容追加到另外一个文件 cat wine.txt &amp;gt;&amp;gt; beer.txt 多个文件合并为一个 cat *.txt &amp;gt; combined.txt 上述命令行，将当前目录以 .txt 结尾的文件，合并到 combined.txt 文件中。
cat 输出显示行号 -n 参数可以显示文件的行号：
cat -n /usr/share/dict/words 1 A 2 a 3 aa 4 aal 5 aalii 输出的每行行尾显示 $ 符号 cat -e test hello everyone, how do you do?</description>
    </item>
    
    <item>
      <title>Git 保存当前进度</title>
      <link>https://kunzhao.org/docs/tutorial/git/git-stash/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/tutorial/git/git-stash/</guid>
      <description>Git 保存当前进度 git stash 命令可以帮助我们保存和恢复日常的工作进度。
应用场景 你正在 dev 分支上开发项目的某个新功能，开发到一半的时候，master 分支的代码（线上正在运行的代码）出现了一个 bug，需要紧急修复。你现在需要从 dev 分支切换到 master 分支修 BUG，而你现在在 dev 分支正在开发的代码也不可能开发到一半就要 push 上去，此时就可以先在 dev 分支把代码给 stash 起来，也就是暂存起来，然后再切换到 master 分支。等 master 分支修复好了后，再切回 dev 分支，执行 stash pop 把这部分代码给恢复出来即可。
下面示例几个基础用法：
保存当前工作进度 git stash 显示进度列表 git stash list stash 就是一个栈数据结构管理的，你可以保存多次工作进度，并且恢复的时候也可以选择恢复哪个。
恢复进度 # 恢复最新保存的工作进度，并将工作进度从 stash 列表中清除 git stash pop # 恢复某个指定的 stash (git stash list 可以看到) git stash pop [&amp;lt;stash&amp;gt;] 命令 git stash apply [&amp;lt;stash&amp;gt;] 同 git stash pop，只是不会从 stash 列表中删除恢复的进度。</description>
    </item>
    
    <item>
      <title>RocketMQ 定时消息和重试消息</title>
      <link>https://kunzhao.org/docs/rocketmq/rocketmq-timing-message-and-retry-message/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/rocketmq/rocketmq-timing-message-and-retry-message/</guid>
      <description>RocketMQ 定时消息和重试消息 讲述 RocketMQ 定时消息和重试消息
一、定时消息概述 RocketMQ 支持 Producer 端发送定时消息，即该消息被发送之后，到一段时间之后才能被 Consumer 消费者端消费。但是当前开源版本的 RocketMQ 所支持的定时时间是有限的、不同级别的精度的时间，并不是任意无限制的定时时间。因此在每条消息上设置定时时间的 API 叫做 setDelayTimeLevel，而非 setDelayTime 这样的命名:
Message msg = new Message(&amp;#34;TopicTest&amp;#34; /* Topic */, &amp;#34;TagA&amp;#34; /* Tag */, (&amp;#34;Hello RocketMQ &amp;#34; + i).getBytes(RemotingHelper.DEFAULT_CHARSET) /* Message body */); msg.setDelayTimeLevel(i + 1); 默认 Broker 服务器端有 18 个定时级别:
public class MessageStoreConfig { private String messageDelayLevel = &amp;#34;1s 5s 10s 30s 1m 2m 3m 4m 5m 6m 7m 8m 9m 10m 20m 30m 1h 2h&amp;#34;; } 这 18 个定时级别在服务器端启动的时候，会被解析并放置到表 delayLevelTable 中。解析的过程就是上述字符串按照空格拆分开，然后根据时间单位的不同再进一步进行计算，得到最终的毫秒时间。级别就是根据这些毫秒时间的顺序而确定的，例如上述 1s 延迟就是级别 1， 5s 延迟就是级别 2，以此类推:</description>
    </item>
    
    <item>
      <title>深度剖析 Apache Dubbo 核心技术</title>
      <link>https://kunzhao.org/docs/books/in-depth_analysis_of_the_core_technology_of_apache_dubbo/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/books/in-depth_analysis_of_the_core_technology_of_apache_dubbo/</guid>
      <description>深度剖析 Apache Dubbo 核心技术 SPI 扩展 Dubbo 支持扩展的核心接口上，都会通过类似 @SPI(&amp;quot;dubbo&amp;quot;) 这样的注解，来标识当前接口的默认实现。如果你想替换掉这个默认实现，那么需要两个步骤。第一，实现 Protocol 接口，然后在 META-INF/dubbo 目录下创建一个名字为 org.apache.dubbo.rpc.Protocol 的文本文件。这个 META-INF 目录如果使用的是 IDEA 开发，那么其应该放到 resources 目录下的顶层，这样打 jar 包的时候，其也会被复制到 jar 包的第一级目录。内容如下：
myProtocol = com.zk.MyProtocol 第二，需要在 XML 配置文件中，声明使用这个扩展实现：
&amp;lt;dubbo:protocol name=&amp;#34;myProtocol&amp;#34;&amp;gt; 其实 JDK 本身也提供了 SPI 扩展，Dubbo 之所以没有使用默认提供的实现，是因为：
 JDK 标准的 SPI 一次性实例化扩展点的所有实现，如果有些没有使用到，那么会浪费资源。 扩展点加载失败的异常提示不是很好。 增强了 Ioc 和 AOP 的支持。  性能 Dubbo 会给每个服务提供者的实现类生产一个 Wrapper 类，这个 Wrapper 类里面最终调用服务提供者的接口实现类，Wrapper 类的存在是为了减少反射的调用。当服务提供方收到消费方发来的请求后，需要根据消费者传递过来的方法名和参数反射调用服务提供者的实现类，而反射本身是有性能开销的，Dubbo 把每个服务提供者的实现类通过 JavaAssist 包装为一个 Wrapper 类以减少反射调用开销。
其实就是由反射改为了比较方法名称，然后调用，伪代码如下：
GreetingServiceImpl impl = (GreetingServiceImpl) object; if (&amp;#34;sayHello&amp;#34;.</description>
    </item>
    
    <item>
      <title>Git 多次提交合并成一次提交</title>
      <link>https://kunzhao.org/docs/tutorial/git/merge-multiple-commit/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/tutorial/git/merge-multiple-commit/</guid>
      <description>Git 多次提交合并成一次提交 你在 dev 分支上开发某个功能，在本地执行了三次 commit，注意这三次 commit 都没有 push 到远程分支，都只是在本地存在。现在你想要在 push 之前，将你本地的这多个 commit 合并成一个 commit，请问应该怎么做？
答案是：git rebase -i HEAD~N，N 代表你想把最近的几条 commitId 记录合并。具体操作步骤如下：
查看提交记录 git log 查看提交记录：
871adf OK, feature Z is fully implemented --- newer commit --┐ 0c3317 Whoops, not yet... | 87871a I&#39;m ready! | 643d0e Code cleanup |-- Join these into one afb581 Fix this and that | 4e9baa Cool implementation | d94e78 Prepare the workbench for feature Z -------------------┘ 6394dc Feature Y --- older commit  假设 6394dc 提交已经 push 上去了 你现在想把 d94e78 ~ 871adf 这几个 commit 合并一下  即最终你再次执行 git log 想要看到的效果如下：</description>
    </item>
    
    <item>
      <title>RocketMQ 主备同步</title>
      <link>https://kunzhao.org/docs/rocketmq/rocketmq-master-slave-sync/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/rocketmq/rocketmq-master-slave-sync/</guid>
      <description>RocketMQ 主备同步 介绍 RocketMQ 的主备同步机制
一、简介 RocketMQ 通过 Master-Slave 主备机制，来实现整个系统的高可用，具体表现在:
 Master 磁盘坏掉，Slave 依然保存了一份 Master 宕机，不影响消费者继续消费  二、搭建环境 我们在一台机器上搭建一个 Master 一个 Slave 的环境:
为了能够将 Master 和 Slave 搭建在同一台计算机上，我们除了需要将 Broker 的角色设置为 SLAVE ，还需要为其指定单独的 brokerId、 storePathRootDir、 storePathCommitLog。
// SLAVE 角色 messageStoreConfig.setBrokerRole(BrokerRole.SLAVE); // 一个机器如果要启动多个 Broker，那么每个 Broker 的 store 根目录必须不同 messageStoreConfig.setStorePathRootDir(storePathRootDir); // 一个机器如果要启动多个 Broker，那么每个 Broker 的 storePathCommitLog 根目录必须不同 messageStoreConfig.setStorePathCommitLog(storePathCommitLog); // 设置 Slave 的 Master HA 地址 messageStoreConfig.setHaMasterAddress(&amp;#34;localhost:10912&amp;#34;); // SLAVE 角色的 brokerId 必须大于 0 brokerConfig.setBrokerId(1); 注意 Slave 和 Master 的 brokerName 必须一致，即它们必须处于同一个 BrokerData 数据结构里面。实际上在做了如上的修改之后， Slave 和 Master 依旧不能同时运行在同一台机器上，因为 Slave 本身也可以称为 Master，接受来自其他 Slave 的请求，因此当运行 Slave 的时候，需要将 HAService 里面的启动 AcceptSocketService 运行的相关方法注释掉。</description>
    </item>
    
    <item>
      <title>人人都是架构师 (一)</title>
      <link>https://kunzhao.org/docs/books/everyone-is-architect/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/books/everyone-is-architect/</guid>
      <description>人人都是架构师 - 分布式系统架构落地与瓶颈突破 分布式系统应对高并发、大流量的常用手段：
 扩容 动静分离 缓存 服务降级 限流  限流 常见算法：
 令牌桶，Nginx 限流模块用的是这个：限制的是流量的平均流入速率，允许一定程度上的突发流量。 漏桶：限制的是流出速率，并且这个速率还是保持不变的，不允许突发流量。  Nginx 限流 http { # 每个 IP 的 session 空间大小 limit_zone one $binary_remote_addr 20m; # 每个 IP 每秒允许发起的请求数 limit_req_zone $binary_remote_addr zone=req_one:20m rate=10r/s; # 每个 IP 能够发起的并发连接数 limit_conn one 10; # 缓存还没有来得及处理的请求 limit_req zone=req_one burst=100; } 消峰  活动分时段 答题验证  高并发读 &amp;ldquo;马某出轨王某&amp;rdquo;、&amp;ldquo;iPhone SE 2020 发布&amp;rdquo; 等这种热点新闻的 key 会始终落在同一个缓存节点上，分布式缓存一定会出现单点瓶颈，其资源连接容易瞬间耗尽。有如下两种方案解决这个问题：
 基于 Redis 的集群多写多读方案。  多写如何保持一致性：将 Key 配置在 ZooKeeper，客户端监听 ZNode，一旦变化，全量更新本地持有的 Key   LocalCache 结合 Redis 集群的多级 Cache 方案。  LocalCache 拉取下来的商品数量有 5 个，但是实际上只有 4 个了，怎么解决？对于这种读场景，允许接受一定程度上的数据脏读，最终扣减库存的时候再提示商品已经售罄即可。    实时热点自动发现 交易系统产生的相关数据、上游系统中埋点上报的数据这两个，异步写入日志，对日志进行次数统计和热点分析</description>
    </item>
    
    <item>
      <title>Git 分支</title>
      <link>https://kunzhao.org/docs/tutorial/git/git-branch/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/tutorial/git/git-branch/</guid>
      <description>Git 分支 Git 的分支管理命令：git branch。
示例 列举本地所有分支 git branch  当前分支会用 * 标识出来，也会用特别的颜色标识出来
 列举本地和远程所有分支 git branch -a 创建分支 git branch &amp;lt;branchName&amp;gt; 删除分支 # 删除时，会检查此分支是否已经合并到其它分支，否则拒绝删除 git branch -d &amp;lt;branchName&amp;gt; # 不管有没有合并到其它分支，都强制删除分支 git branch -D &amp;lt;branchName&amp;gt; 重命名分支 # 如果版本库已经存在 newbranch，则拒绝重命名 git branch -m &amp;lt;oldbranch&amp;gt; &amp;lt;newbranch&amp;gt; # 如果版本库已经存在 newbranch，则强制重命名 git branch -M &amp;lt;oldbranch&amp;gt; &amp;lt;newbranch&amp;gt; 创建并切换分支 git checkout -b &amp;lt;new_branch&amp;gt; 扫描下面二维码在手机端阅读：</description>
    </item>
    
    <item>
      <title>编写可读代码的艺术</title>
      <link>https://kunzhao.org/docs/books/the-art-of-readable-code/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/books/the-art-of-readable-code/</guid>
      <description>编写可读代码的艺术 代码应当易于理解 Q: 可读性基本定理？
 可读性基本原理：使别人理解它所需的时间最小化。
 Q: 代码总是越小越好？
 减少代码行数是一个好目标，但是把理解代码所需的时间最小化是一个更好的目标。
 表面层次的改进 把信息装到名字里 （1）选择专业的词
def getPage(url) 上述例子，get 词没有表达出很多信息。从本地缓存得到一个页面，还是从数据库中，或者从互联网中？如果从互联网中，应该使用更为专业的名字：fetchPage(url) 或 downloadPage(url)。
class BinaryTree { int size(); } 上述例子，size() 返回的是什么？树的高度，节点树，还是树在内存中所占的空间？size() 没有承载更多的信息，更专业的词汇是 height()、numNodes() 或 memoryBytes()。
英语是一门丰富的语言，有很多词汇可以选择。下面是一些例子，这些单词更富有表现力，可能更适合你的语境：
   单词 更多选择     send deliver、dispatch、announce、distribute、route   find search、extract、locate、recover   start launch、create、begin、open   make create、set up、build、generate、compose、add、new    （2）避免像 tmp 和 retval 这样泛泛的名字
除非你有更好的理由！
（3）用具体的名字代替抽象的名字
searchCanStart() 比 canListenOnPort() 更具体一些，这个名字直接描述了方法所做的事情。</description>
    </item>
    
    <item>
      <title>Git 分支合并</title>
      <link>https://kunzhao.org/docs/tutorial/git/git-merge-branch/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/tutorial/git/git-merge-branch/</guid>
      <description>Git 分支合并 某个功能在开发分支上开发完毕后，需要合并到 master 分支，合并分支有两种方式：
 git merge git rebase  分支现状展示  从 master 分支的 A 提交点，拉取了分支 user2/i18n user2/i18n 的功能开发总共有两个 commit：E 和 F master 在 A 提交点之后，又有 B、C 和 D 这三个提交被合入进来  Git merge 我们使用 git merge 来合并 user2/i18n 分支到 master 分支上：
# 切换到 master 分支 git checkout master # 合并 user2/i18n 分支 git merge user2/i18n 合并后的分支示意图：
Git rebase 我们使用 git rebase 来合并 user2/i18n 到 master 分支上：
git checkout user2/i18n git rebase master # 如果有冲突，则需要解决冲突 # 解决完冲突，使用 git add -u 将完成冲突解决的文件加入到暂存区 # git rebase --continue # 直接推送，用本地的 user2/i18n 分支更新远程的 master 分支即可 git push origin user2/i18n:master rebase 之后的分支示例：</description>
    </item>
    
    <item>
      <title>炒股的艺术</title>
      <link>https://kunzhao.org/docs/books/the-wisdom-of-trading-stocks/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/books/the-wisdom-of-trading-stocks/</guid>
      <description>炒股的艺术  如果要我用一句话解释何以一般股民败多胜少，那就是：人性使然！说的全面些，就是这些永远不变的人性&amp;ndash;讨厌风险、急着发财、自以为是、赶潮跟风、因循守旧和耿于报复&amp;ndash;使股民难以逃避开股市的陷阱。说得简单些，就是好贪小便宜、吃不得小亏的心态使得一般股民几乎必然地成为了输家。
 炒股的挑战 炒股与人性 炒股最重要的原则就是止损。但人性是好贪小便宜，不肯吃小亏，只有不断地因为贪了小便宜却失去大便宜，不肯吃小亏最终却吃了大亏，你才能最终学会不贪小便宜，不怕吃小亏。
特殊的赌局 问问你自己喜欢做决定吗？喜欢独自为自己地决定负全部责任吗？对 99% 的人来说，答案是否定的。股市这一恒久的赌局却要求你每时每刻都要做理性的决定，并且为决定的结果负全部的责任！这就淘汰了一大部分股民，因为他们没有办法长期承受这样的心理能力。
一般股民何以失败 人性讨厌风险 纽约有位叫做夏皮诺的心理医生，请了一批人来做两个实验：
 实验一  选择：第一，75% 的机会得到 1000 美元，但有 25% 的机会什么都得不到；第二，确定得到 700 美元。结果 80% 的人选择了第二选择，大多数人宁愿少些，也要确定的利润。
 股民好获小利，买进的股票升了一点，便迫不及待地脱手。这只股票或许有 75% 继续上升地机会，但为了避免 25% 什么都得不到的可能性，股民宁可少赚些。任何炒过股的读者都明白，要用较出场价更高地价位重新入场是多么困难。股价一天比一天高，你只能做旁观者。
  实验二  选择：第一，75% 的机会付出 1000 美元，但有 25% 的机会什么都不付；第二，确定付出 700 美元。结果 75% 的人选择了第一选择。他们为了搏 25% 什么都不付的机会，从数学上讲多失去了 50 美元。
 一旦买进的股票跌了，股民便死皮赖脸不肯止损，想象出各种各样的理由说服自己下跌只是暂时的。其真正的原因只不过为了搏那 25% 可能全身而退的机会！结果是小亏慢慢积累成大亏。
 人的发财心太急 心一旦大了，行动上就开始缺少谨慎。首先我每次买股买得太多，其次止损止得太迟。我为此遭受了巨大的损失。
人好自以为是 一天结束的时候，股票以某一价钱收盘。你有没有思考过它代表了什么？它代表了股市的参与者在今天收市的时候对该股票的认同。
不要太固执己见，不要对自己的分析抱太大的信心。认真观察股市，不对时就认错。否则，你在这行生存的机会是不大的。
人好跟风 人好报复 在股市中，买进的股票跌了，你就再多买一点，因为第二次买的价钱较上次为低，所以平均进价摊低了。从心理上看，你的心态和赌场亏钱时一样。一方面你亏不起，另一方面你在报复股市，报复股市让你亏钱。同时内心希望，只要赢一手，就能连本带利全回来。因为平均进价摊低了，股票的小反弹就能提供你全身而退的机会。
这样的心态是极其有害的。股票跌的时候通常有它跌的理由，常常下跌的股票会越跌越低。这样被套牢，你就越陷越深，直到你心理无法承受的地步。一个致命的大亏损，常常就彻底淘汰了一位股民。
人总是迟疑不决，心怀侥幸 每个炒股人都会经过这个过程。20元买好股票，定好18元止损，当股票跌到18元时，你有没有想想再等等？或许股票马上反弹！股票又跌到16元，你会不会拍自己的脑壳说：“真该按定好的规矩办！18元时就走人；现若股票反弹5毛钱我就一定说再见。”
现股票跌到10元了，你准备怎么办？你会发毛吗？你会不会发狠：“老子这次拼了！现在就是不走，我倒要看看你最低会跌到什么地方？”
当然，最后的结局很少例外，通常是股票学校又多了位交了学费毕不了业的炒股
股票分析的基本知识 技术分析 升势：一浪比一浪高     朋友，你认为什么因素使投资者入市买股票？华尔街有过调查，使一般投资者入场买股票的原因最主要的就是因为股票在升！你明白吗？一般投资者入场买股票主要不是因为股票的成本收益比率低或红利高，而是因为股票在升！升！升！而投资人卖股票的最主要原因是因为股票在跌！在跌！</description>
    </item>
    
    <item>
      <title>Git 解决冲突</title>
      <link>https://kunzhao.org/docs/tutorial/git/git-fix-conflict/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/tutorial/git/git-fix-conflict/</guid>
      <description>Git 解决冲突 某个分支的代码想要合并到其它分支，可能会产生冲突，产生的原因就是这两个分支都对代码的同一个区域做了修改，Git 本身并不知道应该采用哪个修改最为合适，因此需要你来决定。
解决冲突 如下所示是冲突代码的示例：
 A 和 B 之间的代码，是你本地的代码所做的改动 B 和 C 之间的代码，是远程代码所做的改动  你的工作是重新编辑 A 到 C 区域之间的内容，去掉 &amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt; 、=======、&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt; 符号，重新编辑 A 和 C 之间的代码，以让整个项目运行起来。
编辑完之后，可以通过 git add 命令将冲突的文件假如到暂存区，然后再 git commit，就完成了冲突解决。
打开图形界面工具解决冲突 使用图形化工具来帮助你解决冲突，不过需要事先安装工具。打开图形界面工具的命令如下：
git mergetool 打开之前，也可以使用 git config 进行简单的配置，比如使用 vimdiff 工具作为默认的冲突解决工具：
git config merge.tool vimdiff git config merge.conflictstyle diff3 git config mergetool.prompt false 放弃合并操作 你暂时不想解决冲突：
git reset 参考  How to resolve merge conflicts in Git  扫描下面二维码，在手机端阅读：</description>
    </item>
    
    <item>
      <title>Git tag</title>
      <link>https://kunzhao.org/docs/tutorial/git/git-tag/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/tutorial/git/git-tag/</guid>
      <description>Git tag 什么是 Tags Tag 是对某次 commit 的一个有意义的命名，比如某个重大的版本发布，某个重大的 BUG 修复等。如下展示了前端开发框架 React 在开发过程中标记的各个版本的 Tag 列表。
显示版本库的 Tag 列表 git tag 创建 Tag # 在最新的提交是创建一个 Tag git tag myTag # 创建一个带有说明信息的 Tag git tag -m &amp;#34;My fir st annotated tag.&amp;#34; myTag2 删除 Tag git tag -d myTag 重命名 Tag 只能先删除旧的 Tag，然后创建一个新的
将 Tag 推送到远程服务器 # 将 myTag 推送到远程服务器 git push origin myTag # 将本地所有 Tag 推送到远程服务器 git push origin refs/tags/* # 或 git push origin --tags 扫描下面二维码，在手机端阅读：</description>
    </item>
    
    <item>
      <title>Git add 和 Git rm</title>
      <link>https://kunzhao.org/docs/tutorial/git/git-add-and-rm/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/tutorial/git/git-add-and-rm/</guid>
      <description>Git add 和 Git rm  git add 用来从工作区向暂存区添加文件 git rm 用来从工作区向暂存区删除文件  git add 示例 git add [--all|-A] git add . git add -u Git 1.X 版本  假设 . 当前指向的目录是 .git 文件所在的目录
 Git 2.X 版本  假设 . 当前指向的目录是 .git 文件所在的目录
 git rm 示例 # 只从工作区删除文件 rm xxx.txt # 只从暂存区删除文件 git rm --cached # 从工作区和暂存区都删除这个文件 git rm xxx.txt # 递归强制删除 xxx_folder 中的所有文件 # -r: recursive # -f: override the up-to-date check git rm -rf xxx_folder 参考  Difference between “git add -A” and “git add .</description>
    </item>
    
    <item>
      <title>Git push 和 Git pull</title>
      <link>https://kunzhao.org/docs/tutorial/git/git-push-and-pull/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/tutorial/git/git-push-and-pull/</guid>
      <description>Git push 和 Git pull git push 、git pull 用于向远程分支推送文件，以及从远程分支拉取文件等。
远程版本库地址 .git/config 文件中记录了当前仓库远程版本库的地址：
vi .git/config 直接修改这个地址保存后，当前版本库的远程版本库的地址也就变化了。Git 本身也提供了用来操纵版本库地址的命令：
# 添加远程版本库地址 git remote add origin git@github.com:facebook/react.git # 更新远程版本库地址 git remote set-url origin git@github.com:facebook/react.git push 和 pull push 命令和 pull 命令的语法相似：
git push &amp;lt;remote_name&amp;gt; &amp;lt;branch_name&amp;gt; git pull &amp;lt;remote_name&amp;gt; &amp;lt;branch_name&amp;gt; 不带参数，执行命令 git push 的过程（git pull 同理）：
 如果当前分支有 remote（如何知道是否有 remote？还是看 .git/config 文件，如下图所示，每个 branch 的 remote 都不是空的），那么 git push 相当于执行了 git push &amp;lt;remote&amp;gt; 如果没有设置，则相当于执行 git push origin  一般而言，你这个项目本身应该只有一个版本库地址，如下图所示，版本库的名称就叫做 origin，它的地址就是 url 后面的那一部分：</description>
    </item>
    
    <item>
      <title>Git commit</title>
      <link>https://kunzhao.org/docs/tutorial/git/git-commit/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/tutorial/git/git-commit/</guid>
      <description>Git commit git commit 可以将暂存区的文件，commit 提交到本地仓库中。
git commit -m -m 代表 message 信息的意思。git commit 需要一个信息作为它的参数，这个信息是对此次 commit 的简短描述，消息应该放到双引号里面。
git commit -m &amp;#34;my brief description about commit&amp;#34;  如果没有携带 -m 参数，Git 也会弹出编辑器让你输入消息的。
 git commit -a -a 选项代表 all，即所有。该选项可以将本地工作区所有改动的/被删除的文件，直接 commit 到仓库中，而无需调用 git add/rm 命令手动添加或删除。
git commit -am &amp;#34;My message&amp;#34;  -a 并不会将新添加的文件 commit 到版本库中。
 git commit &amp;ndash;amend --amend 选项可以让你修改上一次提交的信息。
# 第一次提交信息 git commit -m &amp;#34;my first message&amp;#34; # 你对 my first message 这个描述不满意 # 所以使用下面命令来修正成你想要的信息 git commit --amend -m &amp;#34;an updated commit message&amp;#34; 参考  Git Commit Command Explained  扫描下面二维码，在手机端阅读：</description>
    </item>
    
    <item>
      <title>Git .gitignore 文件</title>
      <link>https://kunzhao.org/docs/tutorial/git/git-ignore/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/tutorial/git/git-ignore/</guid>
      <description>Git .gitignore 文件 Git 可以使用 .gitignore 文件来对工作区的某个目录、某个文件等设置忽略，忽略后这些文件的状态变化，将不会被记录在 git 中，也不会被 push 到远程服务器上。
如果想要忽略项目里面的某些文件夹，比如 build/、target/、node_modules/ 等文件夹，不 push 到服务器上，就需要在相应的目录中添加一个 .gitignore 文件，并在里面将这些文件夹的名字给加上。
.gitignore 的作用范围 作用范围：.gitignore 文件所处的目录及其子目录。
如何查看哪些文件被忽略了 git status --ignored # 或 git check-ignore -v example.jpg .gitignore 文件语法  # 开始的行代表注释 *：代表任意多个字符，?：代表一个字符，[abc] 代表可选字符范围等 **：匹配任意数量的目录 名称以 / 开头：只忽略此目录下的文件，对于子目录中的文件不忽略 名称以 / 结尾：忽略整个目录，同名文件不忽略；否则同名文件和目录都被忽略 名称以 ! 开头：代表不忽略这个文件  示例 # 任何目录下面的 .DS_Store 文件都会被忽略 .DS_Store # 忽略整个目录 node_modules/ logs/ # 忽略所有以 log 结尾的文件，但是 example.log 不被忽略 *.log !example.log # 忽略 abc 文件夹下面的以 log 结尾的文件，注意：子目录不会被忽略 abc/*.</description>
    </item>
    
  </channel>
</rss>