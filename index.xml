<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>首页 on 赵坤的个人网站</title>
    <link>https://kunzhao.org/</link>
    <description>Recent content in 首页 on 赵坤的个人网站</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh</language>
    <lastBuildDate>Sun, 24 May 2020 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="https://kunzhao.org/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>信息的半衰期</title>
      <link>https://kunzhao.org/posts/half-life-of-information/</link>
      <pubDate>Sat, 16 May 2020 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/posts/half-life-of-information/</guid>
      <description>&lt;p&gt;今天，我想与您讨论一下信息能存活多久的问题，这个问题又会如何影响我们工作的方式。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Best Time to Buy and Sell Stock</title>
      <link>https://kunzhao.org/docs/programmer-interview/algorithm/best-time-to-buy-and-sell-stock/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/programmer-interview/algorithm/best-time-to-buy-and-sell-stock/</guid>
      <description>Best Time to Buy and Sell Stock 题目 LeetCode 地址：Best Time to Buy and Sell Stock
有一个数组，第 i 个元素的值代表第 i 天的股票价格，如果你最多只能进行一次交易（某天买入一支股票，然后过几天卖掉），请问你能收获的最大利润是多少？
分析 这道题有两个简单做法：状态机和动态规划。
使用状态机的做法的好处是，这种思路可以延续到其它几个买卖股票的问题上。关键是要想清楚，某一天有几种状态，在这道题是三种：
 状态 s0: 不买也不卖，无操作。s0 的值只能有一个来源，就是和昨天保持一致，不买也不卖 状态 s1: 买入了股票。s1 的值有两个来源：1. 与昨天一致，即已经买入了，且只能买一次，所以不能再买了，s1 = s1；2. 买入今天的股票，花了 price[i] 钱，s1 = s0 - price[i] 状态 s2: 卖出了股票。s2 的值有两个来源：1. 之前已经卖出了，所以维持卖出状态，不能再次卖了，s2 = s1；2. 卖出之前买入的股票，挣 price[i] 钱，s2 = s1 + price[i]  所以，我们可以得到如下状态转移关系：
 s0 = s0 s1 = s1 s1 = s0 - price[i] s2 = s2 s2 = s1 + price[i]  在这整个过程中，我们都要保证每一天的 s0、s1、s2 都是 max 状态，s2 是最终卖完后的收益，所以返回这个结果就行。</description>
    </item>
    
    <item>
      <title>B站高可用架构实践</title>
      <link>https://kunzhao.org/docs/cloud-plus-bbs/bilibili-high-availability/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/cloud-plus-bbs/bilibili-high-availability/</guid>
      <description>B站高可用架构实践 流量洪峰下要做好高服务质量的架构是一件具备挑战的事情，从Google SRE的系统方法论以及实际业务的应对过程中出发，分享一些体系化的可用性设计。对我们了解系统的全貌上下游的联防有更进一步的了解。
负载均衡 BFE 就是指边缘节点，BFE 选择下游 IDC 的逻辑权衡：
 离 BFE 节点比较近的 基于带宽的调度策略 某个 IDC 的流量已经过载，选择另外一个 IDC  当流量走到某个 IDC 时，这个流量应该如何进行负载均衡？
问题：RPC 定时发送的 ping-pong，也即 healthcheck，占用资源也非常多。服务 A 需要与账号服务维持长连接发送 ping-pong，服务 B 也需要维持长连接发送 ping-pong。这个服务越底层，一般依赖和引用这个服务的资源就越多，一旦有任何抖动，那么产生的这个故障面是很大的。那么应该如何解决？
解决：以前是一个 client 跟所有的 backend 建立连接，做负载均衡。现在引入一个新的算法，子集选择算法，一个 client 跟一小部分的 backend 建立连接。图片中示例的算法，是从《Site Reliability Engineering》这本书里看的。
如何规避单集群抖动带来的问题？多集群。
如上述图片所示，如果采用的是 JSQ 负载均衡算法，那么对于 LBA 它一定是选择 Server Y 这个节点。但如果站在全局的视角来看，就肯定不会选择 Server Y 了，因此这个算法缺乏一个全局的视角。
如果微服务采用的是 Java 语言开发，当它处于 GC 或者 FullGC 的时候，这个时候发一个请求过去，那么它的 latency 肯定会变得非常高，可能会产生过载。
新启动的节点，JVM 会做 JIT，每次新启动都会抖动一波，那么就需要考虑如何对这个节点做预热？
如上图所示，采用 &amp;ldquo;the choice-of-2&amp;rdquo; 算法后，各个机器的 CPU 负载趋向于收敛，即各个机器的 CPU 负载都差不多。Client 如何拿到后台的 Backend 的各项负载？是采用 Middleware 从 Rpc 的 Response 里面获取的，有很多 RPC 也支持获取元数据信息等。</description>
    </item>
    
    <item>
      <title>RocketMQ 消息发送流程</title>
      <link>https://kunzhao.org/docs/rocketmq/rocketmq-send-message-flow/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/rocketmq/rocketmq-send-message-flow/</guid>
      <description>RocketMQ 消息发送流程 本文讲述 RocketMQ 发送一条普通消息的流程。
一、服务器启动 我们可以参考官方文档来启动服务:
 启动 Name 服务器:  sh bin/mqnamesrv  启动 Broker 服务器:  sh bin/mqbroker -n localhost:9876 二、构建消息体 一条消息体最少需要指定两个值:
 所属话题 消息内容  如下就是创建了一条话题为 “Test”，消息体为 “Hello World” 的消息:
Message msg = new Message( &amp;#34;Test&amp;#34;, &amp;#34;Hello World&amp;#34;.getBytes() ); 三、启动 Producer 准备发送消息 如果我们想要发送消息呢，我们还需要再启动一个 DefaultProducer (生产者) 类来发消息:
DefaultMQProducer producer = new DefaultMQProducer(); producer.start(); 现在我们所启动的服务如下所示:
四、Name 服务器的均等性 注意我们上述开启的是单个服务，也即一个 Broker 和一个 Name 服务器，但是实际上使用消息队列的时候，我们可能需要搭建的是一个集群，如下所示:
在 RocketMQ 的设计中，客户端需要首先询问 Name 服务器才能确定一个合适的 Broker 以进行消息的发送:</description>
    </item>
    
    <item>
      <title>VUE 面试题</title>
      <link>https://kunzhao.org/docs/programmer-interview/front-end/vue/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/programmer-interview/front-end/vue/</guid>
      <description>VUE 面试题 整理 VUE 相关的常见面试题
介绍一下 VUE 介绍一下 VUEX VUE 2.X 和 3.0 的区别 （1）数据监听方式变化
VUE 2.X 使用 ES5 的 Object.defineProperty() 的 get() 和 set(newValue) 实现，VUE 3.0 基于 Proxy 监听实现，同时更为强大：
 可以检测属性的新增和删除 可以检测数组索引的变化和 length 的变化 支持 Map、Set、WeakMap 和 WeakSet   优点：速度加倍，内存占用减半。
 （2）体积更小
支持 Tree Shaking，内置组件、内置指令按需引入。
（3）速度更快
参考：vue3.0和vue2.x的区别、Vue 3.0 和 Vue 2.0的对比以及Vue 2.0精讲以及Vue全家桶精讲
VUE 的生命周期 VUE 数据双向绑定原理 VUE 采用发布者-订阅者模式的方式来实现双向绑定。
（1）视图更新数据：
input 标签监听 input 事件即可。
（2）数据更新视图：
Object.defineProperty() 监听数据变化，通过消息订阅器发布消息，订阅者收到消息执行相应的操纵 DOM 的函数，从而更新视图。</description>
    </item>
    
    <item>
      <title>数学之美</title>
      <link>https://kunzhao.org/docs/books/beauty_of_mathematics/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/books/beauty_of_mathematics/</guid>
      <description>数学之美 2000多年前，古埃及人在罗塞塔石碑上，用三种文字记录了托勒密五世登基的诏书，这帮助后人破解了古埃及的象形文字，让我们了解了5000年前古埃及的历史。可见信息冗余是信息安全的保障，这对于信息编码具有重要指导意义。
犹太人为了避免抄错《圣经》，发明了一种校验码的方法，他们把每一个希伯来字母对应于一个数字，这样每行文字加起来便得到一个特殊的数字，这样的数字变成为了这一行的校验码。
隐含马尔可夫链成功应用在机器翻译、拼写纠错、手写体识别、图像处理、基因序列分析、股票预测和投资等方面。
如何准确的识别出一个快递地址，写一个分析器去分析这些描述恐怕是不行的，因为地址是比较复杂的上下文有关的文法。答案是使用有限状态机。当用户输入的地址不太标准或有错别字的时候，有限状态机会束手无措，因为有限状态机是严格匹配的，所以科学家提出了基于概率的有限状态机。
2002 年，Google 想要做一个全新的中、日、韩搜索算法，吴军写的算法比较简单，但是占用内存比较多，Google 服务器数量还没有那么多。辛格提出，用一个拟合函数替换很耗内存的语言模型，无需增加任何服务器，但是搜索质量会降到 80%。辛格指出，这样可以提早两个月将这个新算法提供给中国的用户，用户体验会有质的提高。辛格做事情的哲学，先帮助用户解决 80% 的问题，再慢慢解决剩下的 20% 的问题，是在工业界成功的秘诀之一。
新闻分类的关键在于计算出两篇新闻的相似度，每篇新闻变成一个向量，最后余弦定理可以计算出来相似度。但两两计算的迭代次数太多，如何一次性就把所有新闻的相关性计算出来呢？答案是矩阵运算中的奇异值分解。
如何判断两个集合是否相同？一种答案是双层 for 循环一一比较，复杂度 O(N^2)；稍好一点的办法是对集合进行排序，然后顺序比较，时间复杂度 O(NlogN)；还可以将一个集合的元素放到散列表里面，另外一个与之一一对比，时间复杂度 O(N)，但是额外使用了 O(N) 的空间，不完美；最完美的是计算这两个集合的指纹，对一个集合中的元素分别计算指纹，然后一一相加。
如何判断两个集合基本相同？答案是 Simhash。判断两个网页是否重复，也没有必要完全从头比到尾，只需要每个网页挑选出几个词 (IDF 最大的几个词)，构成特征词，然后计算信息指纹即可。判断一篇文章是否抄袭另外一篇文章，每篇文章切成小的片段，挑选特征词，并计算指纹。YouTuBe 如何从上百万视频中找出一个视频是否另外一个视频的盗版？其核心在于关键帧的提取和特征的提取。关键帧对于视频的重要性，就如同主题词对于新闻的重要性一样。
最大熵原理指出，对一个随机事件的概率分布进行预测时，我们的预测应当满足全部已知的条件，而对未知的情况不要做任何主观假设，这种情况下，概率分布最均匀，预测的风险最小。例如拼音输入法，Wang-Xiao-Bo 转换为王晓波和王小波，唯一确定用户需要的是哪一个，非常难。</description>
    </item>
    
    <item>
      <title>理解 This 关键字</title>
      <link>https://kunzhao.org/docs/javascript/understand-this-keyword/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/javascript/understand-this-keyword/</guid>
      <description>理解 This 关键字 JavaScript 中的 this 所指向的对象，取决于上下文以及函数被调用的方式，本文列举了几种常见的情况，帮助大家理解。
一、全局上下文 当直接在一个全局的上下文中，使用 this 指针的时候，this 指针会指向到全局对象上。例如在浏览器的调试工具栏中直接打印 this 指针，其指向的是 Window 对象：
在 node 中打印 this 指针，其指向的是 node 提供的全局对象，其中包含了进程信息等：
二、Function 上下文 在 Function 上下文中，this 的值取决于 function 是如何被调用的。
(1) Function 调用 当 this 指针定义在一个 function 中，那么此 this 仍然会指向全局对象：
function foo() { console.log(this) } foo(); // Window {parent: Window, postMessage: ƒ, blur: ƒ, focus: ƒ, close: ƒ, …} (2) 严格模式下的 Function 调用 如果在严格模式下定义的 function 的话，this 指针的值将会是 undefined：
function foo() { &amp;#39;use strict&amp;#39;; console.</description>
    </item>
    
    <item>
      <title>如何改进 NGINX 配置文件节省带宽？</title>
      <link>https://kunzhao.org/posts/help-the-world-by-healing-your-nginx-configuration/</link>
      <pubDate>Sun, 24 May 2020 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/posts/help-the-world-by-healing-your-nginx-configuration/</guid>
      <description>&lt;p&gt;2014年，Admiral William H. McRaven 在得克萨斯大学发表了著名的演讲，他说，如果你想改变世界，就从整理床铺开始。有时候小事情会有很大的影响——不管是在早上整理床铺，还是对网站的HTTP服务器配置做一些更改。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Best Time to Buy and Sell Stock Ⅱ</title>
      <link>https://kunzhao.org/docs/programmer-interview/algorithm/best-time-to-buy-and-sell-stock-2/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/programmer-interview/algorithm/best-time-to-buy-and-sell-stock-2/</guid>
      <description>Best Time to Buy and Sell Stock Ⅱ 题目 LeetCode 地址：Best Time to Buy and Sell Stock Ⅱ
有一个数组，第 i 个元素的值代表第 i 天的股票价格，如果你可以进行无限次交易（某天买入一支股票，然后过几天卖掉），请问你能收获的最大利润是多少？
分析 这道题就一个想法，只要今天 price[i] 比昨天 price[i - 1] 的价格涨了，就可以算作是有效的利润，累加到最后的结果中。
答案 // 假设有一个数组，它的第i个元素是一个给定的股票在第i天的价格。 // 设计一个算法来找到最大的利润。你可以完成尽可能多的交易(多次买卖股票)。 // 然而,你不能同时参与多个交易(你必须在再次购买前出售股票)。 // // https://www.lintcode.com/problem/best-time-to-buy-and-sell-stock-ii/description public class BestTimetoBuyandSellStockII { public int maxProfit(int[] prices) { int max = 0; for (int i = 1; i &amp;lt; prices.length; i++) { int diff = prices[i] - prices[i - 1]; if (diff &amp;gt; 0) { max += diff; } } return max; } } 扫描下面二维码，在手机上阅读这篇文章：</description>
    </item>
    
    <item>
      <title>JavaScript 数组</title>
      <link>https://kunzhao.org/docs/javascript/javascript-array/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/javascript/javascript-array/</guid>
      <description>JavaScript 数组 使用 JavaScript 在编程的时候，我们有很大一部分时间都是在与数组打交道，因此对数组常见的方法做到灵活的运用至关重要。本文整理了和 JavaScript 数组相关的，日常经常需要的功能和使用技巧，供大家参阅。
从数组中移除指定元素 查阅 JavaScript 的数组 API，发现其并没有提供一个像 remove(obj) 或 removeAll(obj) 此类的方法，供我们方便的删除对象，因此我们需要通过使用其它的 API 来达到我们移出元素的目的。
(1) 使用 splice 方法 splice 方法可以从指定索引处，向数组中添加元素或者删除元素，其会直接在原数组上改变，因此通过此方法可以达到我们的目的。但是在移除元素之前，我们必须首先通过 indexOf 方法找到我们的元素在数组中处于的索引位置。
const array = [2, 5, 9]; const index = array.indexOf(5); if (index &amp;gt; -1) { array.splice(index, 1); // 1 代表删除 1 个元素 } console.log(array) 当然，如果你不想使用 indexOf 的话，也可以直接从后向前遍历整个数组，对每个符合要求的元素都使用 splice 方法：
const array = [2, 5, 9]; for (var i = array.length; i--; ) { if (array[i] === 5) { array.</description>
    </item>
    
    <item>
      <title>RocketMQ 消息存储流程</title>
      <link>https://kunzhao.org/docs/rocketmq/rocketmq-message-store-flow/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/rocketmq/rocketmq-message-store-flow/</guid>
      <description>RocketMQ 消息存储流程 本文讲述 RocketMQ 存储一条消息的流程。
一、存储位置 当有一条消息过来之后，Broker 首先需要做的是确定这条消息应该存储在哪个文件里面。在 RocketMQ 中，这个用来存储消息的文件被称之为 MappedFile。这个文件默认创建的大小为 1GB。
一个文件为 1GB 大小，也即 1024 * 1024 * 1024 = 1073741824 字节，这每个文件的命名是按照总的字节偏移量来命名的。例如第一个文件偏移量为 0，那么它的名字为 00000000000000000000；当当前这 1G 文件被存储满了之后，就会创建下一个文件，下一个文件的偏移量则为 1GB，那么它的名字为 00000000001073741824，以此类推。
默认情况下这些消息文件位于 $HOME/store/commitlog 目录下，如下图所示:
二、文件创建 当 Broker 启动的时候，其会将位于存储目录下的所有消息文件加载到一个列表中:
当有新的消息到来的时候，其会默认选择列表中的最后一个文件来进行消息的保存:
public class MappedFileQueue { public MappedFile getLastMappedFile() { MappedFile mappedFileLast = null; while (!this.mappedFiles.isEmpty()) { try { mappedFileLast = this.mappedFiles.get(this.mappedFiles.size() - 1); break; } catch (IndexOutOfBoundsException e) { //continue;  } catch (Exception e) { log.</description>
    </item>
    
    <item>
      <title>上帝掷骰子吗</title>
      <link>https://kunzhao.org/docs/books/history_of_quantum_physics/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/books/history_of_quantum_physics/</guid>
      <description>上帝掷骰子吗-量子物理史话 1887年德国，赫兹在实验室证实了电磁波的存在，也证实了光其实是电磁波的一种，两者具有共同的波的特性，古老的光学终于可以被完全包容于新兴的电磁学里面。1901年，赫兹死后的第 7 年，无线电报已经可以穿越大西洋，实现两地的实时通讯了。
赫兹铜环接收器的缺口之间不停地爆发着电火花，明白无误地昭示着电磁波的存在。但偶然间，赫兹又发现了一个奇怪的现象：当有光照射到这个缺口上的时候，似乎火花就出现得更容易一些。
 量子就是能量的最小单位，就是能量里的一美分。一切能量的传输，都只能以这个量为单位来进行，它可以传输一个量子，两个量子，任意整数个量子，但却不能传输1 又1/2 个量子，那个状态是不允许的，就像你不能用现钱支付1 又1/2 美分一样。这个值，现在已经成为了自然科学中最为 重要的常数之一，以它的发现者命名，称为“普朗克常数”，用 h 来表示。
在后来十几年的时间里，普朗克一直认为量子的假设并不是一个物理真实，而纯粹是一个为了方便而引入的假设而已。他不断地告诫人们，在引用普朗克常数 h 的时候，要尽量小心谨慎，不到万不得已千万不要胡思乱想。</description>
    </item>
    
    <item>
      <title>穗康小程序口罩预约前后端架构及产品设计</title>
      <link>https://kunzhao.org/docs/cloud-plus-bbs/suikang-mini-program-design/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/cloud-plus-bbs/suikang-mini-program-design/</guid>
      <description>穗康小程序口罩预约前后端架构及产品设计 在战“疫”期间，腾讯与广州市政府合作，在小程序“穗康”上，2天内上线了全国首款口罩预约功能，上线首日访问量1.7亿，累计参与口罩预约人次1400万+。那么，它是如何在2天内开发上线，扛住了超大并发量呢？其背后的前后端架构是怎样的？
无损服务设计 整个流程下来需要 3 个实时接口：
 药店当前口罩的库存情况 哪个时间段有名额 提交预约实时返回结果  有损服务设计 结果，口罩预约关注度远超预期：
下面展示的 UI 的设计：
为什么有 “损” 平衡的理论就是 CAP 理论、BASE 最终一致性：
牺牲强一致换取高可用 两个机房需要同步，并发性差。以下是优化后的代码，引入计时器：
降低了专线依赖。
怎么 &amp;ldquo;损&amp;rdquo;  放弃绝对一致，追求高可用和快速响应 万有一失，用户重试 伸缩调度，降级服务  （1）穗康小程序 引入消息队列，最终一致：
（2）QQ 相册负载高 选择扩容？带宽和存储成本高。
（3）转账 用户重试极少量消息。再想一下微信的红色感叹号，点一下重新发送。
（4）穗康的预约重试 （5）QQ 相册降级 </description>
    </item>
    
    <item>
      <title>Best Time to Buy and Sell Stock Ⅲ</title>
      <link>https://kunzhao.org/docs/programmer-interview/algorithm/best-time-to-buy-and-sell-stock-3/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/programmer-interview/algorithm/best-time-to-buy-and-sell-stock-3/</guid>
      <description>Best Time to Buy and Sell Stock Ⅲ 题目 LeetCode 地址：Best Time to Buy and Sell Stock Ⅲ
有一个数组，第 i 个元素的值代表第 i 天的股票价格，如果你最多只能进行两次交易（某天买入一支股票，然后过几天卖掉），请问你能收获的最大利润是多少？
分析 参考 Best Time to Buy and Sell Stock 思路上状态机，状态机应用两次即可。
答案 // 最多两次交易 // 且不能同时持有，必须卖掉这个，然后持有另外一个 // https://leetcode.com/problems/best-time-to-buy-and-sell-stock-iii/ // public class BestTimetoBuyandSellStockIII { // Buy Sell Buy Sell  // s0 ----&amp;gt; s1 -----&amp;gt; s2 -----&amp;gt; s3 ------&amp;gt; s4 (end)  // ↑___| ↑__| ↑____| ↑___|  //  public int maxProfit(int[] prices) { if (prices == null || prices.</description>
    </item>
    
    <item>
      <title>RocketMQ 消息接受流程</title>
      <link>https://kunzhao.org/docs/rocketmq/rocketmq-message-receive-flow/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/rocketmq/rocketmq-message-receive-flow/</guid>
      <description>RocketMQ 消息接受流程 本篇讲述 RocketMQ 消息接受流程
一、消费者注册 生产者负责往服务器 Broker 发送消息，消费者则从 Broker 获取消息。消费者获取消息采用的是订阅者模式，即消费者客户端可以任意订阅一个或者多个话题来消费消息:
public class Consumer { public static void main(String[] args) throws InterruptedException, MQClientException { /* * 订阅一个或者多个话题 */ consumer.subscribe(&amp;#34;TopicTest&amp;#34;, &amp;#34;*&amp;#34;); } } 当消费者客户端启动以后，其会每隔 30 秒从命名服务器查询一次用户订阅的所有话题路由信息:
public class MQClientInstance { private void startScheduledTask() { this.scheduledExecutorService.scheduleAtFixedRate(new Runnable() { @Override public void run() { // 从命名服务器拉取话题信息  MQClientInstance.this.updateTopicRouteInfoFromNameServer(); } }, 10, this.clientConfig.getPollNameServerInterval(), TimeUnit.MILLISECONDS); } } 我们由 RocketMQ 消息发送流程 这篇文章知道 RocketMQ 在发送消息的时候，每条消息会以轮循的方式均衡地分发的不同 Broker 的不同队列中去。由此，消费者客户端从服务器命名服务器获取下来的便是话题的所有消息队列:</description>
    </item>
    
    <item>
      <title>代码整洁之道</title>
      <link>https://kunzhao.org/docs/books/clean_code/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/books/clean_code/</guid>
      <description>代码整洁之道 勒布朗法则：Later equals never.
随着混乱的增加，团队生产力也持续下降，趋近于零。生产力下降的时候，管理层只能增加更多的人手，期望提高生产力。
什么是整洁代码  我喜欢优雅和高效的代码。代码逻辑应当直截了当，叫缺陷难以隐藏；尽量减少依赖关系，使之便于维护；依据某种分层战略完善错误处理代码；性能调至最优，省得引诱别人做没规矩的优化，搞出一堆混乱来。整洁的代码只做好一件事。&amp;mdash; Bjarne Stroustrup，C++ 语言发明者
  整洁的代码应可由作者之外的开发者阅读和增补。它应有单元测试和验收测试。它使用有意义的命名。它只提供一种而非多种做一件事的途径。它只有尽量少的依赖关系，且要明确地定义和提供清晰、尽量少的 API。代码应通过其表面表达含义，因为不同的语言导致并非所有必需信息均可通过代码自身清晰表达。&amp;mdash; Dave Thomas, OTI 公司创始人
  整洁的代码总是看起来像是某位特别在意它的人写的。几乎没有改进的余地，代码作者什么都想到了。&amp;mdash; 《修改代码的艺术》作者
 有意义的命名 对于变量，如果其需要注释来补充，那就不算是名副其实。比如你需要定义一个变量，这个变量存储的是消逝的时间，其单位是天，那么下面是一些比较好的命名：
int elapsedTimeInDays; int daysSinceCreation; int daysSinceModification; int fileAgeInDays; 别用 accountList 来指一组账号，除非它真的是 List 类型，List 一词对于程序员有特殊意义，所以用 accountGroup 或 bunchOfAcounts，甚至用 accounts 都会好一些。
别说废话，废话都是冗余。假如你有一个 Product 类，如果还有一个 ProductInfo 或 ProductData 类，它们虽然名称不同，意思却无区别。Info 和 Data 就像 a、an 和 the 一样，是意义含混的废话。下面三个函数的命名，我们怎么知道应该调用哪个呢？
getActiveAccount(); getActiveAccounts(); getActiveAccountInfo(); 使用常量，WORK_DAYS_PER_WEEK 比数字 5 要好找的多。
 对于类名，其应该是名词或名词短语，如 Customer、WikiPage、Account 和 AddressParser，避免使用 Manager、Processor、Data 或 Info 这样的类名。类名不应当是动词。</description>
    </item>
    
    <item>
      <title>Best Time to Buy and Sell Stock Ⅳ</title>
      <link>https://kunzhao.org/docs/programmer-interview/algorithm/best-time-to-buy-and-sell-stock-4/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/programmer-interview/algorithm/best-time-to-buy-and-sell-stock-4/</guid>
      <description>Best Time to Buy and Sell Stock Ⅳ 题目 LeetCode 地址：Best Time to Buy and Sell Stock Ⅳ
有一个数组，第 i 个元素的值代表第 i 天的股票价格，如果你最多只能进行K次交易（某天买入一支股票，然后过几天卖掉），请问你能收获的最大利润是多少？
分析 参考 Best Time to Buy and Sell Stock 思路上状态机，状态机应用K次即可。
答案 // 最多交易 k 次 // https://leetcode.com/problems/best-time-to-buy-and-sell-stock-iv/ // public class BestTimetoBuyandSellStockIV { public int maxProfit(int k, int[] prices) { if (prices == null || prices.length &amp;lt;= 1 || k &amp;lt;= 0) { return 0; } if (k &amp;gt;= prices.</description>
    </item>
    
    <item>
      <title>RocketMQ 消息过滤流程</title>
      <link>https://kunzhao.org/docs/rocketmq/rocketmq-message-filter-flow/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/rocketmq/rocketmq-message-filter-flow/</guid>
      <description>RocketMQ 消息过滤流程 讲述 RocketMQ 消息过滤流程
一、消息过滤类型 Producer 在发送消息的时候可以指定消息的标签类型，还可以为每一个消息添加一个或者多个额外的属性:
// 指定标签 Message msg = new Message(&amp;#34;TopicTest&amp;#34;, &amp;#34;TagA&amp;#34;, (&amp;#34;Hello RocketMQ&amp;#34;).getBytes(RemotingHelper.DEFAULT_CHARSET)); // 添加属性 a msg.putUserProperty(&amp;#34;a&amp;#34;, 5); 根据标签和属性的不同，RocketMQ 客户端在消费消息的时候有三种消息过滤类型:
(1) 标签匹配 consumer.subscribe(&amp;#34;TopicTest&amp;#34;, &amp;#34;TagA | TagB | TagC&amp;#34;); (2) SQL 匹配 consumer.subscribe(&amp;#34;TopicTest&amp;#34;, MessageSelector.bySql( &amp;#34;(TAGS is not null and TAGS in (&amp;#39;TagA&amp;#39;, &amp;#39;TagB&amp;#39;))&amp;#34; + &amp;#34;and (a is not null and a between 0 3)&amp;#34;)); (3) 自定义匹配 客户端实现 MessageFilter 类，自定义过滤逻辑:
ClassLoader classLoader = Thread.currentThread().getContextClassLoader(); File classFile = new File(classLoader.</description>
    </item>
    
    <item>
      <title>企业 IT 架构转型之道</title>
      <link>https://kunzhao.org/docs/books/the_transformation_of_enterprise_it_architecture/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/books/the_transformation_of_enterprise_it_architecture/</guid>
      <description>企业 IT 架构转型之道 共享服务体系搭建 SOA 的主要特性：
 面向服务的分布式计算。 服务间松散耦合。 支持服务的组装。 服务注册和自动发现。 以服务契约方式定义服务交互方式。  基于 “中心化” 的 ESB 服务调用方式  “去中心化” 服务架构调用方式   数据拆分实现数据库能力线性扩展 数据库的读写分离 读写分离基本原理是让主数据库处理事务性增、改、删（INSERT、UPDATE、DELETE）操作，而从数据库专门负责处理查询（SELECT）操作，在数据库的后台会把事务性操作导致的主数据库中的数据变更同步到集群中的从数据库。
数据库分库分表 采用分库分表的方式将业务数据拆分后，如果每一条SQL语句中都能带有分库分表键，SQL语句的执行效率最高：
但不是所有的业务场景在进行数据库访问时每次都能带分库分表键的。比如在买家中心的界面中，要显示买家test1过去三个月的订单列表信息。此时就出现了我们所说的全表扫描，一条SQL语句同时被推送到后端所有数据库中运行。如果是高并发情况下同时请求的话，为了数据库整体的扩展能力，则要考虑下面描述的异构索引手段来避免这样的情况发生。对于在内存中要进行大数据量聚合操作和计算的SQL请求，如果这类SQL的不是大量并发或频繁调用的话，平台本身的性能影响也不会太大，如果这类SQL请求有并发或频繁访问的要求，则要考虑采用其他的平台来满足这一类场景的要求，比如Hadoop这类做大数据量离线分析的产品，如果应用对请求的实时性要求比较高，则可采用如内存数据库或HBase这类平台。
所谓“异构索引表”，就是采用异步机制将原表内的每一次创建或更新，都换另一个维度保存一份完整的数据表或索引表。本质上这是互联网公司很多时候都采用的一个解决思路：“拿空间换时间”。也就是应用在创建或更新一条按照订单ID为分库分表键的订单数据时，也会再保存一份按照买家ID为分库分表键的订单索引数据。
基于订单索引表实现买家订单列表查看流程示意：
实现对数据的异步索引创建有多种实现方式，其中一种就是从数据库层采用 binlog 数据复制的方式实现。
采用数据异构索引的方式在实战中基本能解决和避免90%以上的跨join或全表扫描的情况，是在分布式数据场景下，提升数据库服务性能和处理吞吐能力的最有效技术手段。但在某些场景下，比如淘宝商品的搜索和高级搜索，因为商品搜索几乎是访问淘宝用户都会进行的操作，所以调用非常频繁，如果采用SQL语句的方式在商品数据库进行全表扫描的操作，则必然对数据库的整体性能和数据库连接资源带来巨大的压力。面对此类场景，我们不建议采用数据库的方式提供这样的搜索服务，而是采用专业的搜索引擎平台来行使这样的职能，如Lucene、Solr、ElasticSearch 等。
异步化与缓存原则 业务流程异步化 以淘宝的交易订单为例，目前淘宝的订单创建流程需要调用超过200个服务，就算所有服务的调用时间都控制在20ms内返回结果，整个订单创建的时间也会超过4s：
以异步化方式将上述交易创建过程中，对于有严格先后调用关系的服务保持顺序执行，对于能够同步执行的所有服务均采用异步化方式处理。阿里巴巴内部使用消息中间件的方式实现了业务异步化，提高了服务的并发处理，从而大大减少整个业务请求处理所花的时间。
数据库事务异步化 扣款是一个要求事务一致性的典型场景，稍微数据不一致带来的后果都可能是成百上千（可能在某些借款项目中达到上百万的金额）的金额差异。所以在传统的实现方式中，整个扣款的逻辑代码都是在一个大的事务中，通过数据库的事务特性来实现这样一个稍显复杂的业务一致性。
数据库事务的异步化：通俗来说，就是将大事务拆分成小事务，降低数据库的资源被长时间事务锁占用而造成的数据库瓶颈，就能大大提升平台的处理吞吐量和事务操作的响应时间。
在实际的改造方案中，同样基于消息服务提供的异步机制，将整个还款流程进行异步化的处理：
事务与柔性事务 不管是业务流程异步化，还是数据库事务异步化，其实都面临一个如何保证业务事务一致性的问题。面对这个问题目前并没有完美的解决方案，本节会介绍淘宝是如何对订单创建场景实现业务一致的实践，以及近一两年来我们在分布式事务上所作出的创新尝试，供各技术同行在解决此类问题时借鉴和参考。
关于数据库事务，核心是体现数据库ACID（原子性、一致性、隔离性和持久性）属性，即作为一个事务中包含的所有逻辑处理操作在作用到数据库上时，只有这个事务中所有的操作都成功，对数据库的修改才会永久更新到数据库中，任何一个操作失败，对于数据库之前的修改都会失效。在分布式领域，基于CAP理论和在其基础上延伸出的BASE理论，有人提出了“柔性事务”的概念。
（1）CAP理论
一个分布式系统最多只能同时满足一致性（Consistency）、可用性（Availability）和分区容错性（Partition tolerance）这三项中的两项。“一致性”指更新操作成功并返回客户端完成后，所有节点在同一时间的数据完全一致。“可用性”指用户在访问数据时可以得到及时的响应。“分区容错性”指分布式系统在遇到某节点或网络分区故障的时候，仍然能够对外提供满足一致性和可用性的服务。
CAP定理并不意味着所有系统的设计都必须抛弃三个要素之中的一个。CAP三者可以在一定程度上衡量，并不是非黑即白的，例如可用性从0%到100%有不同等级。
（2）BASE理论
BASE理论是对CAP理论的延伸，核心思想是即使无法做到强一致性（Strong Consistency, CAP的一致性就是强一致性），但应用可以采用适合的方式达到最终一致性（EventualConsitency）。BASE是指基本可用（Basically Available）、柔性状态（Soft State）、最终一致性（Eventual Consistency）。
  “基本可用”是指分布式系统在出现故障的时候，允许损失部分可用性，即保证核心可用。电商大促时，为了应对访问量激增，部分用户可能会被引导到降级页面，服务层也可能只提供降级服务。这就是损失部分可用性的体现。
  “柔性状态”是指允许系统存在中间状态，而该中间状态不会影响系统整体可用性。分布式存储中一般一份数据至少会有三个副本，允许不同节点间副本同步的延时就是柔性状态的体现。MySQLReplication的异步复制也是一种柔性状态体现。
  “最终一致性”是指系统中的所有数据副本经过一定时间后，最终能够达到一致的状态。弱一致性和强一致性相反，最终一致性是弱一致性的一种特殊情况。
  对于如何实现高可用，我们认为：</description>
    </item>
    
    <item>
      <title>Best Time to Buy and Sell Stock With Cooldown</title>
      <link>https://kunzhao.org/docs/programmer-interview/algorithm/best-time-to-buy-and-sell-stock-with-cooldown/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/programmer-interview/algorithm/best-time-to-buy-and-sell-stock-with-cooldown/</guid>
      <description>Best Time to Buy and Sell Stock With Cooldown 题目 LeetCode 地址：Best Time to Buy and Sell Stock With Cooldown
有一个数组，第 i 个元素的值代表第 i 天的股票价格，如果你最多只能进行任意次交易（某天买入一支股票，然后过几天卖掉），你卖出一只股票后，接下来的一天不能买，必须要到后天才能买。也就是说有冷静期1天。请问你能收获的最大利润是多少？_
答案 // https://leetcode.com/problems/best-time-to-buy-and-sell-stock-with-cooldown/ // 交易任意多次，只不过 buy sell 之后的第二天必须 cooldown 隔天才能再次 buy // // https://leetcode.com/problems/best-time-to-buy-and-sell-stock-with-cooldown/discuss/240277/Java-solution-in-Chinese public class BestTimetoBuyandSellStockwithCooldown { public int maxProfit(int[] prices) { if (prices == null || prices.length &amp;lt;= 1) { return 0; } // 买入只能是从前天买入 buy[i] = sell[i - 2] - prices[i];  // 卖出可以昨天卖出 sell[i] = buy[i - 1] + prices[i];  int[] sell = new int[prices.</description>
    </item>
    
    <item>
      <title>Redis 5 设计与源码分析</title>
      <link>https://kunzhao.org/docs/books/redis_5_source_code/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/books/redis_5_source_code/</guid>
      <description>Redis 5 设计与源码分析 Redis 5.0 新特性  新增Streams数据类型，这是 Redis 5.0 最重要的改进之一。可以把Streams当作消息队列。 新的模块API、定时器、集群及字典。 RDB中持久化存储LFU和LRU的信息。 将集群管理功能完全用C语言集成到redis-cli中，Redis 3.x 和 Redis4.x 的集群管理是通过Ruby脚本实现的。 有序集合新增命令ZPOPMIN/ZPOPMAX。 改进HyperLogLog的实现。 新增Client Unblock和Client ID。 新增LOLWUT命令。 Redis主从复制中的从不再称为Slave，改称Replicas。 Redis 5.0引入动态哈希，以平衡CPU的使用率和相应性能，可以通过配置文件进行配置。Redis 5.0默认使用动态哈希。 Redis核心代码进行了部分重构和优化。  简单动态字符串 （1） 长度小于 32 的短字符串
struct __attribute__ ((__packed__))sdshdr5 { unsigned char flags; // 低 3 位存储类型，高 5 位存储长度  char buf[]; // 柔性数组 } 结构如下：
（2） 长度大于 31 的字符串
此处仅展示一个示例：
struct __attribute__ ((__packed__))sdshdr8 { uint8_t len; // 已使用长度  uint8_t alloc; // 已分配的字节总长度  unsigned char flags; // 低 3 位存储类型  char buf[]; // 柔性数组 } SDS 读操作的复杂度多为O(1)，直接读取成员变量；涉及修改的写操作，则可能会触发扩容。</description>
    </item>
    
    <item>
      <title>RocketMQ 消息索引流程</title>
      <link>https://kunzhao.org/docs/rocketmq/rocketmq-message-indexing-flow/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/rocketmq/rocketmq-message-indexing-flow/</guid>
      <description>RocketMQ 消息索引流程 讲述 RocketMQ 消息索引服务
一、消息查询方式 对于 Producer 发送到 Broker 服务器的消息，RocketMQ 支持多种方式来方便地查询消息:
(1) 根据键查询消息 如下所示，在构建消息的时候，指定了这条消息的键为 “OrderID001”:
Message msg = new Message(&amp;#34;TopicTest&amp;#34;, &amp;#34;TagA&amp;#34;, &amp;#34;OrderID001&amp;#34;, // Keys  &amp;#34;Hello world&amp;#34;.getBytes(RemotingHelper.DEFAULT_CHARSET)); 那么，当这条消息发送成功后，我们可以使用 queryMsgByKey 命令查询到这条消息的详细信息:
MQAdminStartup.main(new String[] { &amp;#34;queryMsgByKey&amp;#34;, &amp;#34;-n&amp;#34;, &amp;#34;localhost:9876&amp;#34;, &amp;#34;-t&amp;#34;, &amp;#34;TopicTest&amp;#34;, &amp;#34;-k&amp;#34;, &amp;#34;OrderID001&amp;#34; }); (2) 根据ID(偏移量)查询消息 消息在发送成功之后，其返回的 SendResult 类中包含了这条消息的唯一偏移量 ID (注意此处指的是 offsetMsgId):
用户可以使用 queryMsgById 命令查询这条消息的详细信息:
MQAdminStartup.main(new String[] { &amp;#34;queryMsgById&amp;#34;, &amp;#34;-n&amp;#34;, &amp;#34;localhost:9876&amp;#34;, &amp;#34;-i&amp;#34;, &amp;#34;0A6C73D900002A9F0000000000004010&amp;#34; }); (3) 根据唯一键查询消息 消息在发送成功之后，其返回的 SendResult 类中包含了这条消息的唯一 ID:
用户可以使用 queryMsgByUniqueKey 命令查询这条消息的详细信息:</description>
    </item>
    
    <item>
      <title>RocketMQ 定时消息和重试消息</title>
      <link>https://kunzhao.org/docs/rocketmq/rocketmq-timing-message-and-retry-message/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/rocketmq/rocketmq-timing-message-and-retry-message/</guid>
      <description>RocketMQ 定时消息和重试消息 讲述 RocketMQ 定时消息和重试消息
一、定时消息概述 RocketMQ 支持 Producer 端发送定时消息，即该消息被发送之后，到一段时间之后才能被 Consumer 消费者端消费。但是当前开源版本的 RocketMQ 所支持的定时时间是有限的、不同级别的精度的时间，并不是任意无限制的定时时间。因此在每条消息上设置定时时间的 API 叫做 setDelayTimeLevel，而非 setDelayTime 这样的命名:
Message msg = new Message(&amp;#34;TopicTest&amp;#34; /* Topic */, &amp;#34;TagA&amp;#34; /* Tag */, (&amp;#34;Hello RocketMQ &amp;#34; + i).getBytes(RemotingHelper.DEFAULT_CHARSET) /* Message body */); msg.setDelayTimeLevel(i + 1); 默认 Broker 服务器端有 18 个定时级别:
public class MessageStoreConfig { private String messageDelayLevel = &amp;#34;1s 5s 10s 30s 1m 2m 3m 4m 5m 6m 7m 8m 9m 10m 20m 30m 1h 2h&amp;#34;; } 这 18 个定时级别在服务器端启动的时候，会被解析并放置到表 delayLevelTable 中。解析的过程就是上述字符串按照空格拆分开，然后根据时间单位的不同再进一步进行计算，得到最终的毫秒时间。级别就是根据这些毫秒时间的顺序而确定的，例如上述 1s 延迟就是级别 1， 5s 延迟就是级别 2，以此类推:</description>
    </item>
    
    <item>
      <title>深度剖析 Apache Dubbo 核心技术</title>
      <link>https://kunzhao.org/docs/books/in-depth_analysis_of_the_core_technology_of_apache_dubbo/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/books/in-depth_analysis_of_the_core_technology_of_apache_dubbo/</guid>
      <description>深度剖析 Apache Dubbo 核心技术 SPI 扩展 Dubbo 支持扩展的核心接口上，都会通过类似 @SPI(&amp;quot;dubbo&amp;quot;) 这样的注解，来标识当前接口的默认实现。如果你想替换掉这个默认实现，那么需要两个步骤。第一，实现 Protocol 接口，然后在 META-INF/dubbo 目录下创建一个名字为 org.apache.dubbo.rpc.Protocol 的文本文件。这个 META-INF 目录如果使用的是 IDEA 开发，那么其应该放到 resources 目录下的顶层，这样打 jar 包的时候，其也会被复制到 jar 包的第一级目录。内容如下：
myProtocol = com.zk.MyProtocol 第二，需要在 XML 配置文件中，声明使用这个扩展实现：
&amp;lt;dubbo:protocol name=&amp;#34;myProtocol&amp;#34;&amp;gt; 其实 JDK 本身也提供了 SPI 扩展，Dubbo 之所以没有使用默认提供的实现，是因为：
 JDK 标准的 SPI 一次性实例化扩展点的所有实现，如果有些没有使用到，那么会浪费资源。 扩展点加载失败的异常提示不是很好。 增强了 Ioc 和 AOP 的支持。  性能 Dubbo 会给每个服务提供者的实现类生产一个 Wrapper 类，这个 Wrapper 类里面最终调用服务提供者的接口实现类，Wrapper 类的存在是为了减少反射的调用。当服务提供方收到消费方发来的请求后，需要根据消费者传递过来的方法名和参数反射调用服务提供者的实现类，而反射本身是有性能开销的，Dubbo 把每个服务提供者的实现类通过 JavaAssist 包装为一个 Wrapper 类以减少反射调用开销。
其实就是由反射改为了比较方法名称，然后调用，伪代码如下：
GreetingServiceImpl impl = (GreetingServiceImpl) object; if (&amp;#34;sayHello&amp;#34;.</description>
    </item>
    
    <item>
      <title>RocketMQ 主备同步</title>
      <link>https://kunzhao.org/docs/rocketmq/rocketmq-master-slave-sync/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/rocketmq/rocketmq-master-slave-sync/</guid>
      <description>RocketMQ 主备同步 介绍 RocketMQ 的主备同步机制
一、简介 RocketMQ 通过 Master-Slave 主备机制，来实现整个系统的高可用，具体表现在:
 Master 磁盘坏掉，Slave 依然保存了一份 Master 宕机，不影响消费者继续消费  二、搭建环境 我们在一台机器上搭建一个 Master 一个 Slave 的环境:
为了能够将 Master 和 Slave 搭建在同一台计算机上，我们除了需要将 Broker 的角色设置为 SLAVE ，还需要为其指定单独的 brokerId、 storePathRootDir、 storePathCommitLog。
// SLAVE 角色 messageStoreConfig.setBrokerRole(BrokerRole.SLAVE); // 一个机器如果要启动多个 Broker，那么每个 Broker 的 store 根目录必须不同 messageStoreConfig.setStorePathRootDir(storePathRootDir); // 一个机器如果要启动多个 Broker，那么每个 Broker 的 storePathCommitLog 根目录必须不同 messageStoreConfig.setStorePathCommitLog(storePathCommitLog); // 设置 Slave 的 Master HA 地址 messageStoreConfig.setHaMasterAddress(&amp;#34;localhost:10912&amp;#34;); // SLAVE 角色的 brokerId 必须大于 0 brokerConfig.setBrokerId(1); 注意 Slave 和 Master 的 brokerName 必须一致，即它们必须处于同一个 BrokerData 数据结构里面。实际上在做了如上的修改之后， Slave 和 Master 依旧不能同时运行在同一台机器上，因为 Slave 本身也可以称为 Master，接受来自其他 Slave 的请求，因此当运行 Slave 的时候，需要将 HAService 里面的启动 AcceptSocketService 运行的相关方法注释掉。</description>
    </item>
    
    <item>
      <title>人人都是架构师 (一)</title>
      <link>https://kunzhao.org/docs/books/everyone-is-architect/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/books/everyone-is-architect/</guid>
      <description>人人都是架构师 - 分布式系统架构落地与瓶颈突破 分布式系统应对高并发、大流量的常用手段：
 扩容 动静分离 缓存 服务降级 限流  限流 常见算法：
 令牌桶，Nginx 限流模块用的是这个：限制的是流量的平均流入速率，允许一定程度上的突发流量。 漏桶：限制的是流出速率，并且这个速率还是保持不变的，不允许突发流量。  Nginx 限流 http { # 每个 IP 的 session 空间大小 limit_zone one $binary_remote_addr 20m; # 每个 IP 每秒允许发起的请求数 limit_req_zone $binary_remote_addr zone=req_one:20m rate=10r/s; # 每个 IP 能够发起的并发连接数 limit_conn one 10; # 缓存还没有来得及处理的请求 limit_req zone=req_one burst=100; } 消峰  活动分时段 答题验证  高并发读 &amp;ldquo;马某出轨王某&amp;rdquo;、&amp;ldquo;iPhone SE 2020 发布&amp;rdquo; 等这种热点新闻的 key 会始终落在同一个缓存节点上，分布式缓存一定会出现单点瓶颈，其资源连接容易瞬间耗尽。有如下两种方案解决这个问题：
 基于 Redis 的集群多写多读方案。  多写如何保持一致性：将 Key 配置在 ZooKeeper，客户端监听 ZNode，一旦变化，全量更新本地持有的 Key   LocalCache 结合 Redis 集群的多级 Cache 方案。  LocalCache 拉取下来的商品数量有 5 个，但是实际上只有 4 个了，怎么解决？对于这种读场景，允许接受一定程度上的数据脏读，最终扣减库存的时候再提示商品已经售罄即可。    实时热点自动发现 交易系统产生的相关数据、上游系统中埋点上报的数据这两个，异步写入日志，对日志进行次数统计和热点分析</description>
    </item>
    
  </channel>
</rss>