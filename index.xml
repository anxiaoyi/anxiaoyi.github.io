<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>☁️ 网络协议、🛠️ 系统设计与架构、🚀 RocketMQ 源码分析、☕ Java、💽 数据库、💾 Redis、💻 Unix 知识、📚 阅读 基础知识点分享 on 赵坤的个人网站</title>
    <link>https://kunzhao.org/</link>
    <description>Recent content in ☁️ 网络协议、🛠️ 系统设计与架构、🚀 RocketMQ 源码分析、☕ Java、💽 数据库、💾 Redis、💻 Unix 知识、📚 阅读 基础知识点分享 on 赵坤的个人网站</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-cn</language>
    <lastBuildDate>Wed, 09 Dec 2020 00:00:00 +0000</lastBuildDate><atom:link href="https://kunzhao.org/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>微服务无损扩容</title>
      <link>https://kunzhao.org/posts/lossless-expansion/</link>
      <pubDate>Wed, 09 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/posts/lossless-expansion/</guid>
      <description>微服务无损扩容 技术挑战  拆分的不好，热点数据节点成为瓶颈 数据迁移、路由改变，能否让业务没有感知 扩容失败，如何回滚? 整个过程，如何维持数据一致性?  如何拆分 业务设计表的时候，需要决定哪个键是 shardkey
如何让业务没有感知 时间点如凌晨自动切换；也可以让业务根据实际情况判断，人工切换
整个过程如何高可用    新建数据同步 (sync、async) 关系    持续进行数据校验，计算延时差，小于某个阈值，比如 5 秒    小于阈值后，有请求进来，拒绝掉，让业务去重试，业务的响应时间可能有秒级影响，不过整个持续时间很短。数据很快追上来，这个时候原子修改路由，路由切换好了，就可以重新接受请求了    慢慢地延迟删除冗余数据，防止 IO 波动过大    分布式事务  操作同一个节点，使用普通事务 操作多个节点，使用两阶段提交  参考  腾讯会议核心数据库TDSQL，如何做到快速无损在线扩容?  </description>
    </item>
    
    <item>
      <title>DB2 教程</title>
      <link>https://kunzhao.org/posts/db2-tutorial/</link>
      <pubDate>Sat, 05 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/posts/db2-tutorial/</guid>
      <description>DB2 教程 排序 ORDER BY SELECT select_list FROM table_name ORDER BY expression1 [ASC | DESC], expression2 [ASC | DESC], ... 过滤 DISTINCT SELECT DISTINCT column_name1, column_name2, ... FROM table_name; IN WHERE publisher_id IN (100, 103, 105) LIMIT 行 LIMIT LIMIT 10 OFFSET 5; 也可以写成：
LIMIT 5, 10 FETCH SELECT title, rating FROm books ORDER BY rating DESC FETCH FIRST 10 ROWS ONLY; 下一页：
SELECT title, rating FROm books ORDER BY rating DESC OFFSET 10 ROWS FETCH NEXT 10 ROWS ONLY; DB2 类型 Integers 支持三种：SMALLINT (-32768 ~ 32767)、INT (31 bits)、BIGINT (63 bits)。示例：</description>
    </item>
    
    <item>
      <title>Oracle 教程</title>
      <link>https://kunzhao.org/posts/oracle-tutorial/</link>
      <pubDate>Sat, 05 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/posts/oracle-tutorial/</guid>
      <description>Oracle 教程 select 语句  语句文本的书写不区分大小写。（但字符串在作为值的时候要注意大小写） 连接操作符：  select lastname || &amp;#39;work in&amp;#39; || department_id from tablename; 过滤数据 DISTINCT column_1、column_2、column_3 共同决定一条唯一的记录：
SELECT DISTINCT column_1, column_2, column_3 FROM table_name; FETCH Oracle 没有 LIMIT，使用 FETCH 实现相同效果：
SELECT product_name, quantity FROM inventories INNER JOIN products USING (product_id) ORDER BY quantity DESC FETCH NEXT 5 ROWS ONLY; 更多语法：
 FETCH FIRST 5 PERCENT ROWS ONLY：返回前 5% 百分比 OFFSET 10 ROWS FETCH NEXT 10 ROWS ONLY: 跳过前 10 条，返回下 10 条  IN WHERE salesman_id IN (54, 55, 56) WHERE status IN (&amp;#39;Pending&amp;#39;, &amp;#39;Canceled&amp;#39;) WHERE status NOT IN (&amp;#39;Shipped&amp;#39;, &amp;#39;Canceled&amp;#39;) BETWEEN WHERE order_date BETWEEN DATE &amp;#39;2016-12-01&amp;#39; AND DATE &amp;#39;2016-12-31&amp;#39; WHERE standard_cost NOT BETWEEN 500 AND 600 LIKE  %: 匹配字符串的 0 或者任意多字符 _: 匹配一个字符  WHERE last_name LIKE &amp;#39;St%&amp;#39; IS NULL  NULL 和 &#39;&#39;、0 是不同的。</description>
    </item>
    
    <item>
      <title>War 文件格式</title>
      <link>https://kunzhao.org/posts/war/</link>
      <pubDate>Wed, 12 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/posts/war/</guid>
      <description>WAR file (Web Application Resource or Web application ARchive)。WAR 组织文件的标准方式：
WEB-INF 存储在这个文件夹内的文件，默认情况下浏览器访问不到。
web.xml Tomcat 需要
classes 所有编译的 class 文件
lib 包含项目依赖的所有的 JAR 库
tags 包含 Tag 文件
参考  Web Modules  </description>
    </item>
    
    <item>
      <title>JSP</title>
      <link>https://kunzhao.org/posts/jsp/</link>
      <pubDate>Tue, 11 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/posts/jsp/</guid>
      <description>JSP 脚本 脚本程序可以包含任意量的Java语句、变量、方法或表达式，只要它们在脚本语言中是有效的。
&amp;lt;% 代码片段 %&amp;gt;JSP 声明 &amp;lt;%! int i = 0; %&amp;gt; &amp;lt;%! int a, b, c; %&amp;gt; &amp;lt;%! Circle a = new Circle(2.0); %&amp;gt; JSP 表达式 &amp;lt;p&amp;gt; 今天的日期是: &amp;lt;%= (new java.util.Date()).toLocaleString()%&amp;gt; &amp;lt;/p&amp;gt; JSP 注释 &amp;lt;%-- 该部分注释在网页中不会被显示--%&amp;gt; JSP 指令 &amp;lt;%@ directive attribute=&amp;quot;value&amp;quot; %&amp;gt;三种 directive：
   指令 描述     &amp;lt;%@ page &amp;hellip; %&amp;gt; 定义页面的依赖属性，比如脚本语言、error页面、缓存需求等等   &amp;lt;%@ include &amp;hellip; %&amp;gt; 包含其他文件   &amp;lt;%@ taglib &amp;hellip; %&amp;gt; 引入标签库的定义，可以是自定义标签    &amp;lt;%@ page import=&amp;quot;java.</description>
    </item>
    
    <item>
      <title>IBM MQ</title>
      <link>https://kunzhao.org/posts/ibmmq/</link>
      <pubDate>Mon, 10 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/posts/ibmmq/</guid>
      <description>IBM MQ 架构 IBM WebSphere MQ 架构：
IBM WheSphere MQ 特性：
 支持事务 具有特殊的技术防止消息重复传送，确保消息一次且仅一次传递  概念 消息 队列  本地队列：位于本地物理磁盘 远程队列：本地应用程序只能往里面放消息，不能直接读消息。只能从本地队列读取消息 传输队列：临时存储将要发送到远程队列的消息 启动队列：触发中使用的队列，触发器触发事件时，将触发器消息发送到启动队列 死信队列：存储无法正确发送到目的地的消息的队列  通道 通道：提供从一个队列管理器到另外一个队列管理器的通信路径
通道如何使用：
MQSC MQSC 是用来管理队列管理器等对象的脚本命令，可以使用 runmqsc 向队列管理器发出 MQSC 命令。
MQSC 的官方命令文档：The MQSC Commands
MQSC 的一些规则：
 关键字不区分大小写：ALTER、alter、AlteR 都是一样的 很多命令都有同义词：例如 DEFINE CHANNEL 可以写为 def chl 用单引号引用的字符串，IBM MQ 不做转换处理 每条命令必须以新行开始  Control Commands Control Commands 的官方文档：The control commands
发送消息步骤 发送消息前，需要启动队列管理器、启动监听器（监听在某个端口）。
为了把消息从一个队列管理器发送到另一个队列管理器，您需要定义两个通道；一个是在源队列管理器（指明传输队列名、目标系统的IP:PORT），另一个是在目标队列管理器。
为把消息从一个队列管理器发送到另一个队列管理器，您需要定义六个队列；在源队列管理器需要定义四个（远程队列、启动队列、传输队列、死信队列-推荐），目标队列管理器要定义两个（本地队列、死信队列-推荐）。
编程接口 Queue Manager // declare an object of type queue manager MQQueueManager queueManager = new MQQueueManager(); MQQueueManager queueManager = new MQQueueManager(&amp;#34;qMgrName&amp;#34;); .</description>
    </item>
    
    <item>
      <title>Spring Boot</title>
      <link>https://kunzhao.org/posts/springboot/</link>
      <pubDate>Mon, 10 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/posts/springboot/</guid>
      <description>Spring Boot 提供了两个接口 CommandLineRunner 和 ApplicationRunner，用以当 Spring Boot 应用程序完全启动之前运行指定的代码。
CommandLineRunner @Component public class CommandLineAppStartupRunner implements CommandLineRunner { private static final Logger logger = LoggerFactory.getLogger(CommandLineAppStartupRunner.class); @Override public void run(String...args) throws Exception { logger.info(&amp;#34;Application started with command-line arguments: {} . \n To kill this application, press Ctrl + C.&amp;#34;, Arrays.toString(args)); } } ApplicationRunner 将参数封装为一个对象，可以调用 getOptionNames()、getOptionValues() 和 getSourceArgs() 等便捷的方法。
@Component public class AppStartupRunner implements ApplicationRunner { private static final Logger logger = LoggerFactory.getLogger(AppStartupRunner.class); @Override public void run(ApplicationArguments args) throws Exception { logger.</description>
    </item>
    
    <item>
      <title>JAX-WS</title>
      <link>https://kunzhao.org/posts/jax-ws/</link>
      <pubDate>Fri, 07 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/posts/jax-ws/</guid>
      <description>JAX-WS JAX-WS 代表 Java API for XML Web Service。
WebService  @WebService 用来将**某个类(一个 Interface)**声明为一个 Web Service EndPoint，这个类的实现类也得需要声明 @WebService 接口类的方法必须 public，并且不能使用 static 或 final 来修饰 接口类的方法必须声明 @WebMethod 实现类必须有一个默认的 public 构造器 实现类不要定义 finalize 方法  Apache CXF 定义 Endpoint，此处的 endpointInterface 非常重要，指向的是 Interface 类全称。
@WebService(endpointInterface = &amp;#34;com.baeldung.cxf.introduction.Baeldung&amp;#34;) public class BaeldungImpl implements Baeldung {} 查看 WSDL 信息 URL 后面往往跟一个 ?wsdl 字符串。
底层数据传输 GET WSDL 发送 POST 请求 接受 POST 响应 阅读更多 java 实现WebService 以及不同的调用方式、JAX-WS Web 服务开发调用和数据传输分析</description>
    </item>
    
    <item>
      <title>Oracle</title>
      <link>https://kunzhao.org/posts/oracle/</link>
      <pubDate>Fri, 07 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/posts/oracle/</guid>
      <description>内置数据类型    分类 数据类型 介绍     字符 CHAR [(size [BYTE | CHAR])] 定长字符串，占据 n 字节    NCHAR[(size)] 定长字符串，占据 2n 字节    VARCHAR2(size) 可变长度的字符串    NVARCHAR2(size) 可变长度的 UNICODE 字符串   数值 NUMBER(p,s) p 代表精度(1 - 38)，s 代表 scale (-84 - 127)    FLOAT [(p)] 小数，精度不高    LONG 仅仅为了兼容   日期 DATE 大小固定占用 7 bytes    TIMESTAMP    字节 RAW(size) 定长    LONG RAW 变长，图像、声音、文档、数组，建议使用 LOB    LOB     ROWID 伪列 SELECT ROWID from your_table;  ROWID 不能被用作主键。</description>
    </item>
    
    <item>
      <title>Ant</title>
      <link>https://kunzhao.org/posts/ant/</link>
      <pubDate>Thu, 06 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/posts/ant/</guid>
      <description>Ant 官方教程 官方教程链接
Ant Properties 提供一些键值对，使用 ${key} 来获取其 value。官网 列举了很多内置的 properties。
Ant Classpath 定义 classpath：
&amp;lt;project name=&amp;#34;HelloWorld&amp;#34; basedir=&amp;#34;.&amp;#34; default=&amp;#34;main&amp;#34;&amp;gt; &amp;lt;path id=&amp;#34;classpath&amp;#34;&amp;gt; &amp;lt;fileset dir=&amp;#34;${lib.dir}&amp;#34; includes=&amp;#34;**/*.jar&amp;#34;/&amp;gt; &amp;lt;/path&amp;gt; &amp;lt;target name=&amp;#34;compile&amp;#34;&amp;gt; &amp;lt;mkdir dir=&amp;#34;${classes.dir}&amp;#34;/&amp;gt; &amp;lt;javac srcdir=&amp;#34;${src.dir}&amp;#34; destdir=&amp;#34;${classes.dir}&amp;#34; classpathref=&amp;#34;classpath&amp;#34;/&amp;gt; &amp;lt;/target&amp;gt; &amp;lt;target name=&amp;#34;run&amp;#34; depends=&amp;#34;jar&amp;#34;&amp;gt; &amp;lt;java fork=&amp;#34;true&amp;#34; classname=&amp;#34;${main-class}&amp;#34;&amp;gt; &amp;lt;classpath&amp;gt; &amp;lt;path refid=&amp;#34;classpath&amp;#34;/&amp;gt; &amp;lt;path location=&amp;#34;${jar.dir}/${ant.project.name}.jar&amp;#34;/&amp;gt; &amp;lt;/classpath&amp;gt; &amp;lt;/java&amp;gt; &amp;lt;/target&amp;gt; &amp;lt;/project&amp;gt; Ant Targets Target 是多个 tasks 的容器，这个 Target 用来完成在整个 build 过程中的某个任务，使之达到某个状态。
&amp;lt;target name=&amp;#34;A&amp;#34;/&amp;gt; &amp;lt;target name=&amp;#34;B&amp;#34; depends=&amp;#34;A&amp;#34;/&amp;gt; &amp;lt;target name=&amp;#34;C&amp;#34; depends=&amp;#34;B&amp;#34;/&amp;gt; &amp;lt;target name=&amp;#34;D&amp;#34; depends=&amp;#34;C,B,A&amp;#34;/&amp;gt; 调用链：</description>
    </item>
    
    <item>
      <title>Struts 2</title>
      <link>https://kunzhao.org/posts/struts2/</link>
      <pubDate>Thu, 06 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/posts/struts2/</guid>
      <description>Action 访问 Servlet API 使用 ActionContext 来访问 Servlet API。
    Servlet API JSP 对象     HttpServletRequest request   HttpSession session   ServletContext application     操作 Session：
ActionContext.getContext().getSession().put(&amp;#34;user&amp;#34;, userName); 在 JSP 页面中可以通过
${sessionScope.user}来输出userName。
数据校验 ActionSupport 是一个工具类，已经实现了 Action 接口，实现了 Validatable 接口，提供数据校验功能。
@Override public void validate() { if (getUserName() == null || getUserName().trim().equals(&amp;#34;&amp;#34;)) { addFieldError(&amp;#34;username&amp;#34;, getText(&amp;#34;user.required&amp;#34;)); } } struts.xml 配置文件 分为多个配置文件：</description>
    </item>
    
    <item>
      <title>如何维持缓存的一致性？</title>
      <link>https://kunzhao.org/posts/maintaining-cache-consistency/</link>
      <pubDate>Sun, 31 May 2020 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/posts/maintaining-cache-consistency/</guid>
      <description>&lt;p&gt;Phil Karlton 曾经说过，“计算机科学中只有两件困难的事情：缓存失效和命名问题。” 这句话还有其他很好的举例。我个人最喜欢 Jeff Atwood 的一句话：“计算机科学中有两件困难的事情：缓存失效、命名和一个错误就关闭。”显然，缓存是困难的。就像分布式系统中的几乎所有东西一样，它甚至可能一眼就看不清。我将介绍分布式系统中几种常见的缓存方法，这些方法应该涵盖您将使用的绝大多数缓存系统。具体来说，我将关注如何维护缓存一致性。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>如何改进 NGINX 配置文件节省带宽？</title>
      <link>https://kunzhao.org/posts/help-the-world-by-healing-your-nginx-configuration/</link>
      <pubDate>Sun, 24 May 2020 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/posts/help-the-world-by-healing-your-nginx-configuration/</guid>
      <description>&lt;p&gt;2014年，Admiral William H. McRaven 在得克萨斯大学发表了著名的演讲，他说，如果你想改变世界，就从整理床铺开始。有时候小事情会有很大的影响——不管是在早上整理床铺，还是对网站的HTTP服务器配置做一些更改。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Best Time to Buy and Sell Stock</title>
      <link>https://kunzhao.org/docs/programmer-interview/algorithm/best-time-to-buy-and-sell-stock/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/programmer-interview/algorithm/best-time-to-buy-and-sell-stock/</guid>
      <description>Best Time to Buy and Sell Stock 题目 LeetCode 地址：Best Time to Buy and Sell Stock
有一个数组，第 i 个元素的值代表第 i 天的股票价格，如果你最多只能进行一次交易（某天买入一支股票，然后过几天卖掉），请问你能收获的最大利润是多少？
分析 这道题有两个简单做法：状态机和动态规划。
使用状态机的做法的好处是，这种思路可以延续到其它几个买卖股票的问题上。关键是要想清楚，某一天有几种状态，在这道题是三种：
 状态 s0: 不买也不卖，无操作。s0 的值只能有一个来源，就是和昨天保持一致，不买也不卖 状态 s1: 买入了股票。s1 的值有两个来源：1. 与昨天一致，即已经买入了，且只能买一次，所以不能再买了，s1 = s1；2. 买入今天的股票，花了 price[i] 钱，s1 = s0 - price[i] 状态 s2: 卖出了股票。s2 的值有两个来源：1. 之前已经卖出了，所以维持卖出状态，不能再次卖了，s2 = s1；2. 卖出之前买入的股票，挣 price[i] 钱，s2 = s1 + price[i]  所以，我们可以得到如下状态转移关系：
 s0 = s0 s1 = s1 s1 = s0 - price[i] s2 = s2 s2 = s1 + price[i]  在这整个过程中，我们都要保证每一天的 s0、s1、s2 都是 max 状态，s2 是最终卖完后的收益，所以返回这个结果就行。</description>
    </item>
    
    <item>
      <title>Brave 收集数据</title>
      <link>https://kunzhao.org/docs/tutorial/zipkin/brave/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/tutorial/zipkin/brave/</guid>
      <description>Brave 收集数据 在 Java 生态世界中，Zipkin 团队官方提供了 Brave 用来收集数据到 Zipkin Server 中。其它的用来收集数据的框架还有 cassandra-zipkin-tracing、Dropwizard Zipkin、htrace、Spring Cloud Sleuth 以及 Wingtips 等。
示例代码 配置 Tracer 配置 Tracer 以向 Zipkin Server 上传数据。
// Configure a reporter, which controls how often spans are sent // (this dependency is io.zipkin.reporter2:zipkin-sender-okhttp3) sender = OkHttpSender.create(&amp;#34;http://127.0.0.1:9411/api/v2/spans&amp;#34;); // (this dependency is io.zipkin.reporter2:zipkin-reporter-brave) zipkinSpanHandler = AsyncZipkinSpanHandler.create(sender); // Create a tracing component with the service name you want to see in Zipkin. tracing = Tracing.</description>
    </item>
    
    <item>
      <title>B站高可用架构实践</title>
      <link>https://kunzhao.org/docs/cloud-plus-bbs/bilibili-high-availability/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/cloud-plus-bbs/bilibili-high-availability/</guid>
      <description>B站高可用架构实践 流量洪峰下要做好高服务质量的架构是一件具备挑战的事情，从Google SRE的系统方法论以及实际业务的应对过程中出发，分享一些体系化的可用性设计。对我们了解系统的全貌上下游的联防有更进一步的了解。
负载均衡 BFE 就是指边缘节点，BFE 选择下游 IDC 的逻辑权衡：
 离 BFE 节点比较近的 基于带宽的调度策略 某个 IDC 的流量已经过载，选择另外一个 IDC  当流量走到某个 IDC 时，这个流量应该如何进行负载均衡？
问题：RPC 定时发送的 ping-pong，也即 healthcheck，占用资源也非常多。服务 A 需要与账号服务维持长连接发送 ping-pong，服务 B 也需要维持长连接发送 ping-pong。这个服务越底层，一般依赖和引用这个服务的资源就越多，一旦有任何抖动，那么产生的这个故障面是很大的。那么应该如何解决？
解决：以前是一个 client 跟所有的 backend 建立连接，做负载均衡。现在引入一个新的算法，子集选择算法，一个 client 跟一小部分的 backend 建立连接。图片中示例的算法，是从《Site Reliability Engineering》这本书里看的。
如何规避单集群抖动带来的问题？多集群。
如上述图片所示，如果采用的是 JSQ 负载均衡算法，那么对于 LBA 它一定是选择 Server Y 这个节点。但如果站在全局的视角来看，就肯定不会选择 Server Y 了，因此这个算法缺乏一个全局的视角。
如果微服务采用的是 Java 语言开发，当它处于 GC 或者 FullGC 的时候，这个时候发一个请求过去，那么它的 latency 肯定会变得非常高，可能会产生过载。
新启动的节点，JVM 会做 JIT，每次新启动都会抖动一波，那么就需要考虑如何对这个节点做预热？
如上图所示，采用 &amp;ldquo;the choice-of-2&amp;rdquo; 算法后，各个机器的 CPU 负载趋向于收敛，即各个机器的 CPU 负载都差不多。Client 如何拿到后台的 Backend 的各项负载？是采用 Middleware 从 Rpc 的 Response 里面获取的，有很多 RPC 也支持获取元数据信息等。</description>
    </item>
    
    <item>
      <title>C &amp; C&#43;&#43;</title>
      <link>https://kunzhao.org/docs/tutorial/distributed-storage/c_cpp/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/tutorial/distributed-storage/c_cpp/</guid>
      <description>C &amp;amp; C++  补充 C &amp;amp; C++ 知识点
 xx.a 文件 这是静态链接库文件。
undefined reference to pthread_create g++ -pthread ... 链接静态文件 文件组织形式：
|- include | - leveldb | - db.h | - cache.h | - xxx.h |- build | - libleveldb.a |test.c g++ test.c -I include/ -L build/ -l leveldb -pthread -o test.out ./test.out  include/ 文件夹中包含了头文件 build/ 文件夹包含了 libleveldb.a  参考</description>
    </item>
    
    <item>
      <title>createApp</title>
      <link>https://kunzhao.org/docs/tutorial/vue3/createapp/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/tutorial/vue3/createapp/</guid>
      <description>createApp 一个简单的计数器例子 创建渲染器 挂载 App 上下文 // apiCreateApp.ts export function createAppContext(): AppContext { return { app: null as any, config: { isNativeTag: NO, performance: false, globalProperties: {}, optionMergeStrategies: {}, isCustomElement: NO, errorHandler: undefined, warnHandler: undefined }, mixins: [], components: {}, directives: {}, provides: Object.create(null) } } </description>
    </item>
    
    <item>
      <title>DevOps 简介</title>
      <link>https://kunzhao.org/docs/tutorial/devops/intro/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/tutorial/devops/intro/</guid>
      <description>DevOps 简介 DevOps (Development 与 Operations) 是一种文化，这种文化旨在建立一个使得软件构建、测试、发布等得以快速、稳定，实施交付的环境。
那么如何做到快速？如何做到稳定？答案是自动化工具。开发到测试到上线之间的所有需要手动处理的环节，都是可以尝试优化的点。
DevOps 能力成熟度模型 全球首个 DevOps 标准，即《研发运营一体化（DevOps）能力成熟度模型》，由中国信息通信研究院牵头，云计算开源产业联盟、高效运维社区、 DevOps 时代社区联合 Google、BATJ、清华大学、南京大学、通信及金融等行业顶尖企事业单位专家共同制定。
目前很多公司都在参考这套模型进行实践。
DevOps 工具集锦 信通院整理的的 DevOps 工具集锦（看不清的话，图片上右击，在新标签页中打开图像）：
持续集成  每次提交代码，就会触发完整的流水线。这需要打通版本控制系统和持续集成系统，例如 GitLab 和 Jenkins 集成。 每次流水线，触发自动化测试。 出了问题，第一时间修复。  推荐书籍  《持续交付 2.0》 《DevOps 实践指南》  </description>
    </item>
    
    <item>
      <title>DHCP</title>
      <link>https://kunzhao.org/docs/tutorial/network/dhcp/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/tutorial/network/dhcp/</guid>
      <description>DHCP DHCP 是 Dynamic Host Configuration Protocol (动态主机配置协议) 的缩写。
作用 手机、电脑或其它网络设备想要与其它计算机进行通讯，就需要配置 IP 地址，DHCP 协议就是为网络设备动态分配 IP 地址的一种协议。DHCP 底层基于 UDP 传输层协议，端口 67 是 DHCP Server 端使用的端口，端口 68 是 DHCP Client 端使用的接口。
工作方式 DHCP 协议分配 IP 地址可以分为 4 个步骤：
Discovery 网络中新加入的某个设备（DHCP 客户端），会使用 IP 地址 0.0.0.0 向该网络发送一个广播包，这个包的目的 IP 地址是 255.255.255.255。这个 UDP 包封装的内容如下所示：
   头 内容     MAC 头 源 MAC：设备自身的 MAC 地址，目的 MAC 地址：FF:FF:FF:FF:FF:FF   IP 头 源 IP: 0.</description>
    </item>
    
    <item>
      <title>fastjson 又现高危漏洞！</title>
      <link>https://kunzhao.org/docs/it-zone/2020-06/fastjson-high-risk-vulnerability/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/it-zone/2020-06/fastjson-high-risk-vulnerability/</guid>
      <description>fastjson 又现高危漏洞！ 日期：2020-06-01
 5 月 28 日，据 360 网络安全响应中心发布《Fastjson远程代码执行漏洞通告》显示，由阿里巴巴开源的 fastjson 库 又现高危漏洞，该漏洞可导致不法分子远程执行服务器命令等严重后果。
fastjson 是阿里巴巴的开源JSON解析库，它可以解析JSON格式的字符串，支持将Java Bean序列化为JSON字符串，也可以从JSON字符串反序列化到 JavaBean。
fastjson 存在远程代码执行漏洞，autotype 开关的限制可以被绕过，链式的反序列化攻击者精心构造反序列化利用链，最终达成远程命令执行的后果。此漏洞本身无法绕过 fastjson 的黑名单限制，需要配合不在黑名单中的反序列化利用链才能完成完整的漏洞利用。
该漏洞影响的版本：&amp;lt;= 1.2.68
该漏洞修复建议：
 升级到 fastjson 1.2.69/1.2.70 版本，下载地址为 Releases · alibaba/fastjson 或者通过配置以下参数开启 SafeMode 来防护攻击：ParserConfig.getGlobalInstance().setSafeMode(true);（safeMode 会完全禁用 autotype，无视白名单，请注意评估对业务影响）  </description>
    </item>
    
    <item>
      <title>Git 配置用户名和邮箱</title>
      <link>https://kunzhao.org/docs/tutorial/git/config-user-and-email/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/tutorial/git/config-user-and-email/</guid>
      <description>Git 配置用户名和邮箱 假设你的用户名是 zk，邮箱账号是 xxx@163.com，那么需要提前配置 Git 的用户名和邮箱帐号：
git config --global user.name &amp;#34;zk&amp;#34; git config --global user.email &amp;#34;xxx@163.com&amp;#34; Git 需要知道谁对代码做出了变更，对代码做出变更的这个人的邮件联系方式是什么，以方便追踪。
Git Config 有三个作用域：
 git config --local：只对某个仓库有效 git config --global：对当前用户所有仓库有效 git config --system：对系统所有登录的用户有效  如何查看当前设置的 Git 配置？
git config --list --local git config --list --global git config --list --system  --local 针对的是某个仓库，配置 --local 作用域的时候，需要进入到项目所在的目录才能配置或显示。
 </description>
    </item>
    
    <item>
      <title>grep</title>
      <link>https://kunzhao.org/docs/tutorial/unix-command/grep/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/tutorial/unix-command/grep/</guid>
      <description>grep grep 命令如何使用？grep 命令的常见用法？
简介 grep 命令用于搜索文本。它在给定文件中搜索包含与给定字符串或单词匹配的行。它是 Linux 和类 Unix 系统中最有用的命令之一。让我们看看如何在 Linux 或类 Unix 系统上使用 grep。
grep 命令是一个包含 grep、egrep 和 fgrep 命令的大家族，都用于搜索文本。
常见用法 下面是一些标准的 grep 命令，通过示例说明了如何在Linux、macOS和Unix上使用 grep：
（1）在文件 foo.txt 中搜索单词 word
grep &amp;#39;word&amp;#39; foo.txt （2）在文件 foo.txt 中搜索单词 word，并且忽略大小写
grep -i &amp;#39;word&amp;#39; foo.txt 上述命令会把位于 foo.txt 文件中的 WORD、Word、word 等忽略大小写的 word 全部搜索出来。
（3）在当前目录以及所有子目录中查找单词 word
grep -R &amp;#39;word&amp;#39; .  注意：最后面有一个点，代表当前目录。-r 命令也是递归搜索，只是 -r 不会搜索符号链接文件。
 （4）搜索并显示单词 word 出现的次数
grep -c &amp;#39;word&amp;#39; foo.txt （5）只匹配单词 word</description>
    </item>
    
    <item>
      <title>Kubernetes</title>
      <link>https://kunzhao.org/docs/tutorial/technique/k8s/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/tutorial/technique/k8s/</guid>
      <description>Kubernetes Kubernetes 发音 /Koo-ber-nay-tace/ 或者 /Koo-ber-netties/ 。
解决的问题 微服务部署和配置困难。
 简化应用程序的部署。开发者无须知道背后有多少台机器需要部署，也无需知道自己的 APP 运行在哪几台机器上。 对于资源的更为高效的利用。K8S 可以在任意时刻将 APP 迁移到其他 worker 节点上，以便更好的利用资源。 健康检查。node 挂掉后，自动将 APP 调度到其他节点上。 自动伸缩。K8S 可以自己关注资源的利用率，动态调整 APP 的实例数量。  概念解释 VM 和容器 APP 运行在 VM 中  APP 运行在容器中   K8S 运行 APP 开发者告诉 K8S 的 master 节点，哪些 APP 必须部署在一起，每一个 APP 需要部署几个实例，K8S 就会自动按照要求将这些 APP 部署到 worker 节点上。
K8S 由 master 和 worker 节点构成，其中 K8S 管理控制台位于 master 节点上，可以通过此平台管理整个 K8S 系统；而 worker 节点用于实际运行 APP。</description>
    </item>
    
    <item>
      <title>Map</title>
      <link>https://kunzhao.org/docs/programmer-interview/data-structure/map/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/programmer-interview/data-structure/map/</guid>
      <description>Map </description>
    </item>
    
    <item>
      <title>MySQL 查询</title>
      <link>https://kunzhao.org/docs/tutorial/database/mysql-query/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/tutorial/database/mysql-query/</guid>
      <description>MySQL 查询 MySQL 逻辑架构 连接器 第一步，你会先连接到这个数据库上，这时候接待你的就是连接器。连接器负责跟客户端建立连接、获取权限、维持和管理连接。连接命令一般是这么写的：
mysql -h$ip -P$port -u$user -p 连接完成后，如果你没有后续的动作，这个连接就处于空闲状态，你可以在 show processlist 命令中看到它。客户端如果太长时间没动静，连接器就会自动将它断开。这个时间是由参数 wait_timeout 控制的，默认值是 8 小时。
查询缓存 连接建立完成后，你就可以执行 select 语句了。执行逻辑就会来到第二步：查询缓存。MySQL 拿到一个查询请求后，会先到查询缓存看看，之前是不是执行过这条语句。之前执行过的语句及其结果可能会以 key-value 对的形式，被直接缓存在内存中。key 是查询的语句，value 是查询的结果。如果你的查询能够直接在这个缓存中找到 key，那么这个 value 就会被直接返回给客户端。
但是大多数情况下我会建议你不要使用查询缓存，为什么呢？因为查询缓存往往弊大于利。查询缓存的失效非常频繁，只要有对一个表的更新，这个表上所有的查询缓存都会被清空。因此很可能你费劲地把结果存起来，还没使用呢，就被一个更新全清空了。对于更新压力大的数据库来说，查询缓存的命中率会非常低。除非你的业务就是有一张静态表，很长时间才会更新一次。
你可以将参数 query_cache_type 设置成 DEMAND，这样对于默认的 SQL 语句都不使用查询缓存。
分析器 如果没有命中查询缓存，就要开始真正执行语句了。首先，MySQL 需要知道你要做什么，因此需要对 SQL 语句做解析。分析器先会做“词法分析”。你输入的是由多个字符串和空格组成的一条 SQL 语句，MySQL 需要识别出里面的字符串分别是什么，代表什么。
做完了这些识别以后，就要做“语法分析”。根据词法分析的结果，语法分析器会根据语法规则，判断你输入的这个 SQL 语句是否满足 MySQL 语法。
优化器 经过了分析器，MySQL 就知道你要做什么了。在开始执行之前，还要先经过优化器的处理。优化器是在表里面有多个索引的时候，决定使用哪个索引；或者在一个语句有多表关联（join）的时候，决定各个表的连接顺序。
执行器 MySQL 通过分析器知道了你要做什么，通过优化器知道了该怎么做，于是就进入了执行器阶段，开始执行语句。开始执行的时候，要先判断一下你对这个表 T 有没有执行查询的权限，如果没有，就会返回没有权限的错误。
如果有权限，就打开表继续执行。打开表的时候，执行器就会根据表的引擎定义，去使用这个引擎提供的接口。第一次调用的是“取满足条件的第一行”这个接口，之后循环取“满足条件的下一行”这个接口，这些接口都是引擎中已经定义好的。
ResultSet 的数据存放在哪里 实际上，服务端并不需要保存一个完整的结果集。取数据和发数据的流程是这样的：
 获取一行，写到 net_buffer 中。这块内存的大小是由参数 net_buffer_length 定义的，默认是 16k。 重复获取行，直到 net_buffer 写满，调用网络接口发出去。 如果发送成功，就清空 net_buffer，然后继续取下一行，并写入 net_buffer。 如果发送函数返回 EAGAIN 或 WSAEWOULDBLOCK，就表示本地网络栈（socket send buffer）写满了，进入等待。直到网络栈重新可写，再继续发送。  MySQL 是“边读边发的”，这个概念很重要。这就意味着，如果客户端接收得慢，会导致 MySQL 服务端由于结果发不出去，这个事务的执行时间变长。</description>
    </item>
    
    <item>
      <title>Netflix Eureka 简介</title>
      <link>https://kunzhao.org/docs/tutorial/eureka/intro/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/tutorial/eureka/intro/</guid>
      <description>Netflix Eureka 简介 Eureka 干什么 Eureka 是一套服务治理框架，其包含 Server 端和 Client 端。
架构 为什么需要服务治理 A 服务需要调用 B 服务，B 服务的 URL （可能不止一个）可以通过静态配置来维护，但是随着微服务越来越复杂，静态配置就会越来越难以维护，且维护需要耗费好多人力。
服务治理包括什么    组件 描述     注册中心 每个服务需要向注册中心注册自己提供的服务   服务发现 调用方向注册中心咨询自己调用的服务的地址是什么    </description>
    </item>
    
    <item>
      <title>Redis 数据结构</title>
      <link>https://kunzhao.org/docs/tutorial/redis/datastructure/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/tutorial/redis/datastructure/</guid>
      <description>Redis 数据结构 概览 数据类型和数据结构 键和值用什么组织 哈希桶中的元素保存的并不是值本身，而是指向具体值的指针。
字符串 struct SDS&amp;lt;T&amp;gt; { T capacity; // 数组容量  T len; // 数组长度  byte flags; // 特殊标识位，不理睬它  byte[] content; // 数组内容 } 当字符串比较短时，len 和 capacity 可以使用 byte 和 short 来表示，Redis 为了对内存做极致的优化，不同长度的字符串使用不同的结构体来表示。当字符串长度小于 1M 时，扩容都是加倍现有的空间，如果超过 1M，扩容时一次只会多扩 1M 的空间。需要注意的是字符串最大长度为 512M。
哈希 存储形式：压缩列表 ziplist 和哈希表 hash
struct RedisDb { dict* dict; // all keys key=&amp;gt;value  dict* expires; // all expired keys key=&amp;gt;long(timestamp)  ... } struct zset { dict *dict; // all values value=&amp;gt;score  zskiplist *zsl; } dict 结构内部包含两个 hashtable，通常情况下只有一个 hashtable 是有值的。但是在 dict 扩容缩容时，需要分配新的 hashtable，然后进行渐进式搬迁，这时候两个 hashtable 存储的分别是旧的 hashtable 和新的 hashtable。待搬迁结束后，旧的 hashtable 被删除，新的 hashtable 取而代之。</description>
    </item>
    
    <item>
      <title>RocketMQ 消息发送流程</title>
      <link>https://kunzhao.org/docs/rocketmq/rocketmq-send-message-flow/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/rocketmq/rocketmq-send-message-flow/</guid>
      <description>RocketMQ 消息发送流程  基于 RocketMQ 4.2.0 版本进行的源码分析。
 本文讲述 RocketMQ 发送一条普通消息的流程。
一、服务器启动 我们可以参考官方文档来启动服务:
 启动 Name 服务器:  sh bin/mqnamesrv  启动 Broker 服务器:  sh bin/mqbroker -n localhost:9876 二、构建消息体 一条消息体最少需要指定两个值:
 所属话题 消息内容  如下就是创建了一条话题为 “Test”，消息体为 “Hello World” 的消息:
Message msg = new Message( &amp;#34;Test&amp;#34;, &amp;#34;Hello World&amp;#34;.getBytes() ); 三、启动 Producer 准备发送消息 如果我们想要发送消息呢，我们还需要再启动一个 DefaultProducer (生产者) 类来发消息:
DefaultMQProducer producer = new DefaultMQProducer(); producer.start(); 现在我们所启动的服务如下所示:
四、Name 服务器的均等性 注意我们上述开启的是单个服务，也即一个 Broker 和一个 Name 服务器，但是实际上使用消息队列的时候，我们可能需要搭建的是一个集群，如下所示:</description>
    </item>
    
    <item>
      <title>Spring 常用注解</title>
      <link>https://kunzhao.org/docs/tutorial/spring/annotations/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/tutorial/spring/annotations/</guid>
      <description>Spring 常用注解 SpringBoot 的运行类 @SpringBootApplication public class MainApplication { public static void main(String...args) { SpringApplication.run(MainApplication.class, args); } } 启用 CORS @CrossOrigin(origins = &amp;#34;http://localhost:8080&amp;#34;) @GetMapping(&amp;#34;/user&amp;#34;) public User get() { } </description>
    </item>
    
    <item>
      <title>Stream 编程</title>
      <link>https://kunzhao.org/docs/tutorial/java/stream/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/tutorial/java/stream/</guid>
      <description>Stream 编程 String[] Stream Arrays.stream(lines.split(&amp;#34;\\s+&amp;#34;)) .map(String::toUpperCase) .toArray(String[]::new) Integer[] 或 int[] stream int[] num = {1, 2, 3, 4, 5}; Integer[] result = Arrays.stream(num) .map(x -&amp;gt; x * 2) .boxed() .toArray(Integer[]::new); int[]
Stream&amp;lt;Integer&amp;gt; stream = Stream.of(1, 2, 3, 4, 5); int[] result = stream.map2Int(x -&amp;gt; x).toArray(); lambda 引用外部变量  lambda 引用外部变量为什么必须声明为 final ?
 Local variables in Java have until now been immune to race conditions and visibility problems because they are accessible only to the thread executing the method in which they are declared.</description>
    </item>
    
    <item>
      <title>回溯法</title>
      <link>https://kunzhao.org/docs/tutorial/algorithm/backtracking/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/tutorial/algorithm/backtracking/</guid>
      <description>回溯法 回溯法的套路解法在这篇文章中给了详细的说明。
Subsets 返回一个数组的所有 subsets:
Input: nums = [1,2,3] Output: [[],[1],[2],[1,2],[3],[1,3],[2,3],[1,2,3]] 解法：
public List&amp;lt;List&amp;lt;Integer&amp;gt;&amp;gt; subsets(int[] nums) { List&amp;lt;List&amp;lt;Integer&amp;gt;&amp;gt; list = new ArrayList&amp;lt;&amp;gt;(); Arrays.sort(nums); backtrack(list, new ArrayList&amp;lt;&amp;gt;(), nums, 0); return list; } private void backtrack(List&amp;lt;List&amp;lt;Integer&amp;gt;&amp;gt; list , List&amp;lt;Integer&amp;gt; tempList, int [] nums, int start){ list.add(new ArrayList&amp;lt;&amp;gt;(tempList)); for(int i = start; i &amp;lt; nums.length; i++){ tempList.add(nums[i]); backtrack(list, tempList, nums, i + 1); tempList.remove(tempList.size() - 1); } } 如果这个数组中有重复的数字，那么下面算法展示的是去掉重复数字的写法：
public List&amp;lt;List&amp;lt;Integer&amp;gt;&amp;gt; subsetsWithDup(int[] nums) { List&amp;lt;List&amp;lt;Integer&amp;gt;&amp;gt; list = new ArrayList&amp;lt;&amp;gt;(); Arrays.</description>
    </item>
    
    <item>
      <title>图片优化</title>
      <link>https://kunzhao.org/docs/tutorial/front-end-optimization-guide/image-optimization/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/tutorial/front-end-optimization-guide/image-optimization/</guid>
      <description>图片优化 图片在网页数据的传输中占据了非常大的流量，如何优化图片，对于前端页面加载的性能极其重要。本文讲述了比较常见的几种优化图片的技巧。
图片格式介绍 （1）JPEG
JPEG 是 Joint Photographic Experts Group 的缩写，不支持透明度，常用于网站的 Banner 图。JPEG 使用的是一种有损图像质量的压缩算法，压缩的越狠，图片的质量损失也就越大，图片的尺寸也就越小。根据你网站所能忍受的图片质量，来相应的选择压缩比：
（2）PNG
支持透明度，支持无损压缩，一般图片的尺寸都比较大。
（3）GIF
适合放动画图片。
（4）WebP
🔥Google 2010 年提出的新的图像压缩格式算法，在 2013 年又推出 Animated WebP，即支持动画的 Webp。优点：更优的图像数据压缩算法、拥有肉眼识别无差异的图像质量、具备了无损和有损的压缩模式、Alpha 透明以及动画的特性。
PNG、JPG、WebP 压缩对比：
GIF 和 WebP 对比：
不同网络环境，加载不同尺寸图片 如下是京东网站首页占据 C 位的宣传图：
它的 URL 地址如下，你任意改变这张图片的 URL 里面的宽、高，放到浏览器里面重新进行请求，就可以得到相应大小的图片：
响应式图片 不同平台设备加载不同大小、甚至不同内容的图片！
CSS 媒体查询 @media all and (max-width: 600px) { img { width: 300px; } } @media all and (min-width: 600px) and (max-width: 1200px) { img { width: 900px; } } srcset、sizes、picture 和 source （1）srcset 属性</description>
    </item>
    
    <item>
      <title>数学之美</title>
      <link>https://kunzhao.org/docs/books/beauty_of_mathematics/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/books/beauty_of_mathematics/</guid>
      <description>数学之美 2000多年前，古埃及人在罗塞塔石碑上，用三种文字记录了托勒密五世登基的诏书，这帮助后人破解了古埃及的象形文字，让我们了解了5000年前古埃及的历史。可见信息冗余是信息安全的保障，这对于信息编码具有重要指导意义。
犹太人为了避免抄错《圣经》，发明了一种校验码的方法，他们把每一个希伯来字母对应于一个数字，这样每行文字加起来便得到一个特殊的数字，这样的数字变成为了这一行的校验码。
隐含马尔可夫链成功应用在机器翻译、拼写纠错、手写体识别、图像处理、基因序列分析、股票预测和投资等方面。
如何准确的识别出一个快递地址，写一个分析器去分析这些描述恐怕是不行的，因为地址是比较复杂的上下文有关的文法。答案是使用有限状态机。当用户输入的地址不太标准或有错别字的时候，有限状态机会束手无措，因为有限状态机是严格匹配的，所以科学家提出了基于概率的有限状态机。
2002 年，Google 想要做一个全新的中、日、韩搜索算法，吴军写的算法比较简单，但是占用内存比较多，Google 服务器数量还没有那么多。辛格提出，用一个拟合函数替换很耗内存的语言模型，无需增加任何服务器，但是搜索质量会降到 80%。辛格指出，这样可以提早两个月将这个新算法提供给中国的用户，用户体验会有质的提高。辛格做事情的哲学，先帮助用户解决 80% 的问题，再慢慢解决剩下的 20% 的问题，是在工业界成功的秘诀之一。
新闻分类的关键在于计算出两篇新闻的相似度，每篇新闻变成一个向量，最后余弦定理可以计算出来相似度。但两两计算的迭代次数太多，如何一次性就把所有新闻的相关性计算出来呢？答案是矩阵运算中的奇异值分解。
如何判断两个集合是否相同？一种答案是双层 for 循环一一比较，复杂度 O(N^2)；稍好一点的办法是对集合进行排序，然后顺序比较，时间复杂度 O(NlogN)；还可以将一个集合的元素放到散列表里面，另外一个与之一一对比，时间复杂度 O(N)，但是额外使用了 O(N) 的空间，不完美；最完美的是计算这两个集合的指纹，对一个集合中的元素分别计算指纹，然后一一相加。
如何判断两个集合基本相同？答案是 Simhash。判断两个网页是否重复，也没有必要完全从头比到尾，只需要每个网页挑选出几个词 (IDF 最大的几个词)，构成特征词，然后计算信息指纹即可。判断一篇文章是否抄袭另外一篇文章，每篇文章切成小的片段，挑选特征词，并计算指纹。YouTuBe 如何从上百万视频中找出一个视频是否另外一个视频的盗版？其核心在于关键帧的提取和特征的提取。关键帧对于视频的重要性，就如同主题词对于新闻的重要性一样。
最大熵原理指出，对一个随机事件的概率分布进行预测时，我们的预测应当满足全部已知的条件，而对未知的情况不要做任何主观假设，这种情况下，概率分布最均匀，预测的风险最小。例如拼音输入法，Wang-Xiao-Bo 转换为王晓波和王小波，唯一确定用户需要的是哪一个，非常难。</description>
    </item>
    
    <item>
      <title>文件排序</title>
      <link>https://kunzhao.org/docs/tutorial/bigdata/sort-file/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/tutorial/bigdata/sort-file/</guid>
      <description>文件排序 给定一个包含 40 亿个无符号整数的大型文件，使用最多 1G 内存，对此文件进行排序。
参考  2021-02-18-海量数据  </description>
    </item>
    
    <item>
      <title>服务治理</title>
      <link>https://kunzhao.org/docs/tutorial/distributed/it-govern/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/tutorial/distributed/it-govern/</guid>
      <description>服务治理 企业治理：对企业 IT 的问题梳理、改进、优化，IT 治理是为业务服务的，涉及到了组织、管理效能、架构、基础资源、应用、数据等治理。
 SOA 治理，技术栈太重
  推荐的微服务工程组织模式
  DevOps 最核心的工作就是构建标准化、规范化和自动化的研发流水线或工具链，实现计划、设计、开发、测试、发布和运维的紧密协同。
 DevOps 通常包含如下工作：
 测试用例管理 测试环境管理 自动化持续构建 (CI) 持续部署 (CD) 发布管理 负载测试 应用系统监控 反馈管理  微服务架构 代理模式 Spring Cloud 使用 Zuul 组件实现代理网关。
缺点：
 网络上多了一次请求，比直连模式慢 网关存在单点隐患  直连模式 缺点：
 服务方、调用方耦合性较强  边车模式 弱耦合 SDK 微服务框架，将直连模式的 SDK 拆分出来，以独立进程和微服务应用部署在同一个操作系统中，使其免受技术选型和开发语言的限制，业界称之为 ServiceMesh。
直连模式架构  服务提供方的 SDK 做了什么?
 将业务逻辑封装成一个远程服务，然后暴露出去。Java 普遍采用的手段是：
 Instrumentation 字节码替换技术 InvocationHandler 动态代理技术，生成代理类，让代理类来负责远程请求的解析匹配和本地真实服务的调用。   服务调用放的 SDK 做了什么?</description>
    </item>
    
    <item>
      <title>架构</title>
      <link>https://kunzhao.org/docs/tutorial/sentinel/architecture/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/tutorial/sentinel/architecture/</guid>
      <description>架构 随着微服务的流行，服务和服务之间的稳定性变得越来越重要。Sentinel 是面向分布式服务架构的流量控制组件，主要以流量为切入点，从限流、流量整形、熔断降级、系统负载保护、热点防护等多个维度来帮助开发者保障微服务的稳定性。
有关 Sentinel 更为详细的使用文档和介绍请移至 Sentinel Github Wiki。
 单机和分布式区别
 限流分为单机和分布式两种，单机限流是指限定当前进程里面的某个代码片段的 QPS 或者 并发线程数 或者 整个机器负载指数，一旦超出规则配置的数值就会抛出异常或者返回 false。我把这里的被限流的代码片段称为「临界区」。
而分布式则需要另启一个集中的发票服务器，这个服务器针对每个指定的资源每秒只会生成一定量的票数，在执行临界区的代码之前先去集中的发票服务领票，如果领成功了就可以执行，否则就会抛出限流异常。所以分布式限流代价较高，需要多一次网络读写操作。
 规则控制
 在实际的项目中，规则应该需要支持动态配置。这就需要有一个规则配置源，它可以是 Redis、Zookeeper 等数据库，还需要有一个规则变更通知机制和规则配置后台，允许管理人员可以在后台动态配置规则并实时下发到业务服务器进行控制。
有一些规则源存储不支持事件通知机制，比如关系数据库，Sentinel 也提供了定时刷新规则，比如每隔几秒来刷新内存里面的限流规则。下面是 redis 规则源定义
// redis 地址 RedisConnectionConfig redisConf = new RedisConnectionConfig(&amp;#34;localhost&amp;#34;, 6379, 1000); // 反序列化算法 Converter&amp;lt;String, List&amp;lt;FlowRule&amp;gt;&amp;gt; converter = r -&amp;gt; JSON.parseArray(r, FlowRule.class); // 定义规则源，包含全量和增量部分 // 全量是一个字符串key，增量是 pubsub channel key ReadableDataSource&amp;lt;String, List&amp;lt;FlowRule&amp;gt;&amp;gt; redisDataSource = new RedisDataSource&amp;lt;List&amp;lt;FlowRule&amp;gt;&amp;gt;(redisConf, &amp;#34;app_key&amp;#34;, &amp;#34;app_pubsub_key&amp;#34;, converter); FlowRuleManager.register2Property(redisDataSource.getProperty());  健康状态上报与检查
 接入 Sentinel 的应用服务器需要将自己的限流状态上报到 Dashboard，这样就可以在后台实时呈现所有服务的限流状态。Sentinel 使用拉模型来上报状态，它在当前进程注册了一个 HTTP 服务，Dashboard 会定时来访问这个 HTTP 服务来获取每个服务进程的健康状况和限流信息。</description>
    </item>
    
    <item>
      <title>理解 This 关键字</title>
      <link>https://kunzhao.org/docs/javascript/understand-this-keyword/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/javascript/understand-this-keyword/</guid>
      <description>理解 This 关键字 JavaScript 中的 this 所指向的对象，取决于上下文以及函数被调用的方式，本文列举了几种常见的情况，帮助大家理解。
一、全局上下文 当直接在一个全局的上下文中，使用 this 指针的时候，this 指针会指向到全局对象上。例如在浏览器的调试工具栏中直接打印 this 指针，其指向的是 Window 对象：
在 node 中打印 this 指针，其指向的是 node 提供的全局对象，其中包含了进程信息等：
二、Function 上下文 在 Function 上下文中，this 的值取决于 function 是如何被调用的。
(1) Function 调用 当 this 指针定义在一个 function 中，那么此 this 仍然会指向全局对象：
function foo() { console.log(this) } foo(); // Window {parent: Window, postMessage: ƒ, blur: ƒ, focus: ƒ, close: ƒ, …} (2) 严格模式下的 Function 调用 如果在严格模式下定义的 function 的话，this 指针的值将会是 undefined：
function foo() { &amp;#39;use strict&amp;#39;; console.</description>
    </item>
    
    <item>
      <title>简介</title>
      <link>https://kunzhao.org/docs/tutorial/awk/intro/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/tutorial/awk/intro/</guid>
      <description>简介 AWK 是一门编程语言。
开始 假设您有一个名称为 emp.data 文件，里面存储的内容包含姓名、每小时的薪资、工作的小时，如下所示：
Beth 4.00 0 Dan 3.75 0 Kathy 4.00 10 Mark 5.00 20 Mary 5.50 22 Susie 4.25 18 现在你想要打印工作超过 0 小时的员工的姓名和薪资，对于 AWK 而言，这相当简单：
awk `$3 &amp;gt; 0 { print $1, $2 * $3 }` emp.data 你会得到如下输出：
Kathy 40 Mark 100 Mary 121 Susie 76.5 位于引号中的内容就是 AWK 的完整代码。$3 &amp;gt; 0，会匹配文件的每一行，看这每一行的第 3 列是否大于 0。{ print $1, $2 * $3 } 打印第一列，以及第二列和第三列的乘积。
如果你想要打印出工作小时数是 0 的员工姓名：
awk `$3 == 0 { print $1 }` emp.</description>
    </item>
    
    <item>
      <title>观察者模式</title>
      <link>https://kunzhao.org/docs/programmer-interview/design-pattern/observer/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/programmer-interview/design-pattern/observer/</guid>
      <description>观察者模式 JavaScript class EventObserver { constructor() { this.observers = []; } subscribe(fn) { this.observers.push(fn); } unsubscribe(fn) { this.observers = this.observers.filter((subscriber) =&amp;gt; subscriber !== fn); } broadcast(data) { this.observers.forEach((subscriber) =&amp;gt; subscriber(data)); } } 发布订阅者模式 其实遵循的就是观察者模式
// publisher // Subscriber // unsubscribe // Some place to store callbacks that are registered from subscribers.  function pubSub() { // object which will track of all events and subscription  const subscribers = {} // Publisher:  function publish(eventName, data) { // return if event is not subscribed  if (!</description>
    </item>
    
    <item>
      <title>运行 npm run build</title>
      <link>https://kunzhao.org/docs/tutorial/maven/run-npm-build/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/tutorial/maven/run-npm-build/</guid>
      <description>运行 npm run build &amp;lt;profiles&amp;gt; &amp;lt;!--考虑到window 和linux环境 npm命令格式的问题，使用maven的profile实现动态指定命令--&amp;gt; &amp;lt;profile&amp;gt; &amp;lt;id&amp;gt;window&amp;lt;/id&amp;gt; &amp;lt;properties&amp;gt; &amp;lt;npm&amp;gt;npm.cmd&amp;lt;/npm&amp;gt; &amp;lt;/properties&amp;gt; &amp;lt;activation&amp;gt; &amp;lt;activeByDefault&amp;gt;true&amp;lt;/activeByDefault&amp;gt; &amp;lt;/activation&amp;gt; &amp;lt;/profile&amp;gt; &amp;lt;profile&amp;gt; &amp;lt;id&amp;gt;linux&amp;lt;/id&amp;gt; &amp;lt;properties&amp;gt; &amp;lt;npm&amp;gt;npm&amp;lt;/npm&amp;gt; &amp;lt;/properties&amp;gt; &amp;lt;/profile&amp;gt; &amp;lt;/profiles&amp;gt; &amp;lt;plugins&amp;gt; &amp;lt;plugin&amp;gt; &amp;lt;groupId&amp;gt;org.codehaus.mojo&amp;lt;/groupId&amp;gt; &amp;lt;artifactId&amp;gt;exec-maven-plugin&amp;lt;/artifactId&amp;gt; &amp;lt;executions&amp;gt; &amp;lt;execution&amp;gt; &amp;lt;id&amp;gt;exec-npm-install&amp;lt;/id&amp;gt; &amp;lt;phase&amp;gt;prepare-package&amp;lt;/phase&amp;gt; &amp;lt;goals&amp;gt; &amp;lt;goal&amp;gt;exec&amp;lt;/goal&amp;gt; &amp;lt;/goals&amp;gt; &amp;lt;configuration&amp;gt; &amp;lt;executable&amp;gt;${npm}&amp;lt;/executable&amp;gt; &amp;lt;arguments&amp;gt; &amp;lt;argument&amp;gt;install&amp;lt;/argument&amp;gt; &amp;lt;/arguments&amp;gt; &amp;lt;workingDirectory&amp;gt;${basedir}/src/main/webapp&amp;lt;/workingDirectory&amp;gt; &amp;lt;/configuration&amp;gt; &amp;lt;/execution&amp;gt; &amp;lt;execution&amp;gt; &amp;lt;id&amp;gt;exec-npm-run-build&amp;lt;/id&amp;gt; &amp;lt;phase&amp;gt;prepare-package&amp;lt;/phase&amp;gt; &amp;lt;goals&amp;gt; &amp;lt;goal&amp;gt;exec&amp;lt;/goal&amp;gt; &amp;lt;/goals&amp;gt; &amp;lt;configuration&amp;gt; &amp;lt;executable&amp;gt;${npm}&amp;lt;/executable&amp;gt; &amp;lt;arguments&amp;gt; &amp;lt;argument&amp;gt;run&amp;lt;/argument&amp;gt; &amp;lt;argument&amp;gt;build&amp;lt;/argument&amp;gt; &amp;lt;/arguments&amp;gt; &amp;lt;workingDirectory&amp;gt;${basedir}/src/main/webapp&amp;lt;/workingDirectory&amp;gt; &amp;lt;/configuration&amp;gt; &amp;lt;/execution&amp;gt; &amp;lt;/executions&amp;gt; &amp;lt;/plugin&amp;gt; &amp;lt;/plugins&amp;gt; 执行方式：
 windows 环境: mvn clean package -P window Linux 环境: mvn clean package -P linux  </description>
    </item>
    
    <item>
      <title>信息的半衰期</title>
      <link>https://kunzhao.org/posts/half-life-of-information/</link>
      <pubDate>Sat, 16 May 2020 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/posts/half-life-of-information/</guid>
      <description>&lt;p&gt;今天，我想与您讨论一下信息能存活多久的问题，这个问题又会如何影响我们工作的方式。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Best Time to Buy and Sell Stock Ⅱ</title>
      <link>https://kunzhao.org/docs/programmer-interview/algorithm/best-time-to-buy-and-sell-stock-2/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/programmer-interview/algorithm/best-time-to-buy-and-sell-stock-2/</guid>
      <description>Best Time to Buy and Sell Stock Ⅱ 题目 LeetCode 地址：Best Time to Buy and Sell Stock Ⅱ
有一个数组，第 i 个元素的值代表第 i 天的股票价格，如果你可以进行无限次交易（某天买入一支股票，然后过几天卖掉），请问你能收获的最大利润是多少？
分析 这道题就一个想法，只要今天 price[i] 比昨天 price[i - 1] 的价格涨了，就可以算作是有效的利润，累加到最后的结果中。
答案 // 假设有一个数组，它的第i个元素是一个给定的股票在第i天的价格。 // 设计一个算法来找到最大的利润。你可以完成尽可能多的交易(多次买卖股票)。 // 然而,你不能同时参与多个交易(你必须在再次购买前出售股票)。 // // https://www.lintcode.com/problem/best-time-to-buy-and-sell-stock-ii/description public class BestTimetoBuyandSellStockII { public int maxProfit(int[] prices) { int max = 0; for (int i = 1; i &amp;lt; prices.length; i++) { int diff = prices[i] - prices[i - 1]; if (diff &amp;gt; 0) { max += diff; } } return max; } } 扫描下面二维码，在手机上阅读这篇文章：</description>
    </item>
    
    <item>
      <title>find</title>
      <link>https://kunzhao.org/docs/tutorial/unix-command/find/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/tutorial/unix-command/find/</guid>
      <description>find find 命令的常见用法有哪些？find 命令的例子。
简介 Linux Find命令是类Unix操作系统中最重要、最常用的命令行实用程序之一。find 命令可以，根据不同的查找条件，来查询匹配不同的文件或目录列表。
find 可用于根据各种条件查找，例如您可以按权限、用户、组、文件类型、日期、大小和其他可能的条件查找文件。
通过本文，我们将以示例的形式分享我们的日常Linux find命令体验及其使用。
格式 find [path...] [test...] [action...]  path：find 命令的第一件事，查看每个路径 test：对于遇到的每个文件，find 应用测试条件 action：一旦搜索完成，find 对每个文件执行相应的操作  路径示例：
 find /usr/bin find / find . find ~  测试示例：
 -name pattern：包含 pattern 的文件名 -iname pattern：包含 pattern 的文件名（忽略大小写） -type [df]：文件类型，d 代表目录，f 代表文件 -perm mode：设置为 mode 的文件权限 -user userid：用户为 userid -group groupid：组为 groupid -size [-+]n[cbkMG]：大小为 n[字符(字节)、块、千字节、兆字节、吉字节] -empty：空文件 -amin [-+]n：n 分钟之前访问 -anewer file：file 文件之后访问 -atime [-+]n：n 天之前访问 -cmin [-+]n：n 分钟之前状态改变 -cnewer file：file 文件之后状态改变 -ctime [-+]n：n 天状态之前改变 -mmin [-+]n：n 分钟之前修改 -mtime [-+]n：n 天之前修改 -newer file：file 文件之后修改   - 代表：小于，+ 代表：大于</description>
    </item>
    
    <item>
      <title>HTML 优化</title>
      <link>https://kunzhao.org/docs/tutorial/front-end-optimization-guide/html-optimization/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/tutorial/front-end-optimization-guide/html-optimization/</guid>
      <description>HTML 优化 本文通过一些案例讲述了常见的优化 HTML 的几种小技巧：减少 DOM 树、精简 HTML 文件大小等。
优化 DOM 节点树 去除页面除首屏外的对于用户不可见的信息区块，可以让页面的 DOM 节点数更少，DOM 树结构更简单，然后再使用懒加载异步化请求，去动态加载这些不可见的信息区块。
在《大型网站性能优化实战》这本书中，作者为了优化搜索页面的渲染瓶颈问题，将首屏以下的 33 各搜索结果对应的 HTML 代码放到 &amp;lt;textarea&amp;gt; 节点中，当该区域处于可见状态时，再从 TextArea 中取出 HTML 代码，恢复到 DOM 树中进行渲染。这样一来，页面首次渲染的 DOM 树所包含的节点数大幅度减少，从而有效提高了首次渲染速度。
多个空格合并为一个空格 通过将多个空格合并为一个空格，可以减少 HTML 的大小，从而缩短传输 HTML 文件所需的时间。通常在编写 HTML 文件的时候，总是倾向于格式化它，以方便我们人类阅读，所以这个文件中填充了许多空格，但这些空格对于浏览器来说是用不到的。在替换空格的时候，需要保留 &amp;lt;pre&amp;gt;、&amp;lt;textarea&amp;gt;、&amp;lt;script&amp;gt;、&amp;lt;style&amp;gt; 中的空格。
不过，如果你的网页中使用了 white-space: pre 这个 CSS 属性就要小心了，这个属性可以避免让多个空格压缩为一个，在实际开发网站的时候，其实也很少用到这个属性。如果确实需要，那么就放弃把 HTML 的多个空格合并为一个空格吧。
&amp;lt;html&amp;gt; &amp;lt;head&amp;gt; &amp;lt;title&amp;gt;Hello, world! &amp;lt;/title&amp;gt; &amp;lt;script&amp;gt; var x = &amp;#39;Hello, world!&amp;#39;;&amp;lt;/script&amp;gt; &amp;lt;/head&amp;gt; &amp;lt;body&amp;gt; Hello, World! &amp;lt;pre&amp;gt; Hello, World! &amp;lt;/pre&amp;gt; &amp;lt;/body&amp;gt; &amp;lt;/html&amp;gt; 转为：</description>
    </item>
    
    <item>
      <title>HTTP</title>
      <link>https://kunzhao.org/docs/tutorial/network/http/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/tutorial/network/http/</guid>
      <description>HTTP 常见状态码    状态码 含义     1xx Information response   100 continue   101 Switching Protocols   2xx success   200 OK: 成功响应   201 Created   202 Accepted   204 No Content: 服务器已经成功处理请求，没有返回任何 Body (比如服务器收到一个发邮件的请求，服务器返回 204，表示已经收到请求，邮件后续会发送)   206 Partial Content: 服务器返回了某个文件的一部分   3xx redirection   300 Multiple Choices 是一个用来表示重定向的响应状态码，表示该请求拥有多种可能的响应。用户代理或者用户自身应该从中选择一个。   301 Moved Permanently: 永久重定向   302 Found: 临时重定向   304 Not Modified: 浏览器通过 If-None-Match 头或 If-Modified-Since 头询问，服务器告知文件未改动   4xx client errors   400 Bad Request: 客户端发送的 HTTP 有语法错误、太大、帧错误等   401 Unauthorized   403 Forbidden   404 Not Found   405 Method Not Allowed   429 Too Many Requests   499 Nginx 自己定义的，client has closed connection   5xx server errors   500 Internal Server Error   502 Bad Gateway   503 Service Unavailable   504 Gateway Timeout    HTTP 方法    方法 含义     GET 获取数据   HEAD 与 GET 类似，但只返回响应头   POST 提交表单   PUT 用一个新的资源完全替换掉服务器的资源   DELETE 删除资源   CONNECT 建立一个 tunnel   OPTIONS 询问服务器支持哪些方法   TRACE 发起环回诊断，主要用于诊断   PATCH 对服务器资源进行部分更新    HTTP 报文 在浏览器中输入 &amp;ldquo;kunzhao.</description>
    </item>
    
    <item>
      <title>Java Date 和 Time</title>
      <link>https://kunzhao.org/docs/tutorial/java/date-time/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/tutorial/java/date-time/</guid>
      <description>Java Date 和 Time 日期格式化为 yyyy-MM-dd Java 8 如下：
LocalDateTime ldt = LocalDateTime.now(); DateTimeFormatter formatter = DateTimeFormatter.ofPattern(&amp;#39;yyyy-MM-dd&amp;#39;, Locale.ENGLISH); System.out.println(formatter.format(ldt)); </description>
    </item>
    
    <item>
      <title>JavaScript 数组</title>
      <link>https://kunzhao.org/docs/javascript/javascript-array/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/javascript/javascript-array/</guid>
      <description>JavaScript 数组 使用 JavaScript 在编程的时候，我们有很大一部分时间都是在与数组打交道，因此对数组常见的方法做到灵活的运用至关重要。本文整理了和 JavaScript 数组相关的，日常经常需要的功能和使用技巧，供大家参阅。
从数组中移除指定元素 查阅 JavaScript 的数组 API，发现其并没有提供一个像 remove(obj) 或 removeAll(obj) 此类的方法，供我们方便的删除对象，因此我们需要通过使用其它的 API 来达到我们移出元素的目的。
(1) 使用 splice 方法 splice 方法可以从指定索引处，向数组中添加元素或者删除元素，其会直接在原数组上改变，因此通过此方法可以达到我们的目的。但是在移除元素之前，我们必须首先通过 indexOf 方法找到我们的元素在数组中处于的索引位置。
const array = [2, 5, 9]; const index = array.indexOf(5); if (index &amp;gt; -1) { array.splice(index, 1); // 1 代表删除 1 个元素 } console.log(array) 当然，如果你不想使用 indexOf 的话，也可以直接从后向前遍历整个数组，对每个符合要求的元素都使用 splice 方法：
const array = [2, 5, 9]; for (var i = array.length; i--; ) { if (array[i] === 5) { array.</description>
    </item>
    
    <item>
      <title>leveldb 源码分析与实现</title>
      <link>https://kunzhao.org/docs/tutorial/distributed-storage/leveldb/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/tutorial/distributed-storage/leveldb/</guid>
      <description>leveldb 源码分析与实现  源代码基于 1.22 之后的版本
 特性 leveldb 是一个键值对 library，它的键是有序排列的，用户也可以提供自定义的键比较器，多个操作也可以合并为一起，进行原子操作更新。其架构如下:
编译 mkdir -p build &amp;amp;&amp;amp; cd build cmake -DCMAKE_BUILD_TYPE=Release .. &amp;amp;&amp;amp; cmake --build . 如果 Ubuntu 提示 No CMAKE_CXX_COMPILER could be found :
sudo apt-get update &amp;amp;&amp;amp; sudo apt-get install build-essential 打开数据库 Options // Options to control the behavior of a database (passed to DB::Open) struct LEVELDB_EXPORT Options { // Create an Options object with default values for all fields.</description>
    </item>
    
    <item>
      <title>MySQL 事务实现原理</title>
      <link>https://kunzhao.org/docs/tutorial/database/transaction-internal/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/tutorial/database/transaction-internal/</guid>
      <description>MySQL 事务和锁 事务隔离级别 行为解释  读未提交是指，一个事务还没提交时，它做的变更就能被别的事务看到。 读提交是指，一个事务提交之后，它做的变更才会被其他事务看到。 可重复读是指，一个事务执行过程中看到的数据，总是跟这个事务在启动时看到的数据是一致的。当然在可重复读隔离级别下，未提交变更对其他事务也是不可见的。 串行化，顾名思义是对于同一行记录，“写”会加“写锁”，“读”会加“读锁”。当出现读写锁冲突的时候，后访问的事务必须等前一个事务执行完成，才能继续执行。  读行为 RC 总是读取记录的最新版本，如果该记录被锁住，则读取该记录最新的一次快照，而 RR 是读取该记录事务开始时的那个版本。虽然这两种读取方式不一样，但是它们读取的都是快照数据，并不会被写操作阻塞，所以这种读操作称为 快照读（Snapshot Read）。
除了快照读 ，MySQL 还提供了另一种读取方式：当前读（Current Read），有时候又叫做加锁读（Locking Read） 或者阻塞读（Blocking Read），这种读操作读的不再是数据的快照版本，而是数据的最新版本。
MySQL 隔离级别 可以通过查看 MySQL 中的系统变量 tx_isolation 的值来确定当前 MySQL 正在使用什么隔离级别。
mysql&amp;gt; select @@tx_isolation; +-----------------+ | @@tx_isolation | +-----------------+ | REPEATABLE-READ | +-----------------+ 另外可以使用 SET TRANSACTION 命令修改 MySQL 的隔离级别：
mysql&amp;gt; set session transaction isolation level read committed; 示例 mysql&amp;gt; create table T(c int) engine=InnoDB; insert into T(c) values(1);  读未提交：V1 = V2 = V3 = 2，事务 B 虽然还没有提交，但是结果已经被 A 看到了。 读提交：V1 = 1，V2 = V3 = 2，事务 B 的更新在提交后才能被 A 看到。 可重复读：V1 = V2 = 1，V3 = 2，事务在执行期间看到的数据前后必须是一致的。 串行化：在事务 B 执行“将 1 改成 2”的时候，会被锁住。直到事务 A 提交后，事务 B 才可以继续执行。  隔离级别是如何实现的 在实现上，数据库里面会创建一个视图，访问的时候以视图的逻辑结果为准。在“可重复读”隔离级别下，这个视图是在事务启动时创建的，整个事务存在期间都用这个视图。在“读提交”隔离级别下，这个视图是在每个 SQL 语句开始执行的时候创建的。这里需要注意的是，“读未提交”隔离级别下直接返回记录上的最新值，没有视图概念；而“串行化”隔离级别下直接用加锁的方式来避免并行访问。</description>
    </item>
    
    <item>
      <title>Patterns</title>
      <link>https://kunzhao.org/docs/tutorial/awk/patterns/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/tutorial/awk/patterns/</guid>
      <description>Patterns Patterns 控制是否执行 actions，只有当 pattern 匹配的时候，才会执行 action。
本文介绍六种常用的 pattern：
 BEGIN { statements }：所有行处理之前执行一次 BEGIN END { statements }：所有行处理完了执行一次 END expression { statements }：普通的表达式 /正则表达式/ { statements }：匹配正则 组合表达式 { statements }：使用 &amp;amp;&amp;amp; 或 || 或 ! 进行组合 pattern1, pattern2 { statements }：范围匹配  BEGIN 和 END BEGIN 和 END 只会执行一次，BEGIN 是在开始执行前执行，END 是在结束前执行。
一种常见的使用 BEGIN 的用法是改变默认的列分割符，列分割符默认被一个内置变量 FS 所控制，这个变量的默认值是空格或者tabs。如下示例在 BEGIN 中设置了 FS 为 \t，同时打印了表头。在 END 块中打印了面积和人口的总和。
BEGIN { FS = &amp;#34;\t&amp;#34; printf(&amp;#34;%10s %6s %5s %s\n\n&amp;#34;, &amp;#34;COUNTRY&amp;#34;, &amp;#34;AREA&amp;#34;, &amp;#34;POP&amp;#34;, &amp;#34;CONTINENT&amp;#34;) } { printf(&amp;#34;%10s %6d %5d %s\n&amp;#34;, $1, $2, $3, $4) area = area + $2 pop = pop + $3 } END { printf(&amp;#34;\n%10s %6d %5d\n&amp;#34;, &amp;#34;TOTAL&amp;#34;, area, pop) } expression 表达式示例：</description>
    </item>
    
    <item>
      <title>Redis 线程 I/O 模型</title>
      <link>https://kunzhao.org/docs/tutorial/redis/io-pattern/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/tutorial/redis/io-pattern/</guid>
      <description>Redis 线程 I/O 模型  Redis 是个单线程程序！ 这点必须铭记。
 Redis 单线程为什么这么快? 因为它所有的数据都在内存中，再加上它采用了高效的数据结构，例如哈希表和跳表，这是它实现高性能的一个重要原因。另一方面，就是Redis采用了多路复用机制，使其在网络IO操作中能并发处理大量的客戶端请求，实现高吞吐率。接下来，我们就重点学习下多路复用机制。
单线程如何处理并发客户端? 多路复用
为什么选择单线程?  It’s not very frequent that CPU becomes your bottleneck with Redis, as usually Redis is either memory or network bound. For instance, using pipelining Redis running on an average Linux system can deliver even 1 million requests per second, so if your application mainly uses O(N) or O(log(N)) commands, it is hardly going to use too much CPU.</description>
    </item>
    
    <item>
      <title>RestTemplate</title>
      <link>https://kunzhao.org/docs/tutorial/spring/resttemplate/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/tutorial/spring/resttemplate/</guid>
      <description>RestTemplate postForObject() RestTemplate restTemplate = new RestTemplate(); HttpEntity&amp;lt;Foo&amp;gt; request = new HttpEntity&amp;lt;&amp;gt;(new Foo(&amp;#34;bar&amp;#34;)); Foo foo = restTemplate.postForObject(url, request, Foo.class); exchange() RestTemplate restTemplate = new RestTemplate(); HttpEntity&amp;lt;Foo&amp;gt; request = new HttpEntity&amp;lt;&amp;gt;(new Foo(&amp;#34;bar&amp;#34;)); ResponseEntity&amp;lt;Foo&amp;gt; response = restTemplate.exchange(url, HttpMethod.POST, request, Foo.class); Foo foo = response.getBody(); </description>
    </item>
    
    <item>
      <title>RocketMQ 消息存储流程</title>
      <link>https://kunzhao.org/docs/rocketmq/rocketmq-message-store-flow/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/rocketmq/rocketmq-message-store-flow/</guid>
      <description>RocketMQ 消息存储流程  基于 RocketMQ 4.2.0 版本进行的源码分析。
 本文讲述 RocketMQ 存储一条消息的流程。
一、存储位置 当有一条消息过来之后，Broker 首先需要做的是确定这条消息应该存储在哪个文件里面。在 RocketMQ 中，这个用来存储消息的文件被称之为 MappedFile。这个文件默认创建的大小为 1GB。
一个文件为 1GB 大小，也即 1024 * 1024 * 1024 = 1073741824 字节，这每个文件的命名是按照总的字节偏移量来命名的。例如第一个文件偏移量为 0，那么它的名字为 00000000000000000000；当当前这 1G 文件被存储满了之后，就会创建下一个文件，下一个文件的偏移量则为 1GB，那么它的名字为 00000000001073741824，以此类推。
默认情况下这些消息文件位于 $HOME/store/commitlog 目录下，如下图所示:
二、文件创建 当 Broker 启动的时候，其会将位于存储目录下的所有消息文件加载到一个列表中:
当有新的消息到来的时候，其会默认选择列表中的最后一个文件来进行消息的保存:
public class MappedFileQueue { public MappedFile getLastMappedFile() { MappedFile mappedFileLast = null; while (!this.mappedFiles.isEmpty()) { try { mappedFileLast = this.mappedFiles.get(this.mappedFiles.size() - 1); break; } catch (IndexOutOfBoundsException e) { //continue;  } catch (Exception e) { log.</description>
    </item>
    
    <item>
      <title>Rust 语言首次进入 Tiobe 前 20 名</title>
      <link>https://kunzhao.org/docs/it-zone/2020-06/rust-enter-top-20/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/it-zone/2020-06/rust-enter-top-20/</guid>
      <description>Rust 语言首次进入 Tiobe 前 20 名 日期：2020-06-02
 Rust 在 Tiobe 上的排名已大大提高，从去年的38位上升到今天的20位。Tiobe 的索引基于主要搜索引擎上对某种语言的搜索，因此这并不意味着更多的人正在使用 Rust，但是它表明更多的开发人员正在搜索有关该语言的信息。
在 Stack Overflow 的2020年调查中， Rust 被开发人员连续第五年票选为最受欢迎的编程语言。今年，有86％的开发人员表示他们热衷于使用Rust，但只有5％的开发人员实际将其用于编程。
另一方面，由于Microsoft已公开预览其针对Windows运行时（WinRT）的 Rust 库，因此它可能会得到更广泛的使用 ，这使开发人员可以更轻松地在Rust中编写Windows，跨平台应用程序和驱动程序。
Tiobe软件首席执行官Paul Jansen说，Rust的崛起是因为它是一种“正确的”系统编程语言。
然而，Rust 项目的2020年开发人员调查发现，由于其陡峭的学习曲线以及很少有公司使用它，用户难以采用该语言。 Google 在新的Fuchsia OS 排除了 Rust 语言，因为很少有开发人员对此感到熟悉。</description>
    </item>
    
    <item>
      <title>Spring Cloud Eureka 示例</title>
      <link>https://kunzhao.org/docs/tutorial/eureka/demo/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/tutorial/eureka/demo/</guid>
      <description>Spring Cloud Eureka 示例 搭建服务注册中心 假设你使用的是 Maven，pom.xml 文件内容如下所示：
&amp;lt;?xml version=&amp;#34;1.0&amp;#34; encoding=&amp;#34;UTF-8&amp;#34;?&amp;gt; &amp;lt;project xmlns=&amp;#34;http://maven.apache.org/POM/4.0.0&amp;#34; xmlns:xsi=&amp;#34;http://www.w3.org/2001/XMLSchema-instance&amp;#34; xsi:schemaLocation=&amp;#34;http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd&amp;#34;&amp;gt; &amp;lt;modelVersion&amp;gt;4.0.0&amp;lt;/modelVersion&amp;gt; &amp;lt;parent&amp;gt; &amp;lt;groupId&amp;gt;org.springframework.boot&amp;lt;/groupId&amp;gt; &amp;lt;artifactId&amp;gt;spring-boot-starter-parent&amp;lt;/artifactId&amp;gt; &amp;lt;version&amp;gt;2.3.2.RELEASE&amp;lt;/version&amp;gt; &amp;lt;relativePath/&amp;gt; &amp;lt;!-- lookup parent from repository --&amp;gt; &amp;lt;/parent&amp;gt; &amp;lt;groupId&amp;gt;com.example&amp;lt;/groupId&amp;gt; &amp;lt;artifactId&amp;gt;service-registration-and-discovery-service&amp;lt;/artifactId&amp;gt; &amp;lt;version&amp;gt;0.0.1-SNAPSHOT&amp;lt;/version&amp;gt; &amp;lt;name&amp;gt;service-registration-and-discovery-service&amp;lt;/name&amp;gt; &amp;lt;description&amp;gt;Demo project for Spring Boot&amp;lt;/description&amp;gt; &amp;lt;properties&amp;gt; &amp;lt;java.version&amp;gt;1.8&amp;lt;/java.version&amp;gt; &amp;lt;spring-cloud.version&amp;gt;Hoxton.SR1&amp;lt;/spring-cloud.version&amp;gt; &amp;lt;/properties&amp;gt; &amp;lt;dependencies&amp;gt; &amp;lt;dependency&amp;gt; &amp;lt;groupId&amp;gt;org.springframework.cloud&amp;lt;/groupId&amp;gt; &amp;lt;artifactId&amp;gt;spring-cloud-starter-netflix-eureka-server&amp;lt;/artifactId&amp;gt; &amp;lt;/dependency&amp;gt; &amp;lt;/dependencies&amp;gt; &amp;lt;dependencyManagement&amp;gt; &amp;lt;dependencies&amp;gt; &amp;lt;dependency&amp;gt; &amp;lt;groupId&amp;gt;org.springframework.cloud&amp;lt;/groupId&amp;gt; &amp;lt;artifactId&amp;gt;spring-cloud-dependencies&amp;lt;/artifactId&amp;gt; &amp;lt;version&amp;gt;${spring-cloud.version}&amp;lt;/version&amp;gt; &amp;lt;type&amp;gt;pom&amp;lt;/type&amp;gt; &amp;lt;scope&amp;gt;import&amp;lt;/scope&amp;gt; &amp;lt;/dependency&amp;gt; &amp;lt;/dependencies&amp;gt; &amp;lt;/dependencyManagement&amp;gt; &amp;lt;/project&amp;gt; 启动一个服务注册中心 @EnableEurekaServer @SpringBootApplication public class ServiceRegistrationAndDiscoveryServiceApplication { public static void main(String[] args) { SpringApplication.</description>
    </item>
    
    <item>
      <title>上帝掷骰子吗</title>
      <link>https://kunzhao.org/docs/books/history_of_quantum_physics/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/books/history_of_quantum_physics/</guid>
      <description>上帝掷骰子吗-量子物理史话 1887年德国，赫兹在实验室证实了电磁波的存在，也证实了光其实是电磁波的一种，两者具有共同的波的特性，古老的光学终于可以被完全包容于新兴的电磁学里面。1901年，赫兹死后的第 7 年，无线电报已经可以穿越大西洋，实现两地的实时通讯了。
赫兹铜环接收器的缺口之间不停地爆发着电火花，明白无误地昭示着电磁波的存在。但偶然间，赫兹又发现了一个奇怪的现象：当有光照射到这个缺口上的时候，似乎火花就出现得更容易一些。
 量子就是能量的最小单位，就是能量里的一美分。一切能量的传输，都只能以这个量为单位来进行，它可以传输一个量子，两个量子，任意整数个量子，但却不能传输1 又1/2 个量子，那个状态是不允许的，就像你不能用现钱支付1 又1/2 美分一样。这个值，现在已经成为了自然科学中最为 重要的常数之一，以它的发现者命名，称为“普朗克常数”，用 h 来表示。
在后来十几年的时间里，普朗克一直认为量子的假设并不是一个物理真实，而纯粹是一个为了方便而引入的假设而已。他不断地告诫人们，在引用普朗克常数 h 的时候，要尽量小心谨慎，不到万不得已千万不要胡思乱想。</description>
    </item>
    
    <item>
      <title>创建 Git 仓库</title>
      <link>https://kunzhao.org/docs/tutorial/git/create-repository/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/tutorial/git/create-repository/</guid>
      <description>创建 Git 仓库 （1）已有项目使用 Git 管理
假设你的项目所在文件夹叫做：abc_project
cd abc_project git init （2）新建项目直接使用 Git 管理
假设新建的项目名为 xxx_project
git init xxx_project </description>
    </item>
    
    <item>
      <title>基于 LeapArray 的统计</title>
      <link>https://kunzhao.org/docs/tutorial/sentinel/leaparray/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/tutorial/sentinel/leaparray/</guid>
      <description>基于 LeapArray 的统计 Sentinel 底层采用高性能的滑动窗口数据结构 LeapArray 来统计实时的秒级指标数据，可以很好地支撑写多于读的高并发场景。
Metric 统计类 LeapArray 作为基础设施，其目的主要是为了在底层配合 Metric 类，以便对资源的各种信息做统计，我们来看 Metric 类都需要统计哪些信息：
public interface Metric extends DebugSupport { // 获取总的成功数量  long success(); // 获取最大的成功数量  long maxSuccess(); // 获取异常数量  long exception(); // 获取阻塞的数量  long block(); // 获取总的通过数量  long pass(); // 获取总响应时间  long rt(); // 获取最小的响应时间  long minRt(); } 相应的，在 Metric 接口中，也有添加各种事件的方法：
public interface Metric extends DebugSupport { // 添加 n 个异常  void addException(int n); // 添加 n 个阻塞  void addBlock(int n); // 添加 n 个成功的响应  void addSuccess(int n); // 添加 n 个通过  void addPass(int n); // 在总响应时间上，添加 rt 时间  void addRT(long rt); } 以 ArrayMetric 的 addSuccess(int count) 和 success() 为例，我们看下在内部是如何使用 LeapArray 提供资源统计服务的。</description>
    </item>
    
    <item>
      <title>拷贝资源</title>
      <link>https://kunzhao.org/docs/tutorial/maven/copy-resource/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/tutorial/maven/copy-resource/</guid>
      <description>拷贝资源 &amp;lt;project&amp;gt; ... &amp;lt;build&amp;gt; &amp;lt;plugins&amp;gt; &amp;lt;plugin&amp;gt; &amp;lt;artifactId&amp;gt;maven-resources-plugin&amp;lt;/artifactId&amp;gt; &amp;lt;version&amp;gt;3.2.0&amp;lt;/version&amp;gt; &amp;lt;executions&amp;gt; &amp;lt;execution&amp;gt; &amp;lt;id&amp;gt;copy-resources&amp;lt;/id&amp;gt; &amp;lt;!-- here the phase you need --&amp;gt; &amp;lt;phase&amp;gt;package&amp;lt;/phase&amp;gt; &amp;lt;goals&amp;gt; &amp;lt;goal&amp;gt;copy-resources&amp;lt;/goal&amp;gt; &amp;lt;/goals&amp;gt; &amp;lt;configuration&amp;gt; &amp;lt;outputDirectory&amp;gt;${basedir}/target/extra-resources&amp;lt;/outputDirectory&amp;gt; &amp;lt;resources&amp;gt; &amp;lt;resource&amp;gt; &amp;lt;directory&amp;gt;src/non-packaged-resources&amp;lt;/directory&amp;gt; &amp;lt;filtering&amp;gt;true&amp;lt;/filtering&amp;gt; &amp;lt;/resource&amp;gt; &amp;lt;/resources&amp;gt; &amp;lt;/configuration&amp;gt; &amp;lt;/execution&amp;gt; &amp;lt;/executions&amp;gt; &amp;lt;/plugin&amp;gt; &amp;lt;/plugins&amp;gt; ... &amp;lt;/build&amp;gt; ... &amp;lt;/project&amp;gt; </description>
    </item>
    
    <item>
      <title>数组</title>
      <link>https://kunzhao.org/docs/tutorial/algorithm/array/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/tutorial/algorithm/array/</guid>
      <description>数组 无序数组第 K 大的数字 public int findKthLargest(int[] nums, int k) { k = nums.length - k; // 1 2 3 4 5 6  // ↑(第 2 大)  // ↑(partition = 2 的时候，实际上指向的是这里)  int lo = 0; int hi = nums.length - 1; // ==========================  // while (lo &amp;lt; hi)  // nums = [1]，这种情况进入不了循环  //  // ==========================  while (lo &amp;lt;= hi) { int index = partition(nums, lo, hi); if (index == k) { return nums[index]; } else if (index &amp;lt; k) { lo = index + 1; } else { hi = index - 1; } } return -1; } private int partition(int[] nums, int lo, int high) { int i = lo - 1; int pivot = nums[high]; for (int j = lo; j &amp;lt;= high - 1; j++) { if (nums[j] &amp;lt;= pivot) { i++; swap(nums, i, j); } } swap(nums, i + 1, high); return i + 1; } private void swap(int[] array, int i, int j) { int temp = array[i]; array[i] = array[j]; array[j] = temp; } 过半数的元素 使用**摩尔投票法**：</description>
    </item>
    
    <item>
      <title>文件搜索</title>
      <link>https://kunzhao.org/docs/tutorial/bigdata/search-file/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/tutorial/bigdata/search-file/</guid>
      <description>文件搜索 10亿个数中如何高效地找到最大的一个数以及最大的第K个数
10亿个数中如何高效地找到最大的一个数 将10亿个数据分成1000份，每份100万个数据，找到每份数据中最大的那个数据，最后在剩下的1000个数据里面找出最大的数据。 从100万个数据遍历选择最大的数，此方法需要每次的内存空间为10^6*4=4MB，一共需要1000次这样的比较。
10亿个数中如何高效地找到第K个数 对于top K类问题，通常比较好的方案是分治+hash+小顶堆：
 先将数据集按照Hash方法分解成多个小数据集 然后用小顶堆求出每个数据集中最大的K个数 最后在所有top K中求出最终的top K。  如果是top词频可以使用分治+ Trie树/hash +小顶堆：
 先将数据集按照Hash方法分解成多个小数据集 然后使用Trie树或者Hash统计每个小数据集中的query词频 之后用小顶堆求出每个数据集中出频率最高的前K个数 最后在所有top K中求出最终的top K。  时间复杂度：建堆时间复杂度是O(K),算法的时间复杂度为O(NlogK)。
参考  10亿个数中如何高效地找到最大的一个数以及最大的第K个数  </description>
    </item>
    
    <item>
      <title>服务度量</title>
      <link>https://kunzhao.org/docs/tutorial/distributed/service-measurement/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/tutorial/distributed/service-measurement/</guid>
      <description>服务度量  如果你不能度量它，你就无法改进它。&amp;mdash; 彼得德鲁克
 调用量、延时、异常 点: 单次请求指标采集 线：单服务一分钟指标叠加统计 面：单服务时间纬度汇总统计 对性能进行度量 调用耗时分区统计 部分请求落到了远离中心的 256 ~ 512 ms 这个长尾区间，这就意味着系统中存在异常的延时 &amp;ldquo;毛刺&amp;rdquo;，周期性出现的毛刺，和系统脆弱性有关，在高并发、大负载情况下，这种脆弱性会被放大，给系统造成严重影响。
性能横向对比 服务异常纬度 整体错误分部 </description>
    </item>
    
    <item>
      <title>生命周期</title>
      <link>https://kunzhao.org/docs/tutorial/vue3/lifecycle/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/tutorial/vue3/lifecycle/</guid>
      <description>生命周期  init: 在实例开始初始化时同步调用。此时数据观测、事件等都尚未初始化。 2.0 中更名为 beforeCreate。 created ：在实例创建之后调用。此时已完成数据绑定、事件方法，但尚未开始 DOM 编译，即未挂载到 document 中。 beforeCompile: 在 DOM 编译前调用。 2.0 废弃了该方法，推荐使用 created。 beforeMount: 2.0 新增的生命周期钩子，在 mounted 之前运行。 compiled: 在编译结束时调用。此时所有指令已生效，数据变化已能触发 DOM 更新，但不保证 $el 已插入文档。 2.0 中更名为 mounted。 ready ：在编译结束和 $el 第一次插入文档之后调用。 2.0 废弃了该方法，推荐使用 mounted。这个变化其实已经改变了ready这个生命周期状态，相当于取消了在$el首次插入文档后的钩子函数。 attached ：在 vm.$el 插入 DOM 时调用， ready 会在第一次 attached 后调用。操作 $el 必须使用指令或实例方法（例如 $appendTo()），直接操作 vm.$el 不会触发这个钩子。 2.0 废弃了该方法，推荐在其他钩子中自定义方法检查是否已挂载。 detached: 同 attached 类似，该钩子在 vm.$el 从 DOM 删除时调用，而且必须是指令或实例方法。 2.0 中同样废弃了该方法。 beforeDestroy: 在开始销毁实例时调用，此刻实例仍然有效。 destroyed: 在实例被销毁之后调用。此时所有绑定和实例指令都已经解绑，子实例也被销毁。 beforeUpdate: 2.</description>
    </item>
    
    <item>
      <title>穗康小程序口罩预约前后端架构及产品设计</title>
      <link>https://kunzhao.org/docs/cloud-plus-bbs/suikang-mini-program-design/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/cloud-plus-bbs/suikang-mini-program-design/</guid>
      <description>穗康小程序口罩预约前后端架构及产品设计 在战“疫”期间，腾讯与广州市政府合作，在小程序“穗康”上，2天内上线了全国首款口罩预约功能，上线首日访问量1.7亿，累计参与口罩预约人次1400万+。那么，它是如何在2天内开发上线，扛住了超大并发量呢？其背后的前后端架构是怎样的？
无损服务设计 整个流程下来需要 3 个实时接口：
 药店当前口罩的库存情况 哪个时间段有名额 提交预约实时返回结果  有损服务设计 结果，口罩预约关注度远超预期：
下面展示的 UI 的设计：
为什么有 “损” 平衡的理论就是 CAP 理论、BASE 最终一致性：
牺牲强一致换取高可用 两个机房需要同步，并发性差。以下是优化后的代码，引入计时器：
降低了专线依赖。
怎么 &amp;ldquo;损&amp;rdquo;  放弃绝对一致，追求高可用和快速响应 万有一失，用户重试 伸缩调度，降级服务  （1）穗康小程序 引入消息队列，最终一致：
（2）QQ 相册负载高 选择扩容？带宽和存储成本高。
（3）转账 用户重试极少量消息。再想一下微信的红色感叹号，点一下重新发送。
（4）穗康的预约重试 （5）QQ 相册降级 </description>
    </item>
    
    <item>
      <title>分布式系统一致性问题</title>
      <link>https://kunzhao.org/posts/consistency-problem-of-the-distrubuted-system/</link>
      <pubDate>Fri, 22 Jun 2018 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/posts/consistency-problem-of-the-distrubuted-system/</guid>
      <description>&lt;p&gt;描述解决分布式系统一致性问题的典型思路!&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Best Time to Buy and Sell Stock Ⅲ</title>
      <link>https://kunzhao.org/docs/programmer-interview/algorithm/best-time-to-buy-and-sell-stock-3/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/programmer-interview/algorithm/best-time-to-buy-and-sell-stock-3/</guid>
      <description>Best Time to Buy and Sell Stock Ⅲ 题目 LeetCode 地址：Best Time to Buy and Sell Stock Ⅲ
有一个数组，第 i 个元素的值代表第 i 天的股票价格，如果你最多只能进行两次交易（某天买入一支股票，然后过几天卖掉），请问你能收获的最大利润是多少？
分析 参考 Best Time to Buy and Sell Stock 思路上状态机，状态机应用两次即可。
答案 // 最多两次交易 // 且不能同时持有，必须卖掉这个，然后持有另外一个 // https://leetcode.com/problems/best-time-to-buy-and-sell-stock-iii/ // public class BestTimetoBuyandSellStockIII { // Buy Sell Buy Sell  // s0 ----&amp;gt; s1 -----&amp;gt; s2 -----&amp;gt; s3 ------&amp;gt; s4 (end)  // ↑___| ↑__| ↑____| ↑___|  //  public int maxProfit(int[] prices) { if (prices == null || prices.</description>
    </item>
    
    <item>
      <title>CSS 优化</title>
      <link>https://kunzhao.org/docs/tutorial/front-end-optimization-guide/css-optimization/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/tutorial/front-end-optimization-guide/css-optimization/</guid>
      <description>CSS 优化 本文讲述在实际工作中如何优化 CSS，提升页面加载的性能！
避免使用 @import @import url(&amp;#34;base.css&amp;#34;); @import url(&amp;#34;layout.css&amp;#34;); @import url(&amp;#34;carousel.css&amp;#34;); 由于 @import 属性允许相互之间嵌套引入，因此浏览器必须串行的去下载每一个 @import 引入的文件，因此会增加下载 CSS 文件的时间，而使用 &amp;lt;link&amp;gt; 就可以并行下载 CSS 文件，可有效提升 CSS 加载的性能：
&amp;lt;link rel=&amp;#34;stylesheet&amp;#34; href=&amp;#34;base.css&amp;#34;&amp;gt; &amp;lt;link rel=&amp;#34;stylesheet&amp;#34; href=&amp;#34;layout.css&amp;#34;&amp;gt; &amp;lt;link rel=&amp;#34;stylesheet&amp;#34; href=&amp;#34;carousel.css&amp;#34;&amp;gt; 简化 CSS 选择器 浏览器是从右向左逐步解析选择器表达式的，例如 #id .class &amp;gt; ul a 。首先找到页面上所有匹配 a 的节点，然后找到所有 ul 元素，并且将 a 元素恰好是 ul 元素子节点的元素过滤出来，直至解析到最左侧的选择器 #id 。
如下是在网站上针对 50000 个元素使用不同 CSS 选择器选择元素的时间对比：
   选择器 查询时间(ms)     div 4.8740   .</description>
    </item>
    
    <item>
      <title>Git 查看文件差异</title>
      <link>https://kunzhao.org/docs/tutorial/git/check-file-diff/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/tutorial/git/check-file-diff/</guid>
      <description>Git 查看文件差异 Git 三个区 Git 有三个区：工作区、Stage 区（暂存区）、版本库。这意味着，一个文件可能在这三个区都有所不同。如下图所示，一个文件使用 git add 命令之后，这个文件就转移到了暂存区，继续使用 git commit 之后就转移到了版本库。git diff 使用不同的命令参数可以查看文件在这三个区域中的两两对比的差异。
本地代码（工作区）与暂存区中的差异 git diff 示例结果如下所示：
diff 输出的格式介绍 下面解释上述 git diff 输出的格式：
 第一行，展示了使用什么命令做的比较 第二行，100644 代表这是一个普通文件 --- 表示原始文件，即这个文件没有修改前的内容 +++ 表示新文件，即这个文件修改后的内容 -1,5 中的 - 表示原始文件，1,5 表示从第 1 行到第 4 行做了改动 +1,5 中的 + 表示新文件，1,5 表示从第 1 行到第 4 行做了改动 @@ -1,5 +1,5 @@ 表示这个文件的第 1 行到第 4 行，变更为了新文件的第 1 行到第 4 行  本地代码（工作区）和版本库的差异 git diff HEAD  HEAD 指：当前工作分支的版本库</description>
    </item>
    
    <item>
      <title>HTTP2</title>
      <link>https://kunzhao.org/docs/tutorial/network/http2/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/tutorial/network/http2/</guid>
      <description>HTTP2 二进制分帧层 HTTP/2 所有性能增强的核心在于新的二进制分帧层，它定义了如何封装 HTTP 消息并在客户端与服务器之间传输。
HTTP/1.x 协议以换行符作为纯文本的分隔符，而 HTTP/2 将所有传输的信息分割为更小的消息和帧，并采用二进制格式对它们编码。
数据流、消息和帧 新的二进制分帧机制改变了客户端与服务器之间交换数据的方式。 为了说明这个过程，我们需要了解 HTTP/2 的三个概念：
 数据流：已建立的连接内的双向字节流，可以承载一条或多条消息。 消息：与逻辑请求或响应消息对应的完整的一系列帧。 帧：HTTP/2 通信的最小单位，每个帧都包含帧头，至少也会标识出当前帧所属的数据流。  这些概念的关系总结如下：
 所有通信都在一个 TCP 连接上完成，此连接可以承载任意数量的双向数据流。 每个数据流都有一个唯一的标识符和可选的优先级信息，用于承载双向消息。 每条消息都是一条逻辑 HTTP 消息（例如请求或响应），包含一个或多个帧。 帧是最小的通信单位，承载着特定类型的数据，例如 HTTP 标头、消息负载等等。 来自不同数据流的帧可以交错发送，然后再根据每个帧头的数据流标识符重新组装。  简言之，HTTP/2 将 HTTP 协议通信分解为二进制编码帧的交换，这些帧对应着特定数据流中的消息。所有这些都在一个 TCP 连接内复用。 这是 HTTP/2 协议所有其他功能和性能优化的基础。
请求与响应复用 在 HTTP/1.x 中，如果客户端要想发起多个并行请求以提升性能，则必须使用多个 TCP 连接。 这是 HTTP/1.x 交付模型的直接结果，该模型可以保证每个连接每次只交付一个响应（响应排队）。 更糟糕的是，这种模型也会导致队首阻塞，从而造成底层 TCP 连接的效率低下。
HTTP/2 中新的二进制分帧层突破了这些限制，实现了完整的请求和响应复用：客户端和服务器可以将 HTTP 消息分解为互不依赖的帧，然后交错发送，最后再在另一端把它们重新组装起来。
快照捕捉了同一个连接内并行的多个数据流。 客户端正在向服务器传输一个 DATA 帧（数据流 5），与此同时，服务器正向客户端交错发送数据流 1 和数据流 3 的一系列帧。因此，一个连接上同时有三个并行数据流。
将 HTTP 消息分解为独立的帧，交错发送，然后在另一端重新组装是 HTTP 2 最重要的一项增强。事实上，这个机制会在整个网络技术栈中引发一系列连锁反应，从而带来巨大的性能提升，让我们可以：</description>
    </item>
    
    <item>
      <title>Java 类加载</title>
      <link>https://kunzhao.org/docs/tutorial/java/classloader/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/tutorial/java/classloader/</guid>
      <description>Java 类加载 类编译  .class 文件包含哪些信息 ?
 类加载的过程 参考：《深入理解 Java 虚拟机》
JVM 把 Class 文件加载到内存，然后进行校验、准备、解析、初始化，最终形成可以使用的 Java 类型，这就是类加载机制。其中，校验、准备、解析这三个阶段，放在一起是链接阶段。
 【加载】二进制字节流可以从 JAR、WAR、网络、运行时动态生成（动态代理）、JSP生成。 【验证】文件格式、元数据（信息语义）、字节码验证（类型转换是否有效、跳转指令不会跳到方法体以外的地方去）、符号引用验证。在同一个类中，如果同时出现多个名字相同且描述符也相同的方法，那么 Java 虚拟机会在此阶段报错。 【准备】static final 变量赋值、各个基本数据类型的默认值 【解析】常量池内的符号引用（用符号描述引用目标）替换为直接引用（直接指向目标的指针） 【初始化】编译器收集 static 块、类变量的赋值放到 () 方法中   符号引用存储在哪里
 在编译过程中，我们并不知道目标方法的具体内存地址。因此，Java 编译器会暂时用符号引用来表示该目标方法。符号引用存储在 class 文件的常量池之中。根据目标方法是否为接口方法，这些引用可分为接口符号引用和非接口符号引用。利用“javap -v”打印某个类的常量池。
加载器类型  Bootstrap ClassLoader：加载 JAVA_HOME/lib、或者 -Xbootclasspath，并且是按照名字识别的，如 rt.jar Extension ClassLoader：JAVA_HOME/lib/ext、或者 java.ext.dirs 系统变量 Application ClassLoader：加载用户 ClassPath 上的类库  类加载器之间的层次关系，称之为双亲委派模型。如果一个类收到类加载请求，那么会首先委派给父类，父类反馈无法完成，自己才进行加载。
何时初始化  遇到 new、getstatic、putstatic、invokestatic 这 4 条字节码指令。对应的是 new 一个对象、读取静态字段、设置静态字段（字段没有被 final 修饰，否则在编译器就已经将结果放在常量池了）、调用一个类的静态方法。 java.</description>
    </item>
    
    <item>
      <title>leveldb 源码分析与实现 - 读取</title>
      <link>https://kunzhao.org/docs/tutorial/distributed-storage/leveldb-read/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/tutorial/distributed-storage/leveldb-read/</guid>
      <description>leveldb 源码分析与实现: 读取 读文件的过程 首先查看 memtable，其次查看 immutable memtable，最后尝试从 versions_-&amp;gt;current() 中获取。
// First look in the memtable, then in the immutable memtable (if any). LookupKey lkey(key, snapshot); if (mem-&amp;gt;Get(lkey, value, &amp;amp;s)) { // Done } else if (imm != nullptr &amp;amp;&amp;amp; imm-&amp;gt;Get(lkey, value, &amp;amp;s)) { // Done } else { s = current-&amp;gt;Get(options, lkey, value, &amp;amp;stats); have_stat_update = true; } MemTable // memtable.cc bool MemTable::Get(const LookupKey&amp;amp; key, std::string* value, Status* s) { // 取出和这个 key 关联的 tag  const uint64_t tag = DecodeFixed64(key_ptr + key_length - 8); switch (static_cast&amp;lt;ValueType&amp;gt;(tag &amp;amp; 0xff)) { // 有值  case kTypeValue: { Slice v = GetLengthPrefixedSlice(key_ptr + key_length); value-&amp;gt;assign(v.</description>
    </item>
    
    <item>
      <title>ls</title>
      <link>https://kunzhao.org/docs/tutorial/unix-command/ls/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/tutorial/unix-command/ls/</guid>
      <description>ls ls 命令教程，ls 命令的常见使用方法介绍。
简介 ls 命令是一个命令行实用程序，用于列出通过标准输入提供给它的一个或多个目录的内容。它将结果写入标准输出。ls 命令支持显示关于文件的各种信息、对一系列选项进行排序和递归列表。
示例 （1）显示目录中的文件
ls /home/zk （2）显示隐藏的文件和文件夹
ls -a /home/zk 结果：
ls -a /home/george . .goobook .tmux.conf .. .goobook_auth.json .urlview .asoundrc .inputrc .vim .asoundrc.asoundconf .install.sh .viminfo .asoundrc.asoundconf.bak .irbrc .viminfo.tmp ... （3）列出来的文件，标识上文件的类型
ls -F 显示结果如下所示：
bin@ dotfiles/ file.txt irc/ src/ code/ Downloads/ go/ logs/ 不同文件类型显示的后缀不同：
 /：目录 @：symbolic link |：FIFO =：socket &amp;gt;：door 什么也不显示，代表正常文件  （4）显示更多信息
ls -l 显示结果：
-rwxrw-r-- 10 root root 2048 Jan 13 07:11 afile.</description>
    </item>
    
    <item>
      <title>MySQL Crash Safe</title>
      <link>https://kunzhao.org/docs/tutorial/database/mysql-crash-safe/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/tutorial/database/mysql-crash-safe/</guid>
      <description>MySQL Crash Safe  MySQL 是如何保证数据不丢的？
 WAL 机制 只要 redo log 和 binlog 保证持久化到磁盘，就能确保 MySQL 异常重启后，数据可以恢复。
binlog 的写入机制 其实，binlog 的写入逻辑比较简单：事务执行过程中，先把日志写到 binlog cache，事务提交的时候，再把 binlog cache 写到 binlog 文件中。
系统给 binlog cache 分配了一片内存，每个线程一个，参数 binlog_cache_size 用于控制单个线程内 binlog cache 所占内存的大小。如果超过了这个参数规定的大小，就要暂存到磁盘。
事务提交的时候，执行器把 binlog cache 里的完整事务写入到 binlog 中，并清空 binlog cache。
每个线程有自己 binlog cache，但是共用同一份 binlog 文件。
 图中的 write，指的就是指把日志写入到文件系统的 page cache，并没有把数据持久化到磁盘，所以速度比较快。 图中的 fsync，才是将数据持久化到磁盘的操作。一般情况下，我们认为 fsync 才占磁盘的 IOPS。  write 和 fsync 的时机，是由参数 sync_binlog 控制的：
 sync_binlog=0 的时候，表示每次提交事务都只 write，不 fsync； sync_binlog=1 的时候，表示每次提交事务都会执行 fsync； sync_binlog=N(N&amp;gt;1) 的时候，表示每次提交事务都 write，但累积 N 个事务后才 fsync。  redo log 写入机制 事务在执行过程中，生成的 redo log 是要先写到 redo log buffer 的。redo log 可能存在的三种状态：</description>
    </item>
    
    <item>
      <title>ots parsing error</title>
      <link>https://kunzhao.org/docs/tutorial/spring/ots-parsing-error/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/tutorial/spring/ots-parsing-error/</guid>
      <description>ots parsing error Chrome 下载由 SpringBoot 项目作为 BackEnd，Element-UI 作为前台，并且 Element-UI 打包好的字体由 SpringBoot 进行托管的时候，出现的问题。
解决方法：
&amp;lt;plugin&amp;gt; &amp;lt;groupId&amp;gt;org.apache.maven.plugins&amp;lt;/groupId&amp;gt; &amp;lt;artifactId&amp;gt;maven-resources-plugin&amp;lt;/artifactId&amp;gt; &amp;lt;configuration&amp;gt; &amp;lt;nonFilteredFileExtensions&amp;gt; &amp;lt;nonFilteredFileExtension&amp;gt;ttf&amp;lt;/nonFilteredFileExtension&amp;gt; &amp;lt;nonFilteredFileExtension&amp;gt;woff&amp;lt;/nonFilteredFileExtension&amp;gt; &amp;lt;nonFilteredFileExtension&amp;gt;woff2&amp;lt;/nonFilteredFileExtension&amp;gt; &amp;lt;/nonFilteredFileExtensions&amp;gt; &amp;lt;/configuration&amp;gt; &amp;lt;/plugin&amp;gt; </description>
    </item>
    
    <item>
      <title>Redis RESP 通信协议</title>
      <link>https://kunzhao.org/docs/tutorial/redis/resp/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/tutorial/redis/resp/</guid>
      <description>Redis RESP 通信协议  RESP(Redis Serialization Protocol) 是 Redis 序列化协议的简写。它是一种直观的文本协议，优势在于实现异常简单，解析性能极好。
 RESP Redis 协议将传输的结构数据分为 5 种最小单元类型，单元结束时统一加上回车换行符号\r\n。
 单行字符串 以 + 符号开头。 多行字符串 以 $ 符号开头，后跟字符串长度。NULL 用多行字符串表示，不过长度写为 -1，空串写为 0 整数值 以 : 符号开头，后跟整数的字符串形式。 错误消息 以 - 符号开头。 数组 以 * 号开头，后跟数组的长度。  +hello world\r\n$11\r\nhello world\r\n:1024\r\n-WRONGTYPE Operation against a key holding the wrong kind of value\r\n*3\r\n:1\r\n:2\r\n:3\r\n$-1\r\n$0\r\n\r\nClient 发送给 Server  客户端向服务器发送的指令只有一种格式，多行字符串数组。
 比如 set author codehole 被序列化为：</description>
    </item>
    
    <item>
      <title>RocketMQ 消息接受流程</title>
      <link>https://kunzhao.org/docs/rocketmq/rocketmq-message-receive-flow/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/rocketmq/rocketmq-message-receive-flow/</guid>
      <description>RocketMQ 消息接受流程  基于 RocketMQ 4.2.0 版本进行的源码分析。
 本篇讲述 RocketMQ 消息接受流程
一、消费者注册 生产者负责往服务器 Broker 发送消息，消费者则从 Broker 获取消息。消费者获取消息采用的是订阅者模式，即消费者客户端可以任意订阅一个或者多个话题来消费消息:
public class Consumer { public static void main(String[] args) throws InterruptedException, MQClientException { /* * 订阅一个或者多个话题 */ consumer.subscribe(&amp;#34;TopicTest&amp;#34;, &amp;#34;*&amp;#34;); } } 当消费者客户端启动以后，其会每隔 30 秒从命名服务器查询一次用户订阅的所有话题路由信息:
public class MQClientInstance { private void startScheduledTask() { this.scheduledExecutorService.scheduleAtFixedRate(new Runnable() { @Override public void run() { // 从命名服务器拉取话题信息  MQClientInstance.this.updateTopicRouteInfoFromNameServer(); } }, 10, this.clientConfig.getPollNameServerInterval(), TimeUnit.MILLISECONDS); } } 我们由 RocketMQ 消息发送流程 这篇文章知道 RocketMQ 在发送消息的时候，每条消息会以轮循的方式均衡地分发的不同 Broker 的不同队列中去。由此，消费者客户端从服务器命名服务器获取下来的便是话题的所有消息队列:</description>
    </item>
    
    <item>
      <title>代码整洁之道</title>
      <link>https://kunzhao.org/docs/books/clean_code/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/books/clean_code/</guid>
      <description>代码整洁之道 勒布朗法则：Later equals never.
随着混乱的增加，团队生产力也持续下降，趋近于零。生产力下降的时候，管理层只能增加更多的人手，期望提高生产力。
什么是整洁代码  我喜欢优雅和高效的代码。代码逻辑应当直截了当，叫缺陷难以隐藏；尽量减少依赖关系，使之便于维护；依据某种分层战略完善错误处理代码；性能调至最优，省得引诱别人做没规矩的优化，搞出一堆混乱来。整洁的代码只做好一件事。&amp;mdash; Bjarne Stroustrup，C++ 语言发明者
  整洁的代码应可由作者之外的开发者阅读和增补。它应有单元测试和验收测试。它使用有意义的命名。它只提供一种而非多种做一件事的途径。它只有尽量少的依赖关系，且要明确地定义和提供清晰、尽量少的 API。代码应通过其表面表达含义，因为不同的语言导致并非所有必需信息均可通过代码自身清晰表达。&amp;mdash; Dave Thomas, OTI 公司创始人
  整洁的代码总是看起来像是某位特别在意它的人写的。几乎没有改进的余地，代码作者什么都想到了。&amp;mdash; 《修改代码的艺术》作者
 有意义的命名 对于变量，如果其需要注释来补充，那就不算是名副其实。比如你需要定义一个变量，这个变量存储的是消逝的时间，其单位是天，那么下面是一些比较好的命名：
int elapsedTimeInDays; int daysSinceCreation; int daysSinceModification; int fileAgeInDays; 别用 accountList 来指一组账号，除非它真的是 List 类型，List 一词对于程序员有特殊意义，所以用 accountGroup 或 bunchOfAcounts，甚至用 accounts 都会好一些。
别说废话，废话都是冗余。假如你有一个 Product 类，如果还有一个 ProductInfo 或 ProductData 类，它们虽然名称不同，意思却无区别。Info 和 Data 就像 a、an 和 the 一样，是意义含混的废话。下面三个函数的命名，我们怎么知道应该调用哪个呢？
getActiveAccount(); getActiveAccounts(); getActiveAccountInfo(); 使用常量，WORK_DAYS_PER_WEEK 比数字 5 要好找的多。
 对于类名，其应该是名词或名词短语，如 Customer、WikiPage、Account 和 AddressParser，避免使用 Manager、Processor、Data 或 Info 这样的类名。类名不应当是动词。</description>
    </item>
    
    <item>
      <title>服务管控</title>
      <link>https://kunzhao.org/docs/tutorial/distributed/service-control/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/tutorial/distributed/service-control/</guid>
      <description>服务管控 服务负载 随机策略 各个服务器处理能力不同，处理性能弱的会被打趴。可以加上权重：
collection = {A: 5, B:2, C:2, D:1}(1) 策略1
{A,A,A,A,A,B,B,C,C,D}
random.nextInt(10) 缺点就是这个 collection 集合可能会比较大，内存占用大
(2) 策略2
权重换算成长度，先算出总长度，然后再计算出一个偏移量
totalWeight = sum(collection) offset = random.nextInt(totalWeight) 缺点就是选取的时候，需要遍历集合，复杂度 O(n)
轮询策略 如果各个节点权重一致：
[total_request_count + 1] % node_count 如果权重不同，
collection = {A: 5, B:2, C:2, D:1}那么，最高的权重是 5：
[total_request_count + 1] % maxWeight = currentWeight那么 [currentWeight, maxWeight] 就是可用的权重范围。
一致性 Hash 策略 节点数少，节点变动，大量键发生波动，造成数据倾斜，因此可以引入虚拟节点，每个节点通过引入编号计算多个 Hash 值，模拟多个虚拟节点。
限流 漏桶算法 算法类似于餐厅排号就餐，整个餐厅所能容纳的顾客数量是有限的，有出才能有进。
Semaphore sem = new Semaphore(30); if (sem.</description>
    </item>
    
    <item>
      <title>树</title>
      <link>https://kunzhao.org/docs/tutorial/algorithm/tree/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/tutorial/algorithm/tree/</guid>
      <description>树 BST 第 K 大的数字  二叉搜索树的中序遍历为递增序列。因此这道题可转化为求 “此树的中序遍历倒序的第 k 个节点”。
 class Solution { int res, k; public int kthLargest(TreeNode root, int k) { this.k = k; dfs(root); return res; } void dfs(TreeNode root) { if (root == null) return; dfs(root.right); if (k == 0) return; if (--k == 0) res = root.val; dfs(root.left); } } 时间复杂度：O(N)，空间复杂度：O(N)，当树退化为链表（全部是右节点）的时候，系统使用 O(N) 大小的栈空间。
BST 中序遍历的下一个节点 这道题是 《剑指 Offer》 上的题目，先确定有无指向父节点的指针？</description>
    </item>
    
    <item>
      <title>计算属性</title>
      <link>https://kunzhao.org/docs/tutorial/vue3/computed/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/tutorial/vue3/computed/</guid>
      <description>计算属性 基础用法 var vm = new Vue({ el: &amp;#39;#app&amp;#39;, data: { firstName: &amp;#39;Gavin&amp;#39;， lastName: &amp;#39;CLY&amp;#39; } computed: { fullName: function() { // this 指向 vm 实例 	return this.firstName + &amp;#39; &amp;#39; + this.lastName } } }); HTML 代码：
&amp;lt;p&amp;gt;{{ firstName }}&amp;lt;/p&amp;gt; // Gavin &amp;lt;p&amp;gt;{{ lastName }}&amp;lt;/p&amp;gt; // CLY &amp;lt;p&amp;gt;{{ fullName }}&amp;lt;/p&amp;gt; // Gavin CLY Setter 用法 var vm = new Vue({ el: &amp;#39;#el&amp;#39;, data: { cents: 100， } computed: { price: { set: function(newValue) { this.</description>
    </item>
    
    <item>
      <title>谷歌修改 Chromium 源码中的“黑白名单”术语</title>
      <link>https://kunzhao.org/docs/it-zone/2020-06/chrome-change-blacklist-to-blocklist/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/it-zone/2020-06/chrome-change-blacklist-to-blocklist/</guid>
      <description>谷歌修改 Chromium 源码中的“黑白名单”术语 日期：2020-06-09
 【为了种族中立，谷歌修改 Chromium 源码中的“黑白名单”术语】
国外正在进行的 Black Lives Matter 运动，谷歌已表态支持。
据外媒报道，Google 在修改 Chromium 源码中的有种族歧视色彩的术语，来消除微妙的种族主义形式。
 blacklist 改成 blocklist， whitelist 改成 allowlist；
 2019 年 10 月，Chromium 开源项目的官方代码风格指南中，新增了如何编写种族中立代码的内容。其中明确指出，Chrome 和 Chromium 开发人员应避免使用“黑名单”和“白名单”一词，而应使用中性术语“阻止名单”和“允许名单”。
其实早在 2018 年 5 月，Google 已开始着手删除普通用户在 Chrome 浏览器中能看到的“黑名单”和“白名单”。
但普通用户看不到的 Chrome / Chromium 源码中，还有很多很多，据统计约 2000 多处。</description>
    </item>
    
    <item>
      <title>限流实现原理</title>
      <link>https://kunzhao.org/docs/tutorial/sentinel/flow/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/tutorial/sentinel/flow/</guid>
      <description>限流实现原理 本文以最常见的限流场景来讲述 Sentinel 基础的工作原理。
限流架构图 限流原理的总的架构图如下：
FlowSlot 从 FlowRuleManager 中根据用当前资源名称作为 Key，然后读取出来这个资源绑定的 FlowRule 规则。然后将这些规则作为方法的参数，来调用 FlowRuleChecker 的 checkFlow 方法。
在 checkFlow 内部，遍历这每一个 FlowRule，逐次判断是否可以通过限流检查：
// FlowRuleChecker.java public void checkFlow(Function&amp;lt;String, Collection&amp;lt;FlowRule&amp;gt;&amp;gt; ruleProvider, ResourceWrapper resource, Context context, DefaultNode node, int count, boolean prioritized) throws BlockException { Collection&amp;lt;FlowRule&amp;gt; rules = ruleProvider.apply(resource.getName()); if (rules != null) { for (FlowRule rule : rules) { if (!canPassCheck(rule, context, node, count, prioritized)) { throw new FlowException(rule.getLimitApp(), rule); } } } } 每一个 FlowRule 内部都可以关联不同的 TrafficShapingController，关联不同的流量整形器的代码如下：</description>
    </item>
    
    <item>
      <title>Java 并发 - 锁</title>
      <link>https://kunzhao.org/posts/java-lock/</link>
      <pubDate>Sat, 13 May 2017 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/posts/java-lock/</guid>
      <description>&lt;p&gt;Java 世界中都有哪些锁？锁的分类？如何减少锁的竞争等问题。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>JVM 性能调优</title>
      <link>https://kunzhao.org/posts/jvm-optimization/</link>
      <pubDate>Tue, 02 May 2017 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/posts/jvm-optimization/</guid>
      <description>&lt;p&gt;JVM 如何进行性能调优？&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>APM 及调用链跟踪</title>
      <link>https://kunzhao.org/docs/tutorial/distributed/apm/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/tutorial/distributed/apm/</guid>
      <description>APM 及调用链跟踪  APM: Application Performance Management
 日志埋点  字节码适配自动插码埋点 中间件自动埋点 基于环境语义构建 TraceId  日志采集  RingBuffer 作为日志缓存代替 BlockingQueue，避免锁冲突 避免频繁 I/O：秒级刷盘 压缩：LZO 算法或 Snappy 压缩 无 I/O：  </description>
    </item>
    
    <item>
      <title>Best Time to Buy and Sell Stock Ⅳ</title>
      <link>https://kunzhao.org/docs/programmer-interview/algorithm/best-time-to-buy-and-sell-stock-4/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/programmer-interview/algorithm/best-time-to-buy-and-sell-stock-4/</guid>
      <description>Best Time to Buy and Sell Stock Ⅳ 题目 LeetCode 地址：Best Time to Buy and Sell Stock Ⅳ
有一个数组，第 i 个元素的值代表第 i 天的股票价格，如果你最多只能进行K次交易（某天买入一支股票，然后过几天卖掉），请问你能收获的最大利润是多少？
分析 参考 Best Time to Buy and Sell Stock 思路上状态机，状态机应用K次即可。
答案 // 最多交易 k 次 // https://leetcode.com/problems/best-time-to-buy-and-sell-stock-iv/ // public class BestTimetoBuyandSellStockIV { public int maxProfit(int k, int[] prices) { if (prices == null || prices.length &amp;lt;= 1 || k &amp;lt;= 0) { return 0; } if (k &amp;gt;= prices.</description>
    </item>
    
    <item>
      <title>Git 重置</title>
      <link>https://kunzhao.org/docs/tutorial/git/git-reset/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/tutorial/git/git-reset/</guid>
      <description>Git 重置 git reset 命令是 Git 最危险最容易误用的命令之一！一定要慎用，要清除地知道你自己在做什么！
Git reset 命令格式 git reset [--soft | --mixed | --hard] [&amp;lt;commit&amp;gt;] Git 提交历史记录 cat .git/refs/heads/master 显示的就是当前版本库的最新的 commitid
Git 重置与版本变化关系图 上述图，
 1 代表更新引用指向，即引用指向新的 commit 2 代表暂存区的内容与版本库保持一致 3 代表工作区的内容与暂存区保持一致  使用不同的参数，执行的操作不一样：
 --hard 参数，上图 1、2、3 这三步全部执行 --soft 参数，上图 1 执行 --mixed 参数，上图 1、2 执行 不使用参数，等同于使用了 --mixed 参数  根据上述解释，我们来看几个例子：
彻底回退到上一次提交 git reset --hard HEAD^  HEAD^ 指：HEAD 的父提交，即上一次提交。注意 --hard 选项会将本地工作区的内容也恢复为上一次提交，且不可恢复，所以此命令慎用！！！
 彻底回退到某一次 commit 根据 commit id 回退到某一次的提交：</description>
    </item>
    
    <item>
      <title>HTTP3</title>
      <link>https://kunzhao.org/docs/tutorial/network/http3/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/tutorial/network/http3/</guid>
      <description>HTTP3 HTTP/1.1 和 HTTP/2 使用 TCP 传输协议，HTTP/3 使用 QUIC (Quick UDP Internet Connections) 传输层协议，其是由 Google 开发的一种基于 UDP 的传输协议。之所以用 QUIC 协议的最主要原因，是为了彻底解决队头阻塞问题。
QUIC TCP 队头阻塞 HTTP/2 解决了 HTTP 的队头拥塞（head of line blocking）问题，客户端无须等待一个请求完成才能发送下一个请求，但它解决的只是 HTTP 的队头阻塞问题。
如果 HTTP/2 连接双方的网络中有一个数据包丢失，或者任何一方的网络出现中断，整个TCP连接就会暂停，丢失的数据包需要被重新传输。因为TCP是一个按序传输的链条，因此如果其中一个点丢失了，链路上之后的内容就都需要等待。
这种单个数据包造成的阻塞，就是 TCP 上的队头阻塞（head of line blocking）。
安全性 QUIC 始终保证安全性。QUIC 协议没有明文的版本，所以想要建立一个 QUIC 连接，就必须通过 TLS 1.3 来安全地建立一个加密连接。QUIC 只在加密协议协商时会发送几个明文传送的初始握手报文。
减少延迟 TCP 需要 3 次握手，QUIC 提供了 0-RTT 和 1-RTT 握手，减少了协商和建立连接所需要的时间。
HTTP3 协议特点 协议栈 可靠性 虽然 UDP 不提供可靠的传输，但 QUIC 在基于 UDP 之时增加了一层带来可靠性的层。它提供了数据包重传、拥塞控制、调整传输节奏（pacing）以及其他一些TCP中存在的特性。</description>
    </item>
    
    <item>
      <title>JS 优化</title>
      <link>https://kunzhao.org/docs/tutorial/front-end-optimization-guide/js-optimization/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/tutorial/front-end-optimization-guide/js-optimization/</guid>
      <description>JS 优化 本文介绍常见的优化 JS、提升 JS 加载性能的优化方法！
提升加载性能 script 放入到 body 中 &amp;lt;script&amp;gt; 标签经常以下面的这种方式引入：
&amp;lt;script src=&amp;#34;script.js&amp;#34;&amp;gt;&amp;lt;/script&amp;gt; 当 HTML 解析器看到这一行代码时，就会请求获取脚本，并执行脚本。一旦这个过程完成，解析就可以继续，剩下的 HTML 也可以被分析。所以你可以想象，这个操作会对页面的加载时间产生多么大的影响。如果脚本加载的时间比预期的稍长，例如，如果网络有点慢，或者如果您在移动设备上，并且网速特别慢，则在加载和执行脚本之前，访问者可能会看到一个空白页。
所以推荐将 script 标签从 &amp;lt;head&amp;gt; 位置挪到 &amp;lt;/body&amp;gt; 标签前。如果你这样做了，脚本在所有页面都被解析和加载之后才会加载和执行，这是对 &amp;lt;head&amp;gt; 替代方案的巨大改进。
&amp;lt;script defer src=&amp;#34;script.js&amp;#34;&amp;gt;&amp;lt;/script&amp;gt; Async 和 Defer 如果不考虑兼容旧浏览器，那么 async 和 defer 这两个布尔属性值，会是提升页面加载速度的更好选择：
&amp;lt;script async src=&amp;#34;script.js&amp;#34;&amp;gt;&amp;lt;/script&amp;gt; &amp;lt;script defer src=&amp;#34;script.js&amp;#34;&amp;gt;&amp;lt;/script&amp;gt; 这两个属性都可以达到异步加载和执行 script 标签的目的，如果同时指定了两个，那么 async 优先级高一点，老一点的浏览器不支持 async 会降级到 defer。这些属性只有在页面的 &amp;lt;head&amp;gt; 部分使用 &amp;lt;script&amp;gt; 时才有意义，如果像我们上面看到的那样将脚本放在 &amp;lt;body&amp;gt; 中，则这些属性是无用的。
使用 async 会阻塞 HTML 的解析：
使用 defer 并不会阻塞 HTML 的解析：</description>
    </item>
    
    <item>
      <title>JUC 并发包</title>
      <link>https://kunzhao.org/docs/tutorial/java/juc/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/tutorial/java/juc/</guid>
      <description>JUC 并发包 线程安全  无状态对象（例如 Servlet）一定是线程安全的。 对于可能被多个线程访问的可变状态的变量，用锁来保护它。 不可变对象（所有 field 都是 final，this 指针没有逸出）一定是线程安全的。  Java 内存模型 (JMM) 在并发编程中，需要处理两个关键问题：线程之间如何通信及线程之间如何同步。在命令式编程中，线程之间的通信机制有两种：共享内存和消息传递。
Java的并发采用的是共享内存模型，Java线程之间的通信总是隐式进行，整个通信过程对程序员完全透明。
 线程之间共享程序的公共状态，通过写读内存中的公共状态进行隐式通信。 在共享内存并发模型里，同步是显式进行的。程序员必须显式指定某个方法或某段代码需要在线程之间互斥执行。  Java 线程之间的通信 由 Java 内存模型（本文简称为 JMM ）控制，JMM 决定一个线程对共享变量的写入何时对另一个线程可见。
本地内存是 JMM 的一个抽象概念，并不真实存在。它涵盖了缓存、写缓冲区、寄存器以及其他的硬件和编译器优化。Java内存模型的抽象结构示意图如下:
JMM 通过控制主内存与每个线程的本地内存之间的交互，来为 Java 程序员提供内存可见性保证。
由于 JVM 运行程序的实体是线程，而每个线程创建时JVM都会为其创建一个工作内存(有些地方称为栈空间)，用于存储线程私有的数据，线程与主内存中的变量操作必须通过工作内存间接完成，主要过程是将变量从主内存拷贝的每个线程各自的工作内存空间，然后对变量进行操作，操作完成后再将变量写回主内存，如果存在两个线程同时对一个主内存中的实例对象的变量进行操作就有可能诱发线程安全问题。为了解决类似上述的问题，JVM定义了一组规则，通过这组规则来决定一个线程对共享变量的写入何时对另一个线程可见，这组规则也称为Java内存模型（即JMM），JMM是围绕着程序执行的原子性、有序性、可见性展开的，下面我们看看这三个特性。
可见性 可见性是怎么导致的: 是因为每个 CPU 都有自己的缓存导致的。可见性指的是当一个线程修改了某个共享变量的值，其他线程是否能够马上得知这个修改的值。
 禁止编译器/处理器重排序：JMM属于语言级的内存模型，它确保在不同的编译器和不同的处理器平台之上，通过禁止特定类型的编译器重排序和处理器重排序，为程序员提供一致的内存可见性保证。处理器重排序，是通过在生成指令序列时，插入内存屏障来保证可见性。 synchronized：当线程获取锁时会从主内存中获取共享变量的最新值，释放锁的时候会将共享变量同步到主内存中。从而，synchronized具有可见性。 volatile：通过在指令中添加 lock 指令，以实现内存可见性  原子性 原子性指的是一个操作是不可中断的，即使是在多线程环境下，一个操作一旦开始就不会被其他线程影响。 基本数据类型
JMM 定义了 8 种操作都是原子的，不可再分的。
 lock(锁定)：作用于主内存中的变量，它把一个变量标识为一个线程独占的状态； unlock(解锁):作用于主内存中的变量，它把一个处于锁定状态的变量释放出来，释放后的变量才可以被其他线程锁定 read（读取）：作用于主内存的变量，它把一个变量的值从主内存传输到线程的工作内存中，以便后面的load动作使用； load（载入）：作用于工作内存中的变量，它把read操作从主内存中得到的变量值放入工作内存中的变量副本 use（使用）：作用于工作内存中的变量，它把工作内存中一个变量的值传递给执行引擎，每当虚拟机遇到一个需要使用到变量的值的字节码指令时将会执行这个操作； assign（赋值）：作用于工作内存中的变量，它把一个从执行引擎接收到的值赋给工作内存的变量，每当虚拟机遇到一个给变量赋值的字节码指令时执行这个操作； store（存储）：作用于工作内存的变量，它把工作内存中一个变量的值传送给主内存中以便随后的write操作使用； write（操作）：作用于主内存的变量，它把store操作从工作内存中得到的变量的值放入主内存的变量中。  上面一共有八条原子操作，其中六条可以满足基本数据类型的访问读写具备原子性，还剩下lock和unlock两条原子操作。</description>
    </item>
    
    <item>
      <title>MySQL 索引</title>
      <link>https://kunzhao.org/docs/tutorial/database/mysql-index/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/tutorial/database/mysql-index/</guid>
      <description>MySQL 索引 索引存储结构 InnoDB 的 B+ 树 每一个索引在 InnoDB 里面对应一棵 B+ 树。B+ 树能够很好地配合磁盘的读写特性，减少单次查询的磁盘访问次数。
根据叶子节点的内容，索引类型分为主键索引和非主键索引。
 主键索引的叶子节点存的是整行数据。在 InnoDB 里，主键索引也被称为聚簇索引（clustered index）。 非主键索引的叶子节点内容是主键的值。在 InnoDB 里，非主键索引也被称为二级索引（secondary index）。  主键长度越小，普通索引的叶子节点就越小，普通索引占用的空间也就越小。
 为何可以降低 IO ?
  InnoDB 叶子节点，数据页是双向，单条数据之间单向。
  InnoDB 索引一次读多少？
 这个 16kb 是 innodb 默认的页大小，为什么会有这个概念呢，因为当涉及到数据库读写的时候，规定数据库每次读写都是以 16k 为单位的，一次最少从磁盘中读取 16KB 的内容到内存中，一次最少把内存中的 16KB 内容刷新到磁盘中。
 计算 IO 次数
 我们每次 IO 都是读取数据到内存中进行一些计算。当我们遍历 主键索引的B+树 查找数据的时候， IO 次数是近似于 B+ 树的层数 -1，因为根节点是一直在内存中的。
基本上可以理解为，每次 io 都是在树的一层查找符合的 id 范围的页数据，通过对比页里面的最大最小主键来确定下层的查找范围。
MyISAM 的 B+ 树 MyISAM 索引文件和数据文件是分离的，索引文件仅保存数据记录的地址。</description>
    </item>
    
    <item>
      <title>Redis 持久化</title>
      <link>https://kunzhao.org/docs/tutorial/redis/persistence/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/tutorial/redis/persistence/</guid>
      <description>Redis 持久化 RDB RDB 持久化是把当前进程数据生成快照保存到硬盘的过程，触发 RDB 持久化过程分为手动触发和自动触发。
快照原理 Redis 使用操作系统的多进程 COW (Copy On Write) 机制来实现快照持久化。
Redis 在持久化时会调用 glibc 的函数 fork 产生一个子进程，快照持久化完全交给子进程来处理，父进程继续处理客户端请求。子进程刚刚产生时，它和父进程共享内存里面的代码段和数据段。
子进程做数据持久化，它不会修改现有的内存数据结构，它只是对数据结构进行遍历读取，然后序列化写到磁盘中。但是父进程不一样，它必须持续服务客户端请求，然后对内存数据结构进行不间断的修改。
这个时候就会使用操作系统的 COW 机制来进行数据段页面的分离。数据段是由很多操作系统的页面组合而成，当父进程对其中一个页面的数据进行修改时，会将被共享的页面复制一份分离出来，然后对这个复制的页面进行修改。这时子进程相应的页面是没有变化的，还是进程产生时那一瞬间的数据。
随着父进程修改操作的持续进行，越来越多的共享页面被分离出来，内存就会持续增长。但是也不会超过原有数据内存的 2 倍大小。另外一个 Redis 实例里冷数据占的比例往往是比较高的，所以很少会出现所有的页面都会被分离，被分离的往往只有其中一部分页面。每个页面的大小只有 4K，一个 Redis 实例里面一般都会有成千上万的页面。
子进程因为数据没有变化，它能看到的内存里的数据在进程产生的一瞬间就凝固了，再也不会改变，这也是为什么 Redis 的持久化叫「快照」的原因。接下来子进程就可以非常安心的遍历数据了进行序列化写磁盘了。
触发机制 手动触发分别对应save和bgsave命令：
  save命令：阻塞当前Redis服务器，直到RDB过程完成为止，对于内存比较大的实例会造成长时间阻塞，线上环境不建议使用。
  bgsave命令：Redis进程执行fork操作创建子进程，RDB持久化过程由子进程负责，完成后自动结束。阻塞只发生在fork阶段，一般时间很短。
  除了执行命令手动触发之外，Redis内部还存在自动触发RDB的持久化机制，例如以下场景：
 1）使用save相关配置，如“save m n”。表示m秒内数据集存在n次修改时，自动触发bgsave。 2）如果从节点执行全量复制操作，主节点自动执行bgsave生成RDB文件并发送给从节点。 3）执行debug reload命令重新加载Redis时，也会自动触发save操作。 4）默认情况下执行shutdown命令时，如果没有开启AOF持久化功能则自动执行bgsave。   Redis save 命令已经废弃。
  通过 info stats 命令的 latest_fork_usec 可以查看父进程 fork 时候阻塞的时间 (微秒)。 执行 lastsave 命令，可以查看最后一次生成 RDB 的时间，也对应 info 命令的 rdb_last_save_time 选项。  RDB 文件 RDB文件保存在dir配置指定的目录下，文件名通过dbfilename配置指定。可以通过执行config set dir{newDir}和config set dbfilename{newFileName}运行期动态执行，当下次运行时RDB文件会保存到新目录。</description>
    </item>
    
    <item>
      <title>RocketMQ 消息过滤流程</title>
      <link>https://kunzhao.org/docs/rocketmq/rocketmq-message-filter-flow/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/rocketmq/rocketmq-message-filter-flow/</guid>
      <description>RocketMQ 消息过滤流程  基于 RocketMQ 4.2.0 版本进行的源码分析。
 讲述 RocketMQ 消息过滤流程
一、消息过滤类型 Producer 在发送消息的时候可以指定消息的标签类型，还可以为每一个消息添加一个或者多个额外的属性:
// 指定标签 Message msg = new Message(&amp;#34;TopicTest&amp;#34;, &amp;#34;TagA&amp;#34;, (&amp;#34;Hello RocketMQ&amp;#34;).getBytes(RemotingHelper.DEFAULT_CHARSET)); // 添加属性 a msg.putUserProperty(&amp;#34;a&amp;#34;, 5); 根据标签和属性的不同，RocketMQ 客户端在消费消息的时候有三种消息过滤类型:
(1) 标签匹配 consumer.subscribe(&amp;#34;TopicTest&amp;#34;, &amp;#34;TagA | TagB | TagC&amp;#34;); (2) SQL 匹配 consumer.subscribe(&amp;#34;TopicTest&amp;#34;, MessageSelector.bySql( &amp;#34;(TAGS is not null and TAGS in (&amp;#39;TagA&amp;#39;, &amp;#39;TagB&amp;#39;))&amp;#34; + &amp;#34;and (a is not null and a between 0 3)&amp;#34;)); (3) 自定义匹配 客户端实现 MessageFilter 类，自定义过滤逻辑:
ClassLoader classLoader = Thread.</description>
    </item>
    
    <item>
      <title>SpringBoot 打包成 WAR 部署到 Tomcat</title>
      <link>https://kunzhao.org/docs/tutorial/spring/deploy-to-tomcat/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/tutorial/spring/deploy-to-tomcat/</guid>
      <description>SpringBoot 打包成 WAR 部署到 Tomcat 步骤 移除 Spring Boot 内置的 Tomcat &amp;lt;dependency&amp;gt; &amp;lt;groupId&amp;gt;org.springframework.boot&amp;lt;/groupId&amp;gt; &amp;lt;artifactId&amp;gt;spring-boot-starter-web&amp;lt;/artifactId&amp;gt; &amp;lt;!-- 移除嵌入式tomcat插件 --&amp;gt; &amp;lt;exclusions&amp;gt; &amp;lt;exclusion&amp;gt; &amp;lt;groupId&amp;gt;org.springframework.boot&amp;lt;/groupId&amp;gt; &amp;lt;artifactId&amp;gt;spring-boot-starter-tomcat&amp;lt;/artifactId&amp;gt; &amp;lt;/exclusion&amp;gt; &amp;lt;/exclusions&amp;gt; &amp;lt;/dependency&amp;gt; 添加 provided 的 Tomcat:
&amp;lt;dependency&amp;gt; &amp;lt;groupId&amp;gt;org.apache.tomcat.embed&amp;lt;/groupId&amp;gt; &amp;lt;artifactId&amp;gt;tomcat-embed-jasper&amp;lt;/artifactId&amp;gt; &amp;lt;scope&amp;gt;provided&amp;lt;/scope&amp;gt; &amp;lt;/dependency&amp;gt; 添加 Servlet 支持 &amp;lt;dependency&amp;gt; &amp;lt;groupId&amp;gt;javax.servlet&amp;lt;/groupId&amp;gt; &amp;lt;artifactId&amp;gt;jstl&amp;lt;/artifactId&amp;gt; &amp;lt;/dependency&amp;gt; 设置打包成 WAR &amp;lt;!-- 这里设置打包的形式 默认为jar --&amp;gt; &amp;lt;packaging&amp;gt;war&amp;lt;/packaging&amp;gt; 修改 SpringApplication 配置 import org.springframework.boot.builder.SpringApplicationBuilder; import org.springframework.boot.web.servlet.support.SpringBootServletInitializer; @SpringBootApplication public class SpringBootStartApplication extends SpringBootServletInitializer { public static void main(String...args) { SpringApplication.run(SpringBootStartApplication.class, args); } @Override protected SpringApplicationBuilder configure(SpringApplicationBuilder builder) { // 注意这里要指向原先用main方法执行的Application启动类 	return builder.</description>
    </item>
    
    <item>
      <title>ssh</title>
      <link>https://kunzhao.org/docs/tutorial/unix-command/ssh/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/tutorial/unix-command/ssh/</guid>
      <description>ssh 本文展示了一些常见的 ssh 命令，了解一些 ssh 技巧将有利于任何系统管理员、网络工程师或安全专业人员。
连接远程主机 localhost:~$ ssh -v -p 22 -C neo@remoteserver  -v：打印 debug 日志信息，用于打印连接时候的一些日志。 -p 22：指定连接远程主机的哪个端口，默认情况下，不用指定，因为 ssh 默认端口就是 22。编辑 sshd_config 文件，可以修改默认的 ssh 的监听端口。 -C：传输数据的时候，是否对数据启用压缩。 neo@remoteserver：neo 代表远程主机的用户名，remoteserver 代表远程主机的 IP 或者域名。添加 -4 选项，可以只连接 IPv4 连接；添加 -6 选项，只连接 IPv6 连接。  拷贝文件到远程服务器 远程拷贝文件的命令 scp 建立在 ssh 命令之上：
localhost:~$ scp mypic.png neo@remoteserver:/media/data/mypic_2.png  mypic.png：代表本地电脑上的图片 /media/data/mypic_2.png：代表你想把图片拷贝到远程主机的哪个路径  流量代理 SSH 代理特性被放在第1位是有充分理由的。它的功能比许多用户意识到的要强大得多，它允许您使用几乎任何应用程序访问远程服务器可以访问的任何系统。ssh客户机可以仅用一行代码，就可以使用SOCKS代理服务器在连接隧道上通信。
localhost:~$ ssh -D 8888 user@remoteserver localhost:~$ netstat -pan | grep 8888 tcp 0 0 127.</description>
    </item>
    
    <item>
      <title>v-if 和 v-show</title>
      <link>https://kunzhao.org/docs/tutorial/vue3/v-if-v-show/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/tutorial/vue3/v-if-v-show/</guid>
      <description>v-if 和 v-show 当 v-if 和 v-show 的条件发生变化时， v-if 引起了 dom 操作级别的变化，而 v-show 仅发生了样式的变化，从切换的角度考虑， v-show 消耗的性能要比 v-if 小。
除此之外， v-if 切换时， Vue.js 会有一个局部编译 / 卸载的过程，因为 v-if 中的模板也可能包括数据绑定或子组件。 v-if 会确保条件块在切换当中适当地销毁与中间内部的事件监听器和子组件。而且 v-if是惰性的，如果在初始条件为假时， v-if 本身什么都不会做，而v-show 则仍会进行正常的操作，然后把 css 样式设置为 display:none。
所以，总的来说， v-if 有更高的切换消耗，而 v-show 有更高的初始渲染消耗，我们需要根据实际的使用场景来选择合适的指令。</description>
    </item>
    
    <item>
      <title>企业 IT 架构转型之道</title>
      <link>https://kunzhao.org/docs/books/the_transformation_of_enterprise_it_architecture/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/books/the_transformation_of_enterprise_it_architecture/</guid>
      <description>企业 IT 架构转型之道 共享服务体系搭建 SOA 的主要特性：
 面向服务的分布式计算。 服务间松散耦合。 支持服务的组装。 服务注册和自动发现。 以服务契约方式定义服务交互方式。  基于 “中心化” 的 ESB 服务调用方式  “去中心化” 服务架构调用方式   数据拆分实现数据库能力线性扩展 数据库的读写分离 读写分离基本原理是让主数据库处理事务性增、改、删（INSERT、UPDATE、DELETE）操作，而从数据库专门负责处理查询（SELECT）操作，在数据库的后台会把事务性操作导致的主数据库中的数据变更同步到集群中的从数据库。
数据库分库分表 采用分库分表的方式将业务数据拆分后，如果每一条SQL语句中都能带有分库分表键，SQL语句的执行效率最高：
但不是所有的业务场景在进行数据库访问时每次都能带分库分表键的。比如在买家中心的界面中，要显示买家test1过去三个月的订单列表信息。此时就出现了我们所说的全表扫描，一条SQL语句同时被推送到后端所有数据库中运行。如果是高并发情况下同时请求的话，为了数据库整体的扩展能力，则要考虑下面描述的异构索引手段来避免这样的情况发生。对于在内存中要进行大数据量聚合操作和计算的SQL请求，如果这类SQL的不是大量并发或频繁调用的话，平台本身的性能影响也不会太大，如果这类SQL请求有并发或频繁访问的要求，则要考虑采用其他的平台来满足这一类场景的要求，比如Hadoop这类做大数据量离线分析的产品，如果应用对请求的实时性要求比较高，则可采用如内存数据库或HBase这类平台。
所谓“异构索引表”，就是采用异步机制将原表内的每一次创建或更新，都换另一个维度保存一份完整的数据表或索引表。本质上这是互联网公司很多时候都采用的一个解决思路：“拿空间换时间”。也就是应用在创建或更新一条按照订单ID为分库分表键的订单数据时，也会再保存一份按照买家ID为分库分表键的订单索引数据。
基于订单索引表实现买家订单列表查看流程示意：
实现对数据的异步索引创建有多种实现方式，其中一种就是从数据库层采用 binlog 数据复制的方式实现。
采用数据异构索引的方式在实战中基本能解决和避免90%以上的跨join或全表扫描的情况，是在分布式数据场景下，提升数据库服务性能和处理吞吐能力的最有效技术手段。但在某些场景下，比如淘宝商品的搜索和高级搜索，因为商品搜索几乎是访问淘宝用户都会进行的操作，所以调用非常频繁，如果采用SQL语句的方式在商品数据库进行全表扫描的操作，则必然对数据库的整体性能和数据库连接资源带来巨大的压力。面对此类场景，我们不建议采用数据库的方式提供这样的搜索服务，而是采用专业的搜索引擎平台来行使这样的职能，如Lucene、Solr、ElasticSearch 等。
异步化与缓存原则 业务流程异步化 以淘宝的交易订单为例，目前淘宝的订单创建流程需要调用超过200个服务，就算所有服务的调用时间都控制在20ms内返回结果，整个订单创建的时间也会超过4s：
以异步化方式将上述交易创建过程中，对于有严格先后调用关系的服务保持顺序执行，对于能够同步执行的所有服务均采用异步化方式处理。阿里巴巴内部使用消息中间件的方式实现了业务异步化，提高了服务的并发处理，从而大大减少整个业务请求处理所花的时间。
数据库事务异步化 扣款是一个要求事务一致性的典型场景，稍微数据不一致带来的后果都可能是成百上千（可能在某些借款项目中达到上百万的金额）的金额差异。所以在传统的实现方式中，整个扣款的逻辑代码都是在一个大的事务中，通过数据库的事务特性来实现这样一个稍显复杂的业务一致性。
数据库事务的异步化：通俗来说，就是将大事务拆分成小事务，降低数据库的资源被长时间事务锁占用而造成的数据库瓶颈，就能大大提升平台的处理吞吐量和事务操作的响应时间。
在实际的改造方案中，同样基于消息服务提供的异步机制，将整个还款流程进行异步化的处理：
事务与柔性事务 不管是业务流程异步化，还是数据库事务异步化，其实都面临一个如何保证业务事务一致性的问题。面对这个问题目前并没有完美的解决方案，本节会介绍淘宝是如何对订单创建场景实现业务一致的实践，以及近一两年来我们在分布式事务上所作出的创新尝试，供各技术同行在解决此类问题时借鉴和参考。
关于数据库事务，核心是体现数据库ACID（原子性、一致性、隔离性和持久性）属性，即作为一个事务中包含的所有逻辑处理操作在作用到数据库上时，只有这个事务中所有的操作都成功，对数据库的修改才会永久更新到数据库中，任何一个操作失败，对于数据库之前的修改都会失效。在分布式领域，基于CAP理论和在其基础上延伸出的BASE理论，有人提出了“柔性事务”的概念。
（1）CAP理论
一个分布式系统最多只能同时满足一致性（Consistency）、可用性（Availability）和分区容错性（Partition tolerance）这三项中的两项。“一致性”指更新操作成功并返回客户端完成后，所有节点在同一时间的数据完全一致。“可用性”指用户在访问数据时可以得到及时的响应。“分区容错性”指分布式系统在遇到某节点或网络分区故障的时候，仍然能够对外提供满足一致性和可用性的服务。
CAP定理并不意味着所有系统的设计都必须抛弃三个要素之中的一个。CAP三者可以在一定程度上衡量，并不是非黑即白的，例如可用性从0%到100%有不同等级。
（2）BASE理论
BASE理论是对CAP理论的延伸，核心思想是即使无法做到强一致性（Strong Consistency, CAP的一致性就是强一致性），但应用可以采用适合的方式达到最终一致性（EventualConsitency）。BASE是指基本可用（Basically Available）、柔性状态（Soft State）、最终一致性（Eventual Consistency）。
  “基本可用”是指分布式系统在出现故障的时候，允许损失部分可用性，即保证核心可用。电商大促时，为了应对访问量激增，部分用户可能会被引导到降级页面，服务层也可能只提供降级服务。这就是损失部分可用性的体现。
  “柔性状态”是指允许系统存在中间状态，而该中间状态不会影响系统整体可用性。分布式存储中一般一份数据至少会有三个副本，允许不同节点间副本同步的延时就是柔性状态的体现。MySQLReplication的异步复制也是一种柔性状态体现。
  “最终一致性”是指系统中的所有数据副本经过一定时间后，最终能够达到一致的状态。弱一致性和强一致性相反，最终一致性是弱一致性的一种特殊情况。
  对于如何实现高可用，我们认为：</description>
    </item>
    
    <item>
      <title>分布式限流实现原理</title>
      <link>https://kunzhao.org/docs/tutorial/sentinel/distributed-flow/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/tutorial/sentinel/distributed-flow/</guid>
      <description>分布式限流实现原理  本文讲述 Sentinel 的分布式限流原理。
 模块构成 Sentinel 的分布式限流模块包含：
 sentinel-cluster-common-default: 集群通信的一些通用的类、常量等实现 sentinel-cluster-client-default: 默认的使用 Netty 作为底层通讯的集群 Client 端 sentinel-cluster-server-default: 默认的集群 Server 端  common-default 模块并没有实际的逻辑，只是一些共用的类之类的实现，不再赘述。
Client 端 初始化 Bootstrap Client 端初始化 Bootstrap 并尝试连接 Server 端：
// NettyTransportClient.java private Bootstrap initClientBootstrap() { Bootstrap b = new Bootstrap(); eventLoopGroup = new NioEventLoopGroup(); b.group(eventLoopGroup) .channel(NioSocketChannel.class) .option(ChannelOption.TCP_NODELAY, true) .option(ChannelOption.ALLOCATOR, PooledByteBufAllocator.DEFAULT) .option(ChannelOption.CONNECT_TIMEOUT_MILLIS, ClusterClientConfigManager.getConnectTimeout()) .handler(new ChannelInitializer&amp;lt;SocketChannel&amp;gt;() { @Override public void initChannel(SocketChannel ch) throws Exception { clientHandler = new TokenClientHandler(currentState, disconnectCallback); ChannelPipeline pipeline = ch.</description>
    </item>
    
    <item>
      <title>字符串</title>
      <link>https://kunzhao.org/docs/tutorial/algorithm/string/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/tutorial/algorithm/string/</guid>
      <description>字符串 最小覆盖子串 原题
字符串解码 原题
输入：s = &amp;quot;3[a2[c]]&amp;quot; 输出：&amp;quot;accaccacc&amp;quot; 解法：
public class Solution { int ptr; public String decodeString(String s) { LinkedList&amp;lt;String&amp;gt; stk = new LinkedList&amp;lt;String&amp;gt;(); ptr = 0; while (ptr &amp;lt; s.length()) { char cur = s.charAt(ptr); if (Character.isDigit(cur)) { // 获取一个数字并进栈  String digits = getDigits(s); stk.addLast(digits); } else if (Character.isLetter(cur) || cur == &amp;#39;[&amp;#39;) { // 获取一个字母并进栈  stk.addLast(String.valueOf(s.charAt(ptr++))); } else { ++ptr; LinkedList&amp;lt;String&amp;gt; sub = new LinkedList&amp;lt;String&amp;gt;(); while (!</description>
    </item>
    
    <item>
      <title>Best Time to Buy and Sell Stock With Cooldown</title>
      <link>https://kunzhao.org/docs/programmer-interview/algorithm/best-time-to-buy-and-sell-stock-with-cooldown/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/programmer-interview/algorithm/best-time-to-buy-and-sell-stock-with-cooldown/</guid>
      <description>Best Time to Buy and Sell Stock With Cooldown 题目 LeetCode 地址：Best Time to Buy and Sell Stock With Cooldown
有一个数组，第 i 个元素的值代表第 i 天的股票价格，如果你最多只能进行任意次交易（某天买入一支股票，然后过几天卖掉），你卖出一只股票后，接下来的一天不能买，必须要到后天才能买。也就是说有冷静期1天。请问你能收获的最大利润是多少？
答案 // https://leetcode.com/problems/best-time-to-buy-and-sell-stock-with-cooldown/ // 交易任意多次，只不过 buy sell 之后的第二天必须 cooldown 隔天才能再次 buy // // https://leetcode.com/problems/best-time-to-buy-and-sell-stock-with-cooldown/discuss/240277/Java-solution-in-Chinese public class BestTimetoBuyandSellStockwithCooldown { public int maxProfit(int[] prices) { if (prices == null || prices.length &amp;lt;= 1) { return 0; } // 买入只能是从前天买入 buy[i] = sell[i - 2] - prices[i];  // 卖出可以昨天卖出 sell[i] = buy[i - 1] + prices[i];  int[] sell = new int[prices.</description>
    </item>
    
    <item>
      <title>Git checkout</title>
      <link>https://kunzhao.org/docs/tutorial/git/git-checkout/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/tutorial/git/git-checkout/</guid>
      <description>Git checkout git checkout 检出命令，可以用来切换分支、查看某个 commit 的代码等。
detached HEAD 当你执行 git checkout [commitId] 时，你会看到下面的文件警告：
Note: switching to &#39;467dd6520&#39;. You are in &#39;detached HEAD&#39; state. You can look around, make experimental changes and commit them, and you can discard any commits you make in this state without impacting any branches by switching back to a branch. If you want to create a new branch to retain commits you create, you may do so (now or later) by using -c with the switch command.</description>
    </item>
    
    <item>
      <title>HTTPS</title>
      <link>https://kunzhao.org/docs/tutorial/network/https/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/tutorial/network/https/</guid>
      <description>HTTPS 为什么出现 HTTPS 防止 敏感数据 (银行卡号、账号密码等) 被劫持。HTTPS 会对 HTTP 的请求和响应进行加密，因此即使劫持，攻击者看到的也都是一些随机的字符串。
SSL/TLS 双向非对称加密  Client 和 Server 把自己的公钥公开出去，各自保留自己的私钥。
 客户端 (PubA、PriA) 给服务器 (PubB、PriB) 发送消息的过程如下：
// 私钥签名，再用服务器的公钥加密 let sign = PriA(msg) let encryption = PubB(sign) Client --encryption--&amp;gt; Server 服务器接受客户端消息的过程：
// 私钥解密，再用客户端的公钥验证签名 PubA(unEncryption(PriB, encryption), &#39;验证签名&#39;)  签名和验签：私钥签名，公钥验签，目的防篡改。 加密和解密：公钥加密，私钥解密，目的防止第三方拦截偷听。  单向非对称加密  互联网上，只能 Client 验证 Server，因此只有服务器提供一对公钥和私钥即可。
 当然，如果是银行网银，那么也有验证每个客户端的合法性，给用户发的 U 盘，就包含了客户端的公钥和私钥对，用的是双向非对称加密。
SSL/TLS 的原理就是，先单向非对称加密，然后再对称加密：
RSA 应用场景 （1）加密
Bob 想要给 Alice 发送 &amp;ldquo;Hello Alice!&amp;rdquo; 这个信息：
 公钥加密 私钥解密  （2）数字签名</description>
    </item>
    
    <item>
      <title>Java IO</title>
      <link>https://kunzhao.org/docs/tutorial/java/java-io/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/tutorial/java/java-io/</guid>
      <description>Java IO BIO ServerSocket 示例 { ExecutorService executor = Excutors.newFixedThreadPollExecutor(100);//线程池  ServerSocket serverSocket = new ServerSocket(); serverSocket.bind(8088); while(!Thread.currentThread.isInturrupted()){//主线程死循环等待新连接到来  Socket socket = serverSocket.accept(); executor.submit(new ConnectIOnHandler(socket));//为新的连接创建新的线程 } class ConnectIOnHandler extends Thread{ private Socket socket; public ConnectIOnHandler(Socket socket){ this.socket = socket; } public void run(){ while(!Thread.currentThread.isInturrupted()&amp;amp;&amp;amp;!socket.isClosed()){死循环处理读写事件 String someThing = socket.read()....//读取数据  if(someThing!=null){ ......//处理数据  socket.write()....//写数据  } } } } 这个模型最本质的问题在于，严重依赖于线程。但线程是很”贵”的资源，主要表现在：
   线程的创建和销毁成本很高，在Linux这样的操作系统中，线程本质上就是一个进程。创建和销毁都是重量级的系统函数。    线程本身占用较大内存，像Java的线程栈，一般至少分配512K～1M的空间，如果系统中的线程数过千，恐怕整个JVM的内存都会被吃掉一半。    线程的切换成本是很高的。操作系统发生线程切换的时候，需要保留线程的上下文，然后执行系统调用。如果线程数过高，可能执行线程切换的时间甚至会大于线程执行的时间，这时候带来的表现往往是系统load偏高、CPU sy使用率特别高（超过20%以上)，导致系统几乎陷入不可用的状态。    容易造成锯齿状的系统负载。因为系统负载是用活动线程数或CPU核心数，一旦线程数量高但外部网络环境不是很稳定，就很容易造成大量请求的结果同时返回，激活大量阻塞线程从而使系统负载压力过大。    同步调用示例 服务端响应之前，IO 会阻塞在：java.</description>
    </item>
    
    <item>
      <title>JVM</title>
      <link>https://kunzhao.org/docs/tutorial/java/jvm/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/tutorial/java/jvm/</guid>
      <description>JVM 虚拟机内存模型 程序寄存器 pc register (program counter)： 一个包含当前时刻指令的地址的寄存器，程序寄存器区域是唯一一个在 Java 虚拟机规范中没有规定任何 OutOfMemoryError 情况的区域
虚拟机栈 栈会抛出两种异常：StackOverflowError 和 OutOfMemoryError，在 HotSpot 虚拟机栈中，可以使用参数 -Xss1M 来设置栈的大小为 1MB。随着调用函数参数的增加和局部变量的增加，单次函数调用对栈空间的需求也会增加，因此栈的最大递归次数不是一成不变的。函数嵌套调用的次数由栈的大小决定：栈越大，函数嵌套调用次数越多；对一个函数而言，它的参数越多，内部局部变量越多，它的栈帧就越大，其嵌套调用次数就会越少。
 局部变量表是存放方法参数和局部变量的区域。相对于类属性变量的准备阶段和初始化阶段来说，局部变量没有准备阶段，必须显式初始化。如果是非静态方法，则在 index [O] 位置上存储的是方法所属对象的实例引用，随后存储的是参数和局部变量。字节码指令中的 STORE 指令就是将操作栈申计算完成的局部变量写回局部变量表的存储空间内。 操作栈是一个初始状态为空的桶式结构栈。在方法执行过程中，会有各种指令往栈中写人和提取信息。 JVM 的执行引擎是基于栈的执行引擎，其中的栈指的就是操作栈。 每个栈中包含一个在常量池中对当前方法的引用 ， 目的是支持方法调用过程的动态连接。 方法执行时有两种退出情况。第一， 正常退出，即正常执行到任何方法的返回字节码指令 ， 如 RETURN 、 IRETURN 、 ARETURN 等，第二 ， 异常退出。无论何种退出情况，都将返回至方法当前被调用的位置。  本地方法栈 与 stack 一样，同样抛出两种异常：StackOverflowError 和 OutOfMemoryError。在 sun 的 HOT SPOT 虚拟机中，不区分本地方法栈和虚拟机栈。
元数据区 在 JDK7 及之前的版本中，只有 Hotspot 才有 Perm 区，译为永久代 ， 它在启动时固定大小，很难进行调优，并且 FGC 时会移动类元信息。在某些场景下，如果动态加载类过多，容易产生 Perm 区的 OOM 。为了解决该问题 ， 需要设定运行参数 -XX: MaxPermSize= 1280m ，如果部署到新机器上，往往会因为 NM 参数没有修改导致故障再现。</description>
    </item>
    
    <item>
      <title>MySQL 自增键</title>
      <link>https://kunzhao.org/docs/tutorial/database/auto-increment-id/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/tutorial/database/auto-increment-id/</guid>
      <description>MySQL 自增键 特点  自增键默认从 1 开始，即第一条记录 insert 结束之后，它的键是 1 insert ... on duplicate key，可能会导致，系统自动生成的自增键，在更新阶段用不上。  自增 ID 表定义的自增值达到上限后的逻辑是：再申请下一个 id 时，得到的值保持不变。
create table t( id int unsigned auto_increment primary key ) auto_increment=4294967295; insert into t values(null); -- Duplicate entry &amp;#39;4294967295&amp;#39; for key &amp;#39;PRIMARY&amp;#39; insert into t values(null); 第一个 insert 语句插入数据成功后，这个表的 AUTO_INCREMENT 没有改变（还是 4294967295），就导致了第二个 insert 语句又拿到相同的自增 id 值，再试图执行插入语句，报主键冲突错误。
row_id 如果你创建的 InnoDB 表没有指定主键，那么 InnoDB 会给你创建一个不可见的，长度为 6 个字节的 row_id。InnoDB 维护了一个全局的 dict_sys.row_id 值，所有无主键的 InnoDB 表，每插入一行数据，都将当前的 dict_sys.</description>
    </item>
    
    <item>
      <title>Redis 5 设计与源码分析</title>
      <link>https://kunzhao.org/docs/books/redis_5_source_code/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/books/redis_5_source_code/</guid>
      <description>Redis 5 设计与源码分析 Redis 5.0 新特性  新增Streams数据类型，这是 Redis 5.0 最重要的改进之一。可以把Streams当作消息队列。 新的模块API、定时器、集群及字典。 RDB中持久化存储LFU和LRU的信息。 将集群管理功能完全用C语言集成到redis-cli中，Redis 3.x 和 Redis4.x 的集群管理是通过Ruby脚本实现的。 有序集合新增命令ZPOPMIN/ZPOPMAX。 改进HyperLogLog的实现。 新增Client Unblock和Client ID。 新增LOLWUT命令。 Redis主从复制中的从不再称为Slave，改称Replicas。 Redis 5.0引入动态哈希，以平衡CPU的使用率和相应性能，可以通过配置文件进行配置。Redis 5.0默认使用动态哈希。 Redis核心代码进行了部分重构和优化。  简单动态字符串 （1） 长度小于 32 的短字符串
struct __attribute__ ((__packed__))sdshdr5 { unsigned char flags; // 低 3 位存储类型，高 5 位存储长度  char buf[]; // 柔性数组 } 结构如下：
（2） 长度大于 31 的字符串
此处仅展示一个示例：
struct __attribute__ ((__packed__))sdshdr8 { uint8_t len; // 已使用长度  uint8_t alloc; // 已分配的字节总长度  unsigned char flags; // 低 3 位存储类型  char buf[]; // 柔性数组 } SDS 读操作的复杂度多为O(1)，直接读取成员变量；涉及修改的写操作，则可能会触发扩容。</description>
    </item>
    
    <item>
      <title>Redis 复制</title>
      <link>https://kunzhao.org/docs/tutorial/redis/redis-copy/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/tutorial/redis/redis-copy/</guid>
      <description>Redis 复制 在分布式系统中为了解决单点问题，通常会把数据复制多个副本部署到其他机器，满足故障恢复和负载均衡等需求。Redis 也是如此，它为我们提供了复制功能，实现了相同数据的多个Redis副本。复制功能是高可用 Redis 的基础。
建立复制 从节点执行：
slaveof {masterHost} {masterPort}主从节点复制成功建立后，可以使用 info replication 命令查看复制相关状态。
断开复制 从节点执行：
slaveof no one还可以执行 slaveof {newMasterHost} {newMasterPort} 来实现切主操作，不过会先清空本地数据。
只读 默认，从节点处于只读模式。slave-read-only: true
复制原理 Redis在2.8及以上版本使用psync命令完成主从数据同步，同步过程分为：全量复制和部分复制。
psync 原理  主从节点各自复制偏移量。 主节点复制积压缓冲区。 主节点运行 id 。  通过 info replication 查看 master_repl_offset 和 slave_repl_offset 可以查看到主从节点的复制偏移量。
复制积压缓冲区是保存在主节点上的一个固定长度的队列，默认大小为1MB，当主节点有连接的从节点（slave）时被创建，这时主节点（master）响应写命令时，不但会把命令发送给从节点，还会写入复制积压缓冲区。
由于缓冲区本质上是先进先出的定长队列，所以能实现保存最近已复制数据的功能，用于部分复制和复制命令丢失的数据补救。
每个Redis节点启动后都会动态分配一个40位的十六进制字符串作为运行ID。运行ID的主要作用是用来唯一识别Redis节点，比如从节点保存主节点的运行ID识别自己正在复制的是哪个主节点。节点。如果只使用ip+port的方式识别主节点，那么主节点重启变更了整体数据集（如替换RDB/AOF文件），从节点再基于偏移量复制数据将是不安全的，因此当运行ID变化后从节点将做全量复制。可以运行info server命令查看当前节点的运行ID。
需要注意的是Redis关闭再启动后，运行ID会随之改变。
全量复制 一般用于初次复制场景，Redis早期支持的复制功能只有全量复制，它会把主节点全部数据一次性发送给从节点，当数据量较大时，会对主从节点和网络造成很大的开销。
需要注意，对于数据量较大的主节点，比如生成的RDB文件超过6GB以上时要格外小心。传输文件这一步操作非常耗时，速度取决于主从节点之间网络带宽，通过细致分析Full resync和MASTER&amp;lt;-&amp;gt;SLAVE这两行日志的时间差，可以算出RDB文件从创建到传输完毕消耗的总时间。如果总时间超过repl-timeout所配置的值（默认60秒），从节点将放弃接受RDB文件并清理已经下载的临时文件，导致全量复制失败。
针对数据量较大的节点，建议调大repl-timeout参数防止出现全量同步数据超时。例如对于千兆网卡的机器，网卡带宽理论峰值大约每秒传输100MB，在不考虑其他进程消耗带宽的情况下，6GB的RDB文件至少需要60秒传输时间，默认配置下，极易出现主从数据同步超时。
关于无盘复制：为了降低主节点磁盘开销，Redis支持无盘复制，生成的RDB文件不保存到硬盘而是直接通过网络发送给从节点，通过repl-diskless-sync参数控制，默认关闭。无盘复制适用于主节点所在机器磁盘性能较差但网络带宽较充裕的场景。生成快照是一个遍历的过程，主节点会一边遍历内存，一边将序列化的内容发送到从节点，从节点还是跟之前一样，先将接收到的内容存储到磁盘文件中，再进行一次性加载。
对于从节点开始接收RDB快照到接收完成期间，主节点仍然响应读写命令，因此主节点会把这期间写命令数据保存在复制客户端缓冲区内，当从节点加载完RDB文件后，主节点再把缓冲区内的数据发送给从节点，保证主从之间数据一致性。如果主节点创建和传输RDB的时间过长，对于高流量写入场景非常容易造成主节点复制客户端缓冲区溢出。默认配置为client-output-buffer-limit slave 256MB 64MB 60，如果60秒内缓冲区消耗持续大于64MB或者直接超过256MB时，主节点将直接关闭复制客户端连接，造成全量同步失败。
部分复制 用于处理在主从复制中因网络闪断等原因造成的数据丢失场景，当从节点再次连上主节点后，如果条件允许，主节点会补发丢失数据给从节点。因为补发的数据远远小于全量数据，可以有效避免全量复制的过高开销。
如果主节点的复制积压缓冲区内存在这部分数据则直接发送给从节点，这样就可以保持主从节点复制的一致性。补发的这部分数据一般远远小于全量数据，所以开销很小。
 主节点何时认为从节点断掉?
 主从节点之间网络出现中断时，如果超过 repl-timeout 时间，主节点会认为从节点故障，并中断复制连接。</description>
    </item>
    
    <item>
      <title>RocketMQ 消息索引流程</title>
      <link>https://kunzhao.org/docs/rocketmq/rocketmq-message-indexing-flow/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/rocketmq/rocketmq-message-indexing-flow/</guid>
      <description>RocketMQ 消息索引流程  基于 RocketMQ 4.2.0 版本进行的源码分析。
 讲述 RocketMQ 消息索引服务
一、消息查询方式 对于 Producer 发送到 Broker 服务器的消息，RocketMQ 支持多种方式来方便地查询消息:
(1) 根据键查询消息 如下所示，在构建消息的时候，指定了这条消息的键为 “OrderID001”:
Message msg = new Message(&amp;#34;TopicTest&amp;#34;, &amp;#34;TagA&amp;#34;, &amp;#34;OrderID001&amp;#34;, // Keys  &amp;#34;Hello world&amp;#34;.getBytes(RemotingHelper.DEFAULT_CHARSET)); 那么，当这条消息发送成功后，我们可以使用 queryMsgByKey 命令查询到这条消息的详细信息:
MQAdminStartup.main(new String[] { &amp;#34;queryMsgByKey&amp;#34;, &amp;#34;-n&amp;#34;, &amp;#34;localhost:9876&amp;#34;, &amp;#34;-t&amp;#34;, &amp;#34;TopicTest&amp;#34;, &amp;#34;-k&amp;#34;, &amp;#34;OrderID001&amp;#34; }); (2) 根据ID(偏移量)查询消息 消息在发送成功之后，其返回的 SendResult 类中包含了这条消息的唯一偏移量 ID (注意此处指的是 offsetMsgId):
用户可以使用 queryMsgById 命令查询这条消息的详细信息:
MQAdminStartup.main(new String[] { &amp;#34;queryMsgById&amp;#34;, &amp;#34;-n&amp;#34;, &amp;#34;localhost:9876&amp;#34;, &amp;#34;-i&amp;#34;, &amp;#34;0A6C73D900002A9F0000000000004010&amp;#34; }); (3) 根据唯一键查询消息 消息在发送成功之后，其返回的 SendResult 类中包含了这条消息的唯一 ID:</description>
    </item>
    
    <item>
      <title>top</title>
      <link>https://kunzhao.org/docs/tutorial/unix-command/top/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/tutorial/unix-command/top/</guid>
      <description>top 本文介绍 top 命令的常见例子！top 可以显示系统运行的进程和资源等情况的有用信息。
基础展示 top 上述命令将会显示：
 红色区域：系统的统计信息 蓝色区域：系统所有的进程列表信息  默认情况下，top 命令每隔 3 秒刷新一次。
 红色区域
 第一行展示的是：时间、电脑运行多久了、多少人登录着电脑、过去 1、5、15 分钟电脑的平均负载。 第二行展示的是，任务的总数量，以及各个状态的任务数量。 第三行展示的是 CPU 的一些信息。  CPU 信息的每一列的含义：
 us：用户态 CPU 占用处理器的总时间 sy：内核态 CPU 占用处理器的总时间 ni：使用手动设置的 nice 值执行进程所花费的时间。 id：CPU空闲时间的数量。 wa：CPU等待I/O完成所花费的时间。 hi：维护硬件中断所花费的时间。 si：维护软件中断所花费的时间。 st：由于运行虚拟机而损失的时间（“窃取时间”）。  第四行显示物理内存的总量（以kibibytes为单位），以及空闲、使用、缓冲或缓存的内存量。 第五行显示交换内存的总量（也以kibibytes为单位），以及空闲、使用和可用的内存量。后者包括预期可以从缓存中恢复的内存。
 蓝色区域的，进程列表中的各个列的信息如下：
 PID：进程ID。 USER：进程的所有者。 PR：流程优先级。 NI：这个过程很有价值。 VIRT：进程使用的虚拟内存量。 RES：进程使用的常驻内存量。 SHR：进程使用的共享内存量。 S： 进程的状态。（有关此字段可以采用的值，请参见下面的列表）。 %CPU：自上次更新以来进程使用的CPU时间的份额。 %MEM：使用的物理内存份额。 TIME+：任务使用的总CPU时间（以百分之一秒为单位）。 COMMAND：命令名或命令行（名称+选项）。  内存值以kibibytes为单位显示。进程的状态可以是以下之一：
 D： 不间断睡眠 R： 跑步 S： 睡觉 T： 跟踪（停止） Z： 僵尸  按 Q 退出 top 命令。</description>
    </item>
    
    <item>
      <title>Transactional</title>
      <link>https://kunzhao.org/docs/tutorial/spring/transactional/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/tutorial/spring/transactional/</guid>
      <description>@Transactional Spring @Transactional @Transactional 注解中中几个比较重要的属性：
public @interface Transactional { // REQUIRED: 0,  // SUPPORTS: 1,  // MANDATORY: 2,  // REQUIRES_NEW: 3,  // NOT_SUPPORTED: 4,  // NEVER: 5,  // NESTED: 6  Propagation propagation() default Propagation.REQUIRED; // DEFAULT: -1  // READ_UNCOMMITTED: 1,  // READ_COMMITTED: 2,  // REPEATABLE_READ: 4,  // SERIALIZABLE: 8  Isolation isolation() default Isolation.DEFAULT; @AliasFor(&amp;#34;value&amp;#34;) String transactionManager() default &amp;#34;&amp;#34;; // 从这一点设置的时间点开始（时间点a）到这个事务结束的过程中，其他事务所提交的数据，该事务将看不见！（查询中不会出现别人在时间点a之后提交的数据）  // 注意是一次执行多次查询来统计某些信息，这时为了保证数据整体的一致性，要用只读事务  boolean readOnly() default false; // 超时，事务是否发生回滚  int timeout default -1; } 事务传播属性 Propagation  REQUIRED: 有事务，加入事务，放到一个事务中执行，有异常一起回滚；没有就新创建一个事务。 REQUIRES_NEW: 无论有没有事务，都会新启一个事务，如果原来有，老的挂起，有异常互不干扰。 SUPPORTS: 有事务，加入事务，放到一个事务中执行，有异常一起回滚；否则不创建事务。 MANDATORY: 必须在一个已有事务中执行，否则抛出异常。 NEVER: 必须在一个没有事务中执行，否则抛出异常。 NOT_SUPPORTED: 不开启事务，并挂起任何存在的事务。 NESTED: 如果有事务运行，就作为这个事务的嵌套事务运行；如果没有活动事务，则按REQUIRED属性执行。  @Transactional 使用注意事项  @Transactional 只能应用到 public 方法才有效 @Transactional 不建议用在处理时间过长的事务 一个有 @Transactional 的方法被没有 @Transactional 方法调用时，会导致 Transactional 作用失效。 默认配置下，Spring 只有在抛出的异常为运行时 unchecked 异常时才回滚该事务，也就是抛出的异常为 RuntimeException 的子类(Errors也会导致事务回滚)，而抛出 checked 异常则不会导致事务回滚 。可通过 @Transactional rollbackFor 进行配置。  手动设置事务回滚 // 事务管理器 @Autowired private DataSourceTransactionManager transactionManager; @Transactional public void save(User user) { // 创建一个事务  DefaultTransactionDefinition def = new DefaultTransactionDefinition(); // 显式设置事务名称是只能通过编程完成的操作  def.</description>
    </item>
    
    <item>
      <title>WebMVC 限流实现原理</title>
      <link>https://kunzhao.org/docs/tutorial/sentinel/webmvc-flow/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/tutorial/sentinel/webmvc-flow/</guid>
      <description>WebMVC 限流实现原理 简介 Sentinel 提供了基于 SpringMVC 的限流方式：
@Configuration public class InterceptorConfig implements WebMvcConfigurer { @Override public void addInterceptors(InterceptorRegistry registry) { SentinelWebMvcConfig config = new SentinelWebMvcConfig(); // Enable the HTTP method prefix.  config.setHttpMethodSpecify(true); // Add to the interceptor list.  registry.addInterceptor(new SentinelWebInterceptor(config)).addPathPatterns(&amp;#34;/**&amp;#34;); } } </description>
    </item>
    
    <item>
      <title>体系的深度治理</title>
      <link>https://kunzhao.org/docs/tutorial/distributed/deep-govern/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/tutorial/distributed/deep-govern/</guid>
      <description>体系的深度治理 服务分层与业务中台 DevOps DevOps 工具生态 脱颖而出的工具：
 持续集成工具和工具流引擎：Jenkins 环境隔离&amp;amp;构建：Docker Iaas、Paas、Cloud 基础设施即代码 版本管理工具：Git 协同开发工具：Jira  </description>
    </item>
    
    <item>
      <title>动态规划</title>
      <link>https://kunzhao.org/docs/tutorial/algorithm/dp/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/tutorial/algorithm/dp/</guid>
      <description>动态规划 打家劫舍② 原题
所有的房屋都 围成一圈 ，这意味着第一个房屋和最后一个房屋是紧挨着的。同时，相邻的房屋装有相互连通的防盗系统，如果两间相邻的房屋在同一晚上被小偷闯入，系统会自动报警 。给定一个代表每个房屋存放金额的非负整数数组，计算你 在不触动警报装置的情况下 ，能够偷窃到的最高金额。
class Solution { public int rob(int[] nums) { if(nums.length == 0) return 0; if(nums.length == 1) return nums[0]; return Math.max(myRob(Arrays.copyOfRange(nums, 0, nums.length - 1)), myRob(Arrays.copyOfRange(nums, 1, nums.length))); } private int myRob(int[] nums) { int pre = 0, cur = 0, tmp; for(int num : nums) { tmp = cur; cur = Math.max(pre + num, cur); pre = tmp; } return cur; } } </description>
    </item>
    
    <item>
      <title>在 IE 11 运行</title>
      <link>https://kunzhao.org/docs/tutorial/vue3/run-vue-on-ie/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/tutorial/vue3/run-vue-on-ie/</guid>
      <description>在 IE 11 运行 npm install babel-loader @babel/polyfill --save 然后在 main.js 的最顶部加入下面这句话：
import &amp;#39;@babel/polyfill&amp;#39; </description>
    </item>
    
    <item>
      <title>Best Time to Buy and Sell Stock with Transaction Fee</title>
      <link>https://kunzhao.org/docs/programmer-interview/algorithm/best-time-to-buy-and-sell-stock-with-transaction-fee/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/programmer-interview/algorithm/best-time-to-buy-and-sell-stock-with-transaction-fee/</guid>
      <description>Best Time to Buy and Sell Stock with Transaction Fee  每次交易都需要交易费用
 // 可以交易任意多次 // 只不过每一次都有小费 // // https://leetcode.com/problems/best-time-to-buy-and-sell-stock-with-transaction-fee/discuss/160964/java-Using-State-Machine-like-stock-III public class BestTimetoBuyandSellStockwithTransactionFee { public int maxProfit(int[] prices, int fee) { if (prices == null || prices.length &amp;lt;= 1) { return 0; } int s0 = 0; int s1 = s0 - prices[0]; // 买入  for (int i = 1; i &amp;lt; prices.length; i++) { // 这两种状态都能转移到 s0 状态:  //  // s0 -&amp;gt; s0  // s1 卖出 -&amp;gt; s0  s0 = Math.</description>
    </item>
    
    <item>
      <title>cat</title>
      <link>https://kunzhao.org/docs/tutorial/unix-command/cat/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/tutorial/unix-command/cat/</guid>
      <description>cat cat 命令的常见用法！
查看文件内容 要使用 cat 显示文件的内容，只需传递要查看的一个或多个文件的名称。文件内容将打印到标准输出并在终端中可见。下面的示例假设文件foo.txt 文件只有一行“Hello World”。
cat foo.txt Hello world 如果文件的内容很长，则全部内容将写入终端。在这种情况下，很难找到文件的某些部分。在寻找特定内容时，grep 可能是一个更好的选择。
将一个文件的内容写入到另外一个文件 使用cat工具结合重定向，可以将文件内容写入新的文件。下面的示例假设文件foo.txt文件只有一行“Hello World”并将其写入bar.txt文件.
cat foo.txt &amp;gt; bar.txt cat bar.txt Hello world 如果 bar.txt 文件不存在，那么 cat 工具会自动创建 bar.txt 文件。
将一个文件的内容追加到另外一个文件 cat wine.txt &amp;gt;&amp;gt; beer.txt 多个文件合并为一个 cat *.txt &amp;gt; combined.txt 上述命令行，将当前目录以 .txt 结尾的文件，合并到 combined.txt 文件中。
cat 输出显示行号 -n 参数可以显示文件的行号：
cat -n /usr/share/dict/words 1 A 2 a 3 aa 4 aal 5 aalii 输出的每行行尾显示 $ 符号 cat -e test hello everyone, how do you do?</description>
    </item>
    
    <item>
      <title>CDN</title>
      <link>https://kunzhao.org/docs/tutorial/network/cdn/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/tutorial/network/cdn/</guid>
      <description>CDN  核心理念：就近访问数据
 CDN 分发系统架构 回溯 由于边缘节点数目比较多，但是每个集群规模比较小，不可能缓存下来所有东西，因而可能无法命中，这样就会在边缘节点之上。有区域节点，规模就要更大，缓存的数据会更多，命中的概率也就更大。在区域节点之上是中心节点，规模更大，缓存数据更多。如果还不命中，就只好回源网站访问了。
CDN 可缓存的内容  静态资源：图片、CSS、JS、HTML 文件、流媒体等 动态数据：缓存动态数据  如何找到合适的边缘节点  基于 DNS 的全局负载均衡。
 根据用户 IP、所处的运营商、请求 URL 中携带的参数、服务器的负载情况等综合分析后，全局负载均衡服务器返回一台缓存服务器的 IP 地址。
动态资源如何缓存  边缘计算：动态数据生成的计算、逻辑、存储等，也放到边缘节点，然后定时地从数据源同步存储的数据等内容 路径优化：源站到边缘节点的路径经过优化 (调整 TCP 参数、多路复用、数据压缩)，采用更为可靠的路径来传输  CDN 挂掉怎么办 为了防止 CDN 挂掉，引入的时候要加入一个判断：
&amp;lt;script src=&amp;#34;http://cdn.static.runoob.com/libs/jquery/1.10.2/jquery.min.js&amp;#34;&amp;gt;&amp;lt;/script&amp;gt; &amp;lt;script&amp;gt;window.jQuery || document.write(&amp;#39;&amp;lt;script src=&amp;#34;js/vendor/jquery-1.10.2.min.js&amp;#34;&amp;gt;&amp;lt;\/script&amp;gt;&amp;#39;)&amp;lt;/script&amp;gt; 这段代码第一行很简单就是你正常引入 cdn 的地址。下面一行的话就是首先判断 Windows.jQuery 是否存在；也就是说判断一下这个CDN是不是挂掉了，如果没有挂掉，那么就直接使用，如果挂掉了，那么就要在后面引入自己的本地资源库。这样就可以保证在可以使用 cdn 的时候使用 cdn 不可以使用的时候就加载本地的。</description>
    </item>
    
    <item>
      <title>Git 保存当前进度</title>
      <link>https://kunzhao.org/docs/tutorial/git/git-stash/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/tutorial/git/git-stash/</guid>
      <description>Git 保存当前进度 git stash 命令可以帮助我们保存和恢复日常的工作进度。
应用场景 你正在 dev 分支上开发项目的某个新功能，开发到一半的时候，master 分支的代码（线上正在运行的代码）出现了一个 bug，需要紧急修复。你现在需要从 dev 分支切换到 master 分支修 BUG，而你现在在 dev 分支正在开发的代码也不可能开发到一半就要 push 上去，此时就可以先在 dev 分支把代码给 stash 起来，也就是暂存起来，然后再切换到 master 分支。等 master 分支修复好了后，再切回 dev 分支，执行 stash pop 把这部分代码给恢复出来即可。
下面示例几个基础用法：
保存当前工作进度 git stash 显示进度列表 git stash list stash 就是一个栈数据结构管理的，你可以保存多次工作进度，并且恢复的时候也可以选择恢复哪个。
恢复进度 # 恢复最新保存的工作进度，并将工作进度从 stash 列表中清除 git stash pop # 恢复某个指定的 stash (git stash list 可以看到) git stash pop [&amp;lt;stash&amp;gt;] 命令 git stash apply [&amp;lt;stash&amp;gt;] 同 git stash pop，只是不会从 stash 列表中删除恢复的进度。</description>
    </item>
    
    <item>
      <title>Java 基础</title>
      <link>https://kunzhao.org/docs/tutorial/java/basic/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/tutorial/java/basic/</guid>
      <description>Java 基础 8 种基础数据类型 缓存范围的包装类,在 VM options 加入参数-XX:AutoBoxCacheMax=7777,即可设置最大缓存值为 7777。
char 能存储中文字符吗 在 Java 中，char 类型占 2 个字节，而且 Java 默认采用 Unicode 编码，一个 Unicode 码是 16 位，所以一个 Unicode 码占两个字节，Java 中无论汉字还是英文字母都是用 Unicode 编码来表示的。所以，在Java中，char 类型变量可以存储一个中文汉字。
浮点数 单精度浮点数格式：
字符集 GB2312 收录 6763 个常用汉字；GBK 的 K 是扩展的意思，支持繁体，兼容 GB2312；GB18030 是国家标准，是 GBK 的超集并与之兼容；1994 年公布的 Unicode，编码格式有：UTF-8、UTF-16、UTF-32，UTF 可以理解为对 Unicode 的压缩方式。
访问权限 内部类和静态内部类 内部类有对外层类完全的访问权限。静态内部类没有一个指向嵌套类的引用，所以静态内部类不能够调用外层类的非静态方法，或者访问非静态的字段。
泛型 为什么类型擦除 为了兼容 JDK 5 之前（有泛型功能之前）的项目，否则有大量代码修改的工作。
//编译器的代码 Node node = new Node&amp;lt;String&amp;gt;(); //编译后的代码 Node node = new Node(); 反射 Class.</description>
    </item>
    
    <item>
      <title>JavaScript String 转为 Boolean</title>
      <link>https://kunzhao.org/docs/tutorial/vue3/string-to-boolean/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/tutorial/vue3/string-to-boolean/</guid>
      <description>JavaScript String 转为 Boolean 正确的方法：
let isTrue = (myValue === &amp;#39;true&amp;#39;) 注意如下写法的结果，两个结果都是 true：
let myBool = Boolean(&amp;#39;false&amp;#39;) // true let myBool = !!&amp;#34;false&amp;#34;; // true </description>
    </item>
    
    <item>
      <title>MySQL 高可用</title>
      <link>https://kunzhao.org/docs/tutorial/database/mysql-high-availablity/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/tutorial/database/mysql-high-availablity/</guid>
      <description>MySQL 高可用 主备 M/S 结构 update 语句在节点 A 执行，然后同步到节点 B 的完整流程图:
备库 B 跟主库 A 之间维持了一个长连接。主库 A 内部有一个线程，专门用于服务备库 B 的这个长连接。
binlog 格式  statement：记录 SQL 语句，容易导致主备不一致 row：记录了真实删除行的主键 id，缺点占用空间 mixed: MySQL 自己判断是否会引起主备不一致  如下是可能引起主备不一致的语句示例：
mysql&amp;gt; delete from t where a&amp;gt;=4 and t_modified&amp;lt;=&amp;#39;2018-11-10&amp;#39; limit 1; mysql&amp;gt; insert into t values(10,10, now()); 主备双 M 结构 生产上多用的是互为主备的结构：这样在切换的时候就不用再修改主备关系。
双 M 结构有一个问题需要解决。业务逻辑在节点 A 上更新了一条语句，然后再把生成的 binlog 发给节点 B，节点 B 执行完这条更新语句后也会生成 binlog。如果节点 A 同时是节点 B 的备库，相当于又把节点 B 新生成的 binlog 拿过来执行了一次，然后节点 A 和 B 间，会不断地循环执行这个更新语句，也就是循环复制了。</description>
    </item>
    
    <item>
      <title>Redis 哨兵</title>
      <link>https://kunzhao.org/docs/tutorial/redis/sentinel/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/tutorial/redis/sentinel/</guid>
      <description>Redis 哨兵 Redis的主从复制模式下，一旦主节点由于故障不能提供服务，需要人工将从节点晋升为主节点，同时还要通知应用方更新主节点地址，对于很多应用场景这种故障处理的方式是无法接受的。可喜的是Redis从2.8开始正式提供了Redis Sentinel（哨兵）架构来解决这个问题。
Redis Sentinel 高可用方案 当主节点出现故障时，Redis Sentinel 能自动完成故障发现和故障转移，并通知应用方，从而实现真正的高可用。
Redis Sentinel是一个分布式架构，其中包含若干个Sentinel节点和Redis数据节点，每个Sentinel节点会对数据节点和其余Sentinel节点进行监控，当它发现节点不可达时，会对节点做下线标识。如果被标识的是主节点，它还会和其他Sentinel节点进行“协商”，当大多数Sentinel节点都认为主节点不可达时，它们会选举出一个Sentinel节点来完成自动故障转移的工作，同时会将这个变化实时通知给Redis应用方。整个过程完全是自动的，不需要人工来介入，所以这套方案很有效地解决了Redis的高可用问题。
Sentinel节点本身就是独立的Redis节点，只不过它们有一些特殊，它们不存储数据，只支持部分命令。
实现原理 定时器  每隔10秒，每个Sentinel节点会向主节点和从节点发送info命令获取最新的拓扑结构，   每隔2秒，每个Sentinel节点会向Redis数据节点的__sentinel__：hello频道上发送该Sentinel节点对于主节点的判断以及当前Sentinel节点的信息，同时每个Sentinel节点也会订阅该频道，来了解其他Sentinel节点以及它们对主节点的判断。   每隔1秒，每个Sentinel节点会向主节点、从节点、其余Sentinel节点发送一条ping命令做一次心跳检测，来确认这些节点当前是否可达。  主观下线和客观下线 第三个定时任务，每个Sentinel节点会每隔1秒对主节点、从节点、其他Sentinel节点发送ping命令做心跳检测，当这些节点超过down-after-milliseconds没有进行有效回复，Sentinel节点就会对该节点做失败判定，这个行为叫做主观下线。
当Sentinel主观下线的节点是主节点时，该Sentinel节点会通过sentinelis-master-down-by-addr命令向其他Sentinel节点询问对主节点的判断，当超过&amp;lt;quorum&amp;gt;个数，Sentinel节点认为主节点确实有问题，这时该Sentinel节点会做出客观下线的决定，这样客观下线的含义是比较明显了，也就是大部分Sentinel节点都对主节点的下线做了同意的判定，那么这个判定就是客观的。
领导者 Sentinel 节点选举  Redis 使用了 Raft 算法实现领导者选举。
 故障转移 在从节点列表中选出一个节点作为新的主节点，选择方法如下：
 过滤：“不健康”（主观下线、断线）、5秒内没有回复过Sentinel节点ping响应、与主节点失联超过down-after-milliseconds*10秒。 选择slave-priority（从节点优先级）最高的从节点列表，如果存在则返回，不存在则继续。 选择复制偏移量最大的从节点（复制的最完整），如果存在则返回，不存在则继续。 选择runid最小的从节点。  Sentinel领导者节点会对第一步选出来的从节点执行slaveof no one命令让其成为主节点。
Sentinel领导者节点会向剩余的从节点发送命令，让它们成为新主节点的从节点，复制规则和parallel-syncs参数有关。
Sentinel节点集合会将原来的主节点更新为从节点，并保持着对其关注，当其恢复后命令它去复制新的主节点。</description>
    </item>
    
    <item>
      <title>RocketMQ 定时消息和重试消息</title>
      <link>https://kunzhao.org/docs/rocketmq/rocketmq-timing-message-and-retry-message/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/rocketmq/rocketmq-timing-message-and-retry-message/</guid>
      <description>RocketMQ 定时消息和重试消息  基于 RocketMQ 4.2.0 版本进行的源码分析。
 讲述 RocketMQ 定时消息和重试消息
一、定时消息概述 RocketMQ 支持 Producer 端发送定时消息，即该消息被发送之后，到一段时间之后才能被 Consumer 消费者端消费。但是当前开源版本的 RocketMQ 所支持的定时时间是有限的、不同级别的精度的时间，并不是任意无限制的定时时间。因此在每条消息上设置定时时间的 API 叫做 setDelayTimeLevel，而非 setDelayTime 这样的命名:
Message msg = new Message(&amp;#34;TopicTest&amp;#34; /* Topic */, &amp;#34;TagA&amp;#34; /* Tag */, (&amp;#34;Hello RocketMQ &amp;#34; + i).getBytes(RemotingHelper.DEFAULT_CHARSET) /* Message body */); msg.setDelayTimeLevel(i + 1); 默认 Broker 服务器端有 18 个定时级别:
public class MessageStoreConfig { private String messageDelayLevel = &amp;#34;1s 5s 10s 30s 1m 2m 3m 4m 5m 6m 7m 8m 9m 10m 20m 30m 1h 2h&amp;#34;; } 这 18 个定时级别在服务器端启动的时候，会被解析并放置到表 delayLevelTable 中。解析的过程就是上述字符串按照空格拆分开，然后根据时间单位的不同再进一步进行计算，得到最终的毫秒时间。级别就是根据这些毫秒时间的顺序而确定的，例如上述 1s 延迟就是级别 1， 5s 延迟就是级别 2，以此类推:</description>
    </item>
    
    <item>
      <title>Spring 插件扩展</title>
      <link>https://kunzhao.org/docs/tutorial/spring/spring-plugin/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/tutorial/spring/spring-plugin/</guid>
      <description>Spring 插件扩展 本文汇总一些常见的扩展 Spring 的库的场景和扩展方法。
自定义加载 Properties 文件 Apollo 是携程框架部门研发的分布式配置中心，它的 Java 客户端可以在 Spring 启动的时候将这些配置加载到本地，与 Spring 无缝整合，它的 Java 客户端使用文档请参考 Java 客户端使用指南。无论是支持注解方式 @Value(&amp;quot;${someKeyFromApollo:someDefaultValue}&amp;quot;) 引用，还是在文件中引用 Apollo 服务器上的配置 spring.datasource.url: ${someKeyFromApollo:someDefaultValue} 都是没有问题的。
它的实现原理如下：
public class ApolloApplicationContextInitializer implements ApplicationContextInitializer&amp;lt;ConfigurableApplicationContext&amp;gt; , EnvironmentPostProcessor, Ordered { @Override public void initialize(ConfigurableApplicationContext context) { ConfigurableEnvironment environment = context.getEnvironment(); if (!environment.getProperty(PropertySourcesConstants.APOLLO_BOOTSTRAP_ENABLED, Boolean.class, false)) { logger.debug(&amp;#34;Apollo bootstrap config is not enabled for context {}, see property: ${{}}&amp;#34;, context, PropertySourcesConstants.APOLLO_BOOTSTRAP_ENABLED); return; } logger.debug(&amp;#34;Apollo bootstrap config is enabled for context {}&amp;#34;, context); initialize(environment); } /** * Initialize Apollo Configurations Just after environment is ready.</description>
    </item>
    
    <item>
      <title>分布式事务解决方案汇总</title>
      <link>https://kunzhao.org/docs/tutorial/distributed/transaction/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/tutorial/distributed/transaction/</guid>
      <description>分布式事务解决方案汇总  如何保证转账这个操作在两个系统中同时成功呢？
 2PC 每个参与者要实现三个接口：Prepare、Commit、Rollback 三个接口，这就是 XA 协议。
XA 则规范了 TM 与 RM 之间的通信接口，在 TM 与多个 RM 之间形成一个双向通信桥梁，从而在多个数据库资源下保证 ACID 四个特性。
主要的缺点就是：
 性能问题 事务执行到中间，事务协调者宕机，整个事务处于悬而不决的状态。 一个参与者超时了，那么其它参与者应该提交还是回滚呢？ 2PC 主要用在两个数据库之间，而非两个系统之间。  3PC 3PC 把 2PC 的准备阶段分为了准备阶段和预处理阶段，在第一阶段只是询问各个资源节点是否可以执行事务，而在第二阶段，所有的节点反馈可以执行事务，才开始执行事务操作，最后在第三阶段执行提交或回滚操作。并且在事务管理器和资源管理器中都引入了超时机制，如果在第三阶段，资源节点一直无法收到来自资源管理器的提交或回滚请求，它就会在超时之后，继续提交事务。
所以 3PC 可以通过超时机制，避免管理器挂掉所造成的长时间阻塞问题，但其实这样还是无法解决在最后提交全局事务时，由于网络故障无法通知到一些节点的问题，特别是回滚通知，这样会导致事务等待超时从而默认提交。
消息中间件-最终一致性 消息中间件本身如 Kafka 不提供事务消息功能，那么解决步骤如下：
 系统 A 增加一张消息表，消息写入到消息表中和 DB1 的扣钱操作放到一个数据库的事务里，保证原子性。 系统 A 后台程序源源不断地将消息表中的消息传送给消息中间件，失败了也尝试重传。 系统 B 通过消息中间件的 ACK 机制，明确自己是否消费成功。 系统 B 增加判重表，记录处理成功的消息 ID 和消息中间件对应的 offset，实现业务幂等性，应对重复消费问题；如果业务本身有业务数据，可以判断是否重复，那么就无需这个判重表。  消息中间件如 RocketMQ 本身提供事务消息：
RocketMQ 会定期 (默认 1min) 扫描所有的预发送但是还没有确认的消息，回调给发送方，询问这条消息是要发送出去，还是取消。发送方根据自己的业务数，知道这条消息是应该发送出去 (DB 更新成功)，还是应该取消 (DB 更新失败)。</description>
    </item>
    
    <item>
      <title>深度剖析 Apache Dubbo 核心技术</title>
      <link>https://kunzhao.org/docs/books/in-depth_analysis_of_the_core_technology_of_apache_dubbo/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/books/in-depth_analysis_of_the_core_technology_of_apache_dubbo/</guid>
      <description>深度剖析 Apache Dubbo 核心技术 SPI 扩展 Dubbo 支持扩展的核心接口上，都会通过类似 @SPI(&amp;quot;dubbo&amp;quot;) 这样的注解，来标识当前接口的默认实现。如果你想替换掉这个默认实现，那么需要两个步骤。第一，实现 Protocol 接口，然后在 META-INF/dubbo 目录下创建一个名字为 org.apache.dubbo.rpc.Protocol 的文本文件。这个 META-INF 目录如果使用的是 IDEA 开发，那么其应该放到 resources 目录下的顶层，这样打 jar 包的时候，其也会被复制到 jar 包的第一级目录。内容如下：
myProtocol = com.zk.MyProtocol 第二，需要在 XML 配置文件中，声明使用这个扩展实现：
&amp;lt;dubbo:protocol name=&amp;#34;myProtocol&amp;#34;&amp;gt; 其实 JDK 本身也提供了 SPI 扩展，Dubbo 之所以没有使用默认提供的实现，是因为：
 JDK 标准的 SPI 一次性实例化扩展点的所有实现，如果有些没有使用到，那么会浪费资源。 扩展点加载失败的异常提示不是很好。 增强了 Ioc 和 AOP 的支持。  Java SPI 缺点 Java SPI的使用很简单。也做到了基本的加载扩展点的功能。但Java SPI有以下的不足:
 需要遍历所有的实现，并实例化，然后我们在循环中才能找到我们需要的实现。 配置文件中只是简单的列出了所有的扩展实现，而没有给他们命名。导致在程序中很难去准确的引用它们。 扩展如果依赖其他的扩展，做不到自动注入和装配 不提供类似于 Spring 的 IOC 和 AOP 功能 扩展很难和其他的框架集成，比如扩展里面依赖了一个 Spring bean，原生的 Java SPI 不支持  性能 Dubbo 会给每个服务提供者的实现类生产一个 Wrapper 类，这个 Wrapper 类里面最终调用服务提供者的接口实现类，Wrapper 类的存在是为了减少反射的调用。当服务提供方收到消费方发来的请求后，需要根据消费者传递过来的方法名和参数反射调用服务提供者的实现类，而反射本身是有性能开销的，Dubbo 把每个服务提供者的实现类通过 JavaAssist 包装为一个 Wrapper 类以减少反射调用开销。</description>
    </item>
    
    <item>
      <title>Binary Search 二分搜索</title>
      <link>https://kunzhao.org/docs/programmer-interview/algorithm/binary-search/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/programmer-interview/algorithm/binary-search/</guid>
      <description>Binary Search // https://leetcode.com/problems/binary-search/ // public class BinarySearch { public int search(int[] nums, int target) { if (nums == null || nums.length == 0) { return -1; } int lo = 0; int hi = nums.length - 1; while (lo &amp;lt;= hi) { int m = lo + ((hi - lo) &amp;gt;&amp;gt; 1); if (nums[m] == target) { return m; } else if (nums[m] &amp;gt; target) { hi = m - 1; } else { lo = m + 1; } } return -1; } } </description>
    </item>
    
    <item>
      <title>DNS</title>
      <link>https://kunzhao.org/docs/tutorial/network/dns/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/tutorial/network/dns/</guid>
      <description>DNS DNS 使用的传输层协议 主要使用 UDP 协议，端口 53, 也有一些采用 TCP 来实现。
DNS 层次结构  根 DNS 服务器 ：返回顶级域 DNS 服务器的 IP 地址 顶级域 DNS 服务器：返回权威 DNS 服务器的 IP 地址 权威 DNS 服务器 ：返回相应主机的 IP 地址  DNS 数据库的记录类型    类型 描述     A、AAAA IP 地址   MX SMTP mail exchangers   NS name servers   CNAME domain name aliases    DNS 的解析流程 DNS 做负载均衡 DNS 除了可以通过名称映射为 IP 地址，它还可以做另外一件事，就是负载均衡。</description>
    </item>
    
    <item>
      <title>Git 多次提交合并成一次提交</title>
      <link>https://kunzhao.org/docs/tutorial/git/merge-multiple-commit/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/tutorial/git/merge-multiple-commit/</guid>
      <description>Git 多次提交合并成一次提交 你在 dev 分支上开发某个功能，在本地执行了三次 commit，注意这三次 commit 都没有 push 到远程分支，都只是在本地存在。现在你想要在 push 之前，将你本地的这多个 commit 合并成一个 commit，请问应该怎么做？
答案是：git rebase -i HEAD~N，N 代表你想把最近的几条 commitId 记录合并。具体操作步骤如下：
查看提交记录 git log 查看提交记录：
871adf OK, feature Z is fully implemented --- newer commit --┐ 0c3317 Whoops, not yet... | 87871a I&#39;m ready! | 643d0e Code cleanup |-- Join these into one afb581 Fix this and that | 4e9baa Cool implementation | d94e78 Prepare the workbench for feature Z -------------------┘ 6394dc Feature Y --- older commit  假设 6394dc 提交已经 push 上去了 你现在想把 d94e78 ~ 871adf 这几个 commit 合并一下  即最终你再次执行 git log 想要看到的效果如下：</description>
    </item>
    
    <item>
      <title>JavaScript 模板字符串</title>
      <link>https://kunzhao.org/docs/tutorial/vue3/js-template-string/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/tutorial/vue3/js-template-string/</guid>
      <description>JavaScript 模板字符串 `string text` `string text ${expression}string text` </description>
    </item>
    
    <item>
      <title>MySQL 优化与运维</title>
      <link>https://kunzhao.org/docs/tutorial/database/mysql-ops/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/tutorial/database/mysql-ops/</guid>
      <description>MySQL 优化与运维 基本命名和约束规范  表字符集选则 UTF-8，如果需要 Emoji 表情，需要使用 UTF8mb4 (MySQL 5.5.3 以后支持) 存储引擎尽量使用 InnoDB 变长字符串尽量使用 varchar 单标数据量控制在 1 亿以下 库名、表名、字段名不使用保留字 库名、表名、字段名、索引名使用小写字母，使用划线分割，见名知意 表名不要设计的过长，尽可能用最少的字符表达表的用途  字段规范  所有字段均为 NOT NULL，除非真的想要存储 NULL (解释：NULL 的存储浪费表存储空间，InnoDB 需要额外一个字节存储，NULL 过多会影响优化器选择执行计划) 字段类型满足要求条件下越小越好，使用 UNSIGNED 存储非负整数，实际需要存储负数的场景不多 使用 TIMESTAMP 存储时间 (只能存储到 2038 年) 使用 varchar 存储变长字符串，varchar(M) 的 M 指的是字符数，不是字节数，使用 UNSIGNED INT 存储 IPV4 地址，不过这种方式存储不了 IPV6 使用 DECIMAL 存储精确浮点数，用 float 类型存储可能会存在数据误差 少用 blob text  索引范围  单个索引字段数不超过 5，单表索引数量不超过 5，索引设计遵循 B+Tree 索引最左前缀匹配原则 选则区分度高的列作为索引 建立的索引能覆盖 80% 主要的查询，不求全，解决问题的主要矛盾就好 DML 要和 order by、group by 字段建立合适的索引 避免索引的隐式转换 避免冗余索引  MySQL 可用性 无缝切换主库的方案：</description>
    </item>
    
    <item>
      <title>os-release</title>
      <link>https://kunzhao.org/docs/tutorial/unix-command/os-release/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/tutorial/unix-command/os-release/</guid>
      <description>如何知道是 Ubuntu 还是 Cent OS 系统 ? $ cat /etc/os-release NAME=&amp;#34;Ubuntu&amp;#34; VERSION=&amp;#34;20.04.1 LTS (Focal Fossa)&amp;#34; ID=ubuntu ID_LIKE=debian PRETTY_NAME=&amp;#34;Ubuntu 20.04.1 LTS&amp;#34; VERSION_ID=&amp;#34;20.04&amp;#34; HOME_URL=&amp;#34;https://www.ubuntu.com/&amp;#34; SUPPORT_URL=&amp;#34;https://help.ubuntu.com/&amp;#34; BUG_REPORT_URL=&amp;#34;https://bugs.launchpad.net/ubuntu/&amp;#34; PRIVACY_POLICY_URL=&amp;#34;https://www.ubuntu.com/legal/terms-and-policies/privacy-policy&amp;#34; VERSION_CODENAME=focal UBUNTU_CODENAME=focal </description>
    </item>
    
    <item>
      <title>Redis 集群</title>
      <link>https://kunzhao.org/docs/tutorial/redis/cluster/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/tutorial/redis/cluster/</guid>
      <description>Redis 集群 RedisCluster 是 Redis 的分布式解决方案，在 3.0 版本正式推出，有效地解决了Redis分布式方面的需求。当遇到单机内存、并发、流量等瓶颈时，可以采用 Cluster 架构方案达到负载均衡的目的。
集群如何高可用 增加从节点，做主从复制。Redis Cluster 支持给每个分片增加一个或多个从节点，每个从节点在连接到主节点上之后，会先给主节点发送一个 SYNC 命令，请求一次全量复制，也就是把主节点上全部的数据都复制到从节点上。全量复制完成之后，进入同步阶段，主节点会把刚刚全量复制期间收到的命令，以及后续收到的命令持续地转发给从节点。
因为 Redis 不支持事务，所以它的复制相比 MySQL 更简单，连 Binlog 都省了，直接就是转发客户端发来的更新数据命令来实现主从同步。如果某个分片的主节点宕机了，集群中的其他节点会在这个分片的从节点中选出一个新的节点作为主节点继续提供服务。新的主节点选举出来后，集群中的所有节点都会感知到，这样，如果客户端的请求 Key 落在故障分片上，就会被重定向到新的主节点上。
数据分区 RedisCluster 采用哈希分区规则。
虚拟槽分区巧妙地使用了哈希空间，使用分散度良好的哈希函数把所有数据映射到一个固定范围的整数集合中，整数定义为槽（slot）。这个范围一般远远大于节点数，比如RedisCluster槽范围是0~16383。槽是集群内数据管理和迁移的基本单位。采用大范围槽的主要目的是为了方便数据拆分和集群扩展。每个节点会负责一定数量的槽。
RedisCluser 采用虚拟槽分区，所有的键根据哈希函数映射到 0 ~ 16383 整数槽内，计算公式：slot = CRC16（key）&amp;amp; 16383。每一个节点负责维护一部分槽以及槽所映射的键值数据。
槽集合和节点的关系：
使用 CRC16(key) &amp;amp; 16383 将键映射到槽上：
 虚拟槽分区，解耦了数据和节点之间的关系，简化了节点扩容和收缩难度。
 集群限制  key 批量操作支持有限。如mset、mget，目前只支持具有相同slot值的key执行批量操作。对于映射为不同slot值的key由于执行mSet、mget等操作可能存在于多个节点上因此不被支持。 只支持多key在同一节点上的事务操作，当多个key分布在不同的节点上时无法使用事务功能。 key作为数据分区的最小粒度，因此不能将一个大的键值对象如hash、list等映射到不同的节点。 复制结构只支持一层，从节点只能复制主节点，不支持嵌套树状复制结构。  集群搭建  Redis 集群一般由多个节点组成，节点数量至少为6个才能保证组成完整高可用的集群。 节点握手是指一批运行在集群模式下的节点通过Gossip协议彼此通信，达到感知对方的过程。 Redis集群把所有的数据映射到16384个槽中。每个key会映射为一个固定的槽，只有当节点分配了槽，才能响应和这些槽关联的键命令。 redis-trib.rb是采用Ruby实现的Redis集群管理工具。内部通过Cluster相关命令帮我们简化集群创建、检查、槽迁移和均衡等常见运维操作，使用之前需要安装Ruby依赖环境。  redis-trib.rb create节点通信 Gossip 协议的信息交换机制具有天然的分布式特性，但是有成本：加重带宽和计算的负担。因此选择每次需要通信的节点，变得非常重要：
 每秒随机选取 5 个最久没有通信的节点发送 ping 消息。 每 100 毫秒会扫描本地节点列表，发现最近一次接受 pong 时间大于 cluster_node_timeout / 2 ，则立刻发送 pong 消息，防止该节点信息太长时间未更新。  Gossip 协议类似病毒扩散的方式，将信息传播到其他的节点，这种协议效率很高，只需要广播到附近节点，然后被广播的节点继续做同样的操作即可。当然这种协议也有一个弊端就是：会存在浪费，哪怕一个节点之前被通知到了，下次被广播后仍然会重复转发。</description>
    </item>
    
    <item>
      <title>RocketMQ 主备同步</title>
      <link>https://kunzhao.org/docs/rocketmq/rocketmq-master-slave-sync/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/rocketmq/rocketmq-master-slave-sync/</guid>
      <description>RocketMQ 主备同步  基于 RocketMQ 4.2.0 版本进行的源码分析。
 介绍 RocketMQ 的主备同步机制
一、简介 RocketMQ 通过 Master-Slave 主备机制，来实现整个系统的高可用，具体表现在:
 Master 磁盘坏掉，Slave 依然保存了一份 Master 宕机，不影响消费者继续消费  二、搭建环境 我们在一台机器上搭建一个 Master 一个 Slave 的环境:
为了能够将 Master 和 Slave 搭建在同一台计算机上，我们除了需要将 Broker 的角色设置为 SLAVE ，还需要为其指定单独的 brokerId、 storePathRootDir、 storePathCommitLog。
// SLAVE 角色 messageStoreConfig.setBrokerRole(BrokerRole.SLAVE); // 一个机器如果要启动多个 Broker，那么每个 Broker 的 store 根目录必须不同 messageStoreConfig.setStorePathRootDir(storePathRootDir); // 一个机器如果要启动多个 Broker，那么每个 Broker 的 storePathCommitLog 根目录必须不同 messageStoreConfig.setStorePathCommitLog(storePathCommitLog); // 设置 Slave 的 Master HA 地址 messageStoreConfig.setHaMasterAddress(&amp;#34;localhost:10912&amp;#34;); // SLAVE 角色的 brokerId 必须大于 0 brokerConfig.</description>
    </item>
    
    <item>
      <title>Spring 读取 Properties 实现原理</title>
      <link>https://kunzhao.org/docs/tutorial/spring/spring-read-properties/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/tutorial/spring/spring-read-properties/</guid>
      <description>Spring 读取 Properties 实现原理 public class SpringApplication { private ConfigurableEnvironment prepareEnvironment(SpringApplicationRunListeners listeners, DefaultBootstrapContext bootstrapContext, ApplicationArguments applicationArguments) { // Create and configure the environment 	ConfigurableEnvironment environment = getOrCreateEnvironment(); configureEnvironment(environment, applicationArguments.getSourceArgs()); ConfigurationPropertySources.attach(environment); listeners.environmentPrepared(bootstrapContext, environment); // ...  } protected void configureEnvironment(ConfigurableEnvironment environment, String[] args) { // ... 	configurePropertySources(environment, args); configureProfiles(environment, args); } private ConfigurableEnvironment getOrCreateEnvironment() { if (this.environment != null) { return this.environment; } switch (this.webApplicationType) { case SERVLET: return new StandardServletEnvironment(); case REACTIVE: return new StandardReactiveWebEnvironment(); default: return new StandardEnvironment(); } } } 上述代码可知，SpringApplication 在启动的时候先创建 Environment，然后再配置 Profiles，然后再添加 configurationProperties。一般情况下创建的都是 StandardServletEnvironment 环境。</description>
    </item>
    
    <item>
      <title>人人都是架构师 (一)</title>
      <link>https://kunzhao.org/docs/books/everyone-is-architect/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/books/everyone-is-architect/</guid>
      <description>人人都是架构师 - 分布式系统架构落地与瓶颈突破 分布式系统应对高并发、大流量的常用手段：
 扩容 动静分离 缓存 服务降级 限流  限流 常见算法：
 令牌桶，Nginx 限流模块用的是这个：限制的是流量的平均流入速率，允许一定程度上的突发流量。 漏桶：限制的是流出速率，并且这个速率还是保持不变的，不允许突发流量。  Nginx 限流 http { # 每个 IP 的 session 空间大小 limit_zone one $binary_remote_addr 20m; # 每个 IP 每秒允许发起的请求数 limit_req_zone $binary_remote_addr zone=req_one:20m rate=10r/s; # 每个 IP 能够发起的并发连接数 limit_conn one 10; # 缓存还没有来得及处理的请求 limit_req zone=req_one burst=100; } 消峰  活动分时段 答题验证  高并发读 &amp;ldquo;马某出轨王某&amp;rdquo;、&amp;ldquo;iPhone SE 2020 发布&amp;rdquo; 等这种热点新闻的 key 会始终落在同一个缓存节点上，分布式缓存一定会出现单点瓶颈，其资源连接容易瞬间耗尽。有如下两种方案解决这个问题：
 基于 Redis 的集群多写多读方案。  多写如何保持一致性：将 Key 配置在 ZooKeeper，客户端监听 ZNode，一旦变化，全量更新本地持有的 Key   LocalCache 结合 Redis 集群的多级 Cache 方案。  LocalCache 拉取下来的商品数量有 5 个，但是实际上只有 4 个了，怎么解决？对于这种读场景，允许接受一定程度上的数据脏读，最终扣减库存的时候再提示商品已经售罄即可。    实时热点自动发现 交易系统产生的相关数据、上游系统中埋点上报的数据这两个，异步写入日志，对日志进行次数统计和热点分析</description>
    </item>
    
    <item>
      <title>副本一致性算法</title>
      <link>https://kunzhao.org/docs/tutorial/distributed/multi-replica-consistency/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/tutorial/distributed/multi-replica-consistency/</guid>
      <description>副本一致性算法 Paxos 角色 协议将系统中的节点分为三种角色：Proposer（提案者）、Acceptor（决议者）、Leaner（学习者），他们的具体职责为：
 提案者：对key的值提出自己的值； 决议者：对提案者的提议进行投票，选定一个提案，形成最终决策； 学习者：学习决议者达成共识的决策。  决策 在 Paxos 中，一个决策过程（Round、Phase）分为两个阶段：
(1) phase1（准备阶段）：
Proposer向超过半数（n/2+1）Acceptor发起prepare消息(发送编号)； 如果Acceptor 收到一个编号为 N 的 Prepare 请求，且 N 大于该 Acceptor 已经响应过的所有 Prepare 请求的编号，那么它就会将它已经接受过的编号最大的提案（如果有的话）作为响应反馈给 Proposer，同时该Acceptor 承诺不再接受任何编号小于 N 的提案。否则拒绝返回。
(2) phase2（决议阶段或投票阶段）：
如果超过半数 Acceptor 回复 promise，Proposer向Acceptor发送accept消息。注意此时的V：V 就是收到的响应中编号最大的提案的，如果响应中不包含任何提案，那么V 就由 Proposer 自己决定； Acceptor检查accept消息是否符合规则，只要该 Acceptor 没有对编号大于 N 的 Prepare 请求做出过响应，它就接受该提案。
在实际发展中，Paxos算法也演变出一系列变种：
PBFT（实用拜占庭容错）算法：是一种共识算法，较高效地解决了拜占庭将军问题； Multi-Paxos算法：优化了prepare阶段的效率，同时允许多个Leader并发提议；以及FastPaxos、EPaxos等，这些演变是针对某些问题进行的优化，内核思想还是依托于Paxos。
Raft  Raft 之所以会出现，主要是因为 Paxos 晦涩难懂，大家表示很难看懂。
  Paxos 可以多点写入，无需选举 Leader，每个节点都可以接受写请求。虽然为了避免活锁问题，Multi Paxos 可以选举一个 Leader，但是也不是强制执行的，允许同一时间有多个 Leader 同时存在。多点写入，这增加了复杂度。 Raft 只能单点写入 任意时刻只能有一个有效的 Leader，只能 Leader 接受写请求，Leader 同步给超过半数的 Follower  角色 在 Raft 中，节点被分为 Leader、Follower、Candidate 三种角色：</description>
    </item>
    
    <item>
      <title>Circular Array (循环数组)</title>
      <link>https://kunzhao.org/docs/programmer-interview/algorithm/circular-array/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/programmer-interview/algorithm/circular-array/</guid>
      <description>Circular Array 循环数组 来自一亩三分地，微软面试官问的问题。过去任意 1 秒内来自同一 IP 的请求是否超过 100 次，可以用循环数组可以做。
 微软
 // // https://www.javaguides.net/2018/09/queue-implementation-using-circular-array-in-java.html // package com.zk.algorithm.array; /** * Queue Implementation using Circular Array * @author Ramesh Fadatare * */ public class CircularArray { // Array used to implement the queue.  private int[] queueRep; // 添加数据，存放在 (rear + 1) % size，size++  // 取出数据，(front + 1) % size，size--  private int size, front, rear; // Length of the array used to implement the queue.</description>
    </item>
    
    <item>
      <title>Git 分支</title>
      <link>https://kunzhao.org/docs/tutorial/git/git-branch/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/tutorial/git/git-branch/</guid>
      <description>Git 分支 Git 的分支管理命令：git branch。
示例 列举本地所有分支 git branch  当前分支会用 * 标识出来，也会用特别的颜色标识出来
 列举本地和远程所有分支 git branch -a 创建分支 git branch &amp;lt;branchName&amp;gt; 删除分支 # 删除时，会检查此分支是否已经合并到其它分支，否则拒绝删除 git branch -d &amp;lt;branchName&amp;gt; # 不管有没有合并到其它分支，都强制删除分支 git branch -D &amp;lt;branchName&amp;gt; 重命名分支 # 如果版本库已经存在 newbranch，则拒绝重命名 git branch -m &amp;lt;oldbranch&amp;gt; &amp;lt;newbranch&amp;gt; # 如果版本库已经存在 newbranch，则强制重命名 git branch -M &amp;lt;oldbranch&amp;gt; &amp;lt;newbranch&amp;gt; 创建并切换分支 git checkout -b &amp;lt;new_branch&amp;gt; 扫描下面二维码在手机端阅读：</description>
    </item>
    
    <item>
      <title>htmlWebpackPlugin.options.title</title>
      <link>https://kunzhao.org/docs/tutorial/vue3/change-title/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/tutorial/vue3/change-title/</guid>
      <description>改变 htmlWebpackPlugin.options.title Vue 默认的 HTML 的 title 是 htmlWebpackPlugin.options.title，那么如何进行修改呢？
在项目根目录下，创建 vue.config.js，然后这样写:
// vue.config.js module.exports = { chainWebpack: config =&amp;gt; { config .plugin(&amp;#39;html&amp;#39;) .tap(args =&amp;gt; { args[0].title= &amp;#39;你想设置的title名字&amp;#39; return args }) } } 这个是写在 vue.config.js 中的，假如没有这个文件的话，在根目录创建一个，webpack 在打包的时候会自动扫描是否有这个文件，并将其中的内容与已经设置好的 webpack 内容合并。
熟悉 webpack 的应该知道这是在 webpack 中使用 HtmlWebpackPlugin 的用法
plugins: [ // plugins 的配置  // html-webpack-plugin  // 功能：默认会创建一个空的 HTML，自动引入打包输出的所有资源（JS/CSS）  // 需求：需要有结构的 HTML 文件  new HtmlWebpackPlugin({ // 复制 &amp;#39;./src/index.html&amp;#39; 文件，并自动引入打包输出的所有资源（JS/CSS）  template: &amp;#39;.</description>
    </item>
    
    <item>
      <title>MyBatis</title>
      <link>https://kunzhao.org/docs/tutorial/database/mybatis/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/tutorial/database/mybatis/</guid>
      <description>MyBatis 防止 SQL 注入 $ vs # # 将传入的数据都当成一个字符串，会对自动传入的数据加一个双引号 (底层基于 PreparedStatement)。如：where username=#{username}，如果传入的值是 111,那么解析成 sql 时的值为 where username=&amp;quot;111&amp;quot;, 如果传入的值是id，则解析成的 sql 为 where username=&amp;quot;id&amp;quot;：
&amp;lt;select id=&amp;#34;selectByNameAndPassword&amp;#34; parameterType=&amp;#34;java.util.Map&amp;#34; resultMap=&amp;#34;BaseResultMap&amp;#34;&amp;gt; select id, username, password, role from user where username = #{username,jdbcType=VARCHAR} and password = #{password,jdbcType=VARCHAR} &amp;lt;/select&amp;gt; $ 将传入的数据直接显示生成在 sql 中：
&amp;lt;select id=&amp;#34;selectByNameAndPassword&amp;#34; parameterType=&amp;#34;java.util.Map&amp;#34; resultMap=&amp;#34;BaseResultMap&amp;#34;&amp;gt; select id, username, password, role from user where username = ${username,jdbcType=VARCHAR} and password = ${password,jdbcType=VARCHAR} &amp;lt;/select&amp;gt; # 方式能够很大程度防止sql注入，$ 方式无法防止Sql注入。$ 方式一般用于传入数据库对象，例如传入表名。</description>
    </item>
    
    <item>
      <title>Redis 缓存</title>
      <link>https://kunzhao.org/docs/tutorial/redis/cache/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/tutorial/redis/cache/</guid>
      <description>Redis 缓存 缓存更新策略  低一致性业务建议配置最大内存和淘汰策略的方式使用。 高一致性业务可以结合使用超时剔除和主动更新，这样即使主动更新出了问题，也能保证数据过期时间后删除脏数据。  缓存击穿 为了避免缓存击穿给数据库带来的激增压力，我们的解决方法也比较直接，对于访问特别频繁的热点数据，我们就不设置过期时间了。这样一来，对热点数据的访问请求，都可以在缓存中进行处理，而Redis数万级别的高吞吐量可以很好地应对大量的并发请求访问。
穿透优化 缓存穿透是指查询一个根本不存在的数据，缓存层和存储层都不会命中，通常出于容错的考虑，如果从存储层查不到数据则不写入缓存层。缓存穿透将导致不存在的数据每次请求都要到存储层去查询，失去了缓存保护后端存储的意义。
通常可以在程序中分别统计总调用数、缓存层命中数、存储层命中数，如果发现大量存储层空命中，可能就是出现了缓存穿透问题。造成缓存穿透的基本原因有两个。第一，自身业务代码或者数据出现问题，第二，一些恶意攻击、爬虫等造成大量空命中。下面我们来看一下如何解决缓存穿透问题。
 缓存空对象。设置较短过期时间，自动剔除，可以减少内存占用；存储层有了数据，可以利用消息系统或其它方式清楚掉缓存中的空对象。   布隆过滤器拦截  雪崩优化 大量 Key 同时过期 我们可以避免给大量的数据设置相同的过期时间。如果业务层的确要求有些数据同时失效，你可以在用EXPIRE命令给每个数据设置过期时间时，给这些数据的过期时间增加一个较小的随机数（例如，随机增加1~3分钟），这样一来，不同数据的过期时间有所差别，但差别又不会太大，既避免了大量数据同时过期，同时也保证了这些数据基本在相近的时间失效，仍然能满足业务需求。
除了微调过期时间，我们还可以通过服务降级，来应对缓存雪崩。
所谓的服务降级，是指发生缓存雪崩时，针对不同的数据采取不同的处理方式。
 当业务应用访问的是非核心数据（例如电商商品属性）时，暂时停止从缓存中查询这些数据，而是直接返回预定义信息、空值或是错误信息。 当业务应用访问的是核心数据（例如电商商品库存）时，仍然允许查询缓存，如果缓存缺失，也可以继续通过数据库读取。  Redis 缓存实例故障宕机  保证缓存层服务高可用性。和飞机都有多个引擎一样。可以采用限流或降级方案。   依赖隔离组件为后端限流并降级  热点 Key 重建优化 在缓存失效的瞬间，有大量线程来重建缓存，造成后端负载加大，甚至可能会让应用崩溃。
 互斥锁  Redis 热 Key 如何解决，降级成本地缓存。不过需要加监测，而且 Redis 本身也有 hotkeys 参数可以监测，还可以实时分析用户请求。
MySQL 同步到 Redis 数据更新服务只负责处理业务逻辑，更新 MySQL，完全不用管如何去更新缓存。负责更新缓存的服务，把自己伪装成一个 MySQL 的从节点，从 MySQL 接收 Binlog，解析 Binlog之后，可以得到实时的数据变更信息，然后根据这个变更信息去更新 Redis 缓存。
这种收 Binlog 更新缓存的方案，和收 MQ 消息更新缓存的方案，其实它们的实现思路是一样的，都是异步订阅实时数据变更信息，去更新 Redis。只不过，直接读取 Binlog 这种方式，它的通用性更强。不要求订单服务再发订单消息了，订单更新服务也不用费劲去解决“发消息失败怎么办？”这种数据一致性问题了。</description>
    </item>
    
    <item>
      <title>RocketMQ 事务消息</title>
      <link>https://kunzhao.org/docs/rocketmq/rocketmq-transaction/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/rocketmq/rocketmq-transaction/</guid>
      <description>RocketMQ 事务消息  基于 RocketMQ 4.8.0 版本进行的源码分析。
 讲述 RocketMQ 是如何支持事务消息的。
源码调试过程 mkdir .rocketmq/conf cp distribution/conf/logback_namesrv.xml .rocketmq/conf cp distribution/conf/logback_broker.xml .rocketmq/conf NamesrvStartup.java 加上如下代码：
static { System.setProperty(MixAll.ROCKETMQ_HOME_PROPERTY, &amp;#34;.rocketmq&amp;#34;); } BrokerStartup.java 加上如下代码:
static { System.setProperty(MixAll.ROCKETMQ_HOME_PROPERTY, &amp;#34;.rocketmq&amp;#34;); System.setProperty(MixAll.NAMESRV_ADDR_PROPERTY, &amp;#34;localhost:9876&amp;#34;); } TransactionProducer.java 加上如下代码：
static { System.setProperty(MixAll.NAMESRV_ADDR_PROPERTY, &amp;#34;localhost:9876&amp;#34;); } 运行顺序：
 NamesrvStartup BrokerStartup TransactionProducer  发送事务消息 我们先来看客户端调用 Producer 发送事务消息的过程：
初始化事务环境 初始化事务环境是为了构建 checkExecutor 线程池：
public class TransactionMQProducer extends DefaultMQProducer { @Override public void start() throws MQClientException { this.</description>
    </item>
    
    <item>
      <title>sed</title>
      <link>https://kunzhao.org/docs/tutorial/unix-command/sed/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/tutorial/unix-command/sed/</guid>
      <description>sed 打印文件的第 10-20 行 $ sed -n &amp;#39;10, 20p&amp;#39; input.txt $ awk &amp;#39;10&amp;lt;=NR &amp;amp;&amp;amp; NR &amp;lt;= 20&amp;#39; input.txt $ head -20 input.txt | tail -11 </description>
    </item>
    
    <item>
      <title>TCP</title>
      <link>https://kunzhao.org/docs/tutorial/network/tcp/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/tutorial/network/tcp/</guid>
      <description>TCP TCP 头 三次握手  三次握手恰好可以保证 Client 和 Server 对自己的发送、接受能力做了一次确认。
  connect 和 bind 区别？
  Socket 层面的，是如何和三次握手的过程对应的？
 四次挥手 TIME_WAIT 状态的设计  为什么不直接进入 CLOSED 状态，而是中间有一个 TIME_WAIT 状态 ?
 4元组 (客户端 IP、客户端 Port、服务器 IP、服务器 Port)，无法区分出新连接还是老连接，这会导致老连接上的数据包会串到新的连接上来。
TCP/IP 定义了一个值 MSL，表示数据包在网络上最长逗留时间，默认是 120s。连接保持在 TIME_WAIT 状态，再等待 2 × MSL 时间就可以进入 CLOSED 状态了，防止串数据。
 为什么是两倍的 MSL ?
 因为上图第 4 次发送的数据包，服务器是否收到是不确定的。而如果服务器没有收到，那么服务器会重新发送第三次的数据包。所以整个的时间，最长是两个 MSL。
 为何服务器收到第 4 个 ACK 之后，立刻进入 CLOSED 状态，而不是也进入 TIME_WAIT 状态 ?</description>
    </item>
    
    <item>
      <title>存储高可用方案</title>
      <link>https://kunzhao.org/docs/tutorial/distributed/storage-high-availablity/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/tutorial/distributed/storage-high-availablity/</guid>
      <description>存储高可用方案 数据如何复制 主备复制 最简单的复制方案就是主备复制，MySQL、Redis、MongoDB 都提供了这种复制方案。
缺点：故障的时候，需要人工干预，硬件上有浪费。适合于内部的后台管理系统。
主从复制  从意味着是要干活的，也就是从节点提供读的能力，主提供了读写能力。
 缺点：故障的时候，需要人工干预。一般适用于写少读多的业务。
主备倒换/主从倒换 主主复制 因为数据必须满足可以双向复制，因此适合临时性、可丢失、可覆盖的数据场景
数据集群 参考  从零开始学架构 : 照着做，你也能成为架构师  </description>
    </item>
    
    <item>
      <title>编写可读代码的艺术</title>
      <link>https://kunzhao.org/docs/books/the-art-of-readable-code/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/books/the-art-of-readable-code/</guid>
      <description>编写可读代码的艺术 代码应当易于理解 Q: 可读性基本定理？
 可读性基本原理：使别人理解它所需的时间最小化。
 Q: 代码总是越小越好？
 减少代码行数是一个好目标，但是把理解代码所需的时间最小化是一个更好的目标。
 表面层次的改进 把信息装到名字里 （1）选择专业的词
def getPage(url) 上述例子，get 词没有表达出很多信息。从本地缓存得到一个页面，还是从数据库中，或者从互联网中？如果从互联网中，应该使用更为专业的名字：fetchPage(url) 或 downloadPage(url)。
class BinaryTree { int size(); } 上述例子，size() 返回的是什么？树的高度，节点树，还是树在内存中所占的空间？size() 没有承载更多的信息，更专业的词汇是 height()、numNodes() 或 memoryBytes()。
英语是一门丰富的语言，有很多词汇可以选择。下面是一些例子，这些单词更富有表现力，可能更适合你的语境：
   单词 更多选择     send deliver、dispatch、announce、distribute、route   find search、extract、locate、recover   start launch、create、begin、open   make create、set up、build、generate、compose、add、new    （2）避免像 tmp 和 retval 这样泛泛的名字
除非你有更好的理由！
（3）用具体的名字代替抽象的名字
searchCanStart() 比 canListenOnPort() 更具体一些，这个名字直接描述了方法所做的事情。</description>
    </item>
    
    <item>
      <title>Container With Most Water</title>
      <link>https://kunzhao.org/docs/programmer-interview/algorithm/container-with-most-water/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/programmer-interview/algorithm/container-with-most-water/</guid>
      <description>Container With Most Water // 两个柱子中间包含最多的水 // 可以看一下这道题的这个图 // 这个是两个柱子之间的所能容纳的水的矩形面积 // // https://leetcode.com/problems/container-with-most-water/ // // [1,8,6,2,5,4,8,3,7] // ↑ ↑ // 7 * 7 = 49 // public class ContainerWithMostWater { public int maxArea(int[] height) { int maxArea = Integer.MIN_VALUE; int lo = 0; int hi = height.length - 1; // O(n)  while (lo &amp;lt; hi) { maxArea = Math.max(maxArea, Math.min(height[lo], height[hi]) * (hi - lo)); // =======================================  // 此处这个地方，必须是小的一边移动  // 因为大的移动的话，面积一定变小 (宽度变小，而且高度不会超过小的)  // 而小的移动有可能变大  //  // 另外一种解释：  // 我们选择一个高的，以便容纳更多的水  // https://leetcode.</description>
    </item>
    
    <item>
      <title>Git 分支合并</title>
      <link>https://kunzhao.org/docs/tutorial/git/git-merge-branch/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/tutorial/git/git-merge-branch/</guid>
      <description>Git 分支合并 某个功能在开发分支上开发完毕后，需要合并到 master 分支，合并分支有两种方式：
 git merge git rebase  分支现状展示  从 master 分支的 A 提交点，拉取了分支 user2/i18n user2/i18n 的功能开发总共有两个 commit：E 和 F master 在 A 提交点之后，又有 B、C 和 D 这三个提交被合入进来  Git merge 我们使用 git merge 来合并 user2/i18n 分支到 master 分支上：
# 切换到 master 分支 git checkout master # 合并 user2/i18n 分支 git merge user2/i18n 合并后的分支示意图：
Git rebase 我们使用 git rebase 来合并 user2/i18n 到 master 分支上：
git checkout user2/i18n git rebase master # 如果有冲突，则需要解决冲突 # 解决完冲突，使用 git add -u 将完成冲突解决的文件加入到暂存区 # git rebase --continue # 直接推送，用本地的 user2/i18n 分支更新远程的 master 分支即可 git push origin user2/i18n:master rebase 之后的分支示例：</description>
    </item>
    
    <item>
      <title>perf</title>
      <link>https://kunzhao.org/docs/tutorial/unix-command/perf/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/tutorial/unix-command/perf/</guid>
      <description>perf 内核版本需要 2.6.31 以上。
常用命令
 perf list perf stat perf top perf record perf report perf annotate  perf list 列出所有能够触发 perf 采样点的事件。perf 基本原理是对被检测对象进行采样，采样的方式很多，最简单的方式就是根据 tick 中断进行，还可以用 cache miss 事件触发进行采样。
perf stat 通过概况的方式提供被调试程序运行的整体情况、汇总数据。通过 perf stat 可以很快分析出这个程序是 CPU 密集型还是 IO 密集型，从而可以进行下一步优化。
perf top 实时显示当前系统的性能统计信息，找出当前系统最耗时的某个进程
perf record &amp;amp; perf report perf record 获取某个进程的采样信息，存到 perf.data 文件中，使用 perf report 来显示统计结果。perf record 记录单个函数级别的统计信息，可以定位到某个进程最耗时的函数。
perf record 最常用的选项是 -p 和 -g，-p 指定采样某个进程的信息，-g 生成函数的调用关系表。
perf annotate 读取 perf.data 显示注释的代码，查看程序中哪些代码的耗时比较长。</description>
    </item>
    
    <item>
      <title>Redis 分布式锁 🔒</title>
      <link>https://kunzhao.org/docs/tutorial/redis/distributed-lock/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/tutorial/redis/distributed-lock/</guid>
      <description>Redis 分布式锁 🔒 简单实现 // 这里的冒号:就是一个普通的字符，没特别含义，它可以是任意其它字符，不要误解 &amp;gt; setnx lock:codehole true OK ... do something critical ... &amp;gt; del lock:codehole (integer) 1 缺点：逻辑执行到中间出现异常，可能会导致 del 没有被调用，🔒 得不到释放。
加上过期时间的简单实现 &amp;gt; setnx lock:codehole true OK &amp;gt; expire lock:codehole 5 ... do something critical ... &amp;gt; del lock:codehole (integer) 1 缺点：setnx 和 expire 之间服务器进程突然挂掉了，可能是因为机器掉电或者是被人为杀掉的，就会导致 expire 得不到执行，也会造成死锁。
Redis 2.8 合并 setnx 和 expire 指令 合并为原子操作。
&amp;gt; set lock:codehole true ex 5 nx OK ... do something critical .</description>
    </item>
    
    <item>
      <title>RocketMQ ACL 权限控制</title>
      <link>https://kunzhao.org/docs/rocketmq/rocketmq-acl/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/rocketmq/rocketmq-acl/</guid>
      <description>RocketMQ ACL 权限控制  基于 RocketMQ 4.8.0 版本进行的源码分析。
 RocketMQ 从 4.4.0 版本引入了 ACL 权限控制功能。可以给话题指定权限，只有拥有权限的消费者才可以进行消费。其余 ACL 特性请查看权限控制。
如何使用 首先定义一个 RPCHook：
private static final String ACL_ACCESS_KEY = &amp;#34;RocketMQ&amp;#34;; private static final String ACL_SECRET_KEY = &amp;#34;1234567&amp;#34;; static RPCHook getAclRPCHook() { return new AclClientRPCHook(new SessionCredentials(ACL_ACCESS_KEY,ACL_SECRET_KEY)); } 然后发送消息的时候指定 RPCHook：
DefaultMQProducer producer = new DefaultMQProducer(&amp;#34;ProducerGroupName&amp;#34;, getAclRPCHook()); 接受消息的时候也需要指定具有同样 ACCESS_KEY 和 SECRET_KEY 的 RPCHook：
DefaultMQPullConsumer consumer = new DefaultMQPullConsumer(&amp;#34;please_rename_unique_group_name_6&amp;#34;, getAclRPCHook()); Producer 指定 RPCHook 从示例代码中，我们可以看出可以为 Producer 指定一个 RPCHook，随后此 RPCHook 会被注册进来：</description>
    </item>
    
    <item>
      <title>Spring IOC</title>
      <link>https://kunzhao.org/docs/tutorial/spring/spring-ioc/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/tutorial/spring/spring-ioc/</guid>
      <description>Spring IOC Bean 加载过程 转化 BeanName 我们解析完 XML 配置后创建的 Map，使用的是 beanName 作为 key：
public class DefaultListableBeanFactory extends AbstractAutowireCapableBeanFactory implements ConfigurableListableBeanFactory, BeanDefinitionRegistry, Serializable { // key: bean name  private final Map&amp;lt;String, BeanDefinition&amp;gt; beanDefinitionMap = new ConcurrentHashMap&amp;lt;&amp;gt;(256); } 在获取 Bean 的时候，alias bean name、factory bean name 都要转化为 bean name：
public abstract class AbstractBeanFactory extends FactoryBeanRegistrySupport implements ConfigurableBeanFactory { protected &amp;lt;T&amp;gt; T doGetBean(final String name, @Nullable final Class&amp;lt;T&amp;gt; requiredType, @Nullable final Object[] args, boolean typeCheckOnly) throws BeansException { final String beanName = transformedBeanName(name); } protected String transformedBeanName(String name) { return canonicalName(BeanFactoryUtils.</description>
    </item>
    
    <item>
      <title>UDP</title>
      <link>https://kunzhao.org/docs/tutorial/network/udp/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/tutorial/network/udp/</guid>
      <description>UDP UDP 头 与 TCP 区别  无连接 不保证不丢失、不保证按序到达 基于数据报，一个一个发，一个一个收 无拥塞控制，让我发，我就发，管它洪水滔天 无状态服务  应用场景  需要资源少，网络情况较好的内网，或者对于丢包不敏感的应用 不需要一对一沟通建立连接，可以广播的应用: DHCP 处理速度快、低时延、可以容忍少数丢包 Quick UDP Internet Connections: Google 提出的，降低通信时延 流媒体协议，有的帧比较重要，有的不重要 实时游戏。游戏玩家多，服务器却不多，而维护 TCP 需要一些数据结构 IoT 物联网 4G 网络，数据流量上网的数据面对的协议 GTP-U 就是基于 UDP 的  迅雷为什么用 UDP 便于 NAT 穿透。</description>
    </item>
    
    <item>
      <title>业务高可用方案</title>
      <link>https://kunzhao.org/docs/tutorial/distributed/business-high-availablity/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/tutorial/distributed/business-high-availablity/</guid>
      <description>业务高可用方案 高可用是系统级工程 应对机房断电、火灾、城市地震、水灾等极端情况，就需要异地多活架构。
跨城异地和同城异区 银行存款余额、支付宝余额无法做到跨城异地多活。例如，挖掘机挖断光缆后，广州机房和北京机房是不是可以同时转出去1W元？因此只能做同城异区架构(应对机房级别故障)。
 跨城异地和同城异区，是完全两套不同的架构。距离数字上的变化，量变引起了质变，架构复杂度大大提升，网络传输速度降低，中间不可控因素增多。上述这些问题，同城异区也会遇到，但是概率小很多，而且同城异区还可以搭建多套互联通道，成本可控，搭建同城异区，架构上可以将两个机房当作本地机房来设计，无需额外考虑。
 跨城异地多活  优先实现核心业务的异地多活架构 异地多活理论上就不可能很快，物理因素决定的，因此只同步核心业务的数据，保证最终一致性，不保证实时一致性 多种手段同步数据：消息队列、B 中心本机读取失败再去 A 中心读取一次、重新生成数据方式、数据库同步等 只保证大部分用户的异地多活：异地多活无法保证 100% 的业务可用  异地多活设计步骤  业务分级，挑选核心业务：访问量大的业务、核心业务、产生大量收入的业务 数据分类：数据量、数据是否必须唯一 (例如用户 ID)、实时性、可丢失性 (session)、可恢复性 数据同步方案：MySQL 数据同步、消息队列同步、重复生成 异常处理：避免整体业务不可用、修正异常数据、弥补用户损失  通过多个通道同步的方式，来进行异常处理：
 一个走公网，一个走内网 数据可以重复覆盖  通过同步和访问结合方案的设计，来进行异常处理：
 接口走公网，同步走内网 数据有路由规则 优先读取本地数据，然后再通过接口访问  接口级故障应对  核心思想：优先保证核心业务，优先保证绝大部分用户。
 异地多活架构应对系统级别故障，另外一种常见的是接口级别的故障 (访问超时、异常、响应缓慢)。
具体措施：降级 (应对系统自身故障)、熔断 (应对依赖的外部系统故障)、限流 (性能压测确定阈值)、排队 (限流的变种)
参考  《从零开始学架构 : 照着做，你也能成为架构师》  </description>
    </item>
    
    <item>
      <title>炒股的智慧</title>
      <link>https://kunzhao.org/docs/books/the-wisdom-of-trading-stocks/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/books/the-wisdom-of-trading-stocks/</guid>
      <description>炒股的智慧  如果要我用一句话解释何以一般股民败多胜少，那就是：人性使然！说的全面些，就是这些永远不变的人性&amp;ndash;讨厌风险、急着发财、自以为是、赶潮跟风、因循守旧和耿于报复&amp;ndash;使股民难以逃避开股市的陷阱。说得简单些，就是好贪小便宜、吃不得小亏的心态使得一般股民几乎必然地成为了输家。
 炒股的挑战 炒股与人性 炒股最重要的原则就是止损。但人性是好贪小便宜，不肯吃小亏，只有不断地因为贪了小便宜却失去大便宜，不肯吃小亏最终却吃了大亏，你才能最终学会不贪小便宜，不怕吃小亏。
特殊的赌局 问问你自己喜欢做决定吗？喜欢独自为自己地决定负全部责任吗？对 99% 的人来说，答案是否定的。股市这一恒久的赌局却要求你每时每刻都要做理性的决定，并且为决定的结果负全部的责任！这就淘汰了一大部分股民，因为他们没有办法长期承受这样的心理能力。
一般股民何以失败 人性讨厌风险 纽约有位叫做夏皮诺的心理医生，请了一批人来做两个实验：
 实验一  选择：第一，75% 的机会得到 1000 美元，但有 25% 的机会什么都得不到；第二，确定得到 700 美元。结果 80% 的人选择了第二选择，大多数人宁愿少些，也要确定的利润。
 股民好获小利，买进的股票升了一点，便迫不及待地脱手。这只股票或许有 75% 继续上升地机会，但为了避免 25% 什么都得不到的可能性，股民宁可少赚些。任何炒过股的读者都明白，要用较出场价更高地价位重新入场是多么困难。股价一天比一天高，你只能做旁观者。
  实验二  选择：第一，75% 的机会付出 1000 美元，但有 25% 的机会什么都不付；第二，确定付出 700 美元。结果 75% 的人选择了第一选择。他们为了搏 25% 什么都不付的机会，从数学上讲多失去了 50 美元。
 一旦买进的股票跌了，股民便死皮赖脸不肯止损，想象出各种各样的理由说服自己下跌只是暂时的。其真正的原因只不过为了搏那 25% 可能全身而退的机会！结果是小亏慢慢积累成大亏。
 人的发财心太急 心一旦大了，行动上就开始缺少谨慎。首先我每次买股买得太多，其次止损止得太迟。我为此遭受了巨大的损失。
人好自以为是 一天结束的时候，股票以某一价钱收盘。你有没有思考过它代表了什么？它代表了股市的参与者在今天收市的时候对该股票的认同。
不要太固执己见，不要对自己的分析抱太大的信心。认真观察股市，不对时就认错。否则，你在这行生存的机会是不大的。
人好跟风 人好报复 在股市中，买进的股票跌了，你就再多买一点，因为第二次买的价钱较上次为低，所以平均进价摊低了。从心理上看，你的心态和赌场亏钱时一样。一方面你亏不起，另一方面你在报复股市，报复股市让你亏钱。同时内心希望，只要赢一手，就能连本带利全回来。因为平均进价摊低了，股票的小反弹就能提供你全身而退的机会。
这样的心态是极其有害的。股票跌的时候通常有它跌的理由，常常下跌的股票会越跌越低。这样被套牢，你就越陷越深，直到你心理无法承受的地步。一个致命的大亏损，常常就彻底淘汰了一位股民。
人总是迟疑不决，心怀侥幸 每个炒股人都会经过这个过程。20元买好股票，定好18元止损，当股票跌到18元时，你有没有想想再等等？或许股票马上反弹！股票又跌到16元，你会不会拍自己的脑壳说：“真该按定好的规矩办！18元时就走人；现若股票反弹5毛钱我就一定说再见。”
现股票跌到10元了，你准备怎么办？你会发毛吗？你会不会发狠：“老子这次拼了！现在就是不走，我倒要看看你最低会跌到什么地方？”
当然，最后的结局很少例外，通常是股票学校又多了位交了学费毕不了业的炒股
股票分析的基本知识 技术分析 升势：一浪比一浪高     朋友，你认为什么因素使投资者入市买股票？华尔街有过调查，使一般投资者入场买股票的原因最主要的就是因为股票在升！你明白吗？一般投资者入场买股票主要不是因为股票的成本收益比率低或红利高，而是因为股票在升！升！升！而投资人卖股票的最主要原因是因为股票在跌！在跌！</description>
    </item>
    
    <item>
      <title>ARP</title>
      <link>https://kunzhao.org/docs/tutorial/network/arp/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/tutorial/network/arp/</guid>
      <description>ARP ARP 可以将 IP 解析为 MAC 地址。ARP 只适用于 IPv4，不能用于 IPv6，在 IPv6 可以用 ICMPv6 替代 ARP 发送邻居探索消息。
ARP 工作机制 简而言之，ARP 借助 ARP 请求和 ARP 响应两种类型的包确定 MAC 地址：
IP 地址和 MAC 地址缺一不可 知道 IP 地址还需要知道 MAC 地址吗？
如下图所示，主机 A 想要发送 IP 数据包给主机 B，但是必须经过路由器 C。路由器会隔断两个网络，因此无法直接发送到 B。
以太网发送 IP 包，下次要经过哪个路由器发送数据报，这个“下一个路由器”就是相应的 MAC 地址。
RARP MAC 地址解析为 IP 地址的一种协议。</description>
    </item>
    
    <item>
      <title>Count Of Smaller After Self</title>
      <link>https://kunzhao.org/docs/programmer-interview/algorithm/countofsmallerafterself/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/programmer-interview/algorithm/countofsmallerafterself/</guid>
      <description>Count Of Smaller After Self 题目 数组里面的每一个数字，排在这个数字后面的小于这个数字的有多少个数字
解法 import java.util.ArrayList; import java.util.List; // Input: [5,2,6,1] // Output: [2,1,1,0] // // 统计小于自己的有多少个数字 public class CountOfSmallerAfterSelf { public List&amp;lt;Integer&amp;gt; countSmaller(int[] nums) { List&amp;lt;Integer&amp;gt; result = new ArrayList&amp;lt;&amp;gt;(); for (int i = 0; i &amp;lt; nums.length; i++) { int curr = nums[i]; int count = 0; for (int j = i + 1; j &amp;lt; nums.length; j++) { if (nums[j] &amp;lt; curr) { count++; } } result.</description>
    </item>
    
    <item>
      <title>Git 解决冲突</title>
      <link>https://kunzhao.org/docs/tutorial/git/git-fix-conflict/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/tutorial/git/git-fix-conflict/</guid>
      <description>Git 解决冲突 某个分支的代码想要合并到其它分支，可能会产生冲突，产生的原因就是这两个分支都对代码的同一个区域做了修改，Git 本身并不知道应该采用哪个修改最为合适，因此需要你来决定。
解决冲突 如下所示是冲突代码的示例：
 A 和 B 之间的代码，是你本地的代码所做的改动 B 和 C 之间的代码，是远程代码所做的改动  你的工作是重新编辑 A 到 C 区域之间的内容，去掉 &amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt; 、=======、&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt; 符号，重新编辑 A 和 C 之间的代码，以让整个项目运行起来。
编辑完之后，可以通过 git add 命令将冲突的文件假如到暂存区，然后再 git commit，就完成了冲突解决。
打开图形界面工具解决冲突 使用图形化工具来帮助你解决冲突，不过需要事先安装工具。打开图形界面工具的命令如下：
git mergetool 打开之前，也可以使用 git config 进行简单的配置，比如使用 vimdiff 工具作为默认的冲突解决工具：
git config merge.tool vimdiff git config merge.conflictstyle diff3 git config mergetool.prompt false 放弃合并操作 你暂时不想解决冲突：
git reset 参考  How to resolve merge conflicts in Git  扫描下面二维码，在手机端阅读：</description>
    </item>
    
    <item>
      <title>Java 集合类</title>
      <link>https://kunzhao.org/docs/tutorial/java/java-collection/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/tutorial/java/java-collection/</guid>
      <description>Java 集合类 Collections 框架图 List 框架图 Set 框架图 Map 框架图 Queue 框架图 HashMap  并发下的 HashMap 会有哪些安全问题？
 这里我只是简单的说了写覆盖跟不可重复读（联想到数据库了），面试官就放我过了。
 添加元素时头插还是尾插？
 1.7 头插，1.8 尾插。
数组长度为什么必须是 2 的指数幂 减少哈希冲突，均匀分布元素。
1）通过将 Key 的 hash 值与 length-1 进行 &amp;amp; 运算，实现了当前 Key 的定位，2 的幂次方可以减少冲突（碰撞）的次数，提高 HashMap 查询效率；
2）如果 length 为 2 的次幂，则 length-1 转化为二进制必定是 11111…… 的形式，在于 h 的二进制与操作效率会非常的快，而且空间不浪费；如果 length 不是 2 的次幂，比如 length 为 15，则 length-1 为 14，对应的二进制为 1110，在于 h 与操作，最后一位都为 0，而 0001，0011，0101，1001，1011，0111，1101 这几个位置永远都不能存放元素了，空间浪费相当大，更糟的是这种情况中，数组可以使用的位置比数组长度小了很多，这意味着进一步增加了碰撞的几率，减慢了查询的效率！这样就会造成空间的浪费。</description>
    </item>
    
    <item>
      <title>Redis 过期和淘汰策略</title>
      <link>https://kunzhao.org/docs/tutorial/redis/evict-maxmemory/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/tutorial/redis/evict-maxmemory/</guid>
      <description>Redis 过期和淘汰策略 过期策略  过期的 key 集合
 redis 会将每个设置了过期时间的 key 放入到一个独立的字典中，以后会定时遍历这个字典来删除到期的 key。除了定时遍历之外，它还会使用惰性策略来删除过期的 key，所谓惰性策略就是在客户端访问这个 key 的时候，redis 对 key 的过期时间进行检查，如果过期了就立即删除。定时删除是集中处理，惰性删除是零散处理。
 定时扫描策略
 Redis 默认会每秒进行十次过期扫描，过期扫描不会遍历过期字典中所有的 key，而是采用了一种简单的贪心策略。
 从过期字典中随机 20 个 key； 删除这 20 个 key 中已经过期的 key； 如果过期的 key 比率超过 1/4，那就重复步骤 1；  同时，为了保证过期扫描不会出现循环过度，导致线程卡死现象，算法还增加了扫描时间的上限，默认不会超过 25ms。
业务开发人员一定要注意过期时间，如果有大批量的 key 过期，要给过期时间设置一个随机范围，而不宜全部在同一时间过期，分散过期处理的压力：
# 在目标过期时间上增加一天的随机时间 redis.expire_at(key, random.randint(86400) + expire_ts)  从库的过期策略
 从库不会进行过期扫描，从库对过期的处理是被动的。主库在 key 到期时，会在 AOF 文件里增加一条 del 指令，同步到所有的从库，从库通过执行这条 del 指令来删除过期的 key。
因为指令同步是异步进行的，所以主库过期的 key 的 del 指令没有及时同步到从库的话，会出现主从数据的不一致，主库没有的数据在从库里还存在，比如集群环境分布式锁的算法漏洞就是因为这个同步延迟产生的。</description>
    </item>
    
    <item>
      <title>Spring AOP</title>
      <link>https://kunzhao.org/docs/tutorial/spring/spring-aop/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/tutorial/spring/spring-aop/</guid>
      <description>Spring AOP AspectJ5 Pointcut 表达式 语法    表达式 说明     call(Signature) 匹配 Signature 的任何的对于方法或者构造器的调用   execution(Signature) 匹配 Signature 的任何方法或者构造器的执行   get(Signature) 匹配 Signature 的任何的对于字段的引用   set(Signature) 匹配 Signature 的任何的对于字段的赋值   within(TypePattern) every join point from code defined in a type in TypePattern   target(Type or Id) every join point when the target executing object is an instance of Type or Id&amp;rsquo;s type   args(Type or Id, .</description>
    </item>
    
    <item>
      <title>高并发设计方案</title>
      <link>https://kunzhao.org/docs/tutorial/distributed/high-concurrency/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/tutorial/distributed/high-concurrency/</guid>
      <description>高并发设计方案 高并发读 高并发读的设计思路主要是：加缓存 (Redis、MySQL 的 Slave、CDN)、并发读 (异步 RPC、Google 提出的冗余请求)、重写轻读、提前计算好多个表的关联查询 (定时计算、实时计算)、CQRS (Command Query Responsibility Separation 读写分离)
Google 的冗余请求是指：客户端首先发送一个请求，并等待服务器返回，如果一定时间内未返回，则马上给另外一台服务器发送同样的请求，客户端等待第一个响应到达之后，终止其他请求的处理。这个一定的时间是指：95% 请求的响应时间。
微博的重写轻读方案：
每个人的收件箱是存储在内存中的，需要为这个队列 (Redis 的 &amp;lt;key, list&amp;gt; 实现) 设置一个上限，比如 Twitter 设置的上限是 800。
超出 800 的微博放到 MySQL 中，可以按照 user_id、time 等同时进行分片，然后可以再引入二级索引表：&amp;lt;user_id, month, count&amp;gt; 来查询某个用户在某个月份发表的微博的总数量，根据这个表可以快速定位到 offset = 5000 的微博发生在哪个月份，也就是数据库的分片。
至于粉丝数量比较大的，可以读的时候实时聚合，或者叫做拉。
一个人关注的人当中，有的人是推给他的，有的人是需要去拉的，需要聚合两者，再按时间排序，然后分页显示，这就是推拉结合。
读写分离的典型架构：
高并发写 一般采用的思路就是：数据分片 (分库分表)、任务分片 (Map/Reduce、Tomcat 1+N+M)、异步化 (通过队列发送短信验证码)、串行化+多进程单线程+异步I/O
发送短信验证码是异步的：
广告系统的扣费是异步化的：
LSM 树是异步落盘，提高写入性能的：
Pipeline 也属于异步化，Leader 一批批地处理消息：
容量规划  机器数量怎么计算?
 机器数 = 预估总流量/单机容量  分母是预估(通过历史数据估算，过去24小时的调用量分布，取其中的峰值，再乘以一个系数，比如2倍、3倍)的值 分子通过压力测试得到  必须使用峰值测算，不能用均值，虽然持续时间短，可是没办法，的确需要这么多台机器，这也正是云计算 (弹性计算) 要解决的问题。</description>
    </item>
    
    <item>
      <title>Git tag</title>
      <link>https://kunzhao.org/docs/tutorial/git/git-tag/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/tutorial/git/git-tag/</guid>
      <description>Git tag 什么是 Tags Tag 是对某次 commit 的一个有意义的命名，比如某个重大的版本发布，某个重大的 BUG 修复等。如下展示了前端开发框架 React 在开发过程中标记的各个版本的 Tag 列表。
显示版本库的 Tag 列表 git tag 创建 Tag # 在最新的提交是创建一个 Tag git tag myTag # 创建一个带有说明信息的 Tag git tag -m &amp;#34;My fir st annotated tag.&amp;#34; myTag2 删除 Tag git tag -d myTag 重命名 Tag 只能先删除旧的 Tag，然后创建一个新的
将 Tag 推送到远程服务器 # 将 myTag 推送到远程服务器 git push origin myTag # 将本地所有 Tag 推送到远程服务器 git push origin refs/tags/* # 或 git push origin --tags 扫描下面二维码，在手机端阅读：</description>
    </item>
    
    <item>
      <title>Google SRE</title>
      <link>https://kunzhao.org/docs/books/google-sre/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/books/google-sre/</guid>
      <description>Google SRE 一个需要人工阅读邮件和分析警报来决定目前是否需要采取某种行动的系统从本质上就是错误的。
监控系统的 4 个黄金指标：延迟、流量、错误和饱和度。
对于 SRE 而言，自动化是一种力量倍增器，但不是万能的。当然，对力量的倍增并不能改变力量用在哪的准确性：草率地进行自动化可能在解决问题的同时产出其他问题。
自动化的情景通常是自动化管理系统的生命周期，而非系统内部的数据（修改系统中一些账户的某个子集的属性是相当罕见的）：例如，部署新的服务集群。
 Google 内部使用的监控系统与 Prometheus 非常相似。
白盒监控只能看到已经接受到的请求，并不能看到由于 DNS 故障导致没有发送成功的请求，或者是由于软件服务器崩溃而没有返回的错误。Google SRE 团队通常利用探针程序 (prober) 解决该问题，其使用应用级别的自动请求探测目标是否成功返回。
谷歌内部的每一个可执行文件中都默认包含一个 HTTP 服务，提供标准的监控接口。
 我们强调至少将 SRE 团队 50% 的时间花在软件工程上，其余时间，不超过 25% 的时间用来 on-call，另外 25% 用来处理其他运维工作。
  值得警惕的是，理解一个系统应该如何工作并不能使人成为专家。只能靠调查系统为何不能正常工作才行。&amp;mdash;- Brian Redman
 不要过早的归因于小概率事件，“当你听到蹄子声响时，应该先想到马，而不是斑马”
有很多方法可以简化和加速故障排查过程。可能最基本的是:
 增加可观察性。在实现之初就给每个组件增加白盒监控指标和结构化日志。 利用成熟的、观察性好的组件接口设计系统。  使用唯一标识标记所有组件产生的所有相关 RPC。
前端服务器的负载均衡 搜索请求最重要的是延迟，而对于视频上传请求，用户已经预知该请求将要花费一定的时间，但是同时希望该请求能够一次成功，所以最重要的是吞吐量。需求不同，那么决定哪条线路是最优的也是不同的：
 搜索请求发往最近的、可用的数据中心。评价条件是 RTT。 视频上传流采取另外一条路径，也许是一条目前带宽没有占满的链路，来最大化吞吐量，同时牺牲一定程度的延迟。  现实中，许多其他因素也在最优方案的考虑范围内，有些请求会发到稍远一点的数据中心，以保障该数据中心的缓存处于有效状态。
（1）DNS 负载均衡
DNS 返回多个 A 记录，客户端随机选择。有两个问题：
 每条记录都会引来基本相同的请求流量 客户端无法识别最近的地址  优点就是最简单、最有效的负载均衡。
（2）虚拟 IP 负载均衡</description>
    </item>
    
    <item>
      <title>ICMP</title>
      <link>https://kunzhao.org/docs/tutorial/network/icmp/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/tutorial/network/icmp/</guid>
      <description>ICMP ICMP：确认 IP 包是否成功送达目标地址，通知在发送过程中 IP 包被废弃的原因，改善网络配置等。
ICMP 消息类型 无法到达 超时 IP 包有一个字段叫做 TTL，值随着每次经过一次路由器就会减少 1，减到 0 就会被丢弃，此时 IP 路由器将会发送一个 ICMP 超时的消息。
之所以设置 TTL，视为了避免遇到循环路由，无休止转发的问题。
traceroute 可以显示主机到达特定主机前经历了多少路由器，原理就是从 TTL = 1 开始递增发送 UDP 包，强制接受 ICMP 超时消息的一种方法。
ICMP 回送消息 判断数据包是否已经成功到达
ping 命令就是利用这个消息实现的。</description>
    </item>
    
    <item>
      <title>Redis 事务</title>
      <link>https://kunzhao.org/docs/tutorial/redis/redis-transaction/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/tutorial/redis/redis-transaction/</guid>
      <description>Redis 事务 事务的使用 Redis 在形式上分别是 multi/exec/discard。multi 指示事务的开始，exec 指示事务的执行，discard 指示事务的丢弃。
&amp;gt; multi OK &amp;gt; incr books QUEUED &amp;gt; incr books QUEUED &amp;gt; exec (integer) 1 (integer) 2 所有的指令在 exec 之前不执行，而是缓存在服务器的一个事务队列中，服务器一旦收到 exec 指令，才开始执行整个事务队列，执行完毕后一次性返回所有指令的运行结果。因为 Redis 的单线程特性，它不用担心自己在执行队列的时候被其它指令打搅，可以保证他们能得到的「原子性」执行。
Redis 为事务提供了一个 discard 指令，用于丢弃事务缓存队列中的所有指令，在 exec 执行之前。
&amp;gt; get books (nil) &amp;gt; multi OK &amp;gt; incr books QUEUED &amp;gt; incr books QUEUED &amp;gt; discard OK &amp;gt; get books (nil) 我们可以看到 discard 之后，队列中的所有指令都没执行，就好像 multi 和 discard 中间的所有指令从未发生过一样。
不满足原子性 事务的原子性是指要么事务全部成功，要么全部失败，那么 Redis 事务执行是原子性的么？</description>
    </item>
    
    <item>
      <title>Spring WebMVC</title>
      <link>https://kunzhao.org/docs/tutorial/spring/spring-webmvc/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/tutorial/spring/spring-webmvc/</guid>
      <description>Spring WebMVC  Spring 接受前端请求的处理过程，根据 SpringBoot 2.4.2 版本。
 doService 放入各种属性到 request 对象上，然后交给 doDispatch 进行代理转发：
public class DispatcherServlet extends FrameworkServlet { protected void doService(HttpServletRequest request, HttpServletResponse response) throws Exception { // ...  request.setAttribute(WEB_APPLICATION_CONTEXT_ATTRIBUTE, getWebApplicationContext()); request.setAttribute(LOCALE_RESOLVER_ATTRIBUTE, this.localeResolver); request.setAttribute(THEME_RESOLVER_ATTRIBUTE, this.themeResolver); // ...  doDispatch(request, response); } } doDispatcher public class DispatcherServlet extends FrameworkServlet { protected void doDispatch(HttpServletRequest request, HttpServletResponse response) throws Exception { // 用哪个 Handler 链处理请求  mappedHandler = getHandler(processedRequest); // 用哪个 Handler adapter 处理请求  HandlerAdapter ha = getHandlerAdapter(mappedHandler.</description>
    </item>
    
    <item>
      <title>分布式锁 🔒</title>
      <link>https://kunzhao.org/docs/tutorial/distributed/distributed-lock/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/tutorial/distributed/distributed-lock/</guid>
      <description>分布式锁 🔒 MySQL 分布式锁 表记录 CREATE TABLE `database_lock` ( `id` BIGINT NOT NULL AUTO_INCREMENT, `resource` int NOT NULL COMMENT &amp;#39;锁定的资源&amp;#39;, `description` varchar(1024) NOT NULL DEFAULT &amp;#34;&amp;#34; COMMENT &amp;#39;描述&amp;#39;, PRIMARY KEY (`id`), UNIQUE KEY `uiq_idx_resource` (`resource`) ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COMMENT=&amp;#39;数据库分布式锁表&amp;#39;; 获取锁：
INSERT INTO database_lock(resource, description) VALUES (1, &amp;#39;lock&amp;#39;); 释放锁的时，可以删除这条数据：
DELETE FROM database_lock WHERE resource = 1; 缺点：
 这种锁没有失效时间，一旦释放锁的操作失败就会导致锁记录一直在数据库中，其它线程无法获得锁。这个缺陷也很好解决，比如可以做一个定时任务去定时清理。 这种锁的可靠性依赖于数据库。建议设置备库，避免单点，进一步提高可靠性。 这种锁是非阻塞的，因为插入数据失败之后会直接报错，想要获得锁就需要再次操作。如果需要阻塞式的，可以弄个for循环、while循环之类的，直至INSERT成功再返回。 这种锁也是非可重入的，因为同一个线程在没有释放锁之前无法再次获得锁，因为数据库中已经存在同一份记录了。想要实现可重入锁，可以在数据库中添加一些字段，比如获得锁的主机信息、线程信息等，那么在再次获得锁的时候可以先查询数据，如果当前的主机信息和线程信息等能被查到的话，可以直接把锁分配给它。  悲观锁 我们必须关闭 MySQL 数据库的自动提交属性，因为 MySQL 默认使用autocommit 模式，也就是说，当你执行一个更新操作后，MySQL 会立刻将结果进行提交。</description>
    </item>
    
    <item>
      <title>设计循环队列</title>
      <link>https://kunzhao.org/docs/programmer-interview/algorithm/designcircularqueue/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/programmer-interview/algorithm/designcircularqueue/</guid>
      <description>Design Circular Queue 题目 设计循环队列
解法 public class DesignCircularQueue { static class MyCircularQueue { private int[] queue; private int frontIndex; private int rearIndex; private int size; /** Initialize your data structure here. Set the size of the queue to be k. */ public MyCircularQueue(int k) { this.size = k + 1; this.queue = new int[k + 1]; } /** Insert an element into the circular queue. Return true if the operation is successful.</description>
    </item>
    
    <item>
      <title>Git add 和 Git rm</title>
      <link>https://kunzhao.org/docs/tutorial/git/git-add-and-rm/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/tutorial/git/git-add-and-rm/</guid>
      <description>Git add 和 Git rm  git add 用来从工作区向暂存区添加文件 git rm 用来从工作区向暂存区删除文件  git add 示例 git add [--all|-A] git add . git add -u Git 1.X 版本  假设 . 当前指向的目录是 .git 文件所在的目录
 Git 2.X 版本  假设 . 当前指向的目录是 .git 文件所在的目录
 git rm 示例 # 只从工作区删除文件 rm xxx.txt # 只从暂存区删除文件 git rm --cached # 从工作区和暂存区都删除这个文件 git rm xxx.txt # 递归强制删除 xxx_folder 中的所有文件 # -r: recursive # -f: override the up-to-date check git rm -rf xxx_folder 参考  Difference between “git add -A” and “git add .</description>
    </item>
    
    <item>
      <title>IP</title>
      <link>https://kunzhao.org/docs/tutorial/network/ip/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/tutorial/network/ip/</guid>
      <description>IP IP 地址属于网络层,主要功能在 WLAN 内进行路由寻址,选择最佳路由。
IP 报文在互联网上传输时,可能要经历多个物理网络,才能从源主机到达目标主机。比如在手机上给某个 PC 端的朋友发送一个信息,经过无线网的 IEEE 802.1x 认证,转到光纤通信上,然后进入内部企业网 802.3 ,并最终到达目标 PC 。由于不同硬件的物理特性不同,对数据帧的最大长度都有不同的限制,这个最大长度被称为最大传输单元,即 MTU ( Maximum Transmission Unit )。那么在不同的物理网之间就可能需要对 IP 报文进行分片,这个工作通常由路由器负责完成。</description>
    </item>
    
    <item>
      <title>SpringBoot 自动配置原理</title>
      <link>https://kunzhao.org/docs/tutorial/spring/springboot-autoconfig/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/tutorial/spring/springboot-autoconfig/</guid>
      <description>SpringBoot 自动配置原理  application.properties 配置是如何在 Spring Boot 项目中生效的呢？
 扫描 spring.factories 文件 Spring Boot 关于自动配置的源码在spring-boot-autoconfigure-x.x.x.x.jar中。@SpringBootApplication 引用了 @EnableAutoConfiguration：
@Target({ElementType.TYPE}) @Retention(RetentionPolicy.RUNTIME) @Documented @Inherited @SpringBootConfiguration @EnableAutoConfiguration @ComponentScan( excludeFilters = {@Filter( type = FilterType.CUSTOM, classes = {TypeExcludeFilter.class} ), @Filter( type = FilterType.CUSTOM, classes = {AutoConfigurationExcludeFilter.class} )} ) public @interface SpringBootApplication { } @EnableAutoConfiguration 引入了 AutoConfigurationImportSelector.class：
@Target({ElementType.TYPE}) @Retention(RetentionPolicy.RUNTIME) @Documented @Inherited @AutoConfigurationPackage @Import({AutoConfigurationImportSelector.class}) public @interface EnableAutoConfiguration { } AutoConfigurationImportSelector 的 selectImports 方法通过 SpringFactoriesLoader.loadFactoryNames() 扫描所有具有 META-INF/spring.factories 的 jar 包。</description>
    </item>
    
    <item>
      <title>分布式 ID 设计</title>
      <link>https://kunzhao.org/docs/tutorial/distributed/distributed-id/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/tutorial/distributed/distributed-id/</guid>
      <description>分布式 ID 设计 自己设计 ID 类型  QPS 高：那么粒度要粗一些 粒度小：到达毫秒级，每个毫秒预留 10 位顺序号，所以 QPS 最高达到 1024。每毫秒最多产生 1000 多个 ID。  时间同步 使用 Linux 的 crontab 周期性核准服务器时间：
ntpupdate -u pool.ntp.orgpool.ntp.org ReentrantLock 生成序列 long sequence = 0; long lastTimestamp = -1; Lock = new ReentrantLock(); public void populateId(Id id, IdMeta idMeta) { lock.lock(); try { long timestamp = TimeUtils.genTime(); if (timestamp == lastTimestamp) { sequence++; sequence &amp;amp;= idMeta.geSeqBitsMask(); // 比如最多 1024 个  if (sequence == 0) { timestamp = TimeUtils.</description>
    </item>
    
    <item>
      <title>有序数组查找最小和最大元素的位置</title>
      <link>https://kunzhao.org/docs/programmer-interview/algorithm/findfirstandlastpositionofelementinsortedarray/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/programmer-interview/algorithm/findfirstandlastpositionofelementinsortedarray/</guid>
      <description>有序数组查找最小和最大元素的位置 public class FindFirstandLastPositionofElementinSortedArray { public int[] searchRange(int[] nums, int target) { int minIndex = searchMinIndex(nums, target); if (minIndex == -1) { return new int[]{ -1, -1 }; } int maxIndex = searchMaxIndex(nums, target); return new int[] { minIndex, maxIndex }; } private int searchMaxIndex(int[] nums, int target) { int lo = 0; int hi = nums.length - 1; while (lo &amp;lt;= hi) { int m = lo + ((hi - lo) &amp;gt;&amp;gt; 1); if (nums[m] &amp;gt; target) { hi = m - 1; } else if (nums[m] &amp;lt; target) { lo = m + 1; } else { if (m == nums.</description>
    </item>
    
    <item>
      <title>Git push 和 Git pull</title>
      <link>https://kunzhao.org/docs/tutorial/git/git-push-and-pull/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/tutorial/git/git-push-and-pull/</guid>
      <description>Git push 和 Git pull git push 、git pull 用于向远程分支推送文件，以及从远程分支拉取文件等。
远程版本库地址 .git/config 文件中记录了当前仓库远程版本库的地址：
vi .git/config 直接修改这个地址保存后，当前版本库的远程版本库的地址也就变化了。Git 本身也提供了用来操纵版本库地址的命令：
# 添加远程版本库地址 git remote add origin git@github.com:facebook/react.git # 更新远程版本库地址 git remote set-url origin git@github.com:facebook/react.git push 和 pull push 命令和 pull 命令的语法相似：
git push &amp;lt;remote_name&amp;gt; &amp;lt;branch_name&amp;gt; git pull &amp;lt;remote_name&amp;gt; &amp;lt;branch_name&amp;gt; 不带参数，执行命令 git push 的过程（git pull 同理）：
 如果当前分支有 remote（如何知道是否有 remote？还是看 .git/config 文件，如下图所示，每个 branch 的 remote 都不是空的），那么 git push 相当于执行了 git push &amp;lt;remote&amp;gt; 如果没有设置，则相当于执行 git push origin  一般而言，你这个项目本身应该只有一个版本库地址，如下图所示，版本库的名称就叫做 origin，它的地址就是 url 后面的那一部分：</description>
    </item>
    
    <item>
      <title>Redis 运维与优化</title>
      <link>https://kunzhao.org/docs/tutorial/redis/redis_ops/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/tutorial/redis/redis_ops/</guid>
      <description>Redis 运维与优化 Redis 实例的阻塞点 5 个阻塞点：
 集合全量查询和聚合操作； bigkey 删除； 清空数据库； AOF ⽇志同步写； 从库加载 RDB ⽂件。  客户端交互阻塞 Redis中涉及集合的操作复杂度通常为O(N)，我们要在使⽤时重视起来。例如集合元素全量查询操作 HGETALL、SMEMBERS，以及集合的聚合统计操作，例如求交、并和差集。这些操作可以作为Redis的第⼀个个阻塞点：集合全量查询和聚合操作。
除此之外，集合⾃⾝的删除操作同样也有潜在的阻塞⻛险。删除操作的本质是要释放键值对占⽤的内存空间。你可不要⼩瞧内存的释放过程。释放内存只是第⼀步，为了更加⾼效地管理内存空间，在应⽤程序释放内存时，操作系统需要把释放掉的内存块插⼊⼀个空闲内存块的链表，以便后续进⾏管理和再分配。这个过程本⾝需要⼀定时间，⽽且会阻塞当前释放内存的应⽤程序，所以，如果⼀下⼦释放了⼤量内存，空闲内存块链表操作时间就会增加，相应地就会造成Redis主线程的阻塞。
那么，什么时候会释放⼤量内存呢？其实就是在删除⼤量键值对数据的时候，最典型的就是删除包含了⼤量元素的集合，也称为 bigkey 删除。
既然频繁删除键值对都是潜在的阻塞点了，那么，在 Redis 的数据库级别操作中，清空数据库（例如 FLUSHDB 和 FLUSHALL 操作）必然也是⼀个潜在的阻塞⻛险，因为它涉及到删除和释放所有的键值对。所以，这就是 Redis 的第三个阻塞点：清空数据库。
磁盘交互阻塞 Redis 直接记录 AOF ⽇志时，会根据不同的写回策略对数据做落盘保存。⼀个同步写磁盘的操作的耗时⼤约是1~2ms，如果有⼤量的写操作需要记录在AOF⽇志中，并同步写回的话，就会阻塞主线程了。这就得到了Redis的第四个阻塞点：AOF 日志同步写。
主从节点交互阻塞 在主从集群中，主库需要⽣成RDB⽂件，并传输给从库。主库在复制的过程中，创建和传输RDB⽂件都是由⼦进程来完成的，不会阻塞主线程。但是，对于从库来说，它在接收了RDB⽂件后，需要使⽤ FLUSHDB 命令清空当前数据库，这就正好撞上了刚才我们分析的第三个阻塞点。
此外，从库在清空当前数据库后，还需要把RDB⽂件加载到内存，这个过程的快慢和RDB⽂件的⼤⼩密切相关，RDB⽂件越⼤，加载过程越慢，所以，加载 RDB 文件成为了 Redis 的第五个阻塞点。
切片集群实例交互阻塞 如果你使⽤了Redis Cluster⽅案，⽽且同时正好迁移的是bigkey的话，就会造成主线程的阻塞，因为 Redis Cluster 使⽤了同步迁移。
哪些阻塞点可以异步执行 对于Redis的五⼤阻塞点来说，除了“集合全量查询和聚合操作”和“从库加载RDB⽂件”，其他三个阻塞点涉及的操作都不在关键路径上，所以，我们可以使⽤Redis的异步⼦线程机制来实现bigkey删除，清空数据库，以及AOF⽇志同步写。
异步子线程机制 # 异步删除 UNLINK key # 异步清空 FLUSHDB ASYNC FLUSHALL ASYNC  集合全量查询和聚合操作：可以使⽤ SCAN 命令，分批读取数据，再在客⼾端进⾏聚合计算 从库加载 RDB ⽂件：把主库的数据量⼤⼩控制在 2~4GB 左右，以保证 RDB ⽂件能以较快的速度加载  CPU 结构影响性能 CPU 多核 - 上下文切换 context switch是指线程的上下⽂切换，这⾥的上下⽂就是线程的运⾏时信息。在CPU多核的环境中，⼀个线程先在⼀个CPU核上运⾏，之后⼜切换到另⼀个CPU核上运⾏，这时就会发⽣context switch。</description>
    </item>
    
    <item>
      <title>SpringBoot 启动过程</title>
      <link>https://kunzhao.org/docs/tutorial/spring/springboot-startup/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/tutorial/spring/springboot-startup/</guid>
      <description>SpringBoot 启动过程  基于 Spring 的事件发布和监听机制开始说起。
 初始化 启动流程主要分为三个部分，第一部分进行 SpringApplication 的初始化模块，配置一些基本的环境变量、资源、构造器、监听器。
自动配置 @EnableAutoConfiguration 完成了一下功能：
从 classpath 中搜寻所有的 META-INF/spring.factories 配置文件，并将其中 org.springframework.boot.autoconfigure.EnableutoConfiguration 对应的配置项通过反射实例化为对应的标注了 @Configuration 的 JavaConfig 形式的 IoC 容器配置类，然后汇总为一个并加载到 IoC 容器。
加载 ApplicationContextInitializer 加载所有配置的 ApplicationContextInitializer 并进行实例化，加载 ApplicationContextInitializer 是在 SpringFactoriesLoader.loadFactoryNames 方法里面进行的。这个方法会尝试从类路径的 META-INF/spring.factories 读取相应配置文件，然后进行遍历，读取配置文件中Key为：org.springframework.context.ApplicationContextInitializer 的 value。以 spring-boot 这个包为例，它的 META-INF/spring.factories 部分定义如下所示：
# Initializers org.springframework.context.ApplicationContextInitializer=\ org.springframework.boot.context.ConfigurationWarningsApplicationContextInitializer,\ org.springframework.boot.context.ContextIdApplicationContextInitializer,\ org.springframework.boot.context.config.DelegatingApplicationContextInitializer,\ org.springframework.boot.context.embedded.ServerPortInfoApplicationContextInitializer  接口 ApplicationContextInitializer 的定义
 public interface ApplicationContextInitializer&amp;lt;C extends ConfigurableApplicationContext&amp;gt; { /** * Initialize the given application context.</description>
    </item>
    
    <item>
      <title>数据流寻找中位数</title>
      <link>https://kunzhao.org/docs/programmer-interview/algorithm/findmedianfromdatastream/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/programmer-interview/algorithm/findmedianfromdatastream/</guid>
      <description>数据流寻找中位数 import java.util.Comparator; import java.util.PriorityQueue; // https://leetcode.com/problems/find-median-from-data-stream/ // 剑指 Offer 41 题 // public class FindMedianfromDataStream { // 堆顶是最小的  // 最小堆的堆顶是最大值  //  private PriorityQueue&amp;lt;Integer&amp;gt; minQueue = new PriorityQueue&amp;lt;&amp;gt;(); // 堆顶是最大的  // 最大堆的堆顶是最小的值  private PriorityQueue&amp;lt;Integer&amp;gt; maxQueue = new PriorityQueue&amp;lt;&amp;gt;(new Comparator&amp;lt;Integer&amp;gt;() { @Override public int compare(Integer o1, Integer o2) { return o2.compareTo(o1); } }); private boolean sameSize = true; public FindMedianfromDataStream() { } public void addNum(int num) { if (sameSize) { minQueue.</description>
    </item>
    
    <item>
      <title>设计微博系统</title>
      <link>https://kunzhao.org/docs/tutorial/distributed/design-weibo/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/tutorial/distributed/design-weibo/</guid>
      <description>设计微博系统 架构 信息流聚合一般有三种架构：推模式、拉模式以及推拉结合。
针对关注的粉丝量大的用户采用拉模式，而对于一般用户来说，他们的粉丝量有限，采用推模式问题不大，这样的话一个用户要获取所有关注人的微博，一方面要请求粉丝量大的关注人的发件箱列表，另一方面要请求自己的收件箱列表，再把两者聚合在一起就可以得到完整的 Feed 了。虽然推拉结合的方式看似更加合理，但是由此带来的业务复杂度就比较高了，因为用户的粉丝数是不断变化的，所以对于哪些用户使用推模式，哪些用户使用拉模式，维护起来成本就很高了。所以综合考量下来，微博 Feed 采用了拉模式。
前面提到采用拉模式的话，需要拉取所有关注人的发件箱，在关注人只有几十几百个的时候，获取效率还是非常高的。但是当关注人上千以后，耗时就会增加很多，实际验证获取超过 4000 个用户的发件箱，耗时要几百 ms，并且长尾请求（也就是单次请求耗时超过 1s）的概率也会大大增加。为了解决关注人数上千的用户拉取 Feed 效率低的问题，我们采用了分而治之的思想，在拉取之前把用户的关注人分为几组，并行拉取，这样的话就把一次性的聚合计算操作给分解成多次聚合计算操作，最后再把多次聚合计算操作的结果汇总在一起，类似于 MapReduce 的思路。经过我们的实际验证，通过这种方法可以有效地降级关注人数上千用户拉取 Feed 的耗时，长尾请求的数量也大大减少了。
存储 UID range 作为分片 UID hash 作为分片 关系的存储 (1) 最简单的只需要两张表就够了：
用户信息表：
| user_id | user_info | ...用户关系表，表示，follower_user 关注了 followee_user：
| id | follower_user_id | followee_user_id |
查看 user_a 粉丝多少人：
SELECT COUNT(*) FROM table_relation WHERE followee_user = `user_a`; 查看 user_a 关注了多少人：
SELECT COUNT(*) FROM table_relation WHERE follower_user = `user_a`;  (2) 不过随着用户增长，比如达到1亿，那么平均一对用户关系可能就会有100条关系，那么将会扩展到百亿级别。所以必须水平拆分。用户表好选取拆分的键，就是 user_id。不过关系表，根据 follower_user_id 拆分，那么查询这个人关注了多少人好查询，但是查询某个人有多少粉丝，就需要去所有分片上查询汇总了，相反按照 followee_user_id 拆分，那么这个人查询关注了多少人，就不好查询了。也就是总有一半的场景查询效率低下。</description>
    </item>
    
    <item>
      <title>Git commit</title>
      <link>https://kunzhao.org/docs/tutorial/git/git-commit/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/tutorial/git/git-commit/</guid>
      <description>Git commit git commit 可以将暂存区的文件，commit 提交到本地仓库中。
git commit -m -m 代表 message 信息的意思。git commit 需要一个信息作为它的参数，这个信息是对此次 commit 的简短描述，消息应该放到双引号里面。
git commit -m &amp;#34;my brief description about commit&amp;#34;  如果没有携带 -m 参数，Git 也会弹出编辑器让你输入消息的。
 git commit -a -a 选项代表 all，即所有。该选项可以将本地工作区所有改动的/被删除的文件，直接 commit 到仓库中，而无需调用 git add/rm 命令手动添加或删除。
git commit -am &amp;#34;My message&amp;#34;  -a 并不会将新添加的文件 commit 到版本库中。
 git commit &amp;ndash;amend --amend 选项可以让你修改上一次提交的信息。
# 第一次提交信息 git commit -m &amp;#34;my first message&amp;#34; # 你对 my first message 这个描述不满意 # 所以使用下面命令来修正成你想要的信息 git commit --amend -m &amp;#34;an updated commit message&amp;#34; 参考  Git Commit Command Explained  扫描下面二维码，在手机端阅读：</description>
    </item>
    
    <item>
      <title>Redis 使用场景</title>
      <link>https://kunzhao.org/docs/tutorial/redis/redis-scenario/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/tutorial/redis/redis-scenario/</guid>
      <description>Redis 使用场景 聚合统计  统计手机 App 每天的新增用戶数和第二天的留存用戶数，正好对应了聚合统计。
 要完成这个统计任务，我们可以用一个集合记录所有登录过App的用戶ID，同时，用另一个集合记录每一天登录过App的用戶ID。然后，再对这两个集合做聚合统计。我们来看下具体的操作。
记录所有登录过App的用戶ID还是比较简单的，我们可以直接使用Set类型，把key设置为user280680，表示记录的是用戶ID，value就是一个Set集合，里面是所有登录过App的用戶ID，我们可以把这个Set叫作累计用戶Set，如下图所示：
需要注意的是，累计用戶Set中没有日期信息，我们是不能直接统计每天的新增用戶的。所以，我们还需要把每一天登录的用戶ID，记录到一个新集合中，我们把这个集合叫作每日用戶Set，它有两个特点：
   key是user280680以及当天日期，例如user280680:20200803；    value是Set集合，记录当天登录的用戶ID。    在统计每天的新增用戶时，我们只用计算每日用戶Set和累计用戶Set的差集就行。
Set的差集、并集和交集的计算复杂度较高，在数据量较大的情况下，如果直接执行这些计算，会导致Redis实例阻塞。所以，我给你分享一个小建议：你可以从主从集群中选择一个从库，让它专⻔负责聚合计算，或者是把数据读取到客戶端，在客戶端来完成聚合统计者是把数据读取到客戶端，在客戶端来完成聚合统计，这样就可以规避阻塞主库实例和其他从库实例的⻛险了。
排序统计  最新评论列表
 最新评论列表包含了所有评论中的最新留言，这就要求集合类型能对元素保序，也就是说，集合中的元素可以按序排列，这种对元素保序的集合类型叫作有序集合。
在Redis常用的4个集合类型中（List、Hash、Set、Sorted Set），List和Sorted Set就属于有序集合。
List是按照元素进入List的顺序进行排序的，而Sorted Set可以根据元素的权重来排序，我们可以自己来决定每个元素的权重值。比如说，我们可以根据元素插入Sorted Set的时间确定权重值，先插入的元素权重小，后插入的元素权重大。
我先说说用List的情况。每个商品对应一个List，这个List包含了对这个商品的所有评论，而且会按照评论时间保存这些评论，每来一个新评论，就用LPUSH命令把它插入List的队头。
在只有一⻚评论的时候，我们可以很清晰地看到最新的评论，但是，在实际应用中，网站一般会分⻚显示最新的评论列表，一旦涉及到分⻚操作，List就可能会出现问题了。
二值状态统计 所以，如果只需要统计数据的二值状态，例如商品有没有、用戶在不在等，就可以使用Bitmap，因为它只用一个bit位就能表示0或1。在记录海量数据时，Bitmap能够有效地节省内存空间。
String 不适合存储大量键值对 当时，我们要开发一个图片存储系统，要求这个系统能快速地记录图片ID和图片在存储系统中保存时的ID（可以直接叫作图片存储对象ID）。同时，还要能够根据图片ID快速查找到图片存储对象ID。
图片ID和图片存储对象ID正好一一对应，是典型的“键-单值”模式。所谓的“单值”，就是指键值对中的值就是一个值，而不是一个集合，这和String类型提供的“一个键对应一个值的数据”的保存形式刚好契合。
而且，String类型可以保存二进制字节流，就像“万金油”一样，只要把数据转成二进制字节数组，就可以保存了。
刚开始，我们保存了1亿张图片，大约用了6.4GB的内存。但是，随着图片数据量的不断增加，我们的Redis内存使用量也在增加，结果就遇到了大内存Redis实例因为生成RDB而响应变慢的问题。很显然，String类型并不是一种好的选择，我们还需要进一步寻找能节省内存开销的数据类型方案。
String类型并不是适用于所有场合的，它有一个明显的短板，就是它保存数据时所消耗的内存空间较多。
同时，我还仔细研究了集合类型的数据结构。我发现，集合类型有非常节省内存空间的底层实现结构，但是，集合类型保存的数据模式，是一个键对应一系列值，并不适合直接保存单值的键值对。所以，我们就使用二级编码的方法，实现了用集合类型保存单值键值对，Redis实例的内存空间消耗明显下降了。
String 内存开销大 在刚才的案例中，我们保存了1亿张图片的信息，用了约6.4GB的内存，一个图片ID和图片存储对象ID的记录平均用了64字节。
但问题是，一组图片ID及其存储对象ID的记录，实际只需要16字节就可以了。
其实，除了记录实际数据，String类型还需要额外的内存空间记录数据⻓度、空间使用等信息，这些信息也叫作元数据。当实际保存的数据较小时，元数据的空间开销就显得比较大了，有点“喧宾夺主”的意思。
当你保存64位有符号整数时，String类型会把它保存为一个8字节的Long类型整数，这种保存方式通常也叫作int编码方式。
但是，当你保存的数据中包含字符时，String类型就会用简单动态字符串（Simple Dynamic String，SDS）结构体来保存，如下图所示：
可以看到，在SDS中，buf保存实际数据，而len和alloc本身其实是SDS结构体的额外开销。另外，对于String类型来说，除了SDS的额外开销，还有一个来自于RedisObject结构体的开销。
因为Redis的数据类型有很多，而且，不同数据类型都有些相同的元数据要记录（比如最后一次访问的时间、被引用的次数等），所以，Redis会用一个RedisObject结构体来统一记录这些元数据，同时指向实际数据。
一个RedisObject包含了8字节的元数据和一个8字节指针，这个指针再进一步指向具体数据类型的实际数据所在，例如指向String类型的SDS结构所在的内存地址，可以看一下下面的示意图。
为了节省内存空间，Redis还对Long类型整数和SDS的内存布局做了专⻔的设计。
一方面，当保存的是Long类型整数时，RedisObject中的指针就直接赋值为整数数据了，这样就不用额外的指针再指向整数了，节省了指针的空间开销。
另一方面，当保存的是字符串数据，并且字符串小于等于44字节时，RedisObject中的元数据、指针和SDS是一块连续的内存区域，这样就可以避免内存碎片。这种布局方式也被称为embstr编码方式。
当然，当字符串大于44字节时，SDS的数据量就开始变多了，Redis就不再把SDS和RedisObject布局在一起了，而是会给SDS分配独立的空间，并用指针指向SDS结构。这种布局方式被称为raw编码模式。
因为10位数的图片ID和图片存储对象ID是Long类型整数，所以可以直接用int编码的RedisObject保存。每个int编码的RedisObject元数据部分占8字节，指针部分被直接赋值为8字节的整数了。此时，每个ID会使用16字节，加起来一共是32字节。但是，另外的32字节去哪儿了呢？
Redis会使用一个全局哈希表保存所有键值对，哈希表的每一项是一个dictEntry的结构体，用来指向一个键值对。dictEntry结构中有三个8字节的指针，分别指向key、value以及下一个dictEntry，三个指针共24字节，如下图所示：
但是，这三个指针只有24字节，为什么会占用了32字节呢？这就要提到Redis使用的内存分配库jemalloc了。
jemalloc在分配内存时，会根据我们申请的字节数N，找一个比N大，但是最接近N的2的幂次数作为分配的空间，这样可以减少频繁分配的次数。
如果你申请6字节空间，jemalloc实际会分配8字节空间；如果你申请24字节空间，jemalloc则会分配32字节。所以，在我们刚刚说的场景里，dictEntry结构就占用了32字节。
如果要保存的图片有1亿张，那么1亿条的图片ID记录就需要6.4GB内存空间，其中有4.8GB的内存空间都用来保存元数据了，额外的内存空间开销很大。
Hash 类型二级编码保存 在保存单值的键值对时，可以采用基于Hash类型的二级编码方法。这里说的二级编码，就是把一个单值的数据拆分成两部分，前一部分作为Hash集合的key，后一部分作为Hash集合的value，这样一来，我们就可以把单值数据保存到Hash集合中了。</description>
    </item>
    
    <item>
      <title>排查问题</title>
      <link>https://kunzhao.org/docs/tutorial/distributed/troubleshoot/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/tutorial/distributed/troubleshoot/</guid>
      <description>排查问题 一个根本原因，经过一条或几条传播路径，最后表现出某些现象。
监控  服务表现：问题的具体表现（出错、超时），应用日志、依赖服务的状态等 系统状态：操作系统指标（各种资源状态、系统日志等）、VM 指标（主要是 GC） 硬件指标：CPU、内存、网络、硬盘是否达到瓶颈  业务指标可以通过框架输出日志 + ELK/graphite 之类生成图形，系统监控可以用 Cacti/Zabbix 进行监控。
3 分钟  30 秒获取整体服务情况：请求量、响应时间分布、错误码分布，主要利用的就是业务的监控系统 3 分钟了解某台机器的负载情况：最耗 CPU 的线程和函数（CPU）、TCP 连接状态统计和 buffer 堆积状态 （网络）、程序的内存分布、最耗内存的对象（内存）、当前是哪个程序在占用磁盘 I/O、GC 情况。主要用的就是 Linux 和 Java 的一些工具：top、perf、netstat、iftop、jmap、jstat 等 3 分钟了解请求的链路情况：网络传输、系统调用、库函数调用、应用层函数调用的调用链、输入、输出、时长。TCPdump/strace/ltrace/btrace/housemd 等 3 分钟检索当前系统的快照情况：线程栈情况、某个变量的值、存储或缓存里的某个值是什么。jmap/jstack/gdb/pmap 等  保留现场 系统出错，首先要解决问题，通过运维的介入把服务恢复，同时尽量保留现场 （比如保留一台出问题的机器，只摘除不重启）。其次是通过监控、日志初步定为问题原因后，在线下使用测试环境压测、TCPcopy 等复现问题，这时再排除就没什么心理负担了。
请求 block 或者变慢的时候，用 jstack/jmap/jstat 之类的都来一遍，其他类型的 Linux 程序主要会留 gcore 和各种指标类的数据，top/perf/strace。
jdump 命令需要很长时间，线上无法服务，应该先摘掉机器，再进行 dump，如果无法摘，则考虑 btrace/housemd 挂到进程上分析，不过 btrace 可能会导致应用假死，几率是几十分之一，慎用。
 参考  《高可用系统 - 第一卷》  </description>
    </item>
    
    <item>
      <title>旋转有序数组中寻找最小数字</title>
      <link>https://kunzhao.org/docs/programmer-interview/algorithm/findminimuminrotatedsortedarray/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/programmer-interview/algorithm/findminimuminrotatedsortedarray/</guid>
      <description>旋转有序数组中寻找最小数字 // 没有重复元素 // 1 2 3 4 5 6 7 // // 5 6 7 1 2 3 4 // lo hi // public class FindMinimuminRotatedSortedArray { public int findMin(int[] nums) { int lo = 0; // always point to 前半部分  int hi = nums.length - 1; // always point to 后半部分  if (nums[lo] &amp;gt; nums[hi]) { while (lo &amp;lt; hi) { if (hi - lo == 1) { return nums[hi]; } int m = lo + ((hi - lo) &amp;gt;&amp;gt; 1); if (nums[m] &amp;lt; nums[0]) { // middle 位于后半部分  hi = m; } else if (nums[m] &amp;gt; nums[nums.</description>
    </item>
    
    <item>
      <title>Hystrix</title>
      <link>https://kunzhao.org/docs/tutorial/distributed/hystrix/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/tutorial/distributed/hystrix/</guid>
      <description>Hystrix Hystrix 隔离策略  THREAD 隔离：在单独的线程上执行，并发请求受到线程池中线程数量的限制。 SEMAPHORE 隔离：在调用线程上执行，并发请求受到信号计数的限制。  通常情况下，使用信号量隔离的场景，调用量非常的，线程切换开销太高，只适用于非网络调用。</description>
    </item>
    
    <item>
      <title>Redis 6</title>
      <link>https://kunzhao.org/docs/tutorial/redis/redis6/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/tutorial/redis/redis6/</guid>
      <description>Redis 6 介绍 Redis 6 的几个关键新特性。
多线程处理 在 Redis 6.0 中，非常受关注的第一个新特性就是多线程。这是因为，Redis一直被大家熟知的就是它的单线程架构，虽然有些命令操作可以用后台线程或子进程执行（比如数据删除、快照生成、AOF重写），但是，从网络IO处理到实际的读写命令处理，都是由单个线程完成的。
随着网络硬件的性能提升，Redis的性能瓶颈有时会出现在网络IO的处理上，也就是说，单个主线程处理网单个主线程处理网络请求的速度跟不上底层网络硬件的速度络请求的速度跟不上底层网络硬件的速度。
为了应对这个问题，一般有两种方法。
第一种方法是，用用戶态网络协议栈（例如DPDK）取代内核网络协议栈，让网络请求的处理不用在内核里执行，直接在用戶态完成处理就行。
对于高性能的Redis来说，避免频繁让内核进行网络请求处理，可以很好地提升请求处理效率。但是，这个方法要求在Redis的整体架构中，添加对用戶态网络协议栈的支持，需要修改Redis源码中和网络相关的部分（例如修改所有的网络收发请求函数），这会带来很多开发工作量。而且新增代码还可能引入新Bug，导致系统不稳定。所以，Redis 6.0中并没有采用这个方法。
第二种方法就是采用多个IO线程来处理网络请求，提高网络请求处理的并行度。Redis 6.0就是采用的这种方法。
但是，Redis的多IO线程只是用来处理网络请求的，对于读写命令，Redis仍然使用单线程来处理。这是因为，Redis处理请求时，网络处理经常是瓶颈，通过多个IO线程并行处理网络操作，可以提升实例的整体处理性能。而继续使用单线程执行命令操作，就不用为了保证Lua脚本、事务的原子性，额外开发多线程互斥机制了。这样一来，Redis线程模型实现就简单了。
Multiple Reactors 目前 Linux 平台上主流的高性能网络库/框架中，大都采用 Reactor 模式，比如 netty、libevent、libuv、POE(Perl)、Twisted(Python)等。
Reactor 模式本质上指的是使用 I/O 多路复用(I/O multiplexing) + 非阻塞 I/O(non-blocking I/O) 的模式。
单 Reactor 模式，引入多线程之后会进化为 Multi-Reactors 模式，基本工作模式如下：
区别于单 Reactor 模式，这种模式不再是单线程的事件循环，而是有多个线程（Sub Reactors）各自维护一个独立的事件循环，由 Main Reactor 负责接收新连接并分发给 Sub Reactors 去独立处理，最后 Sub Reactors 回写响应给客户端。
Multiple Reactors 模式通常也可以等同于 Master-Workers 模式，比如 Nginx 和 Memcached 等就是采用这种多线程模型，虽然不同的项目实现细节略有区别，但总体来说模式是一致的。
Redis 网络多线程设计思路 Redis 虽然也实现了多线程，但是却不是标准的 Multi-Reactors/Master-Workers 模式：</description>
    </item>
    
    <item>
      <title>寻找峰值元素</title>
      <link>https://kunzhao.org/docs/programmer-interview/algorithm/findpeakelement/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/programmer-interview/algorithm/findpeakelement/</guid>
      <description>寻找峰值元素 题目 你给出一个整数数组(size为n)，其具有以下特点：
 相邻位置的数字是不同的 A[0] &amp;lt; A[1] 并且 A[n - 2] &amp;gt; A[n - 1]  假定P是峰值的位置则满足A[P] &amp;gt; A[P-1]且A[P] &amp;gt; A[P+1]，返回数组中任意一个峰值的位置。
 数组保证至少存在一个峰 如果数组存在多个峰，返回其中任意一个就行 数组至少包含 3 个数   微软面试题
 解法 // https://www.lintcode.com/problem/find-peak-element/description // // Microsoft // A[P] &amp;gt; A[P-1] &amp;amp;&amp;amp; A[P] &amp;gt; A[P+1] public class FindPeakElement { // 返回的是索引  //  // 数组太大的话，会超时  public int findPeak(int[] A) { // [x,x,x,x,x]  int lo = 1; int hi = A.</description>
    </item>
    
    <item>
      <title>架构案例参考</title>
      <link>https://kunzhao.org/docs/tutorial/distributed/architecture-cases/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/tutorial/distributed/architecture-cases/</guid>
      <description>架构案例参考 本文收集了一些其他文章中所写的，在做系统设计时候的对于一些案例的思考。
在腾讯 QQ 的红包活动中，对于活动的展示、错峰的内容、预下载资源的内容等，都是采取的全局配置策略进行全局控制的。而为了让用户能够错峰进入活动，避免给后台带来瞬间冲击的问题，其采用 uid % gap 的方式对用户的进入时间进行了错峰划分，但是这样带来的问题是有可能身边的人都看到活动入口了，但是自己还看不到入口，所以还应该将地理位置因素也考虑进去：
 根据用户地理位置 adcode 和错峰配置进行映射，得到映射后的分区索引 i； 计算得到一次错峰时间：T1 = T0 + i*interval； 对于同一批次的用户，通过随机时间，将这些用户随机均匀地映射分布到对应较小的时间段内，计算得到二次错峰时间：T2 = T1 + hash(uin)%interval； 得到的二次错峰时间T2即为用户实际可以看到入口参与活动的时间：T = T2； 对于地理位置一次错峰可能出现的异常情况，如用户未授权获取地理位置（占比30%左右）、国外用户无adcode未匹配到分区索引等，客户端可采取一定的兜底策略，如根据用户账号uin进行随机映射到某个分区：i = hash(uin) % regions.count 。  而在活动期间产生的数据的上报流程如下所示，可以看到其上报的时机、上报的方式等都支持非常灵活的调整策略：
而在上报的链路中，SSO接入层和上报服务后台也分别用过载策略和降级策略来应对过载的风险，其后台接口中包含了 reportLevel 和 reportLevelTime 这两个上报降级信息字段。
参考  大流量冲击下，腾讯QQ客户端如何保障春节红包活动的用户体验？  </description>
    </item>
    
    <item>
      <title>寻找重复数字</title>
      <link>https://kunzhao.org/docs/programmer-interview/algorithm/findtheduplicatenumber/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/programmer-interview/algorithm/findtheduplicatenumber/</guid>
      <description>寻找重复数字 // Given an array nums containing n + 1 integers where each integer is between 1 and n (inclusive), // prove that at least one duplicate number must exist. // Assume that there is only one duplicate number, find the duplicate one. // // 1 到 n 的数字，某个数字重复，可能重复次数 &amp;gt; 1 // // Input: [3,1,3,4,2] // Output: 3 // // https://leetcode.com/problems/find-the-duplicate-number/ public class FindtheDuplicateNumber { // ==================================  // 数组不允许修改版本  //  // 剑指 Offer  // ==================================  public int findDuplicate(int[] nums) { int lo = 1; int hi = nums.</description>
    </item>
    
    <item>
      <title>设计 Youtube</title>
      <link>https://kunzhao.org/docs/tutorial/distributed/design-youtube/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/tutorial/distributed/design-youtube/</guid>
      <description>设计 Youtube 参考  How to Design Youtube (Part II)  </description>
    </item>
    
    <item>
      <title>第一个缺失的最小正数</title>
      <link>https://kunzhao.org/docs/programmer-interview/algorithm/firstmissingpositive/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/programmer-interview/algorithm/firstmissingpositive/</guid>
      <description>第一个缺失的最小正数 import java.util.ArrayList; import java.util.Collections; import java.util.HashSet; import java.util.List; import java.util.Set; // https://leetcode.com/problems/first-missing-positive/ // Given an unsorted integer array, find the smallest missing positive integer. // // Input: [3,4,-1,1] // Output: 2 // // Input: [7,8,9,11,12] // Output: 1 // public class FirstMissingPositive { // ===============================  // 不使用辅助空间  //  // 最核心的是，遇见哪些数字可以不用管:  // - 负数  // - 大于 nums.length 的数  // ===============================  public int firstMissingPositive(int[] nums) { int i = 0; while (i &amp;lt; nums.</description>
    </item>
    
    <item>
      <title>数据流的第一个唯一数字</title>
      <link>https://kunzhao.org/docs/programmer-interview/algorithm/firstuniquenumberindatastream/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/programmer-interview/algorithm/firstuniquenumberindatastream/</guid>
      <description>数据流的第一个唯一数字 import java.util.HashMap; import java.util.LinkedHashMap; import java.util.Map; // https://www.lintcode.com/problem/first-unique-number-in-data-stream/description // // 给一个连续的数据流,写一个函数返回终止数字到达时的第一个唯一数字（包括终止数字）, // 如果在终止数字前无唯一数字或者找不到这个终止数字, 返回 -1. public class FirstUniqueNumberinDataStream { public int firstUniqueNumber(int[] nums, int number) { boolean hasStopNumber = false; HashMap&amp;lt;Integer, Integer&amp;gt; map = new LinkedHashMap&amp;lt;&amp;gt;(); for (int i = 0; i &amp;lt; nums.length; i++) { int count= map.getOrDefault(nums[i], 0); map.put(nums[i], count + 1); if (nums[i] == number) { hasStopNumber = true; break; } } if (!hasStopNumber) { return -1; } for (Map.</description>
    </item>
    
    <item>
      <title>设计 tinyURL</title>
      <link>https://kunzhao.org/docs/tutorial/distributed/design-tinyurl/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/tutorial/distributed/design-tinyurl/</guid>
      <description>设计 TinyURL 设计一个 TinyURL 服务，当输入 https://leetcode.com/problems/design-tinyurl 时，返回 http://tinyurl.com/4e9iAk。
基础想法，a-zA-Z0-9 有 62 个字符，所以可以随机生成一个长度为 6 位的字符串。只要重复了，就一直不停的循坏调用直到生成一个不重复的。
import java.util.concurrent.ThreadLocalRandom; class Codec { static final Map&amp;lt;String, String&amp;gt; shortToLongMap = new HashMap&amp;lt;String, String&amp;gt;(); static final Map&amp;lt;String, String&amp;gt; LongToShortMap = new HashMap&amp;lt;String, String&amp;gt;(); static final String BASE_HOST = &amp;#34;http://tinyurl.com/&amp;#34;; static final int K = 6; // Encodes a URL to a shortened URL.  public String encode(String longUrl) { if(LongToShortMap.containsKey(longUrl)) return LongToShortMap.get(longUrl); String shortUrl = generateRandomShortUrl(); while(shortToLongMap.</description>
    </item>
    
    <item>
      <title>插入区间</title>
      <link>https://kunzhao.org/docs/programmer-interview/algorithm/insertinterval/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/programmer-interview/algorithm/insertinterval/</guid>
      <description>插入区间 import java.util.ArrayList; import java.util.Collections; import java.util.Comparator; import java.util.List; import com.zk.algorithm.beans.Interval; // Input: intervals = [[1,2],[3,5],[6,7],[8,10],[12,16]], newInterval = [4,8] // Output: [[1,2],[3,10],[12,16]] // Explanation: Because the new interval [4,8] overlaps with [3,5],[6,7],[8,10]. public class InsertInterval { // 插入一个新的 interval  // 如果有交集，那么合并  public List&amp;lt;Interval&amp;gt; insert(List&amp;lt;Interval&amp;gt; intervals, Interval newInterval) { intervals.add(newInterval); Collections.sort(intervals, new Comparator&amp;lt;Interval&amp;gt;() { public int compare(Interval a, Interval b) { if (a.start &amp;lt; b.start) { return -1; } else if (a.</description>
    </item>
    
    <item>
      <title>数组交集</title>
      <link>https://kunzhao.org/docs/programmer-interview/algorithm/intersectionoftwoarrays/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/programmer-interview/algorithm/intersectionoftwoarrays/</guid>
      <description>数组交集 方法一 // // Input: nums1 = [4,9,5], nums2 = [9,4,9,8,4] // Output: [9,4] // public class IntersectionofTwoArrays { public int[] intersection(int[] nums1, int[] nums2) { Set&amp;lt;Integer&amp;gt; set1 = toSet(nums1); Set&amp;lt;Integer&amp;gt; set2 = toSet(nums2); return findIntersection(set1, set2); } private int[] findIntersection(Set&amp;lt;Integer&amp;gt; set1, Set&amp;lt;Integer&amp;gt; set2) { List&amp;lt;Integer&amp;gt; list = new ArrayList&amp;lt;&amp;gt;(); for (int num: set2) { if (set1.contains(num)) { list.add(num); } } int[] res = new int[list.size()]; for (int i = 0; i &amp;lt; list.</description>
    </item>
    
    <item>
      <title>最小的K个数</title>
      <link>https://kunzhao.org/docs/programmer-interview/algorithm/ksmallestnuminanarray/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/programmer-interview/algorithm/ksmallestnuminanarray/</guid>
      <description>最小的K个数 import java.util.ArrayList; // 牛客网 // https://www.nowcoder.com/practice/6a296eb82cf844ca8539b57c23e6e9bf // 最小的 k 个数 // public class KSmallestNumInAnArray { public ArrayList&amp;lt;Integer&amp;gt; GetLeastNumbers_Solution(int[] input, int k) { int lo = 0; int hi = input.length - 1; while (lo &amp;lt;= hi) { int kth = partition(input, lo, hi); if (kth == k - 1) { ArrayList&amp;lt;Integer&amp;gt; res = new ArrayList&amp;lt;&amp;gt;(); for (int i = 0; i &amp;lt; k; i++) { res.add(input[i]); } return res; } else if (kth &amp;lt; k - 1) { lo = kth + 1; } else { hi = kth - 1; } } return new ArrayList&amp;lt;Integer&amp;gt;(); } private int partition(int[] nums, int lo, int hi) { int left = lo - 1; int pivot = nums[hi]; for (int i = lo; i &amp;lt;= hi - 1; i++) { if (nums[i] &amp;lt;= pivot) { swap(nums, ++left, i); } } swap(nums, left + 1, hi); return left + 1; } private void swap(int[] nums, int i, int j) { int tmp = nums[i]; nums[i] = nums[j]; nums[j] = tmp; } } </description>
    </item>
    
    <item>
      <title>绝对值差为K的数对数量</title>
      <link>https://kunzhao.org/docs/programmer-interview/algorithm/kdiffpairsinanarray/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/programmer-interview/algorithm/kdiffpairsinanarray/</guid>
      <description>绝对值差为K的数对数量 描述 给定一个整数数组和一个整数k，您需要找到数组中唯一k-diff对的数量。这里k-diff对被定义为整数对(i, j)，其中i和j都是数组中的数字，它们的绝对差是k。
 对(i,j)和(j,i)计为同一对。 数组的长度不超过10,000。 给定输入中的所有整数都属于以下范围：[ -1e7, 1e7]。  答案 import java.util.Arrays; // https://www.lintcode.com/problem/k-diff-pairs-in-an-array/description // Amazon // // 这个 pair 差的绝对值 == k public class KdiffPairsinanArray { // O(n^2)  public int findPairs(int[] nums, int k) { Arrays.sort(nums); int count = 0; for (int i = 0; i &amp;lt; nums.length - 1; i++) { if (i &amp;gt; 0 &amp;amp;&amp;amp; nums[i] == nums[i - 1]) { continue; } for (int j = i + 1; j &amp;lt; nums.</description>
    </item>
    
    <item>
      <title>第 K 个最大的数字</title>
      <link>https://kunzhao.org/docs/programmer-interview/algorithm/kthlargestelement/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/programmer-interview/algorithm/kthlargestelement/</guid>
      <description>第 K 个最大的数字 数组中的第 K 个最大数字 // 数组无序 public class KthLargestElementinanArray { public int findKthLargest(int[] nums, int k) { k = nums.length - k; // 1 2 3 4 5 6  // ↑(第 2 大)  // ↑(partition = 2 的时候，实际上指向的是这里)  int lo = 0; int hi = nums.length - 1; // ==========================  // while (lo &amp;lt; hi)  // nums = [1]，这种情况进入不了循环  //  // ==========================  while (lo &amp;lt;= hi) { int index = partition(nums, lo, hi); if (index == k) { return nums[index]; } else if (index &amp;lt; k) { lo = index + 1; } else { hi = index - 1; } } return -1; } private int partition(int[] nums, int lo, int high) { int i = lo - 1; int pivot = nums[high]; for (int j = lo; j &amp;lt;= high - 1; j++) { if (nums[j] &amp;lt;= pivot) { i++; swap(nums, i, j); } } swap(nums, i + 1, high); return i + 1; } private void swap(int[] array, int i, int j) { int temp = array[i]; array[i] = array[j]; array[j] = temp; } } 数据流中的第 K 个最大数字  堆  import java.</description>
    </item>
    
    <item>
      <title>第 K 个最小的数字</title>
      <link>https://kunzhao.org/docs/programmer-interview/algorithm/kthsmallestelement/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/programmer-interview/algorithm/kthsmallestelement/</guid>
      <description>第 K 个最小的数字 9 * 9 乘法表中的第 K 个最小数字 // http://exercise.acmcoder.com/online/online_judge_ques?ques_id=3819&amp;amp;konwledgeId=40 // https://leetcode.com/problems/kth-smallest-number-in-multiplication-table/ // // 百度乘法表 // 9 * 9 乘法表 // public class KthSmallestNumberinMultiplicationTable { public int findKthNumber(int m, int n, int k) { int lo = 1; int hi = m * n; while (lo &amp;lt;= hi) { int middle = lo + ((hi - lo) &amp;gt;&amp;gt; 1); int count = countLessOrEqualK(m, n, middle); if (count &amp;lt; k) { lo = middle + 1; } else { hi = middle - 1; } } return lo; } private int countLessOrEqualK(int m, int n, int k) { int c = 0; for (int i = 1; i &amp;lt;= m; i++) { // 1 2 3 4  // 2 4 6 8  // 3 6 9 12  //  // k = 5  // - k &amp;gt;= 第 1 行的 (1 2 3 4) 最后的 4，所以 c += n 个  // - k &amp;lt; 第 2 行的 (2 4 6 8) 最后的 8，所以 c += k / i 个  //  if (k &amp;gt;= n * i) { c += n; } else { c += k / i; } } return c; } } 行或列均有序的矩阵中的第 K 个最小数字 // matrix = [ // [ 1, 5, 9], // [10, 11, 13], // [12, 13, 15] // ], // k = 8,  // return 13.</description>
    </item>
    
    <item>
      <title>数组元素所能拼成的最大数字</title>
      <link>https://kunzhao.org/docs/programmer-interview/algorithm/largestnumber/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/programmer-interview/algorithm/largestnumber/</guid>
      <description>数组元素所能拼成的最大数字 import java.util.ArrayList; import java.util.Collections; import java.util.Comparator; import java.util.List; public class LargestNumber { public String largestNumber(int[] nums) { List&amp;lt;String&amp;gt; numList = toList(nums); Collections.sort(numList, new Comparator&amp;lt;String&amp;gt;() { @Override public int compare(String a, String b) { return (b + a).compareTo(a + b); } }); final StringBuilder sb = new StringBuilder(); for (String str: numList) { sb.append(str); } String res = sb.toString(); if (allZero(res)) { return &amp;#34;0&amp;#34;; } return res; } private boolean allZero(String str) { for (char c: str.</description>
    </item>
    
    <item>
      <title>柱状图中最大的矩形</title>
      <link>https://kunzhao.org/docs/programmer-interview/algorithm/largestrectangleinhistogram/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/programmer-interview/algorithm/largestrectangleinhistogram/</guid>
      <description>柱状图中最大的矩形 描述 题目来源
给定 n 个非负整数，用来表示柱状图中各个柱子的高度。每个柱子彼此相邻，且宽度为 1 。求在该柱状图中，能够勾勒出来的矩形的最大面积。
题解 // https://leetcode.com/problems/largest-rectangle-in-histogram/ 直方图 // __ // __| | // | | | // | | | __ // __ | | |__| | // | |__| | | | | // |__|__|__|__|__|__| // public class LargestRectangleinHistogram { public int largestRectangleArea(int[] heights) { // =================================  // 左边最多延展到哪个索引  // =================================  // 左边比自己大的或相等的  //  // 单调栈找到第一个比自己大的或者小的数字  int[] left = new int[heights.</description>
    </item>
    
    <item>
      <title>最长序列</title>
      <link>https://kunzhao.org/docs/programmer-interview/algorithm/longestsequence/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/programmer-interview/algorithm/longestsequence/</guid>
      <description>最长序列 最长连续递增相差为 1 的序列 import java.util.Arrays; // [100, 4, 200, 1, 3, 2] // // 必须是连续的 1 2 3 4 差值为 1 public class LongestConsecutiveSequence { public int longestConsecutive(int[] nums) { if (nums.length == 0) { return 0; } Arrays.sort(nums); int longestStreak = 1; int currentStreak = 1; for (int i = 1; i &amp;lt; nums.length; i++) { if (nums[i] != nums[i - 1]) { if (nums[i] == nums[i - 1] + 1) { currentStreak += 1; } else { longestStreak = Math.</description>
    </item>
    
    <item>
      <title>找出过半数的元素</title>
      <link>https://kunzhao.org/docs/programmer-interview/algorithm/majorityelement/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/programmer-interview/algorithm/majorityelement/</guid>
      <description>找出过半数的元素 // Given an array of size n, find the majority element. // The majority element is the element that appears more than ⌊ n/2 ⌋ times. // You may assume that the array is non-empty and the majority element always exist in the array. // public class MajorityElement { public int majorityElement(int[] nums) { int candidate = nums[0]; int count = 1; for (int i = 1; i &amp;lt; nums.</description>
    </item>
    
    <item>
      <title>最大的岛屿</title>
      <link>https://kunzhao.org/docs/programmer-interview/algorithm/maxareaofisland/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/programmer-interview/algorithm/maxareaofisland/</guid>
      <description>最大的岛屿 // 时间复杂度 O(row * col)，因为每个小方格访问一次 // public class MaxAreaofIsland { public int maxAreaOfIsland(int[][] grid) { int row = grid.length; int col = grid[0].length; boolean[][] visited = new boolean[row][col]; int max = 0; for (int r = 0; r &amp;lt; row; r++) { for (int c = 0; c &amp;lt; col; c++) { max = Math.max(maxArea(grid, visited, r, c), max); } } return max; } private int maxArea(int[][] grid, boolean[][] visited, int r, int c) { if (r &amp;lt; 0 || r &amp;gt;= grid.</description>
    </item>
    
    <item>
      <title>直线上最多的点数</title>
      <link>https://kunzhao.org/docs/programmer-interview/algorithm/maxpointsonaline/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/programmer-interview/algorithm/maxpointsonaline/</guid>
      <description>直线上最多的点数 描述 题目 给定一个二维平面，平面上有 n 个点，求最多有多少个点在同一条直线上。
输入: [[1,1],[3,2],[5,3],[4,1],[2,3],[1,4]]
输出: 4
解释:
^|| o| o o| o| o o+-------------------&amp;gt;0 1 2 3 4 5 6题解 public class MaxPointsonaLine { public int maxPoints(Point[] points) { if (points.length &amp;lt;= 1) { return points.length; } int max = 0; for (int i = 0; i &amp;lt; points.length - 1; i++) { for (int j = i + 1; j &amp;lt; points.</description>
    </item>
    
    <item>
      <title>最大的矩形</title>
      <link>https://kunzhao.org/docs/programmer-interview/algorithm/maximalrectangle/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/programmer-interview/algorithm/maximalrectangle/</guid>
      <description>最大的矩形 描述 题目 给定一个仅包含 0 和 1 的二维二进制矩阵，找出只包含 1 的最大矩形，并返回其面积。
输入:[[&amp;quot;1&amp;quot;,&amp;quot;0&amp;quot;,&amp;quot;1&amp;quot;,&amp;quot;0&amp;quot;,&amp;quot;0&amp;quot;],[&amp;quot;1&amp;quot;,&amp;quot;0&amp;quot;,&amp;quot;1&amp;quot;,&amp;quot;1&amp;quot;,&amp;quot;1&amp;quot;],[&amp;quot;1&amp;quot;,&amp;quot;1&amp;quot;,&amp;quot;1&amp;quot;,&amp;quot;1&amp;quot;,&amp;quot;1&amp;quot;],[&amp;quot;1&amp;quot;,&amp;quot;0&amp;quot;,&amp;quot;0&amp;quot;,&amp;quot;1&amp;quot;,&amp;quot;0&amp;quot;]]输出: 6答案 // Given a matrix: // [ // [1, 1, 0, 0, 1], // [0, 1, 0, 0, 1], // [0, 0, 1, 1, 1], // [0, 0, 1, 1, 1], // [0, 0, 0, 0, 1] // ] // return 6. public class MaximalRectangle { public int maximalRectangle(boolean[][] matrix) { if (matrix == null || matrix.</description>
    </item>
    
    <item>
      <title>子数组的最大平均值</title>
      <link>https://kunzhao.org/docs/programmer-interview/algorithm/maximumaveragesubarray/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/programmer-interview/algorithm/maximumaveragesubarray/</guid>
      <description>子数组的最大平均值 描述 原题 给定一个由 n 个整数组成的数组，找到给定长度 k 的连续子数组，该子数组具有最大平均值。你需要输出最大平均值。
答案  前缀和  // https://www.lintcode.com/problem/maximum-average-subarray/description // 给定一个由 n 个整数组成的数组，找到给定长度 k 的连续子数组，该子数组具有最大平均值。你需要输出最大平均值。 // 注意这个长度 k 是固定的 // public class MaximumAverageSubarray { public double findMaxAverage(int[] nums, int k) { int[] prefixSum = prefixSum(nums); int maxSum = 0; for (int i = k; i &amp;lt; prefixSum.length; i++) { maxSum = Math.max(maxSum, prefixSum[i] - prefixSum[i - k]); } return maxSum * 1.0 / k; } private int[] prefixSum(int[] nums) { int[] prefixSum = new int[nums.</description>
    </item>
    
    <item>
      <title>连续子数组最大乘积</title>
      <link>https://kunzhao.org/docs/programmer-interview/algorithm/maximumproductsubarray/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/programmer-interview/algorithm/maximumproductsubarray/</guid>
      <description>连续子数组最大乘积 // 连续子数组最大乘积 public class MaximumProductSubarray { public int maxProduct(int[] nums) { int min = nums[0]; int max = nums[0]; int ans = nums[0]; for (int i = 1; i &amp;lt; nums.length; i++) { // ==============================  // max 值基于更新后的 min 值进行了计算  // ==============================  int A = nums[i] * min; int B = nums[i] * max; min = min(A, B, nums[i]); max = max(A, B, nums[i]); if (max &amp;gt; ans) { ans = max; } } return ans; } private int min(int.</description>
    </item>
    
    <item>
      <title>最大子数组之和为 K</title>
      <link>https://kunzhao.org/docs/programmer-interview/algorithm/maximumsizesubarraysumequalsk/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/programmer-interview/algorithm/maximumsizesubarraysumequalsk/</guid>
      <description>最大子数组之和为 K  微软
 描述 给一个数组nums和目标值k，找到数组中最长的子数组，使其中的元素和为k。如果没有，则返回0。
 数组之和保证在32位有符号整型数的范围内
 题解  前缀和 + Map  import java.util.HashMap; import java.util.Map; // https://www.lintcode.com/problem/maximum-size-subarray-sum-equals-k/description // Facebook // // 微软面试题 // longest consecutive sequence of numbers that sum to K // https://www.1point3acres.com/bbs/thread-541121-1-1.html // // 给一个数组nums和目标值k，找到数组中最长的子数组，使其中的元素和为k。如果没有，则返回0。 // // ↓ ↓ (k = 17) // 2 [ 3 5 6 3 ] 8 public class MaximumSizeSubarraySumEqualsk { public int maxSubArrayLen(int[] nums, int k) { int[] prefixSum = prefixSum(nums); // 感觉就是跟 two sum 似的  // 借助 map 直接让复杂度降低了  Map&amp;lt;Integer, Integer&amp;gt; map = new HashMap&amp;lt;&amp;gt;(); // 左边的边界  map.</description>
    </item>
    
    <item>
      <title>最大子矩阵</title>
      <link>https://kunzhao.org/docs/programmer-interview/algorithm/maximumsubmatrix/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/programmer-interview/algorithm/maximumsubmatrix/</guid>
      <description>最大子矩阵 描述 原题 给出一个大小为 n x n 的矩阵，里面元素为 正整数 和 负整数 ，找到具有最大和的子矩阵。
输入:matrix = [[1,3,-1],[2,3,-2],[-1,-2,-3]]输出: 9解释:具有最大和的子矩阵是:[[1,3],[2,3]]题解  二维数组的前缀和  // https://www.lintcode.com/problem/maximum-submatrix/description // // Given an n x n matrix of positive and negative integers, // find the submatrix with the largest possible sum. // public class MaximumSubmatrix { public int maxSubmatrix(int[][] matrix) { if (matrix == null || matrix.</description>
    </item>
    
    <item>
      <title>最大的交换</title>
      <link>https://kunzhao.org/docs/programmer-interview/algorithm/maximumswap/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/programmer-interview/algorithm/maximumswap/</guid>
      <description>最大的交换 描述 原题 给定一个非负整数, 你可以选择交换它的两个数位. 返回你能获得的最大的合法的数.
 给定的数字在 [0, 10^8] 范围内
 输入: 2736输出: 7236解释: 交换数字2和数字7.题解 // https://www.lintcode.com/problem/maximum-swap/description // // 给定一个非负整数, 你可以选择交换它的两个数位. 返回你能获得的最大的合法的数. // // 输入: 2736 // 输出: 7236 // 解释: 交换数字2和数字7. // // 给定的数字在 [0, 10^8] 范围内 public class MaximumSwap { public static void main(String...args) { MaximumSwap maximumSwap = new MaximumSwap(); System.out.println(maximumSwap.maximumSwap0(98368)); System.out.println(maximumSwap.maximumSwap0(1993)); } public int maximumSwap0(int num) { char[] arr = String.valueOf(num).toCharArray(); int[] max = new int[arr.</description>
    </item>
    
    <item>
      <title>两个有序数组合并后的中位数</title>
      <link>https://kunzhao.org/docs/programmer-interview/algorithm/medianoftwosortedarrays/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/programmer-interview/algorithm/medianoftwosortedarrays/</guid>
      <description>两个有序数组合并后的中位数  微软
 题解 public class MedianofTwoSortedArrays { public double findMedianSortedArrays(int[] nums1, int[] nums2) { int n = nums1.length + nums2.length; if (n % 2 == 1) { return findKth(nums1, nums2, 0, nums1.length - 1, 0, nums2.length - 1, n / 2 + 1); } else { double a = findKth(nums1, nums2, 0, nums1.length - 1, 0, nums2.length - 1, n / 2); double b = findKth(nums1, nums2, 0, nums1.</description>
    </item>
    
    <item>
      <title>合并区间</title>
      <link>https://kunzhao.org/docs/programmer-interview/algorithm/mergeintervals/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/programmer-interview/algorithm/mergeintervals/</guid>
      <description>合并区间 描述 原题 给出一个区间的集合，请合并所有重叠的区间。
输入: [[1,3],[2,6],[8,10],[15,18]]输出: [[1,6],[8,10],[15,18]]解释: 区间 [1,3] 和 [2,6] 重叠, 将它们合并为 [1,6].题解 // Input: [[1,3],[2,6],[8,10],[15,18]] // Output: [[1,6],[8,10],[15,18]] // Explanation: Since intervals [1,3] and [2,6] overlaps, merge them into [1,6]. // // 56: https://leetcode.com/problems/merge-intervals/ public class MergeIntervals { public List&amp;lt;Interval&amp;gt; merge(List&amp;lt;Interval&amp;gt; intervals) { if (intervals == null || intervals.isEmpty()) { return Collections.emptyList(); } Collections.sort(intervals, new Comparator&amp;lt;Interval&amp;gt;() { @Override public int compare(Interval a, Interval b) { if (a.</description>
    </item>
    
    <item>
      <title>合并 K 个有序数组</title>
      <link>https://kunzhao.org/docs/programmer-interview/algorithm/mergeksortedarrays/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/programmer-interview/algorithm/mergeksortedarrays/</guid>
      <description>合并 K 个有序数组 题解  优先级队列  import java.util.PriorityQueue; // https://www.lintcode.com/problem/merge-k-sorted-arrays/description // public class MergeKSortedArrays { public int[] mergekSortedArrays(int[][] arrays) { PriorityQueue&amp;lt;Integer&amp;gt; queue = new PriorityQueue&amp;lt;&amp;gt;(); int n = 0; for (int i = 0; i &amp;lt; arrays.length; i++) { for (int j = 0; j &amp;lt; arrays[i].length; j++) { n++; queue.offer(arrays[i][j]); } } int[] sortedArr = new int[n]; int index = 0; while (!queue.isEmpty()) { sortedArr[index++] = queue.poll(); } return sortedArr; } } </description>
    </item>
    
    <item>
      <title>长度最小的子数组</title>
      <link>https://kunzhao.org/docs/programmer-interview/algorithm/minimumsizesubarraysum/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/programmer-interview/algorithm/minimumsizesubarraysum/</guid>
      <description>长度最小的子数组 描述 题目 给定一个含有 n 个正整数的数组和一个正整数 s ，找出该数组中满足其和 ≥ s 的长度最小的 连续 子数组，并返回其长度。如果不存在符合条件的子数组，返回 0。
输入：s = 7, nums = [2,3,1,2,4,3]输出：2解释：子数组 [4,3] 是该条件下的长度最小的子数组。题解 // Given an array of n positive integers and a positive integer s, // find the minimal length of a contiguous subarray of which the sum ≥ s. If there isn&amp;#39;t one, return 0 instead. // // Input: s = 7, nums = [2,3,1,2,4,3] // Output: 2 // Explanation: the subarray [4,3] has the minimal length under the problem constraint.</description>
    </item>
    
    <item>
      <title>数据流滑动窗口平均值</title>
      <link>https://kunzhao.org/docs/programmer-interview/algorithm/movingaveragefromdatastream/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/programmer-interview/algorithm/movingaveragefromdatastream/</guid>
      <description>数据流滑动窗口平均值 描述 原题 给出一串整数流和窗口大小，计算滑动窗口中所有整数的平均值。
题解 import java.util.LinkedList; import java.util.Queue; // https://www.lintcode.com/problem/moving-average-from-data-stream/description // 给出一串整数流和窗口大小，计算滑动窗口中所有整数的平均值。 // // MovingAverage m = new MovingAverage(3); // m.next(1) = 1 // 返回 1.00000 // m.next(10) = (1 + 10) / 2 // 返回 5.50000 // m.next(3) = (1 + 10 + 3) / 3 // 返回 4.66667 // m.next(5) = (10 + 3 + 5) / 3 // 返回 6.00000 // public class MovingAveragefromDataStream { private final int size; private final Queue&amp;lt;Integer&amp;gt; queue = new LinkedList&amp;lt;&amp;gt;(); private double sum; /* * @param size: An integer */ public MovingAveragefromDataStream(int size) { this.</description>
    </item>
    
    <item>
      <title>下一个更大元素 II</title>
      <link>https://kunzhao.org/docs/programmer-interview/algorithm/nextgreaterelementii/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/programmer-interview/algorithm/nextgreaterelementii/</guid>
      <description>下一个更大元素 II 描述 原题 给定一个循环数组（最后一个元素的下一个元素是数组的第一个元素），输出每个元素的下一个更大元素。数字 x 的下一个更大的元素是按数组遍历顺序，这个数字之后的第一个比它更大的数，这意味着你应该循环地搜索它的下一个更大的数。如果不存在，则输出 -1。
输入: [1,2,1]输出: [2,-1,2]解释: 第一个 1 的下一个更大的数是 2；数字 2 找不到下一个更大的数； 第二个 1 的下一个最大的数需要循环搜索，结果也是 2。题解 // 循环数组 // Input: [1,2,1] // Output: [2,-1,2] public class NextGreaterElementII { // O(n^2)  public int[] nextGreaterElements(int[] nums) { int[] greater = new int[nums.length]; for (int i = 0; i &amp;lt; nums.length; i++) { greater[i] = findNextGreat(nums, i); } return greater; } private int findNextGreat(int[] nums, int i) { int great = nums[i]; int j = i + 1; while (j &amp;lt; nums.</description>
    </item>
    
    <item>
      <title>下一个排列</title>
      <link>https://kunzhao.org/docs/programmer-interview/algorithm/nextpermutation/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/programmer-interview/algorithm/nextpermutation/</guid>
      <description>下一个排列  微软
 描述 原题 实现获取下一个排列的函数，算法需要将给定数字序列重新排列成字典序中下一个更大的排列。
如果不存在下一个更大的排列，则将数字重新排列成最小的排列（即升序排列）。
必须原地修改，只允许使用额外常数空间。
以下是一些例子，输入位于左侧列，其相应输出位于右侧列。
1,2,3 → 1,3,23,2,1 → 1,2,31,1,5 → 1,5,1题解 public class NextPermutation { // 1 5 8 4 7 6 5 3 1  // ↑  // ↑(5 &amp;gt; 4 最后一个大于它的)  // 1 5 8 5 7 6 4 3 1 (交换)  // ↑(reverse)↑  // 1 5 8 5 1 3 4 6 7  //  // 找到第一个不符合从右到左升序对的数字 i = 4  // 找到第一个刚刚大于 nums[i] 的数字 j = 5  // swap(i, j)  // reverse(i + 1)  //  // ↓ (第一个不符合的数字 3，如果相等，比如多个 3 还要再往前找)  // 7 3 6 4 2  // ↑ (第一个刚刚大于 3 的数字 4)  //  // 7 4 6 3 2 (交换)  //  // 7 4 2 3 6 (4 后面的数字也交换)  public void nextPermutation(int[] nums) { int i = nums.</description>
    </item>
    
    <item>
      <title>数飞机</title>
      <link>https://kunzhao.org/docs/programmer-interview/algorithm/numberofairplanesinthesky/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/programmer-interview/algorithm/numberofairplanesinthesky/</guid>
      <description>数飞机 描述 原题 给出飞机的起飞和降落时间的列表，用序列 interval 表示. 请计算出天上同时最多有多少架飞机？
 如果多架飞机降落和起飞在同一时刻，我们认为降落有优先权。
 输入: [(1, 10), (2, 3), (5, 8), (4, 7)]输出: 3解释: 第一架飞机在1时刻起飞, 10时刻降落.第二架飞机在2时刻起飞, 3时刻降落.第三架飞机在5时刻起飞, 8时刻降落.第四架飞机在4时刻起飞, 7时刻降落.在5时刻到6时刻之间, 天空中有三架飞机.题解 import java.util.ArrayList; import java.util.Collections; import java.util.Comparator; import java.util.List; import com.zk.algorithm.beans.Interval; // https://www.lintcode.com/problem/number-of-airplanes-in-the-sky/description // Amazon // // Input: [(1, 10), (2, 3), (5, 8), (4, 7)] // Output: 3 // Explanation: // The first airplane takes off at 1 and lands at 10.</description>
    </item>
    
    <item>
      <title>分割等和子集</title>
      <link>https://kunzhao.org/docs/programmer-interview/algorithm/partitionequalsubsetsum/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/programmer-interview/algorithm/partitionequalsubsetsum/</guid>
      <description>分割等和子集 描述 原题 给定一个只包含正整数的非空数组。是否可以将这个数组分割成两个子集，使得两个子集的元素和相等。
注意:
 每个数组中的元素不会超过 100 数组的大小不会超过 200  输入: [1, 5, 11, 5]输出: true解释: 数组可以分割成 [1, 5, 5] 和 [11].题解 import java.util.Arrays; // https://leetcode.com/problems/partition-equal-subset-sum/ // // 0 1 背包问题 // 从 nums.length 个数中找出若干个数，使其和 == sum /2 // // 416. Two subset public class PartitionEqualSubsetSum { public boolean canPartition(int[] nums) { int sum = 0; for (int num : nums) { sum += num; } if ((sum &amp;amp; 1) == 1) { return false; } // ======================  // sum 变为一半  // ======================  sum /= 2; int n = nums.</description>
    </item>
    
    <item>
      <title>数组除了自身的乘积</title>
      <link>https://kunzhao.org/docs/programmer-interview/algorithm/productofarrayexceptself/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/programmer-interview/algorithm/productofarrayexceptself/</guid>
      <description>描述 原题 给定 n 个整数的数组 nums，其中 n &amp;gt; 1，返回一个数组输出，使得 output[i] 等于 nums 的所有除了nums[i] 的元素的乘积。
输入: [1,2,3,4]输出: [24,12,8,6]解释:2*3*4=241*3*4=121*2*4=81*2*3=6题解 // 给定n个整数的数组nums，其中n&amp;gt; 1，返回一个数组输出，使得output [i]等于nums的所有除了nums [i]的元素的乘积。 // 在没有除和O(n)时间内解决 // https://www.lintcode.com/problem/product-of-array-except-self/description // 输入: [1,2,3,4] // 输出: [24,12,8,6] // 解释: // 2*3*4=24 // 1*3*4=12 // 1*2*4=8 // 1*2*3=6 // // 输入: [2,3,8] // 输出: [24,16,6] // 解释: // 3*8=24 // 2*8=16 // 2*3=6 public class ProductofArrayExceptSelf { public int[] productExceptSelf(int[] nums) { //  // 2, 3, 8  //  // 2, 6, 1  // 1, 24, 8  //  // 24, 16, 6  int[] leftProduct = new int[nums.</description>
    </item>
    
    <item>
      <title>根据身高重建队列</title>
      <link>https://kunzhao.org/docs/programmer-interview/algorithm/queuereconstructionbyheight/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/programmer-interview/algorithm/queuereconstructionbyheight/</guid>
      <description>根据身高重建队列 原题 假设有打乱顺序的一群人站成一个队列。 每个人由一个整数对(h, k)表示，其中h是这个人的身高，k是排在这个人前面且身高大于或等于h的人数。 编写一个算法来重建这个队列。
注意：
 总人数少于1100人。  示例
输入:[[7,0], [4,4], [7,1], [5,0], [6,1], [5,2]]输出:[[5,0], [7,0], [5,2], [6,1], [4,4], [7,1]]题解 import java.util.ArrayList; import java.util.Arrays; import java.util.Comparator; import java.util.List; // https://leetcode.com/problems/queue-reconstruction-by-height/ public class QueueReconstructionbyHeight { // [[7,0], [7,1], [6,1], [5,2], [5,0], [4,4]]  //  // [[7,0]]  // [[7,0], [7,1]]  // [[7,0], [6,1], [7,1]]  // [[7,0], [6,1], [5,2], [7,1]]  // [[5,0], [7,0], [6,1], [5,2], [7,1]]  // [[5,0], [7,0], [6,1], [5,2], [4,4], [7,1]]  public int[][] reconstructQueue(int[][] people) { // 个高的排在最前面，个矮的排在后面  Arrays.</description>
    </item>
    
    <item>
      <title>限流器</title>
      <link>https://kunzhao.org/docs/programmer-interview/algorithm/ratelimiter/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/programmer-interview/algorithm/ratelimiter/</guid>
      <description>限流器  基于 Token Bucket 的限流算法 基于 Redis 的限流算法  public class RateLimiter { public static long now() { return System.currentTimeMillis(); } // ==================  // - Token Bucket  // - Redis  // ==================  // =========================  // Token Bucket 算法  // 每过 RATE / PER 时间，就加  // =========================  public static class TokenBucketRateLimiter { private long lastCheck = now(); private static final int RATE = 5; // 5 requests  private static final int PER = 8; // 8 seconds  private int allowance = RATE; public boolean overhead(String key) { long current = now(); long timePassed = current - lastCheck; lastCheck = timePassed; // ======================  // 过去的这段时间内可以增加多少个 allowance  // ======================  allowance += timePassed * (RATE / PER); if (allowance &amp;gt; RATE) { allowance = RATE; } // ======================  // 是否能够减去 1.</description>
    </item>
    
    <item>
      <title>删除排序数组中的重复项</title>
      <link>https://kunzhao.org/docs/programmer-interview/algorithm/removeduplicatesfromsortedarray/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/programmer-interview/algorithm/removeduplicatesfromsortedarray/</guid>
      <description>删除排序数组中的重复项 描述 原题 给定一个排序数组，你需要在 原地 删除重复出现的元素，使得每个元素只出现一次，返回移除后数组的新长度。
不要使用额外的数组空间，你必须在 原地 修改输入数组 并在使用 O(1) 额外空间的条件下完成。
 示例 1:
给定数组 nums = [1,1,2], 函数应该返回新的长度 2, 并且原数组 nums 的前两个元素被修改为 1, 2。 你不需要考虑数组中超出新长度后面的元素。题解 // 排序数组 // 移除重复数字 public class RemoveDuplicatesfromSortedArray { public int removeDuplicates(int[] nums) { // [1,1,1,1,2,2,3,4,5,5]  //  int noDuplicated = 0; for (int i = 1; i &amp;lt; nums.length; i++) { if (nums[i] == nums[i - 1]) { continue; } else { nums[++noDuplicated] = nums[i]; } } return nums.</description>
    </item>
    
    <item>
      <title>两个有序数组第 K 大的数</title>
      <link>https://kunzhao.org/docs/programmer-interview/algorithm/kth-of-two-sorted-array/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/programmer-interview/algorithm/kth-of-two-sorted-array/</guid>
      <description>两个有序数组第 K 大的数 O(n) 解法 class Main { static int kth(int arr1[], int arr2[], int m, int n, int k) { int[] sorted1 = new int[m + n]; int i = 0, j = 0, d = 0; while (i &amp;lt; m &amp;amp;&amp;amp; j &amp;lt; n) { if (arr1[i] &amp;lt; arr2[j]) sorted1[d++] = arr1[i++]; else sorted1[d++] = arr2[j++]; } while (i &amp;lt; m) sorted1[d++] = arr1[i++]; while (j &amp;lt; n) sorted1[d++] = arr2[j++]; return sorted1[k - 1]; } // main function  public static void main (String[] args) { int arr1[] = {2, 3, 6, 7, 9}; int arr2[] = {1, 4, 8, 10}; int k = 5; System.</description>
    </item>
    
    <item>
      <title>移除元素</title>
      <link>https://kunzhao.org/docs/programmer-interview/algorithm/removeelement/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/programmer-interview/algorithm/removeelement/</guid>
      <description>移除元素 描述 原题 给你一个数组 nums 和一个值 val，你需要 原地 移除所有数值等于 val 的元素，并返回移除后数组的新长度。
不要使用额外的数组空间，你必须仅使用 O(1) 额外空间并 原地 修改输入数组。
元素的顺序可以改变。你不需要考虑数组中超出新长度后面的元素。 示例 1:
给定 nums = [3,2,2,3], val = 3,函数应该返回新的长度 2, 并且 nums 中的前两个元素均为 2。你不需要考虑数组中超出新长度后面的元素。题解 public class RemoveElement { // [1,1,1,2,2]  public int removeElement(int[] nums, int val) { int valid = -1; for (int i = 0; i &amp;lt; nums.length; i++) { if (nums[i] != val) { nums[++valid] = nums[i]; } } return nums.</description>
    </item>
    
    <item>
      <title>逆序对</title>
      <link>https://kunzhao.org/docs/programmer-interview/algorithm/reversepairs/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/programmer-interview/algorithm/reversepairs/</guid>
      <description>逆序对 描述 数组的逆序对个数
题解 // https://www.lintcode.com/problem/reverse-pairs/description // // Input: A = [2, 4, 1, 3, 5] // Output: 3 // Explanation: // (2, 1), (4, 1), (4, 3) are reverse pairs // // 逆序对个数 public class ReversePairs { public long reversePairs(int[] A) { return mergeSort(A, 0, A.length - 1); } private long mergeSort(int[] A, int lo, int hi) { int sum = 0; if (lo &amp;lt; hi) { int mid = lo + ((hi - lo) &amp;gt;&amp;gt; 1); // =====================  // 注意：这个地方是都加了一遍  // =====================  sum += mergeSort(A, lo, mid); sum += mergeSort(A, mid + 1, hi); sum += merge(A, lo, mid, hi); } return sum; } private int merge(int[] A, int lo, int mid, int hi) { int[] temp = new int[hi - lo + 1]; int tempIndex = 0; int loIndex = lo; int hiIndex = mid + 1; int count = 0; while (loIndex &amp;lt;= mid &amp;amp;&amp;amp; hiIndex &amp;lt;= hi) { // left | right  // 3 5 6 | 2  //  // 3 比 2 大的话，那么 3 5 6 都比 2 大  if (A[loIndex] &amp;gt; A[hiIndex]) { count += mid - loIndex + 1; temp[tempIndex++] = A[hiIndex++]; } else { temp[tempIndex++] = A[loIndex++]; } } while (loIndex &amp;lt;= mid) { temp[tempIndex++] = A[loIndex++]; } while (hiIndex &amp;lt;= hi) { temp[tempIndex++] = A[hiIndex++]; } tempIndex = 0; while (tempIndex &amp;lt; temp.</description>
    </item>
    
    <item>
      <title>旋转图像</title>
      <link>https://kunzhao.org/docs/programmer-interview/algorithm/rotateimage/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/programmer-interview/algorithm/rotateimage/</guid>
      <description>旋转图像 描述 原题 给定一个 n × n 的二维矩阵表示一个图像。
将图像顺时针旋转 90 度。
说明：
你必须在原地旋转图像，这意味着你需要直接修改输入的二维矩阵。请不要使用另一个矩阵来旋转图像。
题解 // Given input matrix = // [ // [1,2,3], // [4,5,6], // [7,8,9] // ],  // rotate the input matrix in-place such that it becomes: // [ // [7,4,1], // [8,5,2], // [9,6,3] // ] public class RotateImage { public void rotate(int[][] matrix) { int n = matrix.length; for (int i = 0; i &amp;lt; n / 2; i++) { // ↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓  // ↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓  //  // 【j 走到哪里停】?</description>
    </item>
    
    <item>
      <title>二维数组中的查找</title>
      <link>https://kunzhao.org/docs/programmer-interview/algorithm/searcha2dmatrix/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/programmer-interview/algorithm/searcha2dmatrix/</guid>
      <description>二维数组中的查找 描述  剑指offer  在一个 n * m 的二维数组中，每一行都按照从左到右递增的顺序排序，每一列都按照从上到下递增的顺序排序。请完成一个函数，输入这样的一个二维数组和一个整数，判断数组中是否含有该整数。
题解 // 这个算法适用于行有序、列有序的情况 public class Searcha2DMatrix { public boolean searchMatrix(int[][] matrix, int target) { if (matrix.length == 0) { return false; } int m = matrix.length; int n = matrix[0].length; // 第一行最后一个数字  //  int r = 0; int c = n - 1; while (r &amp;lt; m &amp;amp;&amp;amp; c &amp;gt;= 0) { int val = matrix[r][c]; if (target &amp;gt; val) { r++; } else if (target &amp;lt; val) { c--; } else { return true; } } return false; } } </description>
    </item>
    
    <item>
      <title>搜索区间</title>
      <link>https://kunzhao.org/docs/programmer-interview/algorithm/searchforarange/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/programmer-interview/algorithm/searchforarange/</guid>
      <description>搜索区间 描述 原题 给定一个包含 n 个整数的排序数组，找出给定目标值 target 的起始和结束位置。
如果目标值不在数组中，则返回 [-1, -1]
题解 // LintCode // https://www.lintcode.com/problem/search-for-a-range/leaderboard // public class SearchforaRange { public int[] searchRange(int[] A, int target) { if (A == null || A.length == 0) { return new int[]{ -1, -1 }; } int start = searchStartIndex(A, target); int end = searchEndIndex(A, target); return new int[]{ start, end }; } // target 开始的地方  private int searchStartIndex(int[] A, int target) { int lo = 0; int hi = A.</description>
    </item>
    
    <item>
      <title>搜索旋转排序数组</title>
      <link>https://kunzhao.org/docs/programmer-interview/algorithm/searchinrotatedsortedarray/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/programmer-interview/algorithm/searchinrotatedsortedarray/</guid>
      <description>搜索旋转排序数组 Search in Rotated Sorted Array 和 Search in Rotated Sorted Array II
数组无重复数字 // 么有重复数字 public class SearchinRotatedSortedArray { // https://leetcode.com/problems/search-in-rotated-sorted-array/discuss/14472/Java-AC-Solution-using-once-binary-search  // 使用一次二分搜索  //  // 核心思想: 确定 m 位于哪一边，然后确定 target 是不是位于有序的一边  //  public int search(int[] nums, int target) { int lo = 0; int hi = nums.length - 1; while (lo &amp;lt;= hi) { int m = lo + ((hi - lo) &amp;gt;&amp;gt; 1); if (nums[m] == target) { return m; } // 6 7 1 2 3 4 5  // ↑ ↑ ↑ ↑ ↑  //  // 1 2 3 4 5 6 7  // ↑ ↑ ↑ ↑ ↑ ↑ ↑  //  // 右侧有序  // target 是不是位于有序右侧空间  if (nums[m] &amp;lt;= nums[hi]) { if (target &amp;gt; nums[m] &amp;amp;&amp;amp; target &amp;lt;= nums[hi]) { lo = m + 1; } else { hi = m - 1; } } else { // 6 7 1 2 3 4 5  // ↑ ↑  //  // target 是否位于左侧有序空间内  if (target &amp;gt;= nums[lo] &amp;amp;&amp;amp; target &amp;lt; nums[m]) { hi = m - 1; } else { lo = m + 1; } } } return -1; } // ================================  // 下面这个方案先查找 min 值  // ================================  public int search0(int[] nums, int target) { // ================================  // 忘记这一步骤了  // ================================  if (nums.</description>
    </item>
    
    <item>
      <title>滑动窗口最大值</title>
      <link>https://kunzhao.org/docs/programmer-interview/algorithm/slidingwindowmaximum/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/programmer-interview/algorithm/slidingwindowmaximum/</guid>
      <description>滑动窗口最大值 描述 原题 给定一个数组 nums，有一个大小为 k 的滑动窗口从数组的最左侧移动到数组的最右侧。你只可以看到在滑动窗口内的 k 个数字。滑动窗口每次只向右移动一位。
返回滑动窗口中的最大值。
输入: nums = [1,3,-1,-3,5,3,6,7], 和 k = 3输出: [3,3,5,5,6,7] 解释: 滑动窗口的位置 最大值--------------- -----[1 3 -1] -3 5 3 6 7 31 [3 -1 -3] 5 3 6 7 31 3 [-1 -3 5] 3 6 7 51 3 -1 [-3 5 3] 6 7 51 3 -1 -3 [5 3 6] 7 61 3 -1 -3 5 [3 6 7] 7题解 import java.</description>
    </item>
    
    <item>
      <title>滑动窗口中位数</title>
      <link>https://kunzhao.org/docs/programmer-interview/algorithm/slidingwindowmedian/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/programmer-interview/algorithm/slidingwindowmedian/</guid>
      <description>滑动窗口中位数 描述 原题 中位数是有序序列最中间的那个数。如果序列的大小是偶数，则没有最中间的数；此时中位数是最中间的两个数的平均数。
例如：
 [2,3,4]，中位数是 3 [2,3]，中位数是 (2 + 3) / 2 = 2.5  给你一个数组 nums，有一个大小为 k 的窗口从最左端滑动到最右端。窗口中有 k 个数，每次窗口向右移动 1 位。你的任务是找出每次窗口移动后得到的新窗口中元素的中位数，并输出由它们组成的数组。
示例：
给出 nums = [1,3,-1,-3,5,3,6,7]，以及 k = 3。
窗口位置 中位数--------------- -----[1 3 -1] -3 5 3 6 7 11 [3 -1 -3] 5 3 6 7 -11 3 [-1 -3 5] 3 6 7 -11 3 -1 [-3 5 3] 6 7 31 3 -1 -3 [5 3 6] 7 51 3 -1 -3 5 [3 6 7] 6因此，返回该滑动窗口的中位数数组 [1,-1,-1,3,5,6]。</description>
    </item>
    
    <item>
      <title>颜色分类</title>
      <link>https://kunzhao.org/docs/programmer-interview/algorithm/sortcolors/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/programmer-interview/algorithm/sortcolors/</guid>
      <description>颜色分类 描述 原题 给定一个包含红色、白色和蓝色，一共 n 个元素的数组，原地对它们进行排序，使得相同颜色的元素相邻，并按照红色、白色、蓝色顺序排列。
此题中，我们使用整数 0、 1 和 2 分别表示红色、白色和蓝色。
题解 public class SortColors { // 0,0,1,1,2,2  //  // 2 0 1 0 1 1 2  public void sortColors(int[] nums) { // 000001111122222  // ↑ ↑  // l r  //  int left = 0; int right = nums.length - 1; int i = 0; while (i &amp;lt;= right) { if (nums[i] == 0) { // =========================  // 遇到 0 就换到左边  //  // 0 0 0 0 1 1 1 1 0 2  // ↑ ↑  // left i  //  // =========================  swap(nums, left++, i++); } else if (nums[i] == 1) { i++; } else { // =========================  // right 指向的是第一个非 2 的位置  //  // 遇到 2 就换到右边，但是换过来的不一定是 1 还是 0，所以 i 不能动  //  // 1 1 1 1 1 2 2 0  // ↑ ↑  // i right  //  // =========================  swap(nums, i, right--); } } } private void swap(int[] nums, int i, int j) { int tmp = nums[i]; nums[i] = nums[j]; nums[j] = tmp; } } </description>
    </item>
    
    <item>
      <title>螺旋矩阵</title>
      <link>https://kunzhao.org/docs/programmer-interview/algorithm/spiralmatrix/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/programmer-interview/algorithm/spiralmatrix/</guid>
      <description>螺旋矩阵 Spiral Matrix 和 Spiral Matrix II
返回螺旋顺序 给定一个包含 m x n 个元素的矩阵（m 行, n 列），请按照顺时针螺旋顺序，返回矩阵中的所有元素。
import java.util.ArrayList; import java.util.Collections; import java.util.List; public class SpiralMatrix { public List&amp;lt;Integer&amp;gt; spiralOrder(int[][] matrix) { if (matrix == null || matrix.length == 0) { return Collections.emptyList(); } List&amp;lt;Integer&amp;gt; res = new ArrayList&amp;lt;&amp;gt;(); int left = 0; int right = matrix[0].length - 1; int top = 0; int bottom = matrix.length - 1; while (true) { for (int c = left; c &amp;lt;= right; c++) { res.</description>
    </item>
    
    <item>
      <title>分割数组的最大值</title>
      <link>https://kunzhao.org/docs/programmer-interview/algorithm/splitarraylargestsum/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/programmer-interview/algorithm/splitarraylargestsum/</guid>
      <description>分割数组的最大值 描述 原题 给定一个非负整数数组和一个整数 m，你需要将这个数组分成 m 个非空的连续子数组。设计一个算法使得这 m 个子数组各自和的最大值最小。
注意: 数组长度 n 满足以下条件:
 1 ≤ n ≤ 1000 1 ≤ m ≤ min(50, n)  输入:nums = [7,2,5,10,8]m = 2输出:18解释:一共有四种方法将nums分割为2个子数组。其中最好的方式是将其分为[7,2,5] 和 [10,8]，因为此时这两个子数组各自的和的最大值为18，在所有情况中最小。题解 // 数组包含非负整数，以及一个 整数 m // 将数组分成 m 个连续的 subarray // 写一个算法，来使得所有的这些 subarrays 的最大和最小 // // [7,2,5,10,8] // // https://leetcode.com/problems/split-array-largest-sum/discuss/89817/Clear-Explanation%3A-8ms-Binary-Search-Java public class SplitArrayLargestSum { // [.......]  //  // max: 所有数相加  // min: Math.</description>
    </item>
    
    <item>
      <title>X 的平方根</title>
      <link>https://kunzhao.org/docs/programmer-interview/algorithm/sqrt/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/programmer-interview/algorithm/sqrt/</guid>
      <description>X 的平方根 描述 原题 实现 int sqrt(int x) 函数。
计算并返回 x 的平方根，其中 x 是非负整数。
由于返回类型是整数，结果只保留整数的部分，小数部分将被舍去。
题解 public class Sqrt { public int mySqrt(int x) { // 注意边界条件  if (x == 0) { return 0; } int lo = 1; int hi = x / 2; int ans = lo; while (lo &amp;lt;= hi) { int mid = lo + ((hi - lo) &amp;gt;&amp;gt; 1); // 注意这里  // 防止溢出  if (mid &amp;gt; x / mid) { hi = mid - 1; } else if (mid &amp;lt;= x / mid) { ans = mid; lo = mid + 1; } } return ans; } } </description>
    </item>
    
    <item>
      <title>乘积小于K的子数组</title>
      <link>https://kunzhao.org/docs/programmer-interview/algorithm/subarrayproductlessthank/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/programmer-interview/algorithm/subarrayproductlessthank/</guid>
      <description>乘积小于K的子数组 描述 原题 给定一个正整数数组 nums。
找出该数组内乘积小于 k 的连续的子数组的个数。
示例 1:
输入: nums = [10,5,2,6], k = 100输出: 8解释: 8个乘积小于100的子数组分别为: [10], [5], [2], [6], [10,5], [5,2], [2,6], [5,2,6]。需要注意的是 [10,5,2] 并不是乘积小于100的子数组。题解 // Input: nums = [10, 5, 2, 6], k = 100 // Output: 8 // Explanation: The 8 subarrays that have product less than 100 are: [10], [5], [2], [6], [10, 5], [5, 2], [2, 6], [5, 2, 6].</description>
    </item>
    
    <item>
      <title>和为K的子数组</title>
      <link>https://kunzhao.org/docs/programmer-interview/algorithm/subarraysumequalsk/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/programmer-interview/algorithm/subarraysumequalsk/</guid>
      <description>和为K的子数组 描述 给定一个整数数组和一个整数 k，你需要找到该数组中和为 k 的连续的子数组的个数。
示例 1 :
输入:nums = [1,1,1], k = 2输出: 2 , [1,1] 与 [1,1] 为两种不同的情况。题解 // Given an array of integers and an integer k, you need to find the total number of continuous subarrays whose sum equals to k. // // 和为 k 的连续子数组，有多少组 public class SubarraySumEqualsK { public int subarraySum(int[] nums, int k) { int[] preSum = calcPreSum(nums); int count = 0; for (int i = 0; i &amp;lt; preSum.</description>
    </item>
    
    <item>
      <title>K 个不同整数的子数组</title>
      <link>https://kunzhao.org/docs/programmer-interview/algorithm/subarrayswithkdifferentintegers/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/programmer-interview/algorithm/subarrayswithkdifferentintegers/</guid>
      <description>K 个不同整数的子数组 描述 给定一个正整数数组 A，如果 A 的某个子数组中不同整数的个数恰好为 K，则称 A 的这个连续、不一定独立的子数组为好子数组。
（例如，[1,2,3,1,2] 中有 3 个不同的整数：1，2，以及 3。）
返回 A 中好子数组的数目。
示例 1：
输入：A = [1,2,1,2,3], K = 2输出：7解释：恰好由 2 个不同整数组成的子数组：[1,2], [2,1], [1,2], [2,3], [1,2,1], [2,1,2], [1,2,1,2].题解 import java.util.HashMap; import java.util.Map; // Input: A = [1,2,1,2,3], K = 2 // Output: 7 // Explanation: Subarrays formed with exactly 2 different integers: [1,2], [2,1], [1,2], [2,3], [1,2,1], [2,1,2], [1,2,1,2]. // // 子数组里面有 k 个不同的数字 // // 解法参考了 // https://leetcode.</description>
    </item>
    
    <item>
      <title>2、3、4个数之和</title>
      <link>https://kunzhao.org/docs/programmer-interview/algorithm/sum/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/programmer-interview/algorithm/sum/</guid>
      <description>2、3、4个数之和 从 nums 数组中找到数字相加的结果符合要求的几个数字。
两数之和 import java.util.HashMap; import java.util.Map; // 返回索引 // // O(N) public class TwoSum { public int[] twoSum(int[] nums, int target) { Map&amp;lt;Integer, Integer&amp;gt; map = new HashMap&amp;lt;&amp;gt;(); for (int i = 0; i &amp;lt; nums.length; i++) { if (map.containsKey(target - nums[i])) { return new int[]{ map.get(target - nums[i]), i }; } map.put(nums[i], i); } return new int[]{}; } } 三个数之和 import java.util.List; import java.util.LinkedList; import java.util.ArrayList; import java.</description>
    </item>
    
    <item>
      <title>子数组的最小值之和</title>
      <link>https://kunzhao.org/docs/programmer-interview/algorithm/sumofsubarrayminimums/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/programmer-interview/algorithm/sumofsubarrayminimums/</guid>
      <description>子数组的最小值之和 描述 原题 给定一个整数数组 A，找到 min(B) 的总和，其中 B 的范围为 A 的每个（连续）子数组。
由于答案可能很大，因此返回答案模 10^9 + 7。
示例：
输入：[3,1,2,4]输出：17解释：子数组为 [3]，[1]，[2]，[4]，[3,1]，[1,2]，[2,4]，[3,1,2]，[1,2,4]，[3,1,2,4]。 最小值为 3，1，2，4，1，1，2，1，1，1，和为 17。题解 import java.util.Stack; // // 连续子数组里面的最小值 min 相加的和 // [3,1,2,4]: // // [3][1][2][4][3,1][1,2][2,4][3,1,2][1,2,4][3,1,2,4] // public class SumofSubarrayMinimums { public int sumSubarrayMins(int[] A) { Stack&amp;lt;Integer&amp;gt; stack = new Stack&amp;lt;Integer&amp;gt;(); // ==========================================  // 最左侧，第一个比 A[i] 小的值  // ==========================================  int[] leftMin = new int[A.length]; for (int i = 0; i &amp;lt; A.</description>
    </item>
    
    <item>
      <title>第三大的数</title>
      <link>https://kunzhao.org/docs/programmer-interview/algorithm/thirdmaximumnumber/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/programmer-interview/algorithm/thirdmaximumnumber/</guid>
      <description>第三大的数 描述 给定一个非空数组，返回此数组中第三大的数。如果不存在，则返回数组中最大的数。要求算法时间复杂度必须是 O(n)。
示例 1:
输入: [3, 2, 1]输出: 1解释: 第三大的数是 1.题解 // 返回第三大，如果不存在，返回最大的 // // Input: [3, 2, 1] // Output: 1 // Explanation: The third maximum is 1. // // Input: [2, 2, 3, 1] // Output: 1 // Explanation: Note that the third maximum here means the third maximum distinct number. // Both numbers with value 2 are both considered as second maximum. // // https://leetcode.</description>
    </item>
    
    <item>
      <title>前K大数</title>
      <link>https://kunzhao.org/docs/programmer-interview/algorithm/topklargestnumbers/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/programmer-interview/algorithm/topklargestnumbers/</guid>
      <description>前K大数 描述 原题 在一个数组中找到前K大的数
题解 // https://www.lintcode.com/problem/top-k-largest-numbers/description // // Input: [3, 10, 1000, -99, 4, 100] and k = 3 // Output: [1000, 100, 10] import java.util.*; public class TopkLargestNumbers { public int[] topk(int[] nums, int k) { PriorityQueue&amp;lt;Integer&amp;gt; queue = new PriorityQueue&amp;lt;&amp;gt;(new Comparator&amp;lt;Integer&amp;gt;() { @Override public int compare(Integer o1, Integer o2) { return o1.compareTo(o2); } }); for (int num: nums) { queue.offer(num); if (queue.size() &amp;gt; k) { queue.poll(); } } // addFirst();  // addLast();  // removeFirst();  // removeLast();  int[] res = new int[queue.</description>
    </item>
    
    <item>
      <title>有效的山脉数组</title>
      <link>https://kunzhao.org/docs/programmer-interview/algorithm/validmountainarray/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/programmer-interview/algorithm/validmountainarray/</guid>
      <description>有效的山脉数组 原题 给定一个整数数组 A，如果它是有效的山脉数组就返回 true，否则返回 false。
让我们回顾一下，如果 A 满足下述条件，那么它是一个山脉数组：
 A.length &amp;gt;= 3 在 0 &amp;lt; i &amp;lt; A.length - 1 条件下，存在 i 使得：  A[0] &amp;lt; A[1] &amp;lt; ... A[i-1] &amp;lt; A[i] A[i] &amp;gt; A[i+1] &amp;gt; ... &amp;gt; A[A.length - 1]    题解 // https://leetcode.com/problems/valid-mountain-array/ // // (1) A.length &amp;gt;= 3 // (2) There exists some i with 0 &amp;lt; i &amp;lt; A.length - 1 such that: // A[0] &amp;lt; A[1] &amp;lt; .</description>
    </item>
    
    <item>
      <title>有效的数独</title>
      <link>https://kunzhao.org/docs/programmer-interview/algorithm/validsudoku/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/programmer-interview/algorithm/validsudoku/</guid>
      <description>有效的数独 描述 原题 判断一个 9x9 的数独是否有效。只需要根据以下规则，验证已经填入的数字是否有效即可。
 数字 1-9 在每一行只能出现一次。 数字 1-9 在每一列只能出现一次。 数字 1-9 在每一个以粗实线分隔的 3x3 宫内只能出现一次。  题解 import java.util.HashMap; import java.util.HashSet; import java.util.Map; import java.util.Set; // https://leetcode.com/problems/valid-sudoku/ // // public class ValidSudoku { public boolean isValidSudoku(char[][] board) { int m = board.length; int n = board[0].length; Map&amp;lt;Integer, Set&amp;lt;Integer&amp;gt;&amp;gt; rowMap = new HashMap&amp;lt;&amp;gt;(); Map&amp;lt;Integer, Set&amp;lt;Integer&amp;gt;&amp;gt; colMap = new HashMap&amp;lt;&amp;gt;(); // 1 2 3  // 4 5 6  // 7 8 9  Map&amp;lt;Integer, Set&amp;lt;Integer&amp;gt;&amp;gt; smallBoxMap = new HashMap&amp;lt;&amp;gt;(); for (int i = 0; i &amp;lt; m; i++) { for (int j = 0; j &amp;lt; n; j++) { char c = board[i][j]; if (c == &amp;#39;.</description>
    </item>
    
    <item>
      <title>有效三角形的个数</title>
      <link>https://kunzhao.org/docs/programmer-interview/algorithm/validtrianglenumber/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/programmer-interview/algorithm/validtrianglenumber/</guid>
      <description>有效三角形的个数 描述 原题 给定一个包含非负整数的数组，你的任务是统计其中可以组成三角形三条边的三元组个数。
示例 1:
输入: [2,2,3,4]输出: 3解释:有效的组合是: 2,3,4 (使用第一个 2)2,3,4 (使用第二个 2)2,2,3题解 import java.util.Arrays; // 给定一个包含非负整数的数组，你的任务是计算从数组中选出的可以制作三角形的三元组数目，如果我们把它们作为三角形的边长。 // 非负 // // https://www.lintcode.com/problem/valid-triangle-number/description // public class ValidTriangleNumber { // ERROR: O(n ^ 2)，错误解法  public int triangleNumber(int[] nums) { // a + b &amp;gt; c  // c &amp;lt; a + b  //  // 1 2 3 4  Arrays.sort(nums); int count = 0; // 2 2 3 4  // ↑  // 2, 2, 4  // 2, 3, 4  // 2, 3, 4  // 2, 2, 3  for (int i = 0; i &amp;lt; nums.</description>
    </item>
    
    <item>
      <title>组合总和</title>
      <link>https://kunzhao.org/docs/programmer-interview/algorithm/combinationsum/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/programmer-interview/algorithm/combinationsum/</guid>
      <description>组合总和 下属题目，所有数字均是正整数
Combination Sum 原题 一个数组，从这个数组中找出所有相加等于 target 的元素的组合，数组中的每一个数字可以被多次重复选取。
 数组无重复数字。
 import java.util.ArrayList; import java.util.List; // Input: candidates = [2,3,5], target = 8, // A solution set is: // [ // [2,2,2,2], // [2,3,3], // [3,5] // ] // // candidates 里面没有重复数字 // 每一个 candidate 可以重复使用多次 // // 时间复杂度可以转为，见这个帖子分析 // https://leetcode.com/problems/combination-sum/discuss/16634/if-asked-to-discuss-the-time-complexity-of-your-solution-what-would-you-say // // 每个元素有 ceil(target / element) 个 // 展开后的数组个数为 n&amp;#39; = ceil(target / element) * n // 最后时间复杂度为 O(k * 2 ^ n&amp;#39;) // public class CombinationSum { public List&amp;lt;List&amp;lt;Integer&amp;gt;&amp;gt; combinationSum(int[] candidates, int target) { List&amp;lt;List&amp;lt;Integer&amp;gt;&amp;gt; res = new ArrayList&amp;lt;&amp;gt;(); helper(candidates, res, new ArrayList&amp;lt;Integer&amp;gt;(), 0, 0, target); return res; } private void helper(int[] candidates, List&amp;lt;List&amp;lt;Integer&amp;gt;&amp;gt; res, List&amp;lt;Integer&amp;gt; cur, int curSum, int index, int target) { if (curSum &amp;gt; target) { return; } if (curSum == target) { res.</description>
    </item>
    
    <item>
      <title>组合</title>
      <link>https://kunzhao.org/docs/programmer-interview/algorithm/combinations/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/programmer-interview/algorithm/combinations/</guid>
      <description>组合 描述 原题 给定两个整数 n 和 k，返回 1 &amp;hellip; n 中所有可能的 k 个数的组合。
示例:
输入: n = 4, k = 2输出:[[2,4],[3,4],[2,3],[1,2],[1,3],[1,4],]题解 import java.util.ArrayList; import java.util.List; // Input: n = 4, k = 2 // Output: // [ // [2,4], // [3,4], // [2,3], // [1,2], // [1,3], // [1,4], // ] // // 时间复杂度看起来像是 C(n, k)，从 n 个数里面选择 k 个 // 所以总的时间复杂度为 C(n, k) * O(k) public class Combinations { public List&amp;lt;List&amp;lt;Integer&amp;gt;&amp;gt; combine(int n, int k) { List&amp;lt;List&amp;lt;Integer&amp;gt;&amp;gt; res = new ArrayList&amp;lt;&amp;gt;(); int[] array = buildArray(n); helper(res, new ArrayList&amp;lt;Integer&amp;gt;(), array, k, 0); return res; } private void helper(List&amp;lt;List&amp;lt;Integer&amp;gt;&amp;gt; res, List&amp;lt;Integer&amp;gt; cur, int[] array, int k, int begin) { // Base Case  // 得到之后，需要花费 O(K) 来拷贝结果到 res 里面  //  if (cur.</description>
    </item>
    
    <item>
      <title>为运算表达式设计优先级</title>
      <link>https://kunzhao.org/docs/programmer-interview/algorithm/differentwaystoaddparentheses/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/programmer-interview/algorithm/differentwaystoaddparentheses/</guid>
      <description>为运算表达式设计优先级 描述 原题 给定一个含有数字和运算符的字符串，为表达式添加括号，改变其运算优先级以求出不同的结果。你需要给出所有可能的组合的结果。有效的运算符号包含 +, - 以及 * 。
输入: &amp;quot;2-1-1&amp;quot;输出: [0, 2]解释: ((2-1)-1) = 0 (2-(1-1)) = 2 头条面试题
 题解 import java.util.LinkedList; import java.util.List; // 头条面试题 // // https://leetcode.com/problems/different-ways-to-add-parentheses/ // Input: &amp;#34;2*3-4*5&amp;#34; // Output: [-34, -14, -10, -10, 10] // Explanation: // (2*(3-(4*5))) = -34 // ((2*3)-(4*5)) = -14 // ((2*(3-4))*5) = -10 // (2*((3-4)*5)) = -10 // (((2*3)-4)*5) = 10 // // 只有 +、- 和 * // // 有几种不同的结果 public class DifferentWaysToAddParentheses { public List&amp;lt;Integer&amp;gt; diffWaysToCompute(String input) { List&amp;lt;Integer&amp;gt; ret = new LinkedList&amp;lt;Integer&amp;gt;(); for (int i = 0; i &amp;lt; input.</description>
    </item>
    
    <item>
      <title>快算 24</title>
      <link>https://kunzhao.org/docs/programmer-interview/algorithm/game24/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/programmer-interview/algorithm/game24/</guid>
      <description>快算 24 描述 原题 你有 4 张写有 1 到 9 数字的牌。你需要判断是否能通过 *，/，+，-，(，) 的运算得到 24。
题解 import java.util.ArrayList; // Input: [4, 1, 8, 7] // Output: True // Explanation: (8-4) * (7-1) = 24 // // https://leetcode.com/articles/24-game/ public class Game24 { public boolean judgePoint24(int[] nums) { ArrayList A = new ArrayList&amp;lt;Double&amp;gt;(); for (int v: nums) { A.add((double) v); } return solve(A); } private boolean solve(ArrayList&amp;lt;Double&amp;gt; nums) { if (nums.size() == 0) return false; if (nums.</description>
    </item>
    
    <item>
      <title>生成括号对</title>
      <link>https://kunzhao.org/docs/programmer-interview/algorithm/generateparentheses/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/programmer-interview/algorithm/generateparentheses/</guid>
      <description>生成括号对 描述 原题 数字 n 代表生成括号的对数，请你设计一个函数，用于能够生成所有可能的并且 有效的 括号组合。
输入：n = 3输出：[&amp;quot;((()))&amp;quot;,&amp;quot;(()())&amp;quot;,&amp;quot;(())()&amp;quot;,&amp;quot;()(())&amp;quot;,&amp;quot;()()()&amp;quot;]题解 import java.util.LinkedList; import java.util.List; // 时间复杂度，总的括号对个数是 Catalan number 个 // O(C(2n, n) / (n + 1)) // public class GenerateParentheses { public List&amp;lt;String&amp;gt; generateParenthesis(int n) { List&amp;lt;String&amp;gt; res = new LinkedList&amp;lt;&amp;gt;(); helper(res, &amp;#34;&amp;#34;, 0, 0, n); return res; } private void helper(List&amp;lt;String&amp;gt; res, String cur, int open, int close, int n) { if (open == n &amp;amp;&amp;amp; close == n) { res.</description>
    </item>
    
    <item>
      <title>字母大小写全排列</title>
      <link>https://kunzhao.org/docs/programmer-interview/algorithm/lettercasepermutation/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/programmer-interview/algorithm/lettercasepermutation/</guid>
      <description>字母大小写全排列 描述 给定一个字符串S，通过将字符串S中的每个字母转变大小写，我们可以获得一个新的字符串。返回所有可能得到的字符串集合。
题解 import java.util.ArrayList; import java.util.List; // Examples: // Input: S = &amp;#34;a1b2&amp;#34; // Output: [&amp;#34;a1b2&amp;#34;, &amp;#34;a1B2&amp;#34;, &amp;#34;A1b2&amp;#34;, &amp;#34;A1B2&amp;#34;]  // Input: S = &amp;#34;3z4&amp;#34; // Output: [&amp;#34;3z4&amp;#34;, &amp;#34;3Z4&amp;#34;]  // Input: S = &amp;#34;12345&amp;#34; // Output: [&amp;#34;12345&amp;#34;] // // 假设字符串中包含 k 个需要转的字符 // 那么总共有 2 ^ k 个状态，base case 需要拷贝，那么就是 O(n) // 所以复杂度为 O(n * 2^k) public class LetterCasePermutation { public List&amp;lt;String&amp;gt; letterCasePermutation(String S) { List&amp;lt;String&amp;gt; res = new ArrayList&amp;lt;&amp;gt;(); helper(res, S.</description>
    </item>
    
    <item>
      <title>电话号码的字母组合</title>
      <link>https://kunzhao.org/docs/programmer-interview/algorithm/lettercombinationsofaphonenumber/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/programmer-interview/algorithm/lettercombinationsofaphonenumber/</guid>
      <description>电话号码的字母组合 描述 给定一个仅包含数字 2-9 的字符串，返回所有它能表示的字母组合。
给出数字到字母的映射如下（与电话按键相同）。注意 1 不对应任何字母。
题解 import java.util.HashMap; import java.util.LinkedList; import java.util.List; import java.util.Map; // 时间复杂度为 O(3 ^ N * 4 ^ M) 次方个 // // 每一个数有 3 种选法的有 N 个 // 每一个数有 4 种选法的有 M 个 // public class LetterCombinationsofaPhoneNumber { static Map&amp;lt;Character, String&amp;gt; map = new HashMap&amp;lt;&amp;gt;(); static { map.put(&amp;#39;2&amp;#39;, &amp;#34;abc&amp;#34;); map.put(&amp;#39;3&amp;#39;, &amp;#34;def&amp;#34;); map.put(&amp;#39;4&amp;#39;, &amp;#34;ghi&amp;#34;); map.put(&amp;#39;5&amp;#39;, &amp;#34;jkl&amp;#34;); map.put(&amp;#39;6&amp;#39;, &amp;#34;mno&amp;#34;); map.put(&amp;#39;7&amp;#39;, &amp;#34;pqrs&amp;#34;); map.put(&amp;#39;8&amp;#39;, &amp;#34;tuv&amp;#34;); map.put(&amp;#39;9&amp;#39;, &amp;#34;wxyz&amp;#34;); } public List&amp;lt;String&amp;gt; letterCombinations(String digits) { List&amp;lt;String&amp;gt; res = new LinkedList&amp;lt;&amp;gt;(); if (digits == null || digits.</description>
    </item>
    
    <item>
      <title>N 皇后</title>
      <link>https://kunzhao.org/docs/programmer-interview/algorithm/nqueues/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/programmer-interview/algorithm/nqueues/</guid>
      <description>N 皇后 描述 原题 n 皇后问题研究的是如何将 n 个皇后放置在 n×n 的棋盘上，并且使皇后彼此之间不能相互攻击。
题解 import java.util.ArrayList; import java.util.Arrays; import java.util.LinkedList; import java.util.List; public class NQueues { public List&amp;lt;List&amp;lt;String&amp;gt;&amp;gt; solveNQueens(int n) { char[][] grid = new char[n][n]; for (int i = 0; i &amp;lt; n; i++) { Arrays.fill(grid[i], &amp;#39;.&amp;#39;); } List&amp;lt;List&amp;lt;String&amp;gt;&amp;gt; res = new ArrayList&amp;lt;List&amp;lt;String&amp;gt;&amp;gt;(); helper(res, grid, 0, n); return res; } // 方法是对于固定的列 colIndex，依次试探第 0 1 2 ... n 行，然后看是否 OK，如果 OK，试探 colIndex + 1 列  // colIndex == n 的时候，就可以返回了  private void helper(List&amp;lt;List&amp;lt;String&amp;gt;&amp;gt; res, char[][] grid, int colIndex /** 对于固定的列 */, int n) { if (colIndex == n) { res.</description>
    </item>
    
    <item>
      <title>CSS 垂直居中</title>
      <link>https://kunzhao.org/docs/programmer-interview/front-end/css-center/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/programmer-interview/front-end/css-center/</guid>
      <description>CSS 垂直居中 有固定的高度和宽度 主要是依靠 absolute 属性置于距离左上角 50% 的位置，然后再利用 margin 调整位置。
.parent { position: relative; } .child { width: 300px; height: 100px; padding: 20px; position: absolute; top: 50%; left: 50%; margin: -70px 0 0 -170px; } 效果如下  假如不添加 margin   无固定的高度和宽度 使用 transform 属性：
.parent { position: relative; } .child { position: absolute; top: 50%; left: 50%; transform: translate(-50%, -50%); } 使用 flexbox 布局 .container { display: flex; justify-content: center; align-items: center; }  justify-content: center：水平居中 align-items: center：垂直居中  单行文本水平垂直居中 transform .</description>
    </item>
    
    <item>
      <title>Git .gitignore 文件</title>
      <link>https://kunzhao.org/docs/tutorial/git/git-ignore/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/tutorial/git/git-ignore/</guid>
      <description>Git .gitignore 文件 Git 可以使用 .gitignore 文件来对工作区的某个目录、某个文件等设置忽略，忽略后这些文件的状态变化，将不会被记录在 git 中，也不会被 push 到远程服务器上。
如果想要忽略项目里面的某些文件夹，比如 build/、target/、node_modules/ 等文件夹，不 push 到服务器上，就需要在相应的目录中添加一个 .gitignore 文件，并在里面将这些文件夹的名字给加上。
.gitignore 的作用范围 作用范围：.gitignore 文件所处的目录及其子目录。
如何查看哪些文件被忽略了 git status --ignored # 或 git check-ignore -v example.jpg .gitignore 文件语法  # 开始的行代表注释 *：代表任意多个字符，?：代表一个字符，[abc] 代表可选字符范围等 **：匹配任意数量的目录 名称以 / 开头：只忽略此目录下的文件，对于子目录中的文件不忽略 名称以 / 结尾：忽略整个目录，同名文件不忽略；否则同名文件和目录都被忽略 名称以 ! 开头：代表不忽略这个文件  示例 # 任何目录下面的 .DS_Store 文件都会被忽略 .DS_Store # 忽略整个目录 node_modules/ logs/ # 忽略所有以 log 结尾的文件，但是 example.log 不被忽略 *.log !example.log # 忽略 abc 文件夹下面的以 log 结尾的文件，注意：子目录不会被忽略 abc/*.</description>
    </item>
    
    <item>
      <title>Java 垃圾回收器</title>
      <link>https://kunzhao.org/docs/programmer-interview/java/java-gc/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/programmer-interview/java/java-gc/</guid>
      <description>Java 垃圾回收器 判断对象是否可回收 如何判断一个对象属于垃圾对象呢？
引用计数法 对于一个对象 A，只要有任意一个对象引用了 A，则 A 的计数器加 1，当引用失效的时候，引用计数器就减 1。如果 A 的应用计数器为 0，则对象 A 就不可能再被使用。
 缺点：无法处理循环引用的问题。
 可达性分析算法 通过一系列的称为 GC Roots 的对象作为起始点，从这些节点开始向下搜索，搜索所走过的循环称为引用链。当一个对象到 GC Roots 没有任何引用链的时候，则证明此对象是不可达的，因此它们会被判定为可回收对象。
可以作为 GC Roots 的对象：
 类静态属性中引用的对象 常量引用的对象 虚拟机栈中引用的对象 本地方法栈中引用的对象  finalize 方法中复活 finalize() 方法只会被调用一次：
@Override protected void finalize() throws Throwable { super.finalize(); obj = this; } 下述代码在内存中如何放置的示例：
StringBuffer str = new StringBuffer(&amp;#34;Hello world&amp;#34;); 假设以上代码是在函数体内运行的，那么:
四个引用  软引用: java.lang.ref.SoftReference 可被回收的引用 弱引用: 发现即回收。由于垃圾回收器的线程通常优先级很大，因此并不一定很快地发现持有弱引用的对象。 虚引用: 跟踪垃圾回收过程  内存泄露 while (true) { for (int i=0; i&amp;lt;10000; i++) { if (!</description>
    </item>
    
    <item>
      <title>Oracle</title>
      <link>https://kunzhao.org/docs/tutorial/database/oracle/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/tutorial/database/oracle/</guid>
      <description>Oracle 执行计划 使用 EXPLAIN PLAN 得到 SQL 语句的执行计划：
EXPLAIN PLAN FOR SELECT * FROM emp WHERE deptno = 10 ORDER BY ename; SELECT plan_table_output FROM TABLE(DBMS_XPLAN.DISPLAY(&amp;#39;PLAN_TABLE&amp;#39;)); -- 或者 SELECT * from table(dbms_xplan.display); Oracle 执行计划显示的是一个树形结构，其阐述了 SQL 引擎执行操作的顺序，树的每一个节点代表一个操作：表访问、连接或排序等，各个操作之间存在父子关系。
   Operation 解释 SQL     TABLE ACCESS FULL 全表扫描    PARTITION RANGE SINGLE 单个分区扫描 SELECT * FROM t WHERE n1 = 3 AND d1 = to_date(&#39;2007-07-19&#39;, &#39;yyyy-mm-dd&#39;)   PARTITION RANGE ITERATOR 多个分区扫描 SELECT * FROM t WHERE n1 = 3 AND d1 &amp;lt; to_date(&#39;2007-07-19&#39;, &#39;yyyy-mm-dd&#39;)   PARTITION RANGE INLIST 存在 IN 的多个分区扫描 SELECT * FROM t WHERE n1 IN (1, 3) AND d1 = to_date(&#39;2007-07-19&#39;, &#39;yyyy-mm-dd&#39;)   PARTITION RANGE ALL 所有分区扫描 SELECT * FROM t WHERE n1 BETWEEN 6000 AND 7000   PARTITION RANGE OR OR 条件分区扫描 SELECT * FROM t WHERE n1 = 3 OR d1 = to_date(&#39;2007-07-19&#39;, &#39;yyyy-mm-dd&#39;)   INDEX FULL SCAN 全索引扫描    INDEX FAST FULL SCAN 快速全索引扫描    TABLE ACCESS BY USER ROWID 直接指定 ROWID SELECT * FROM emp WHERE rowid IN (&#39;ASDJOWF&#39;, &#39;ADSOFJO&#39;)   TABLE ACCESS BY INDEX ROWID     INDEX UNIQUE SCAN 用上了唯一索引    INDEX RANGE SCAN 用上了非唯一索引     Oracle vs MySQL     Oracle MySQL     事务默认隔离级别 read commited repeatable read   价格 ORACLE 11g 标准版售价在六位数 开源免费   AUTO_INCREMENT 不可以声明，主键自带自增长 可以声明   索引 Oracle 的索引是数据库级别，不可以同名 MySQL 的索引是表级别的，可以同名   数字类型 NUMBER INT/DECIMAL   分页 Oracle 是需要用到伪列 ROWNUM 和嵌套查询 LIMIT X, Y   默认端口 1521 3306    参考  Oracle与MySQL的SQL语句区别 Oracle 执行计划（Explain Plan） 《Oracle性能诊断艺术》  </description>
    </item>
    
    <item>
      <title>可扩展性</title>
      <link>https://kunzhao.org/docs/tutorial/sentinel/spi/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/tutorial/sentinel/spi/</guid>
      <description>可扩展性 SpiLoader public final class SpiLoader { public static &amp;lt;T&amp;gt; T loadFirstInstanceOrDefault(Class&amp;lt;T&amp;gt; clazz, Class&amp;lt;? extends T&amp;gt; defaultClass) { AssertUtil.notNull(clazz, &amp;#34;SPI class cannot be null&amp;#34;); AssertUtil.notNull(defaultClass, &amp;#34;default SPI class cannot be null&amp;#34;); try { String key = clazz.getName(); // Not thread-safe, as it&amp;#39;s expected to be resolved in a thread-safe context.  ServiceLoader&amp;lt;T&amp;gt; serviceLoader = SERVICE_LOADER_MAP.get(key); if (serviceLoader == null) { serviceLoader = ServiceLoaderUtil.getServiceLoader(clazz); SERVICE_LOADER_MAP.put(key, serviceLoader); } for (T instance : serviceLoader) { if (instance.</description>
    </item>
    
    <item>
      <title>平均负载</title>
      <link>https://kunzhao.org/docs/tutorial/unix-optimize/avg-load/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/tutorial/unix-optimize/avg-load/</guid>
      <description>平均负载  作者：赵坤
 uptime 命令 了解负载情况：
$ uptime 22:39:37 up 2:47, 1 user, load average: 1.44, 1.12, 0.79 含义：
# 当前时间 22:39:37 # 系统运行多久了 up 2:47 # 当前有几个用户登录 1 user # 过去 1 分钟、5 分钟、15 分钟的平均负载 load average: 1.44, 1.12, 0.79 平均负载的含义  平均负载是指单位时间内，系统处于可运行状态和不可中断状态的平均进程数，也就是平均活跃进程数。它不仅包括了正在使用 CPU 的进程，还包括等待 CPU 和等待 I/O 的进程。
  可运行状态的进程，是指正在使用 CPU 或者正在等待 CPU 的进程，也就是我们常用 ps 命令看到的，处于 R 状态（Running 或 Runnable）的进程。 不可中断状态的进程则是正处于内核态关键流程中的进程，并且这些流程是不可打断的，比如最常见的是等待硬件设备的 I/O 响应，也就是我们在 ps 命令中看到的 D 状态（Uninterruptible Sleep，也称为 Disk Sleep）的进程。  $ ps -efl F S UID PID PPID C PRI NI ADDR SZ WCHAN STIME TTY TIME CMD 4 S root 1 0 0 80 0 - 42420 - 19:51 ?</description>
    </item>
    
    <item>
      <title>并发 - 多线程的实现方式</title>
      <link>https://kunzhao.org/docs/programmer-interview/java/multi-thread/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/programmer-interview/java/multi-thread/</guid>
      <description>多线程的实现方式 Java多线程实现方式主要有四种：
 继承 Thread 类 实现 Runnable 接口 实现 Callable 接口 使用线程池  继承 Thread 类 class MyThread extends Thread { @Override public void run() { System.out.println(&amp;#34;MyThread.run()&amp;#34;); } } MyThread myThread1 = new MyThread(); MyThread myThread2 = new MyThread(); myThread1.start(); myThread2.start(); 实现 Runnable 接口 class MyTask implements Runnable { @Override public void run() { System.out.println(&amp;#34;MyTask running....&amp;#34;); } } new Thread(new MyTask()).start(); 实现 Callable 接口 Callable 接口可以在任务执行完之后获取结果：
public class MyCallable implements Callable&amp;lt;String&amp;gt; { @Override public String call() throws Exception { return String.</description>
    </item>
    
    <item>
      <title>设计数据密集型应用程序 - 可靠 &amp; 可扩展 &amp; 可维护</title>
      <link>https://kunzhao.org/docs/books/ddia/ddia-chapter1/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/books/ddia/ddia-chapter1/</guid>
      <description>设计数据密集型应用程序 - 可靠 &amp;amp; 可扩展 &amp;amp; 可维护  笔记来自于 《Designing Data-Intensive Applications》 的第一章
 何为数据密集型应用程序 很多应用程序都需要用到如下和数据打交道的系统:
 数据库 缓存 搜索数据 &amp;amp; 索引 流处理 批量处理  设计这样的应用程序需要考虑很多因素，在此重点关注:
 可靠性: 系统持续工作 可扩展: 能维持系统负载 (Load) 的增长 可维护: 多人维护  Twitter 的负载  2012 年 Tweet 平均产生的速率: 4.6k/s，峰值速率可以达到 12k/s. 用户浏览首页的这个 API 请求平均: 300k/s.  Twitter 主要的挑战在于，每个用户可以关注很多人，每个人可以被很多人关注。实现这种系统通常有两种方式:
(1) 用户发布 Tweet 直接写入到大的 Tweet 表中即可。而用户浏览首页，需要首先查找用户关注的所有人，找到这些人发布的所有 Tweet，然后(按照时间)合并这些 Tweet:
SELECT tweets.*, users.* FROM tweets JOIN users ON tweets.sender_id = users.</description>
    </item>
    
    <item>
      <title>CPU 上下文切换</title>
      <link>https://kunzhao.org/docs/tutorial/unix-optimize/context-switch/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/tutorial/unix-optimize/context-switch/</guid>
      <description>CPU 上下文切换  作者：赵坤
 CPU 上下文  CPU 上下文是 CPU 在运行任何任务前，必须的依赖环境。在每个任务运行前，CPU 需要知道任务从哪里加载、又从哪里开始运行，所以这些环境通常包括 CPU 寄存器和程序计数器等。
 查看系统上下文切换情况 可以使用 vmstat 查询：
# 每隔 5 秒查询一次 $ vmstat 5 procs -----------memory---------- ---swap-- -----io---- -system-- ------cpu----- r b swpd free buff cache si so bi bo in cs us sy id wa st 0 0 256 170532 136656 3361432 0 0 38 53 189 557 6 2 92 0 0 0 0 256 170060 136668 3362284 0 0 0 62 441 785 2 1 97 0 0 0 0 256 170320 136676 3362360 0 0 0 13 706 1002 3 1 97 0 0  cs：每秒上下文切换的次数</description>
    </item>
    
    <item>
      <title>并发 - synchronized</title>
      <link>https://kunzhao.org/docs/programmer-interview/java/synchronized/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/programmer-interview/java/synchronized/</guid>
      <description>synchronized 锁的对象是谁 当你使用 synchronized 关键字的时候，JVM 底层使用 Monitor 锁来实现同步。而锁的对象可以分为：
 如果 synchronized 的是普通方法，那么锁是当前实例 如果 synchronized 的是静态方法，那么锁是当前类的 Class 如果 synchronized 的是同步块，那么锁是括号里面的对象  synchronized 同步块 底层基于 monitorenter 和 monitorexit 这一对指令实现的。
public void foo(Object lock) { synchronized (lock) { lock.hashCode(); } } 上面的Java代码将编译为下面的字节码：
public void foo(java.lang.Object); Code: 0: aload_1 1: dup 2: astore_2 3: monitorenter 4: aload_1 5: invokevirtual java/lang/Object.hashCode:()I 8: pop 9: aload_2 10: monitorexit 11: goto 19 14: astore_3 15: aload_2 16: monitorexit 17: aload_3 18: athrow 19: return Exception table: from to target type 4 11 14 any 14 17 14 any synchronized 方法 方法标记为 ACC_SYNCHRONIZED，同样需要进行 monitorenter 操作。</description>
    </item>
    
    <item>
      <title>移动端响应式布局</title>
      <link>https://kunzhao.org/docs/programmer-interview/front-end/mobile-responsive/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/programmer-interview/front-end/mobile-responsive/</guid>
      <description>移动端响应式布局 1px 的坑  1px 的坑：CSS 中的 1px 并不是固定的大小，它是一个跟设备大小有关系的单位。PC 端的 5px 单位看到的视觉效果并不等同于移动端看到的 5px 的效果。
 1 CSS 像素与屏幕物理像素的换算公式：
1 CSS 像素 = 物理像素 / 分辨率 rem rem 是一种相对于根字体大小的相对单位。根字体就是 &amp;lt;html&amp;gt; 元素的字体，改变了 &amp;lt;html&amp;gt; 字体的大小，那么整个页面上基于 rem 的大小都会改变。一般初始值是 16px。
这种方案需要监听屏幕窗口大小的变化，然后动态地改变 &amp;lt;html&amp;gt; 的 font-size，这个 font-size 一变化，整个页面的其他元素的大小也会跟着变化，从而达到适配的效果。
function refreshRem() { var docEl = doc.documentElement; var width = docEl.getBoundingClientRect().width; var rem = width / 10; docEl.style.fontSize = rem + &amp;#39;px&amp;#39;; flexible.rem = win.rem = rem; } win.addEventListener(&amp;#39;resize&amp;#39;, refreshRem); 有了这个函数，再使用 CSS 预编译插件 px2rem 将 CSS 中定义的 px 转为 rem 单位即可。</description>
    </item>
    
    <item>
      <title>设计数据密集型应用程序 - 数据模型 &amp; 查询语言</title>
      <link>https://kunzhao.org/docs/books/ddia/ddia-chapter2/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/books/ddia/ddia-chapter2/</guid>
      <description>设计数据密集型应用程序 - 数据模型 &amp;amp; 查询语言  笔记来自于 《Designing Data-Intensive Applications》 的第二章
 LinkedIn 的简历 简历是一种 self-contained 文档，采用 JSON 的表达方式应该会更为合适。
JSON 示例如下:
{ &amp;#34;user_id&amp;#34;: 251, &amp;#34;first_name&amp;#34;: &amp;#34;Bill&amp;#34;, &amp;#34;last_name&amp;#34;: &amp;#34;Gates&amp;#34;, &amp;#34;summary&amp;#34;: &amp;#34;Co-chair of the Bill &amp;amp; Melinda Gates... Active blogger.&amp;#34;, &amp;#34;region_id&amp;#34;: &amp;#34;us:91&amp;#34;, &amp;#34;industry_id&amp;#34;: 131, &amp;#34;photo_url&amp;#34;: &amp;#34;/p/7/000/253/05b/308dd6e.jpg&amp;#34;, &amp;#34;positions&amp;#34;: [ {&amp;#34;job_title&amp;#34;: &amp;#34;Co-chair&amp;#34;, &amp;#34;organization&amp;#34;: &amp;#34;Bill &amp;amp; Melinda Gates Foundation&amp;#34;}, {&amp;#34;job_title&amp;#34;: &amp;#34;Co-founder, Chairman&amp;#34;, &amp;#34;organization&amp;#34;: &amp;#34;Microsoft&amp;#34;} ], &amp;#34;education&amp;#34;: [ {&amp;#34;school_name&amp;#34;: &amp;#34;Harvard University&amp;#34;, &amp;#34;start&amp;#34;: 1973, &amp;#34;end&amp;#34;: 1975}, {&amp;#34;school_name&amp;#34;: &amp;#34;Lakeside School, Seattle&amp;#34;, &amp;#34;start&amp;#34;: null, &amp;#34;end&amp;#34;: null} ], &amp;#34;contact_info&amp;#34;: { &amp;#34;blog&amp;#34;: &amp;#34;http://thegatesnotes.</description>
    </item>
    
    <item>
      <title>CPU 飙升或 load 飙升</title>
      <link>https://kunzhao.org/docs/tutorial/unix-optimize/high-cpu-and-load/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/tutorial/unix-optimize/high-cpu-and-load/</guid>
      <description>CPU 飙升或 load 飙升 CPU 使用率飙升怎么办 ? 通过 top、ps、pidstat 等工具，你能够轻松找到 CPU 使用率较高（比如 100% ）的进程。接下来，你可能又想知道，占用 CPU 的到底是代码里的哪个函数呢？找到它，你才能更高效、更针对性地进行优化。
哪种工具适合在第一时间分析进程的 CPU 问题呢？我的推荐是 perf。perf 是 Linux 2.6.31 以后内置的性能分析工具。它以性能事件采样为基础，不仅可以分析系统的各种事件和内核性能，还可以用来分析指定应用程序的性能问题。
# -g开启调用关系分析，-p指定php-fpm的进程号21515 $ perf top -g -p 21515  用户 CPU 和 Nice CPU 高，说明用户态进程占用了较多的 CPU，所以应该着重排查进程的性能问题。 系统 CPU 高，说明内核态占用了较多的 CPU，所以应该着重排查内核线程或者系统调用的性能问题。  CPU 毛刺  参考  某服务所在机器统计显示，其 CPU 使用率在高峰时段出现毛刺。
 查看 CPU 1 分钟平均负载，发现 1 分钟平均负载有高有低，波动明显。说明机器上有些进程使用 CPU 波动很大。 登录机器排查进程，使用top指令。因为 CPU 会明显上升，重点怀疑使用 CPU 总时间高的进程，在打开 top 后，使用shift +t可以按照 CPU TIME 进行排序。 perf top -p 45558 gcore pid 可以保留堆栈信息，明确看到负载的位置  Java 高 CPU 传统的方案：</description>
    </item>
    
    <item>
      <title>position 属性</title>
      <link>https://kunzhao.org/docs/programmer-interview/front-end/position/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/programmer-interview/front-end/position/</guid>
      <description>position 属性 作用：决定一个元素放在页面的哪个位置。
static 这是默认值。含义：不要以任何特殊的方式摆放这个元素的位置。
relative 这个属性同 static 的表现一致。如果你加了其它的属性比如 top、right、bottom、left 属性，那么就会导致它相应的偏离自己原来的默认位置。
fixed 让元素相对于浏览器的窗口摆放位置。这个元素不会随着页面的滚动而滚动。
absolute 让元素相对于离自己最近的 position 属性的值是非 static 的祖先元素摆放位置。如果实在找不到 position 属性是非 static 的祖先，那么就会相对于 body 元素摆放位置，随着页面的滚动而滚动。
sticky sticky 是粘性定位 (动态定位)。它依据滚动的位置动态地在 fixed 定位和 relative 定位之间切换。
参考  CSS position explained  </description>
    </item>
    
    <item>
      <title>并发 - ThreadLocal</title>
      <link>https://kunzhao.org/docs/programmer-interview/java/threadlocal/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/programmer-interview/java/threadlocal/</guid>
      <description>ThreadLocal 作用 有一个比喻：
学生需要在签字墙签字，锁 相当于只有一个签字笔，学生们需要争抢这个签字笔；而 ThreadLocal 相当于给每个学生发了一个签字笔，每人一个，效率大大提升。
底层原理 假如你自己需要实现 ThreadLocal&amp;lt;T&amp;gt; 相关的 API，请问你会怎么做？
 你可能会使用 ConcurrentHashMap&amp;lt;Thread, T&amp;gt;，以 Thread.currentThread() 作为 key，这完全可以。但是缺点明显：1. 处理并发问题；2. 必须有指针指向 Thraed 和 这个对象，即使 Thraed 已经结束了，可以被 GC 了。 那我们改为  Collections.synchronizedMap(new WeakHashMap&amp;lt;Thread, T&amp;gt;()) 怎样？ 可以解决 GC 问题，但是多线程问题仍然没有解决。  Java 实现的想法，没有用 &amp;lt;Thread, T&amp;gt; ，而是大概如下：
new WeakHashMap&amp;lt;ThreadLocal,T&amp;gt;() 而事实上，在每个 Thread 内部也的确有这么一个 Map 指针：
public class Thread implements Runnable { ThreadLocal.ThreadLocalMap threadLocals = null; } 虽然 ThreadLocalMap 并不是一个 WeakHashMap，但是它的设计类似 WeakHashMap，它的 Key 是由 Weak Reference 引用的。</description>
    </item>
    
    <item>
      <title>设计数据密集型应用程序 - 存储和读取</title>
      <link>https://kunzhao.org/docs/books/ddia/ddia-chapter3/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/books/ddia/ddia-chapter3/</guid>
      <description>设计数据密集型应用程序 - 存储和读取  笔记来自于 《Designing Data-Intensive Applications》 的第三章
 精心选取的索引可以提升查询的速度，但是也会影响写入的速度。很多数据库系统内部会采用一种 append-only log file 文件，来记录更新了什么数据。
Hash 索引 使用 in-memory hash map 对只进行追加写入的文件进行索引:
如上述讨论，我们只对文件追加，但是如何防止文件大到超出磁盘空间呢？一种可行的办法是，将 log 文件切分为 segments (当一个 segment 文件达到某个大小的时候，就关闭它，然后开始往新的 segment 文件中写入)，我们可以在这些 compaction 中进行 compaction (去除对 key 的重复的历史更新，只保留最近一次的更新即可)。
事实上，在执行 compaction (可以让 segment 文件不至于太大) 的时候，我们还可以同时 merge segments 到新的 segment 文件中，可以使用一个后台线程来执行这些操作。在执行操作的同时，我们依然可以使用旧的 segment 文件继续对外提供 read 和 write 服务。当 merge 完毕后，我们再切换到新的 segment 文件上，然后将旧的 segment 文件删除即可。
现在每一个 segment 文件都拥有了自己的 in-memory hash table，存储了 key 到文件偏移量的映射关系。根据 key 查找值的过程，我们首先检查最近的 segment 的 hash map，如果 key 不在里面，我们就查找第二个 segment，以此类推。merge 操作本身会保证 segment 文件不至于太多，所以我们也无须查看太多的 hash map。当然在实际实现中，还是有很多问题需要考虑:</description>
    </item>
    
    <item>
      <title>CSS 盒模型</title>
      <link>https://kunzhao.org/docs/programmer-interview/front-end/box-sizing/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/programmer-interview/front-end/box-sizing/</guid>
      <description>CSS 盒模型 作用 决定一个元素占据多大的矩形面积。
W3C 盒模型 （标准模型） .myClass { box-sizing: content-box; }  box-sizing 属性的默认值是：content-box
 IE 盒模型 .myClass { box-sizing: border-box; } W3C VS IE 对比 </description>
    </item>
    
    <item>
      <title>并发 - 线程池</title>
      <link>https://kunzhao.org/docs/programmer-interview/java/threadpool/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/programmer-interview/java/threadpool/</guid>
      <description>线程池 简介 好处 说明：线程池的好处是减少在创建和销毁线程上所消耗的时间以及系统资源的开销，解决资源不足的问题。如果不使用线程池，有可能造成系统创建大量同类线程而导致消耗完内存或者“过度切换”的问题。
设计哲学 将任务的提交与执行解耦开，从而无须太大的困难就能为某种类型的任务指定和修改执行策略。
用法 任务无须返回值，调用这个方法：
public void execute(Runnable command) {} 需要返回值的任务，调用 submit：
Future&amp;lt;Object&amp;gt; future = executor.submit(hasReturnValuetask); try { Object s = future.get(); } catch (InterruptedException e) { // ... } catch (ExecutionException e) { // ... } 构造器参数 public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&amp;lt;Runnable&amp;gt; workQueue, ThreadFactory threadFactory, RejectedExecutionHandler handler) { // ... } execute() 方法运行原理 （1） 如果当前运行的线程少于 corePoolSize，则创建新线程来执行任务。部分代码片段如下：
if (workerCountOf(c) &amp;lt; corePoolSize) { if (addWorker(command, true)) return; c = ctl.</description>
    </item>
    
    <item>
      <title>设计数据密集型应用程序 - 编码与演化</title>
      <link>https://kunzhao.org/docs/books/ddia/ddia-chapter4/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/books/ddia/ddia-chapter4/</guid>
      <description>设计数据密集型应用程序 - 编码与演化  笔记来自于 《Designing Data-Intensive Applications》 的第四章
 JSON 的二进制编码 { &amp;#34;userName&amp;#34;: &amp;#34;Martin&amp;#34;, &amp;#34;favoriteNumber&amp;#34;: 1337, &amp;#34;interests&amp;#34;: [&amp;#34;daydreaming&amp;#34;, &amp;#34;hacking&amp;#34;] } MessagePack, a binary encoding for JSON.
第一个字节 0x83 表示接下来将会是一个对象，第二个字节 0xa8，表示接下来是一个字符串。
Thrift 和 Protocol Buffers Protocol Buffers 是由 Google 开发的，Thrift 是有 Facebook 开发的，二者均需要使用一个 schema 来帮助编码。在 Thrift 世界中，对上述 JSON 的编码，需要首先使用 Thrift IDL 来描述 schema:
struct Person { 1: required string userName, 2: optional i64 favoriteNumber, 3: optional list&amp;lt;string&amp;gt; interests } Protocol Buffers 中定义的 schema 如下所示:</description>
    </item>
    
    <item>
      <title>BFC 和 IFC</title>
      <link>https://kunzhao.org/docs/programmer-interview/front-end/bfc_ifc/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/programmer-interview/front-end/bfc_ifc/</guid>
      <description>BFC 和 IFC BFC - Block formatting context 简介 BFC（Block Formatting Context）直译为“块级格式化范围”。是 W3C CSS 2.1 规范中的一个概念，它决定了元素如何对其内容进行定位，以及与其他元素的关系和相互作用。当涉及到可视化布局的时候，Block Formatting Context 提供了一个环境，HTML 元素在这个环境中按照一定规则进行布局。一个环境中的元素不会影响到其它环境中的布局。
具有 BFC 特性的元素可以看作是隔离了的独立容器，容器里面的元素不会在布局上影响到外面的元素，并且 BFC 具有普通容器所没有的一些特性。
何时触发 BFC  &amp;lt;html&amp;gt; float 属性不为 none position 属性是 absolute 或 fixed overflow 属性不为 visible display 属性为 inline-block display 属性为 table-cell、table-caption、table、table-row 等表格元素 display 属性为 flow-root display 属性为 flex、inline-flex display 属性为 grid、inline-grid column-count 或 column-width 属性不为 auto 的 column-span 属性为 all  BFC 作用 消除外边距重叠 发生外边距重叠 &amp;lt;body&amp;gt; &amp;lt;div style=&amp;#34;margin-bottom: 100px&amp;#34;&amp;gt;&amp;lt;/div&amp;gt; &amp;lt;div style=&amp;#34;margin-top: 100px&amp;#34;&amp;gt;&amp;lt;/div&amp;gt; &amp;lt;/body&amp;gt;   分别放在不同的 BFC 容器中 &amp;lt;div style=&amp;#34;overflow: hidden;&amp;#34;&amp;gt; &amp;lt;p style=&amp;#34;margin-bottom: 100px;&amp;#34;&amp;gt;&amp;lt;/p&amp;gt; &amp;lt;/div&amp;gt; &amp;lt;div style=&amp;#34;overflow: hidden;&amp;#34;&amp;gt; &amp;lt;p style=&amp;#34;margin-top: 100px;&amp;#34;&amp;gt;&amp;lt;/p&amp;gt; &amp;lt;/div&amp;gt;    包含浮动的元素 包含 float 孩子，容器高度变窄 &amp;lt;div style=&amp;#34;border: 1px solid #000;&amp;#34;&amp;gt; &amp;lt;div style=&amp;#34;width: 100px; height: 100px; float: left;&amp;#34;&amp;gt;&amp;lt;/div&amp;gt; &amp;lt;/div&amp;gt;   触发容器的 BFC，正常计算高度 &amp;lt;div style=&amp;#34;border: 1px solid #000; overflow: hidden&amp;#34;&amp;gt; &amp;lt;div style=&amp;#34;width: 100px; height: 100px; float: left;&amp;#34;&amp;gt;&amp;lt;/div&amp;gt; &amp;lt;/div&amp;gt;    阻止元素被浮动元素覆盖 div B 被 float div A 覆盖 &amp;lt;div class=&amp;#34;A&amp;#34; style=&amp;#34;float: left&amp;#34;&amp;gt;&amp;lt;/div&amp;gt; &amp;lt;div class=&amp;#34;B&amp;#34;&amp;gt;&amp;lt;/div&amp;gt;   触发容器的 BFC &amp;lt;div class=&amp;#34;A&amp;#34; style=&amp;#34;float: left&amp;#34;&amp;gt;&amp;lt;/div&amp;gt; &amp;lt;div class=&amp;#34;B&amp;#34; style=&amp;#34;overflow: hidden&amp;#34;&amp;gt;&amp;lt;/div&amp;gt;    IFC - Inline formatting context 什么时候触发 IFC 当一个 block 容器只包含 inline 元素的时候就会触发 IFC</description>
    </item>
    
    <item>
      <title>并发 - volatile</title>
      <link>https://kunzhao.org/docs/programmer-interview/java/volatile/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/programmer-interview/java/volatile/</guid>
      <description>volatile 作用  在多处理器中，保证共享变量的 “可见性”（一个线程修改后，另外一个线程能立即读取到这个最新修改的值） 禁止对指令进行重排序  为什么要指令重排 为了消除指令与指令间的等待，在不影响单线程程序执行结果的前提下，尽可能提高并行度。
三大特性  原子性 有序性 可见性  对比 synchronized  volatile 无法保证原子性 volatile 不会使线程陷入阻塞，不会引起线程上下文的切换和调度  典型用法 数绵羊程序：
volatile boolean sleep; while (!sleep) { countSleep(); } 底层原理 有 volatile 变量修饰的共享变量进行写操作的时候会多出一行以 lock;  指令开头的汇编代码。而 lock;  指令相当于一个内存屏障，其作用如下所示：
 将当前处理器缓存行的数据写回到系统内存。 这个写回内存的操作会使在其他 CPU 里缓存了该内存地址的数据无效。  </description>
    </item>
    
    <item>
      <title>设计数据密集型应用程序 - Replication</title>
      <link>https://kunzhao.org/docs/books/ddia/ddia-chapter5/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/books/ddia/ddia-chapter5/</guid>
      <description>设计数据密集型应用程序 - Replication Replication 就是将相同数据的拷贝防止在多个通过网络连接在一起的机器上。
为什么需要 Replication  让数据在地理位置上更靠近用户 部分数据坏掉的时候，系统依然能持续工作 可伸缩，增加机器即可增加吞吐量  如果你需要 replication 的数据不发生变化，那么 replication 的过程是及其简单的，你只需拷贝到其它各个机器上，然后你的任务就完成了。然而 replication 最难的地方也就在这个地方，如何处理变化的数据？接下来就介绍三种常见的处理 replication 中数据变化的算法: single-leader、multi-leader、leaderless。
Leaders 和 Followers 每一个存储一份数据库拷贝的节点称之为: replica。每一个 replica 都需要处理写数据的操作，久而久之，每一个节点之间存储的数据也就不再一致了。解决这种问题最常见的办法就是: leader-based replication (active/passive 或 master-slave replication)，它的工作原理如下:
 其中某个 replica 被指定为 leader (master 或 primary)，客户端想要写数据，那么必须将它们的写数据的请求发送给 leader，然后 leader 随后写入到自己的本地磁盘中。 其余的 replica 称之为 follower (read replicas, slaves, secondaries, hot standbys)，当 leader 写入数据到本地磁盘的时候，同时将数据改变的部分作为 replication log 或者 change stream 发送给它的 followers。每一个 follower 根据收到的 log 按照和 leader 处理不同写操作之间的相同的顺序，来更新它自己本地的数据。 当一个客户端想要读取数据的时候，它可以发送读请求给 leader 或者任意一个 follower。但是写请求的话只能发送给 leader。  这种模式的 replication 内置在许多数据库中，例如: PostgreSQL、MySQL、Oracle Data Guard、SQL Server 的 AlwaysOn Availability Groups，甚至在许多非关系型数据库中也有它的身影，例如: MongoDB、RethinkDB、Espresso，这种模式也局限于数据库，像消息中间件 Kafka 和 RabbitMQ 高可用的队列都依赖它，一些网络文件系统和 replicated block devices 例如 DRBD 也是同样的道理。</description>
    </item>
    
    <item>
      <title>ConcurrentHashMap 1.8</title>
      <link>https://kunzhao.org/docs/programmer-interview/java/concurrenthashmap-18/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/programmer-interview/java/concurrenthashmap-18/</guid>
      <description>ConcurrentHashMap 1.8 计算 size() final long sumCount() { CounterCell[] as = counterCells; CounterCell a; long sum = baseCount; if (as != null) { for (int i = 0; i &amp;lt; as.length; ++i) { if ((a = as[i]) != null) sum += a.value; } } return sum; } public int size() { long n = sumCount(); return ((n &amp;lt; 0L) ? 0 : (n &amp;gt; (long)Integer.MAX_VALUE) ? Integer.MAX_VALUE : (int)n); } </description>
    </item>
    
    <item>
      <title>CyclicBarrier</title>
      <link>https://kunzhao.org/docs/programmer-interview/java/cyclicbarrier/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/programmer-interview/java/cyclicbarrier/</guid>
      <description>CyclicBarrier 作用 让一组线程等待某个事件(barrier)的发生。
实现原理 在 dowait 方法中有如下计数器：
int index = --count; if (index == 0) { // tripped  boolean ranAction = false; try { final Runnable command = barrierCommand; if (command != null) command.run(); ranAction = true; nextGeneration(); return 0; } finally { if (!ranAction) breakBarrier(); } } 其中 runGeneration 或 breakBarrier 中有如下代码片段：
trip.signalAll(); trip 是信号量：
/** Condition to wait on until tripped */ private final Condition trip = lock.</description>
    </item>
    
    <item>
      <title>左固定右自适应</title>
      <link>https://kunzhao.org/docs/programmer-interview/front-end/layout-left-fix-right-responsive/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/programmer-interview/front-end/layout-left-fix-right-responsive/</guid>
      <description>两列布局：左固定，右自适应 &amp;lt;div class=&amp;#34;container&amp;#34;&amp;gt; &amp;lt;div class=&amp;#34;left&amp;#34;&amp;gt; &amp;lt;p&amp;gt;这是左边的盒子&amp;lt;/p&amp;gt; &amp;lt;/div&amp;gt; &amp;lt;div class=&amp;#34;right&amp;#34;&amp;gt; &amp;lt;p&amp;gt;这是右边的盒子&amp;lt;/p&amp;gt; &amp;lt;/div&amp;gt; &amp;lt;/div&amp;gt; 双 float .container::after { content: &amp;#34;&amp;#34;; display: block; clear: both; } .left, .right { box-sizing: border-box; float: left; } .right { width: calc(100% - 120px); } float + margin-left .container::after { content: &amp;#34;&amp;#34;; display: block; clear: both; } .left { box-sizing: border-box; float: left; } .right { margin-left: 120px; } absolute + margin-left .left { box-sizing: border-box; position: absolute; } .</description>
    </item>
    
    <item>
      <title>设计数据密集型应用程序 - Partitioning</title>
      <link>https://kunzhao.org/docs/books/ddia/ddia-chapter6/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/books/ddia/ddia-chapter6/</guid>
      <description>设计数据密集型应用程序 - Partitioning  在上一章中，我们讨论了复制，即在不同的节点上拥有相同数据的多个副本。对于非常大的数据集或非常高的查询吞吐量，这是不够的：我们需要将数据分成多个分区，也称为分片。
 通常，分区的定义方式是，每一条数据（每个记录、行或文档）只属于一个分区。实现这一点有多种方法，我们将在本章中深入讨论。实际上，每个分区都是自己的小数据库，尽管数据库可能支持同时接触多个分区的操作。
想要分区数据的主要原因是可伸缩性。不同的分区可以放在一个无共享集群中的不同节点。因此，大型数据集可以分布在多个磁盘上，查询负载可以分布在多个处理器上。
对于在单个分区上操作的查询，每个节点都可以独立地为自己的分区执行查询，因此可以通过添加更多的节点来扩展查询吞吐量。大型、复杂的查询可以跨多个节点并行化，尽管这会变得非常困难。
分区数据库在20世纪80年代由 Teradata 和 Tandem NonStop SQL[1] 等产品开创，最近又被 NoSQL 数据库和基于 Hadoop 的数据仓库重新发现。有些系统是为事务性工作负载而设计的，而其他系统则是为分析而设计的：这种差异会影响系统的优化方式，但是分区的基本原理适用于这两种工作负载。
在这一章中，我们将首先了解划分大型数据集的不同方法，并观察数据索引与分区之间的交互作用。然后我们将讨论负载均衡，如果您想在集群中添加或删除节点，这是必需的。最后，我们将概述数据库如何将请求路由到正确的分区并执行查询。
分区和复制 每个分区通常与复制节点的多个副本合并存储。尽管每个记录的容错性可能仍属于一个不同的节点，但这意味着每个记录的容错性仍然不同。
一个节点可以存储多个分区。如果使用主从复制模型，分区和复制的组合可以如下图所示。每个分区的 Leader 被分配给一个节点，它的跟随者被分配给其他节点。每个节点可能是某些分区的 Leader 节点和其他分区的跟随节点。
我们在第5章中讨论的关于数据库复制的所有内容都同样适用于分区的复制。分区方案的选择主要与复制方案的选择无关，因此在本章中我们将保持简单，而忽略复制。
键值对数据的分区 假设你有大量的数据，你想对它进行分区。如何决定在哪些节点上存储哪些记录？
我们分区的目标是将数据和查询负载均匀地分布在节点上。如果每个节点都得到公平的共享，那么理论上10个节点应该能够处理10倍于单个节点的数据量和10倍的读写吞吐量（暂时忽略复制）。
如果分区不公平，使得一些分区比其他分区拥有更多的数据或查询，我们称之为倾斜分区。倾斜的存在使得分区变得更少有效。在一个极端的情况是，所有的负载都可能在一个分区上结束，因此10个节点中有9个是空闲的，而您的瓶颈是单个繁忙的节点。具有不成比例的高负载的分区称为热点。
避免热点的最简单方法是将记录随机分配给节点。这样可以将数据均匀地分布在各个节点上，但它有一个很大的缺点：当您试图读取一个特定的项时，您无法知道它在哪个节点上，所以必须并行地查询所有节点。
我们可以做得更好。现在我们假设您有一个简单的键值数据模型，在这个模型中，您总是通过主键访问记录。例如，在一本老式的纸质百科全书中，您按标题查找条目；由于所有条目都是按标题字母顺序排序的，因此您可以很快找到要查找的条目。
根据键的范围分区 分区的一种方法是给每个分区分配一个连续的键范围（从最小值到最大值），就像纸质百科全书一样。如果知道范围之间的边界，就可以很容易地确定哪个分区包含给定的键。如果您还知道哪个分区分配给哪个节点，那么您可以直接向适当的节点提出请求（或者，对于百科全书，从书架上挑选正确的书）。
键的范围不一定均匀分布，因为数据可能不均匀分布。例如，在图6-2中，卷1包含以A和B开头的单词，而第12卷包含以T、U、V、X、Y和Z开头的单词。如果字母表中每两个字母有一个卷，则某些卷会比其他的大得多。为了使数据均匀分布，分区边界需要与数据相适应。
分区边界可以由管理员手动选择，也可以由数据库自动选择（我们将在第209页的“重新平衡分区”中更详细地讨论分区边界的选择）。Bigtable、它的开源等价HBase[2，3]、reinstdb和2.4[4]之前的MongoDB都使用这种分区策略。
在每个分区中，我们可以按排序顺序保存键（参见第76页的“SSTables和LSMTrees”）。这样做的优点是范围扫描很容易，您可以将键视为一个连接索引，以便在一个查询中获取多个相关记录（请参阅第87页的“多列索引”）。例如，考虑一个存储来自传感器网络的数据的应用程序，其中的键是测量的时间戳（年-月-日-时-分-秒）。在这种情况下，范围扫描非常有用，因为它们可以让你很容易地获取某个月的所有读数。
但是，键范围划分的缺点是某些访问模式可能导致热点。如果键是时间戳，则分区对应于时间范围，例如，每天一个分区。不幸的是，由于我们在测量时将数据从传感器写入数据库，所以所有的写入操作最终都会转到同一个分区（今天的分区），这样分区就可以在其他分区空闲的情况下进行写操作[5]。
为了避免传感器数据库中的这个问题，您需要使用时间戳以外的东西作为 Key 的第一个元素。例如，您可以在每个时间戳前面加上传感器名称，以便首先按传感器名称，然后按时间进行分区。假设有多个传感器同时处于活动状态，那么写入负载最终将更加均匀地分布在各个分区上。现在，当您想要在一个时间范围内获取多个传感器的值时，需要对每个传感器名称执行单独的范围查询。
根据键的 Hash 进行分区 由于存在倾斜和热点的风险，许多分布式数据存储使用哈希函数来确定给定 Key 的分区。
一个好的散列函数接受倾斜的数据并使其均匀分布。假设您有一个32位哈希函数，它接受一个字符串。无论何时给它一个新字符串，它都会返回一个介于0和232-1之间的随机数。即使输入字符串非常相似，它们的哈希值也均匀地分布在这个数字范围内。
出于分区的目的，散列函数不需要加密性强：例如，Cassandra 和 MongoDB 使用 MD5，而 Voldemort 使用 Fowler–Noll–Vo 函数。许多编程语言都内置了简单的哈希函数（因为它们用于哈希表），但是它们可能不适合分区：例如，在 Java 中 Object.hashCode（）和 Ruby 的 Object# 哈希，同一个键在不同的进程中可能有不同的哈希值[6]。
一旦你有了一个合适的 Key 哈希函数，你就可以为每个分区分配一个哈希范围（而不是一个Key范围），哈希在分区范围内的每个 Key 都将存储在该分区中。如图6-3所示。</description>
    </item>
    
    <item>
      <title>flex 布局</title>
      <link>https://kunzhao.org/docs/programmer-interview/front-end/flex/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/programmer-interview/front-end/flex/</guid>
      <description>flex 布局 flex 容器 开启 flex 容器 .myClass { /** inline-flex 也可以开启 */ display: flex; } flex-direction flex-direction 定义了 main axis，其决定容器内的元素是横向布局还是纵向布局，其可选值如下：
 row (默认) row-reverse column column-reverse  flex-wrap flex-wrap 指定容器内的元素如何换行，默认情况下是挤在一行。其可选值如下：
 nowrap (默认) wrap：from top to bottom wrap-reverse：from bottom to top  flex-flow flex-flow 是 flex-direction 和 flex-wrap 这两个属性的缩写，能够同时定义这两个属性。
.myClass { flex-flow: flex-direction flex-wrap; }  flex-flow 的默认值：row nowrap
 justify-content 在 main axis 轴上如何利用剩余空间：
align-items 在 cross axis 轴上如何利用空间：</description>
    </item>
    
    <item>
      <title>设计数据密集型应用程序 - 事务</title>
      <link>https://kunzhao.org/docs/books/ddia/ddia-chapter7/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/books/ddia/ddia-chapter7/</guid>
      <description>设计数据密集型应用程序 - 事务  一些作者声称，一般的两阶段提交由于其带来的性能或可用性问题，支持起来过于昂贵。我们认为，最好让应用程序程序员在瓶颈出现时处理由于过度使用事务而导致的性能问题，而不是总是围绕缺少事务进行编码。 &amp;mdash; James Corbett et al., Spanner: Google’s Globally-Distributed Database (2012)
 在数据系统的严酷现实中，很多事情都会出错：
 数据库软件或硬件可能随时发生故障（包括在写入操作的中间）。 应用程序可能随时崩溃（包括一系列操作的中途）。 网络中断可能会意外地切断应用程序与数据库的连接，或断开一个数据库节点与另一个数据库节点的连接。 多个客户端可能同时写入数据库，覆盖彼此的更改。 客户端可能会读取没有意义的数据，因为它只更新了一部分。 客户端之间的竞争条件可能会导致令人惊讶的错误。  为了可靠，系统必须处理这些故障，并确保它们不会导致整个系统的灾难性故障。然而，实现容错机制需要大量的工作。它需要仔细考虑所有可能出错的地方，并进行大量测试以确保解决方案能够实际工作。
几十年来，事务一直是简化这些问题的首选机制。事务是应用程序将多个读写操作组合到一个逻辑单元中的一种方法。从概念上讲，事务中的所有读写操作都作为一个操作执行：要么整个事务成功（commit），要么失败（abort，rollback）。如果失败，应用程序可以安全地重试。有了事务，应用程序的错误处理就变得简单多了，因为它不需要担心部分失败，也就是说，有些操作成功，有些操作失败（无论什么原因）。
如果你花了数年时间处理事务，它们可能看起来很明显，但我们不应该认为它们是理所当然的。事务不是自然规律；创建事务的目的是为了简化访问数据库的应用程序的编程模型。通过使用事务，应用程序可以自由地忽略某些潜在的错误场景和并发问题，因为数据库会处理它们（我们称之为安全保证）。
并不是每个应用程序都需要事务，有时削弱事务性保证或完全放弃事务性保证有好处（例如，为了获得更高的性能或更高的可用性）。一些安全属性可以在没有事务的情况下实现。
你如何判断你是否需要事务？为了回答这个问题，我们首先需要确切地了解事务可以提供什么样的安全保障，以及与之相关的成本。虽然乍一看事务似乎很简单，但实际上有许多微妙但重要的细节在起作用。
在本章中，我们将研究许多可能出错的例子，并探索数据库用来防范这些问题的算法。我们将特别深入到并发控制领域，讨论可能发生的各种竞争条件，以及数据库如何实现隔离级别，如读提交、快照隔离和串行化。
本章适用于单节点和分布式数据库；在第8章中，我们将重点讨论仅在分布式系统中出现的特定挑战。
事务的模糊概念 现在几乎所有的关系型数据库和一些非关系型数据库都支持事务。其中大多数都遵循ibmsystemr在1975年引入的样式，第一个SQL数据库[1，2，3]。虽然一些实现细节有所改变，但40年来，总体思路基本不变：MySQL、PostgreSQL、Oracle、sqlserver等的事务支持与systemr惊人地相似。
在21世纪末，非关系（NoSQL）数据库开始流行起来。他们希望通过提供新的数据模型（见第2章）和默认的复制（第5章）和分区（第6章）来改善关系现状。事务是这场运动的主要牺牲品：许多新一代数据库完全放弃了事务，或者重新定义了这个词来描述一组比以前理解的要弱得多的保证[4]。
随着这种新的分布式数据库的大肆宣传，人们普遍认为事务是可伸缩性的对立面，任何大型系统都必须放弃事务，以保持良好的性能和高可用性[5,6]。另一方面，事务性保证有时由数据库供应商提出，作为“严肃的应用程序”和“有价值的数据”的基本要求。
事实并非如此简单：与其他技术设计选择一样，事务有其优势和局限性。为了理解这些权衡，让我们详细介绍事务在正常操作和各种极端（但现实）情况下可以提供的保证。
ACID 的意义 事务提供的安全保证通常用众所周知的缩写ACID来描述，它代表原子性、一致性、隔离性和持久性。它是1983年由Theo Härder和Andreas Reuter[7]创造的，目的是为了在数据库。
但是在实践中，一个数据库的ACID实现并不等同于另一个数据库的实现。例如，正如我们将要看到的，孤立的含义有很多模棱两可的地方。高层次的想法是正确的，但魔鬼在于细节。今天，当一个系统声称“符合ACID”时，你还不清楚到底能得到什么样的保证。不幸的是，ACID已经成为一个市场术语。
（不符合ACID标准的系统有时称为BASE，它代表基本可用、软状态和最终一致性[9]。这甚至比ACID的定义更模糊。似乎对base唯一合理的定义是“not ACID”；也就是说，它几乎可以表示任何你想要的东西。）
让我们深入研究原子性、一致性、隔离性和持久性的定义，因为这将使我们完善我们对事务的概念。
（1）原子性
一般来说，原子是指不能分解成更小的东西零件。零件在计算机的不同分支中，单词的意思是相似但又微妙不同的东西。例如，在多线程编程中，如果一个线程执行原子操作，这意味着另一个线程不可能看到该操作的一半finishedresult。系统只能处于操作前或操作后的状态，而不是介于两者之间的状态。
相比之下，在ACID环境中，原子性与并发性无关。它没有描述如果多个进程试图同时访问同一个数据会发生什么，因为这是在字母I下的隔离（参见第225页的“隔离”）。
相反，ACID原子性描述的是，如果客户端想要进行多个写操作，但在处理了一些写入操作之后发生了错误，例如，进程崩溃、网络连接中断、磁盘已满或违反了某些完整性约束。如果写入操作被组合到一个atomic transaction中，并且由于错误而无法完成（提交）事务，则事务将中止，数据库必须放弃或撤消迄今为止在该事务中所做的任何写入操作。
如果没有原子性，如果在进行多次更改的过程中发生了错误，则很难知道哪些更改已生效，哪些更改没有生效。应用程序可以重试，但这有可能使同一更改发生两次，从而导致重复或不正确的数据。原子性简化了这个问题：如果一个事务被中止，应用程序可以确保它没有改变任何东西，所以它可以安全地被中止重试过了。
ACID原子性的定义特性是能够在出错时中止事务并放弃该事务中的所有写操作。也许可终止性比原子性更好，但我们还是坚持原子性，因为这是一个常用的词。
（2）一致性
“一致性”这个词严重超载：
 在第5章中，我们讨论了副本一致性以及异步复制系统中出现的最终一致性问题（请参阅第161页的“复制延迟问题”）。 一致哈希是一些系统用于重新平衡的分区方法（请参阅第204页的“一致哈希”）。 在CAP定理（见第9章）中，一致性一词用于表示线性化（见324页的“线性化能力”）。 在ACID的上下文中，一致性是指数据库处于“良好状态”的特定于应用程序的概念  不幸的是，同一个词至少有四种不同的意思。
ACID一致性的思想是关于数据的某些陈述（不变量）必须始终为真-例如，在一个会计系统中，所有账户的贷方和借方必须总是平衡的。如果事务以根据这些不变量有效的adatabase开始，并且事务期间的任何写入都保持有效性，那么您可以确保这些不变量始终是满意。
不过，这种一致性的思想依赖于应用程序的不变量概念，并且由应用程序负责定义它的事务处理是正确的，以便保留一致性。这不是数据库可以保证的：如果你写的坏数据违反了你的不变量，数据库不能阻止你。（数据库可以检查某些特定类型的不变量，例如使用foreignkey约束或唯一性约束。但是，一般情况下，应用程序会定义哪些数据有效或无效，而数据库只存储这些数据。）
原子性、隔离性和持久性是数据库的属性，而一致性（在 ACID 意义上）是应用程序的属性。为了实现一致性，应用程序可能会重新连接数据库的原子性和隔离属性，但这并不仅仅取决于数据库。因此，字母C并不真的属于ACID。
（3）隔离
大多数数据库同时由多个客户端访问。如果他们在读写数据库的不同部分，这是没有问题的，但是如果他们访问相同的数据库记录，你可能会遇到并发问题（竞争条件）。
假设您有两个客户端同时递增存储在数据库中的计数器。每个客户端需要读取当前值，添加1，然后将新值写回（假设数据库中没有内置任何增量操作）。在图7-1中，计数器应该从42增加到44，因为发生了两个增量，但实际上由于竞争条件，它只增加到43。</description>
    </item>
    
    <item>
      <title>CSS 九宫格</title>
      <link>https://kunzhao.org/docs/programmer-interview/front-end/css-jiugongge/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/programmer-interview/front-end/css-jiugongge/</guid>
      <description>CSS 九宫格 公共 CSS 属性 .square{ position: relative; width: 100%; height: 0; padding-bottom: 100%; /* padding百分比是相对父元素宽度计算的 */ margin-bottom: 30px; } .square-inner{ position: absolute; top: 0; left: 0; width: 100%; height: 100%; /* 铺满父元素容器，这时候宽高就始终相等了 */ } .square-inner&amp;gt;li{ width: calc(98% / 3); /* calc里面的运算符两边要空格 */ height: calc(98% / 3); margin-right: 1%; margin-bottom: 1%; overflow: hidden; } FlexBox HTML：
&amp;lt;div class=&amp;#34;square&amp;#34;&amp;gt; &amp;lt;ul class=&amp;#34;square-inner flex&amp;#34;&amp;gt; &amp;lt;li&amp;gt;1&amp;lt;/li&amp;gt; &amp;lt;li&amp;gt;2&amp;lt;/li&amp;gt; &amp;lt;li&amp;gt;3&amp;lt;/li&amp;gt; &amp;lt;li&amp;gt;4&amp;lt;/li&amp;gt; &amp;lt;li&amp;gt;5&amp;lt;/li&amp;gt; &amp;lt;li&amp;gt;6&amp;lt;/li&amp;gt; &amp;lt;li&amp;gt;7&amp;lt;/li&amp;gt; &amp;lt;li&amp;gt;8&amp;lt;/li&amp;gt; &amp;lt;li&amp;gt;9&amp;lt;/li&amp;gt; &amp;lt;/ul&amp;gt; &amp;lt;/div&amp;gt;   CSS：</description>
    </item>
    
    <item>
      <title>设计数据密集型应用程序 - 分布式系统的难点</title>
      <link>https://kunzhao.org/docs/books/ddia/ddia-chapter8/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/books/ddia/ddia-chapter8/</guid>
      <description>设计数据密集型应用程序 - 分布式系统的难点 在最后几章中，一个反复出现的主题是系统如何处理出错的事情。例如，我们讨论了副本故障转移（第156页的“处理节点中断”）、复制延迟（“复制延迟的问题”，第161页）和事务的通用控制（“弱隔离级别”，第233页）。随着我们逐渐了解实际系统中可能出现的各种边缘情况，我们会更好地处理它们。
然而，尽管我们谈了很多关于错误的话题，但最后几章仍然过于乐观。现实更加黑暗。我们现在将把我们的悲观情绪最大化，并假设任何可能出错的事情都会出错。我（经验丰富的系统运营商会告诉你这是一个合理的假设。如果你问得好的话，他们可能会一边给你讲一些可怕的故事，一边抚摸着过去战争留下的伤疤。）
在分布式系统中工作与在一台计算机上编写软件有着根本的不同，主要的区别在于有许多新的和令人兴奋的方法来解决问题[1,2]。在这一章中，我们将领略到实践中出现的问题，并理解我们可以依赖和不能依赖的东西。
最后，作为工程师，我们的任务是构建能够完成其工作的系统（即，满足用户期望的保证），尽管一切都出了问题。在第9章中，我们将看到一些在分布式系统中可以提供这种保证的算法的例子。但首先，在本章中，我们必须了解我们面临的挑战。
本章对分布式系统中可能出现的问题进行了彻底的悲观和令人沮丧的概述。我们将研究网络问题（第277页“不可靠的网络”）；时钟和计时问题（“287页不可靠的时钟”）；并讨论它们在多大程度上是可以避免的。所有这些问题的后果都会让人迷失方向，所以我们将探讨如何思考一个分散的系统的状态，以及如何对已经发生的事情进行推理（“知识、真理和谎言”，第300页）
故障和部分故障 当您在单台计算机上编写程序时，它通常会以相当可预测的方式运行：要么起作用，要么不起作用。 Buggy软件可能会显示出计算机有时“日子不好过”（此问题通常通过重新启动得以解决），但这主要是软件编写不当造成的。
单台计算机上的软件应该是片状的并没有根本原因：当硬件正常工作时，相同的操作总是产生相同的结果（这是确定性的）。如果出现硬件问题（例如内存损坏或连接器松动），其后果通常是整个系统故障（例如，kernel panic，“蓝屏死机”，“启动失败”）。一台拥有良好软件的个人计算机通常要么功能完全正常，要么完全坏掉，但不能介于两者之间。
在设计计算机时，这是一个经过深思熟虑的选择：如果发生内部故障，我们宁愿计算机完全崩溃，而不是返回错误的结果，因为错误的结果很难处理并且令人困惑。因此，计算机隐藏了实现它们的模糊物理现实，并提供了一个数学上完美运作的理想化系统模型。CPU指令总是做同样的事情；如果您将一些数据写入内存或磁盘，这些数据将保持完整，不会随机损坏。这种始终正确计算的设计目标可以追溯到第一台数字计算机[3]。
当你写的软件运行在多台计算机上，通过一个网络连接起来，情况就完全不同了。在分布式系统中，我们不再是在一个理想化的系统模型中运行，我们别无选择，只能面对物理世界的混乱现实。在现实世界中，很多事情都可能出问题，正如这则轶事所说明的那样：
 以我有限的经验，我曾处理过单个数据中心（DC）中长期存在的网络分区，PDU [配电单元]故障，交换机故障，整个机架的意外重启，整个DC骨干网故障，整个DC 停电，降血糖的司机将他的福特皮卡车砸到DC的HVAC（加热，通风和空调）系统中。 而且我甚至都不是行动主义者。 &amp;ndash; Coda Hale
 在分布式系统中，即使系统的其他部分工作正常，也很有可能以某些无法预测的方式破坏了系统的某些部分。 这称为部分故障。 困难在于部分故障是不确定的：如果您尝试执行涉及多个节点和网络的任何操作，则该故障有时可能会工作，并且有时会出现无法预测的故障。
正如我们将看到的，您甚至可能不知道某事是否成功，因为消息在网络上传输所花费的时间也是不确定的！ 这种不确定性和部分故障的可能性使分布式系统难以使用[5]。
云计算和超级计算 关于如何构建大型计算系统，存在一系列哲学：
 一方面是高性能计算（HPC）领域。 具有数千个CPU的超级计算机通常用于计算密集型科学计算任务，例如天气预报或分子计算 动力学（模拟原子和分子的运动）。 另一个极端是云计算，它的定义不是很明确[6]，但通常与多租户数据中心，与IP网络连接的商用计算机（通常是以太网），弹性/按需资源分配和计量相关帐单。 传统企业数据中心位于这些极端之间。  这些哲学带来了处理错误的不同方法。在超级计算机中，作业通常会不时地将其计算状态检查点确定为持久存储。 如果一个节点发生故障，一种常见的解决方案是简单地停止整个集群工作负载。 修复故障节点后，从最后一个检查点[7，8]重新开始计算。 因此，与分布式系统相比，超级计算机更像是单节点计算机：超级计算机通过使其逐步升级为完全故障来处理部分故障-如果系统的任何部分发生故障，则只需让所有程序崩溃（就像单个计算机上的内核崩溃一样） 机）。
在本书中，我们重点介绍用于实现Internet服务的系统，这些系统通常看起来与超级计算机有很大的不同：
 从某种意义上讲，许多与Internet相关的应用程序都是在线的，它们需要能够随时为用户提供低延迟的服务。使服务不可用（例如，停止群集进行修复）是不可接受的。相反，可以停止和重新启动离线（批处理）作业（如天气模拟），而影响却很小。 超级计算机通常由专用硬件构建，其中每个节点都非常可靠，并且节点通过共享内存和远程进行通信 直接内存访问（RDMA）。另一方面，云服务中的节点是由商用机器构建，由于规模经济，它们可以以较低的成本提供同等的性能，但故障率也更高。 大型数据中心网络通常基于IP和以太网，以Clos拓扑排列以提供较高的对等带宽[9]。超级计算机通常使用专门的网络拓扑，例如多维网格和圆环[10]，对于具有已知通信模式的HPC工作负载，它们会产生更好的性能。 系统越大，其组件之一损坏的可能性就越大。随着时间的流逝，破碎的事物会得到修复，而新的事物会破碎，但是在具有数千个节点的系统中，可以合理地假设某些事物总是破碎的[7]。当错误处理策略仅由放弃组成时，大型系统最终可能会花费大量时间从故障中恢复，而不是做有用的工作[8]。 如果系统可以容忍发生故障的节点并且仍然可以整体正常工作，那么这对于操作和维护是非常有用的功能：例如，您可以执行滚动升级（请参见第4章），一次重新启动一个节点，服务将继续为用户提供服务而不会中断。在云环境中，如果一台虚拟机性能不佳，则可以将其杀死并请求新的虚拟机（希望新的虚拟机更快）。 在地理上分散的部署中（将数据保持在地理上靠近您的用户以减少访问延迟），通信很可能通过Internet进行，与本地网络相比，这种通信速度慢且不可靠。超级计算机通常假定其所有节点都靠近在一起。  如果要使分布式系统正常工作，我们必须接受部分故障的可能性，并在软件中建立容错机制。 换句话说，我们需要使用不可靠的组件来构建可靠的系统。 （如第6页上的“可靠性”所述，没有完美的可靠性之类的东西，因此我们需要理解我们可以实际承诺的限制。）
即使在仅包含几个节点的小型系统中，也要考虑部分故障。 在小型系统中，大多数组件很可能在大多数时间都能正常工作。 但是，系统的某些部分迟早会出现故障，软件必须以某种方式进行处理。 故障处理必须是软件设计的一部分，并且您（作为软件的操作员）需要知道发生故障时软件会带来什么行为。
认为错误很少发生并希望每次获得的都是最好的结果是不明智的。 重要的是要考虑各种可能的故障，甚至是不太可能的故障，并在测试环境中人为地创建此类情况以查看会发生什么。 在分布式系统中，怀疑，悲观和偏执会产生回报。
从不可靠的组件构建可靠的系统
您可能想知道这是否有意义—直观上看，系统似乎只能与最不可靠的组件（最薄弱的环节）一样可靠。事实并非如此：实际上，从较不可靠的基础结构构建更可靠的系统是计算中的旧想法[11]。例如：
 纠错码允许通过通信信道准确传输数字数据，例如由于无线网络上的无线电干扰，这种通信信道偶尔会出错一些[12]。 IP（Internet协议）不可靠：它可能会丢弃，延迟，重复或重新排序数据包。 TCP（传输控制协议）提供了更可靠的 IP上的传输层：它确保丢失的数据包被重新传输，重复数据被消除以及数据包按照发送的顺序重新组装。  尽管系统可能比其基础部分更可靠，但始终可以限制其可靠性。例如，纠错码可以处理少量的单位错误，但是如果您的信号被干扰淹没，则可以通过通信通道获取多少数据就受到了根本的限制[13]。 TCP可以向您隐藏数据包丢失，重复和重新排序的过程，但是它不能神奇地消除网络中的延迟。</description>
    </item>
    
    <item>
      <title>清除浮动</title>
      <link>https://kunzhao.org/docs/programmer-interview/front-end/clear-float/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/programmer-interview/front-end/clear-float/</guid>
      <description>清除浮动 clear:both 给浮动元素后面的元素添加 clear: both 属性。
.element { clear: both; } 空 DIV &amp;lt;div style=&amp;#34;clear: both;&amp;#34;&amp;gt;&amp;lt;/div&amp;gt; overflow：触发 BFC 给浮动元素的容器添加 overflow:hidden; 或 overflow:auto; 可以清除浮动，另外在 IE6 中还需要触发 hasLayout ，例如为父元素设置容器宽高或设置 zoom:1。
:after 添加一个 :after 伪元素来清除浮动。
.clearfix:after { content: &amp;#34;.&amp;#34;; visibility: hidden; display: block; height: 0; clear: both; } 参考  All About Floats CSS - 清除浮动  </description>
    </item>
    
    <item>
      <title>设计数据密集型应用程序 - 一致性和共识</title>
      <link>https://kunzhao.org/docs/books/ddia/ddia-chapter9/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/books/ddia/ddia-chapter9/</guid>
      <description>设计数据密集型应用程序 - 一致性和共识  本章我们看下场景的算法或协议是如何构建 fault-tolerant 分布式系统的。
 一致性保证 多数 replicated 数据库提供了 最终一致性，但是并未强调需要等待多久才会达成一致。
线性化 线性化系统，一个 Client 写入，其他 Client 立即可以读取到最新的值。图 9-1 展示的是非线性的系统：
什么让那个系统线性化？ 读请求和写请求同时发出，那么返回的可能是最新值也可能是旧值，如图 9-2 所示，x 可以是寄存器里面的值，也可以是 key-value store 里面的某个键，也可以是关系型数据库的某一行，文档数据库的某一个文档：
如何使其线性化？必须添加限制：某个 Client 读取返回 1 的时候，随后的读取也必须都返回 1，即使 write 操作还没有完成：
我们可以进一步精简，如图 9-4:
图 9-4 ，我们在 read 和 write 之外增加了新的操作：cas(x, v_old, v_new) =&amp;gt; r。记录下所有请求和响应，看是否位于一个合法的顺序的线上面，可以检测是否是线性化的。
依赖线性化 哪些系统必须依赖线性化？
 single-leader 依靠锁来选举 leader，这个锁的实现必须是线性化的。 数据库中某条记录是唯一的，必须依赖线性化。 跨通道时序依赖，message queue 必须快于 storage service，否则可能看到的是旧的图片、或看不到图片，因为使用的是两个 Channel。  实现线性化系统 线性化：对外表现就好像只有一份数据，并且所有操作都是原子的。使一个系统 fault-tolerant 的最常见的方式是 replication：
 Single-leader replication: 如果所有 read 都从 leader 或者已经追上 leader 的 follower 读取的话，那么他们自然是线性化的。 一致性算法：一致性协议提供了防止脑裂和陈旧的副本的方法，这正是 ZooKeeper 和 etcd 所做的。 Multi-leader replication: 肯定是非线性化的，因为数据会被异步的同步到其他节点上。 Leaderless replication：大概率也是非线性  线性化与法定人数 (w + r &amp;gt; n)</description>
    </item>
    
    <item>
      <title>CSS 画三角形</title>
      <link>https://kunzhao.org/docs/programmer-interview/front-end/css-triangle/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/programmer-interview/front-end/css-triangle/</guid>
      <description>CSS 画三角形 上三角形 #triangle-up { width: 0; height: 0; border-left: 50px solid transparent; border-right: 50px solid transparent; border-bottom: 100px solid red; } 下三角形 #triangle-down { width: 0; height: 0; border-left: 50px solid transparent; border-right: 50px solid transparent; border-top: 100px solid red; } 左三角形 #triangle-left { width: 0; height: 0; border-top: 50px solid transparent; border-right: 100px solid red; border-bottom: 50px solid transparent; } 右三角形 #triangle-right { width: 0; height: 0; border-top: 50px solid transparent; border-left: 100px solid red; border-bottom: 50px solid transparent; } 左上朝向的直角三角形 #triangle-topleft { width: 0; height: 0; border-top: 100px solid red; border-right: 100px solid transparent; } 右上朝向的直角三角形 #triangle-topright { width: 0; height: 0; border-top: 100px solid red; border-left: 100px solid transparent; } 左下朝向的直角三角形 #triangle-bottomleft { width: 0; height: 0; border-bottom: 100px solid red; border-right: 100px solid transparent; } 右下朝向的直角三角形 #triangle-bottomright { width: 0; height: 0; border-bottom: 100px solid red; border-left: 100px solid transparent; } 参考  The Shape of CSS  </description>
    </item>
    
    <item>
      <title>CSS 选择器</title>
      <link>https://kunzhao.org/docs/programmer-interview/front-end/css-selector/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/programmer-interview/front-end/css-selector/</guid>
      <description>CSS 选择器 选择器类型    选择器 示例     ID #id   class .class   标签 p   通用 *   属性 [type=&amp;quot;text&amp;quot;]   伪类 :hover   伪元素 ::first-line   子选择器、相邻选择器     权重优先级 important &amp;gt; 内嵌样式 &amp;gt; ID &amp;gt; 类 &amp;gt; 标签 | 伪类 | 属性选择 &amp;gt; 伪元素 &amp;gt; 继承 &amp;gt; 通配符
权重赋值  内联样式如 style=XXX：1000 ID 选择器：100 类、伪类、属性选择器：10 标签、伪元素选择器：1 通配符、子选择器、相邻选择器等：0  比较规则：逐级比较。权重一样的 CSS 表达式，在样式表中后声明的优先。</description>
    </item>
    
    <item>
      <title>CSS 两边固定中间自适应布局</title>
      <link>https://kunzhao.org/docs/programmer-interview/front-end/fixed-side-responsive-middle/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/programmer-interview/front-end/fixed-side-responsive-middle/</guid>
      <description>CSS 两边固定中间自适应布局 中间 float BFC 布局 &amp;lt;div class=&amp;#34;container&amp;#34;&amp;gt; &amp;lt;div class=&amp;#34;left&amp;#34;&amp;gt;&amp;lt;/div&amp;gt; &amp;lt;div class=&amp;#34;right&amp;#34;&amp;gt;&amp;lt;/div&amp;gt; &amp;lt;div class=&amp;#34;center&amp;#34;&amp;gt; &amp;lt;h1&amp;gt;浮动布局&amp;lt;/h1&amp;gt; &amp;lt;/div&amp;gt; &amp;lt;/div&amp;gt; .container &amp;gt; div{ height: 200px; } .left { float: left; width: 300px; background: red; } .right { float: right; width: 300px; background: blue; } .center { overflow: hidden; background: yellow; }  缺点：中间浮动布局的内容最后才加载
 圣杯布局  父元素：需要内边距 三个孩子全部是：float: left 左右分别是相对布局  &amp;lt;div class=&amp;#34;container&amp;#34;&amp;gt; &amp;lt;div class=&amp;#34;center&amp;#34;&amp;gt; &amp;lt;h1&amp;gt;圣杯布局&amp;lt;/h1&amp;gt; &amp;lt;/div&amp;gt; &amp;lt;div class=&amp;#34;left&amp;#34;&amp;gt;&amp;lt;/div&amp;gt; &amp;lt;div class=&amp;#34;right&amp;#34;&amp;gt;&amp;lt;/div&amp;gt; &amp;lt;/div&amp;gt; .container { padding: 0 300px; } .</description>
    </item>
    
    <item>
      <title>CSS3 新特性</title>
      <link>https://kunzhao.org/docs/programmer-interview/front-end/css3-new-feature/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/programmer-interview/front-end/css3-new-feature/</guid>
      <description>CSS3 新特性 新特性概览    新特性 说明     新的选择器    阴影 Box 阴影、文本阴影   圆角    渐变    透明度    Transitions    Transformations 旋转、缩放、扭曲、平移等   动画    多列布局    Flexbox 构建 Flex 布局   Grids 构建二维布局   @font face 嵌入更多字体   @media 响应式设计    阴影：box-shadow 圆角：border-radius .</description>
    </item>
    
    <item>
      <title>ES6 新特性</title>
      <link>https://kunzhao.org/docs/programmer-interview/front-end/es6-new-feature/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/programmer-interview/front-end/es6-new-feature/</guid>
      <description>ES6 新特性 var =&amp;gt; let/const var 是 function-scoped 的 var x = 3; function func(randomize) { if (randomize) { var x = Math.random(); // (A) scope: whole function  return x; } return x; // accesses the x from line A } func(false); // undefined   let/const 是 block-scoped 的 let x = 3; function func(randomize) { if (randomize) { let x = Math.random(); return x; } return x; } func(false); // 3    IIFE =&amp;gt; block ES5 使用 IIFE 限制 tmp 作用域 (function () { // open IIFE  var tmp = ···; ··· }()); // close IIFE  console.</description>
    </item>
    
    <item>
      <title>display</title>
      <link>https://kunzhao.org/docs/programmer-interview/front-end/display/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/programmer-interview/front-end/display/</guid>
      <description>display 常设置的值 div { display: inline; display: inline-block; display: block; display: run-in; display: none; } Flexbox .header { display: flex; } Flow-Root  flow-root 创建了一个新的 BFC 。
 .group { display: flow-root; } Grid body { display: grid; } Table div { display: table; display: table-cell; display: table-column; display: table-colgroup; display: table-header-group; display: table-row-group; display: table-footer-group; display: table-row; display: table-caption; } </description>
    </item>
    
    <item>
      <title>ES2020 新特性</title>
      <link>https://kunzhao.org/docs/programmer-interview/front-end/es2020/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/programmer-interview/front-end/es2020/</guid>
      <description>ES2020 新特性 BigInt JavaScript 最大数值 Number.MAX_SAFE_INTEGER，那么如何表达比这个数值更大的数字呢？
// 注意后缀有 n：表示 large number const bigNum = 10000000000000n; console.log(bigNum * 2n); 动态 import const doMath = async (num1, num2) =&amp;gt; { if (num1 &amp;amp;&amp;amp; num2) { const math = await import(&amp;#39;./math.js&amp;#39;) console.log(math.add(5, 10)) } } doMath(4, 2) Nullish Coalescing let person = { profile: { name: &amp;#34;&amp;#34;, age: 0 } }; // 默认值 console.log(person.profile.name || &amp;#34;Anonymous&amp;#34;) console.log(person.profile.age || 18) 现在可以不使用 ||，而用 ?? 来指定默认值了：</description>
    </item>
    
    <item>
      <title>创建对象</title>
      <link>https://kunzhao.org/docs/programmer-interview/front-end/create-object/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/programmer-interview/front-end/create-object/</guid>
      <description>创建对象 new Object() var d = new Object(); Object.create() var a = Object.create(null); 内部原理 Object.create = function (proto, propertiesObject) { if (typeof proto !== &amp;#39;object&amp;#39; &amp;amp;&amp;amp; typeof proto !== &amp;#39;function&amp;#39;) { throw new TypeError(&amp;#39;Object prototype may only be an Object: &amp;#39; + proto); } else if (proto === null) { throw new Error(&amp;#34;This browser&amp;#39;s implementation of Object.create is a shim and doesn&amp;#39;t support &amp;#39;null&amp;#39; as the first argument.&amp;#34;); } if (typeof propertiesObject !</description>
    </item>
    
    <item>
      <title>Object.freeze()</title>
      <link>https://kunzhao.org/docs/programmer-interview/front-end/object-freeze/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/programmer-interview/front-end/object-freeze/</guid>
      <description>Object.freeze() 作用  可以冻结一个对象。一个被冻结的对象再也不能被修改；冻结了一个对象则不能向这个对象添加新的属性，不能删除已有属性，不能修改该对象已有属性的可枚举性、可配置性、可写性，以及不能修改已有属性的值。此外，冻结一个对象后该对象的原型也不能被修改。
 行为 Object.freeze() 是浅冻结，浅不可变。
var ob1 = { foo : 1, bar : { value : 2 } }; Object.freeze( ob1 ); const ob2 = { foo : 1, bar : { value : 2 } } ob1.foo = 4; // (frozen) ob1.foo not modified ob2.foo = 4; // (const) ob2.foo modified  ob1.bar.value = 4; // (frozen) modified, because ob1.bar is nested ob2.bar.value = 4; // (const) modified  ob1.</description>
    </item>
    
    <item>
      <title>Cookie 和 Session</title>
      <link>https://kunzhao.org/docs/programmer-interview/front-end/cookie-session/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/programmer-interview/front-end/cookie-session/</guid>
      <description>Cookie 和 Session Cookie 作用  登录、购物车、游戏分数 用户个性化信息、主题、其他设置 记录和分析用户行为  创建 Cookie 服务器在返回网页内容的时候，使用 Set-Cookie 头来创建 Cookie：
HTTP/2.0 200 OK Content-Type: text/html Set-Cookie: yummy_cookie=choco Set-Cookie: tasty_cookie=strawberry [page content] Cookie 的有效期  Session：浏览器关闭当前 Tab 页就过期 Expires 和 Max-Age  Set-Cookie: &amp;lt;cookie-name&amp;gt;=&amp;lt;cookie-value&amp;gt;; Expires=&amp;lt;date&amp;gt; Set-Cookie: &amp;lt;cookie-name&amp;gt;=&amp;lt;cookie-value&amp;gt;; Max-Age=&amp;lt;non-zero-digit&amp;gt; Cookie 访问权限 Set-Cookie: id=a3fWa; Expires=Wed, 21 Oct 2021 07:28:00 GMT; Secure; HttpOnly  Secure：只有 HTTPS 协议的时候，浏览器端的 Cookie 才会上传到 Server HttpOnly：声明这个的 Cookie，使用 Document.cokie 无法读和写  JavaScript 读写 Cookie document.</description>
    </item>
    
    <item>
      <title>call、apply、bind</title>
      <link>https://kunzhao.org/docs/programmer-interview/front-end/call-apply-bind/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/programmer-interview/front-end/call-apply-bind/</guid>
      <description>call、apply、bind call func.call([thisArg[, arg1, arg2, ...argN]]) 底层原理 /** * 每个函数都可以调用call方法，来改变当前这个函数执行的this关键字，并且支持传入参数 */ Function.prototype.myCall = function(context) { //第一个参数为调用call方法的函数中的this指向  var context = context || global; //将this赋给context的fn属性  context.fn = this;//此处this是指调用myCall的function  var arr = []; for (var i=0,len=arguments.length;i&amp;lt;len;i++) { arr.push(&amp;#34;arguments[&amp;#34; + i + &amp;#34;]&amp;#34;); } //执行这个函数，并返回结果  var result = eval(&amp;#34;context.fn(&amp;#34; + arr.toString() + &amp;#34;)&amp;#34;); //将this指向销毁  delete context.fn; return result; } apply func.apply(thisArg, [ argsArray]) 底层原理 /** * apply函数传入的是this指向和参数数组 */ Function.prototype.myApply = function(context, arr) { var context = context || global; context.</description>
    </item>
    
    <item>
      <title>画正方形</title>
      <link>https://kunzhao.org/docs/programmer-interview/front-end/css-square/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/programmer-interview/front-end/css-square/</guid>
      <description>画正方形 实现一个正方形，拖拽窗口，正方形等比例缩放
vw &amp;lt;div class=&amp;#34;square&amp;#34;&amp;gt; &amp;lt;h1&amp;gt;This is a Square&amp;lt;/h1&amp;gt; &amp;lt;/div&amp;gt; .square { background: #000; width: 50vw; height: 50vw; } .square h1 { color: #fff; } padding-bottom &amp;lt;div style=&amp;#34;height:0;width:20%;padding-bottom:20%;background-color:red&amp;#34;&amp;gt; &amp;lt;div&amp;gt; Content goes here &amp;lt;/div&amp;gt; &amp;lt;/div&amp;gt; 参考  [How to style a div to be a responsive square?(https://stackoverflow.com/questions/19068070/how-to-style-a-div-to-be-a-responsive-square)  </description>
    </item>
    
    <item>
      <title>CSS 画圆</title>
      <link>https://kunzhao.org/docs/programmer-interview/front-end/css-draw-circle/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/programmer-interview/front-end/css-draw-circle/</guid>
      <description>CSS 画圆 border-radius #circle { width: 200px; height: 200px; background: #f00; border-radius: 50%; } </description>
    </item>
    
    <item>
      <title>CSS 画扇形</title>
      <link>https://kunzhao.org/docs/programmer-interview/front-end/css-sector/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/programmer-interview/front-end/css-sector/</guid>
      <description>CSS 画扇形 #cone { width: 0; height: 0; border-left: 70px solid transparent; border-right: 70px solid transparent; border-top: 100px solid red; border-radius: 50%; } </description>
    </item>
    
    <item>
      <title>三栏等宽布局</title>
      <link>https://kunzhao.org/docs/programmer-interview/front-end/three-equal-layout/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/programmer-interview/front-end/three-equal-layout/</guid>
      <description>三栏等宽布局 &amp;lt;ul&amp;gt; &amp;lt;li&amp;gt;111&amp;lt;/li&amp;gt; &amp;lt;li&amp;gt;222&amp;lt;/li&amp;gt; &amp;lt;li&amp;gt;333&amp;lt;/li&amp;gt; &amp;lt;/ul&amp;gt; float ul { width: 500px; background: #ccc; overflow: hidden; } li { list-style: none; width: 33.33%; float: left; background: red; } flex ul { width: 500px; background: #ccc; display: flex; } li { list-style: none; flex: 1; background: red; } </description>
    </item>
    
    <item>
      <title>CSS 画半圆</title>
      <link>https://kunzhao.org/docs/programmer-interview/front-end/css-draw-half-circle/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/programmer-interview/front-end/css-draw-half-circle/</guid>
      <description>CSS 画半圆 $size: 45px; div { background: #9e978e; display: inline-block; margin: 0 1em 1em 0; } .top, .bottom { height: $size; width: $size * 2; } .right, .left { height: $size * 2; width: $size; } .top { border-top-left-radius: $size * 2; border-top-right-radius: $size * 2; } .right { border-bottom-right-radius: $size * 2; border-top-right-radius: $size * 2; } .bottom { border-bottom-left-radius: $size * 2; border-bottom-right-radius: $size * 2; } .left { border-bottom-left-radius: $size * 2; border-top-left-radius: $size * 2; } 效果：</description>
    </item>
    
    <item>
      <title>动画</title>
      <link>https://kunzhao.org/docs/programmer-interview/front-end/animation/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/programmer-interview/front-end/animation/</guid>
      <description>动画 CSS animation .element { animation: pulse 5s infinite; } @keyframes pulse { 0% { background-color: #001F3F; } 100% { background-color: #FF4136; } } 在 @keyframes 中，0% 代表动画的开始，100% 代表动画的结束。animation 可用的子属性：
.element { animation-name: stretch; animation-duration: 1.5s; animation-timing-function: ease-out; animation-delay: 0s; animation-direction: alternate; animation-iteration-count: infinite; animation-fill-mode: none; animation-play-state: running; } CSS transition transition 控制的是从一种状态/阶段/样式，转变为另外一种状态/阶段/样式，animation 控制的是整个动画的每一帧。
.example { transition: [transition-property] [transition-duration] [transition-timing-function] [transition-delay]; } 鼠标悬浮在 div 的时候，转变 background 和 padding 的状态：
div { transition: all 0.</description>
    </item>
    
    <item>
      <title>CSS 单位</title>
      <link>https://kunzhao.org/docs/programmer-interview/front-end/css-units/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/programmer-interview/front-end/css-units/</guid>
      <description>CSS 单位 绝对单位    单位 描述     cm 厘米   mm 毫米   in 英寸   px 像素   pt points   pc picas (1pc = 12pt)    相对单位    单位 描述     em 相对于当前元素的 font-size，2em 意味着两倍 font-size 的大小   ex 相对于当前字体的 x-height   ch 相对于 &amp;lsquo;0&amp;rsquo; 的宽度   rem 相对于根元素的字体大小   vw 相当于 viewport 宽度的 1%   vh 相当于 viewport 高度的 1%   vmin 相当于 viewport 较短边的 1%   vmax 相当于 viewport 较长边的 1%   % 相对于父元素    参考  CSS Units  </description>
    </item>
    
    <item>
      <title>prototype、__proto__、[[prototype]]</title>
      <link>https://kunzhao.org/docs/programmer-interview/front-end/prototype/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/programmer-interview/front-end/prototype/</guid>
      <description>prototype、proto、[[prototype]] prototype 谁创建的 当你创建一个 Function object 的时候，一个名字为 prototype 的属性也会自动创建，并附着在 function object 上。
function Foo() { this.name = &amp;#34;Zhao Kun&amp;#34;; } Foo.hasOwnProperty(&amp;#39;prototype&amp;#39;); // true [[prototype]] 谁创建的 使用 new 关键字创建一个新的对象，那么这个对象本身会有一个内部的/私有的或指针指向 Foo 的 prototype：
function Foo() { this.name = &amp;#34;Zhao Kun&amp;#34;; } let b = new Foo(); b.[[Prototype]] === Foo.prototype // true proto 谁创建的 __proto__ 是 [[prototype]] 的 public 形式的指针：
let b = new Foo(); b.__proto___ === Foo.prototype // true 自 ECMAScript5 起，你有另外一种选择，可以拿到这个对象内部的私有的 [[prototype]] 的这个指针：</description>
    </item>
    
    <item>
      <title>HTML 语义化</title>
      <link>https://kunzhao.org/docs/programmer-interview/front-end/html-semantic/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/programmer-interview/front-end/html-semantic/</guid>
      <description>HTML 语义化 作用 Web语义化是指使用恰当语义的html标签、class类名等内容，让页面具有良好的结构与含义，从而让人和机器都能快速理解网页内容。语义化的web页面一方面可以让机器在更少的人类干预情况下收集并研究网页的信息，从而可以读懂网页的内容，然后将收集汇总的信息进行分析，结果为人类所用；另一方面它可以让开发人员读懂结构和用户以及屏幕阅读器（如果访客有视障）能够读懂内容。 简单来说就是利于 SEO，便于阅读维护理解。
常见语义化标签  i：专业术语 em：强调文本 strong：这个文本非常重要 section：文档中的一个区域、一节 article：文档、页面、网站中的独立结构 aside：附属信息 nav：页面的导航链接区域 footer：页脚 hgroup：文章的标题 header：页眉  dl、dt、dd &amp;lt;dl&amp;gt; 代表 description list，这个 list 封装了若干个 terms (&amp;lt;dt&amp;gt;) 以及 descriptions (&amp;lt;dd&amp;gt;) 信息。
&amp;lt;dl&amp;gt; &amp;lt;dt&amp;gt;火狐浏览器&amp;lt;/dt&amp;gt; &amp;lt;dd&amp;gt; 由 Mozilla 组织以及数百个志愿者一起开发的一款免费、开源、跨平台的 Web 浏览器。 &amp;lt;/dd&amp;gt; &amp;lt;dt&amp;gt;Chrome 浏览器&amp;lt;/dt&amp;gt; &amp;lt;dd&amp;gt; 谷歌浏览器，是一个由Google（谷歌）公司开发的开放源代码网页浏览器。 &amp;lt;/dd&amp;gt; &amp;lt;/dl&amp;gt; </description>
    </item>
    
    <item>
      <title>ShardingSphere 3.X</title>
      <link>https://kunzhao.org/docs/tutorial/database/sharding-sphere/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/tutorial/database/sharding-sphere/</guid>
      <description>ShardingSphere 3.X 分片 分片键 用于分片的数据库字段，是将数据库(表)水平拆分的关键字段。例：将订单表中的订单主键的尾数取模分片，则订单主键为分片字段。 SQL中如果无分片字段，将执行全路由，性能较差。 除了对单分片字段的支持，ShardingSphere也支持根据多个字段进行分片。
分片算法 通过分片算法将数据分片，支持通过=、BETWEEN和IN分片。分片算法需要应用方开发者自行实现，可实现的灵活度非常高。
 精确分片算法 PreciseShardingAlgorithm: 用于处理使用单一键作为分片键的 = 与 IN 进行分片的场景。 范围分片算法 RangeShardingAlgorithm: 用于处理使用单一键作为分片键的 BETWEEN AND 进行分片的场景。 复合分片算法 ComplexKeysShardingAlgorithm: 用于处理使用多键作为分片键进行分片的场景。 Hint 分片算法 HintShardingAlgorithm: 用于处理使用 Hint 行分片的场景。  分片策略 包含分片键和分片算法，由于分片算法的独立性，将其独立抽离。真正可用于分片操作的是分片键 + 分片算法，也就是分片策略。目前提供5种分片策略。
 标准分片策略 复合分片策略 行表达式分片策略: 使用 Groovy 表达式 Hint 分片策略 不分片策略   行表达式语法说明
 行表达式的使用非常直观，只需要在配置中使用${ expression }或$-&amp;gt;{ expression }标识行表达式即可。 目前支持数据节点和分片算法这两个部分的配置。行表达式的内容使用的是Groovy的语法，Groovy能够支持的所有操作，行表达式均能够支持。
${begin..end}表示范围区间
${[unit1, unit2, unit_x]}表示枚举值
(1) 行表达式 ${[&#39;online&#39;, &#39;offline&#39;]}_table${1..3} 解析为：
online_table1, online_table2, online_table3, offline_table1, offline_table2, offline_table3 (2) 数据节点配置</description>
    </item>
    
    <item>
      <title>二叉搜索树中删除一个节点</title>
      <link>https://kunzhao.org/docs/programmer-interview/algorithm/delete-node-in-bst/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/programmer-interview/algorithm/delete-node-in-bst/</guid>
      <description>二叉搜索树中删除一个节点  微软
 // https://leetcode.com/problems/delete-node-in-a-bst/ // // 微软面试题 // // 这道题的删除节点，就是把这个节点所有的孩子都给删除了 public class DeleteNodeinaBST { public TreeNode deleteNode(TreeNode root, int key) { // ================  // search the node  // ================  TreeNode curr = root; TreeNode predecessor = null; // 我们是从 root 的 left 树进去的吗?  boolean left = false; while (curr != null) { if (curr.val == key) { break; } else if (curr.val &amp;gt; key) { predecessor = curr; curr = curr.</description>
    </item>
    
    <item>
      <title>内存</title>
      <link>https://kunzhao.org/docs/tutorial/unix-optimize/memory/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/tutorial/unix-optimize/memory/</guid>
      <description>内存  作者：赵坤
 内存分配 首先给出 32 位系统虚拟内存空间分布图：
在 C 语言中，内存分配采用 malloc() 函数进行分配。底层实现：
 申请的内存小于 128K，使用 brk() 函数完成，也就是从上图中的堆中分配的内存 申请的内存大于 128K，使用 mmap() 内存映射函数完成，也就是从上图中的文件映射中分配的内存  内存回收 应用程序应通过 free() 或 unmap() 来释放内存。
当然，系统也会监管进程的内存，当发现系统内存不足时，会采取措施：
 使用 LRU 算法回收缓存 回收不常访问的内存，写到 Swap 区（位于硬盘上） 杀死进程  虚拟内存 分段机制 分段机制下的虚拟地址由两部分组成，段选择子和段内偏移量。段选择子就保存在咱们前面讲过的段寄存器里面。段选择子里面最重要的是段号，用作段表的索引。段表里面保存的是这个段的基地址、段的界限和特权等级等。虚拟地址中的段内偏移量应该位于 0 和段界限之间。如果段内偏移量是合法的，就将段基地址加上段内偏移量得到物理内存地址。
分段对内存区域的映射以程序为单位，内存不足，换入换出到磁盘的是整个程序，粒度比较大，产生大量磁盘 IO，而根据程序的局部性原理，程序运行时，某个时间段，一般只是频繁用到很小的一部分数据。那么可以利用更小粒度的内存分割和映射方法，这就是分页。
分页 (Paging) 对于物理内存，操作系统把它分成一块一块大小相同的页，这样更方便管理，例如有的内存页面长时间不用了，可以暂时写到硬盘上，称为换出。一旦需要的时候，再加载进来，叫做换入。这样可以扩大可用物理内存的大小，提高物理内存的利用率。
这个换入和换出都是以页为单位的。页面的大小一般为 4KB。为了能够定位和访问每个页，需要有个页表，保存每个页的起始地址，再加上在页内的偏移量，组成线性地址，就能对于内存中的每个位置进行访问了。
虚拟地址分为两部分，页号和页内偏移。页号作为页表的索引，页表包含物理页每页所在物理内存的基地址。这个基地址与页内偏移的组合就形成了物理内存地址。
内存映射  用户态内存映射函数 mmap，包括用它来做匿名映射和文件映射。 用户态的页表结构，存储位置在 mm_struct 中。 在用户态访问没有映射的内存会引发缺页异常，分配物理页表、补齐页表。如果是匿名映射则分配物理内存；如果是 swap，则将 swap 文件读入；如果是文件映射，则将文件读入。  查看整个系统的内存 $ free total used free shared buff/cache available Mem: 6030036 2312004 266488 624252 3451544 2911700 Swap: 2097148 256 2096892 查看某个进程的内存 使用 top 或 ps：</description>
    </item>
    
    <item>
      <title>基础 - finally</title>
      <link>https://kunzhao.org/docs/programmer-interview/java/finally/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/programmer-interview/java/finally/</guid>
      <description>finally 常见疑惑代码片段 （1）下面代码中的 finally 块会执行吗？
try { // do something  System.exit(1); } finally{ System.out.println(“Print from finally”); } 答案：不会。
（2）finally 会执行吗？
public static int test() { try { return 0; } finally { System.out.println(&amp;#34;finally trumps return.&amp;#34;); } } 答案：
finally trumps return. 0 （3）这个方法返回的值是 10 还是 12？
public static int getMonthsInYear() { try { return 10; } finally { return 12; } } 答案：12
（4）执行顺序
try{ int divideByZeroException = 5 / 0; } catch (Exception e){ System.</description>
    </item>
    
    <item>
      <title>HTML5 新特性</title>
      <link>https://kunzhao.org/docs/programmer-interview/front-end/html5-new-feature/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/programmer-interview/front-end/html5-new-feature/</guid>
      <description>HTML5 新特性 新的 HTML5 语义 章节、轮廓等语义标签 &amp;lt;section&amp;gt;、&amp;lt;article&amp;gt;、&amp;lt;nav&amp;gt;、&amp;lt;header&amp;gt;、&amp;lt;footer&amp;gt;、&amp;lt;aside&amp;gt;
音频、视频 &amp;lt;audio&amp;gt;、&amp;lt;video&amp;gt;
input 校验 &amp;lt;input&amp;gt; 标签引入了新的属性：
 required：表单的这个字段不为空 minlength 和 maxlength：文本的长度要求 min 和 max：数值类型的大小值约束 type：是否是数值？邮件地址？或其它类型 pattern：输入的内容必须符合整个正则表达式  新的语义元素 &amp;lt;mark&amp;gt;、&amp;lt;figure&amp;gt;、&amp;lt;figcaption&amp;gt;、&amp;lt;data&amp;gt;、&amp;lt;time&amp;gt;、&amp;lt;output&amp;gt;、&amp;lt;progress&amp;gt;、&amp;lt;meter&amp;gt;、&amp;lt;main&amp;gt;
iframe 安全  sandbox 属性：附加更多限制 srcdoc 属性：内嵌的 HTML 内容  MathML 数学公式 使用 MathML 直接插入数学公式
数据传输 Web Sockets 浏览器和服务器建立一个长久连接，双方都可以发送信息给对方。
Server-sent events Server 推送 event 给客户端：
const evtSource = new EventSource(&amp;#39;ssedemo.php&amp;#39;) WebRTC RTC：Real-Time Communication
存储 IndexedDB 选择多个文件 &amp;lt;input type = &#39;file&#39;&amp;gt; 新增 multiple 属性，可选择多个文件。
多媒体 Camera API &amp;lt;input type=&amp;#34;file&amp;#34; id=&amp;#34;take-picture&amp;#34; accept=&amp;#34;image/*&amp;#34;&amp;gt; Graphics canvas 画布</description>
    </item>
    
    <item>
      <title>Java 异常</title>
      <link>https://kunzhao.org/docs/programmer-interview/java/java-exception/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/programmer-interview/java/java-exception/</guid>
      <description>Java 异常 异常架构图 The class Exception and any subclasses that are not also subclasses of RuntimeException are checked exceptions.
RuntimeException Java 常见 RuntimeException：
 ArithmeticException ClassCastException ConcurrentModificationException NullPointerException IndexOutOfBoundsException  Exception 常见 Checked Exception：
 InterruptedException IOException SQLException  NoClassDefFoundError vs ClassNotFoundException 当应用程序运行的过程中尝试使用类加载器去加载 Class 文件的时候，如果没有在 classpath 中查找到指定的类，就会抛出ClassNotFoundException。一般情况下，当我们使用 Class.forName() 或者 ClassLoader.loadClass 以及使用ClassLoader.findSystemClass() 在运行时加载类的时候，如果类没有被找到，那么就会导致 JVM 抛出ClassNotFoundException。
 NoClassDefFoundError
 Thrown if the Java Virtual Machine or a ClassLoader instance tries to load in the definition of a class (as part of a normal method call or as part of creating a new instance using the new expression) and no definition of the class could be found.</description>
    </item>
    
    <item>
      <title>二叉搜索树中新增一个节点</title>
      <link>https://kunzhao.org/docs/programmer-interview/algorithm/insert-into-bst/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/programmer-interview/algorithm/insert-into-bst/</guid>
      <description>二叉搜索树中新增一个节点  微软
 // https://leetcode.com/problems/insert-into-a-binary-search-tree/ // 保证二叉树原来没有值为 val 的节点 // // 微软面试题 public class InsertintoaBinarySearchTree { public TreeNode insertIntoBST(TreeNode root, int val) { if (root == null) { return new TreeNode(val); } TreeNode backupRoot = root; TreeNode predecessor = null; while (root != null) { predecessor = root; if (root.val &amp;gt; val) { root = root.left; } else if (root.val &amp;lt; val) { root = root.right; } } if (predecessor.</description>
    </item>
    
    <item>
      <title>meta</title>
      <link>https://kunzhao.org/docs/programmer-interview/front-end/meta/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/programmer-interview/front-end/meta/</guid>
      <description>meta 作用 提供 Document 的元信息。
charset 属性 &amp;lt;head&amp;gt; &amp;lt;meta charset=&amp;#34;UTF-8&amp;#34;&amp;gt; &amp;lt;/head&amp;gt; content 属性 &amp;lt;head&amp;gt; &amp;lt;meta name=&amp;#34;description&amp;#34; content=&amp;#34;Free Web tutorials&amp;#34;&amp;gt; &amp;lt;meta name=&amp;#34;keywords&amp;#34; content=&amp;#34;HTML,CSS,XML,JavaScript&amp;#34;&amp;gt; &amp;lt;/head&amp;gt; http-equiv &amp;lt;!-- Redirect page after 3 seconds --&amp;gt; &amp;lt;meta http-equiv=&amp;#34;refresh&amp;#34; content=&amp;#34;3;url=https://www.mozilla.org&amp;#34;&amp;gt; name &amp;lt;head&amp;gt; &amp;lt;meta name=&amp;#34;description&amp;#34; content=&amp;#34;Free Web tutorials&amp;#34;&amp;gt; &amp;lt;meta name=&amp;#34;keywords&amp;#34; content=&amp;#34;HTML,CSS,JavaScript&amp;#34;&amp;gt; &amp;lt;meta name=&amp;#34;author&amp;#34; content=&amp;#34;John Doe&amp;#34;&amp;gt; &amp;lt;meta name=&amp;#34;viewport&amp;#34; content=&amp;#34;width=device-width, initial-scale=1.0&amp;#34;&amp;gt; &amp;lt;/head&amp;gt; </description>
    </item>
    
    <item>
      <title>二叉树的直径</title>
      <link>https://kunzhao.org/docs/programmer-interview/algorithm/diameter-of-binary-tree/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/programmer-interview/algorithm/diameter-of-binary-tree/</guid>
      <description>二叉树的直径  微软
 // https://leetcode.com/problems/diameter-of-binary-tree/ // // 二叉树的直径 // // Given a binary tree // 1 // / \ // 2 3 // / \ // 4 5 // Return 3, which is the length of the path [4,2,1,3] or [5,2,1,3]. public class DiameterofBinaryTree { public int diameterOfBinaryTree(TreeNode root) { if (root == null) { return 0; } int rootDiameter = depth(root.left) + depth(root.right); int leftDiameter = diameterOfBinaryTree(root.left); int rightDiameter = diameterOfBinaryTree(root.</description>
    </item>
    
    <item>
      <title>中序遍历的下一个节点</title>
      <link>https://kunzhao.org/docs/programmer-interview/algorithm/next-node-of-inorder-traverse/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/programmer-interview/algorithm/next-node-of-inorder-traverse/</guid>
      <description>中序遍历的下一个节点 给定一个二叉树和其中的一个结点，请找出中序遍历顺序的下一个结点并且返回。注意，树中的结点不仅包含左右子结点，同时包含指向父结点的指针。
// https://www.nowcoder.com/practice/9023a0c988684a53960365b889ceaf5e // // 牛客网 // 二叉树中包含指向父节点的指针 next public class NextNodeOfBinaryTree { public TreeLinkNode GetNext(TreeLinkNode pNode) { if (pNode == null) { return null; } // 1  // 2 3  // 4 5 6 7  // 8 9  if (pNode.right != null) { // 2 的下一个节点:  //  // 如果 8 存在，那么最终是 8  // 如果 8 不存在，那么最终是 5  TreeLinkNode p = pNode.</description>
    </item>
    
    <item>
      <title>二叉树最大路径和</title>
      <link>https://kunzhao.org/docs/programmer-interview/algorithm/binary-tree-maximum-path-sum/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/programmer-interview/algorithm/binary-tree-maximum-path-sum/</guid>
      <description>二叉树最大路径和 解法一 // // 从树的任何一个节点开始，到任何一个节点结束，路径和最长 // 至少包含一个节点 // // Hard 级别 // public class BinaryTreeMaximumPathSum { int result = Integer.MIN_VALUE; public int maxPathSum(TreeNode root) { helper(root); return result; } private int helper(TreeNode root) { if (root == null) { return 0; } int left = helper(root.left); int right = helper(root.right); // - 只选择 root  // - 选择 root + left  // - 选择 root + right  // - 为什么没有 left ?</description>
    </item>
    
    <item>
      <title>二叉树非递归中序遍历</title>
      <link>https://kunzhao.org/docs/programmer-interview/algorithm/binary-tree-inorder-traversal/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/programmer-interview/algorithm/binary-tree-inorder-traversal/</guid>
      <description>二叉树非递归中序遍历 public class BinaryTreeInorderTraversal { public List&amp;lt;Integer&amp;gt; inorderTraversal(TreeNode root) { if (root == null) { return Collections.emptyList(); } List&amp;lt;Integer&amp;gt; res = new ArrayList&amp;lt;&amp;gt;(); Stack&amp;lt;TreeNode&amp;gt; stack = new Stack&amp;lt;&amp;gt;(); TreeNode curr = root; // 1  // / \  // 2 3  // / \  // 4 5  // / \  // 6 7  //  // 4 2 6 5 7 1 3  while (true) { // =========================  // 这个地方容易出错：  //  // stack.</description>
    </item>
    
    <item>
      <title>二叉树的公共祖先</title>
      <link>https://kunzhao.org/docs/programmer-interview/algorithm/lowest-common-ancestor-of-a-binary-search-tree/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/programmer-interview/algorithm/lowest-common-ancestor-of-a-binary-search-tree/</guid>
      <description>二叉树的公共祖先 二叉树的公共祖先 // 所有 NODE 节点的值都是唯一的 // p 和 q 一定存在于二叉树里面 public class LowestCommonAncestorofaBinaryTree { // =========================  // 这个方法最优  // =========================  public TreeNode lowestCommonAncestor0(TreeNode root, TreeNode p, TreeNode q) { if (root == null || root == p || root == q) { return root; } TreeNode left = lowestCommonAncestor(root.left, p, q); TreeNode right = lowestCommonAncestor(root.right, p, q); if (left != null &amp;amp;&amp;amp; right != null) { return root; } return left !</description>
    </item>
    
    <item>
      <title>一颗二叉树是否是另外一颗的子树</title>
      <link>https://kunzhao.org/docs/programmer-interview/algorithm/is-subtree-another-tree/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/programmer-interview/algorithm/is-subtree-another-tree/</guid>
      <description>一颗二叉树是否是另外一颗的子树 // O(N^2) public class SubtreeOfAnotherTree { public boolean isSubtree(TreeNode s /** root tree */, TreeNode t /** sub tree */) { return isSameTree(s, t) || (s != null ? (isSubtree(s.left, t) || isSubtree(s.right, t)) : false); } private boolean isSameTree(TreeNode a, TreeNode b) { if (a == null &amp;amp;&amp;amp; b == null) { return true; } if (a == null || b == null) { return false; } if (a.</description>
    </item>
    
    <item>
      <title>二叉树右视图</title>
      <link>https://kunzhao.org/docs/programmer-interview/algorithm/binary-tree-right-side-view/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/programmer-interview/algorithm/binary-tree-right-side-view/</guid>
      <description>二叉树右视图  微软问的其实是左视图。 原题
 递归 public class Solution { public List&amp;lt;Integer&amp;gt; rightSideView(TreeNode root) { List&amp;lt;Integer&amp;gt; result = new ArrayList&amp;lt;Integer&amp;gt;(); rightView(root, result, 0); return result; } public void rightView(TreeNode curr, List&amp;lt;Integer&amp;gt; result, int currDepth){ if (curr == null){ return; } if (currDepth == result.size()){ result.add(curr.val); } rightView(curr.right, result, currDepth + 1); rightView(curr.left, result, currDepth + 1); } } 层次遍历 public class Solution { public List&amp;lt;Integer&amp;gt; rightSideView(TreeNode root) { Queue&amp;lt;TreeNode&amp;gt; queue = new LinkedList&amp;lt;&amp;gt;(); List&amp;lt;Integer&amp;gt; rst = new ArrayList&amp;lt;&amp;gt;(); if (root == null) return rst; queue.</description>
    </item>
    
    <item>
      <title>JavaScript 检测数组</title>
      <link>https://kunzhao.org/docs/programmer-interview/front-end/js-detect-array/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/programmer-interview/front-end/js-detect-array/</guid>
      <description>JavaScript 检测数组 Array.isArray Array.isArray(obj) 兼容旧版本：
if (typeof Array.isArray === &amp;#39;undefined&amp;#39;) { Array.isArray = function(obj) { return Object.prototype.toString.call(obj) === &amp;#39;[object Array]&amp;#39;; } } constructor function isArray(obj) { return !!obj &amp;amp;&amp;amp; obj.constructor === Array; } </description>
    </item>
    
    <item>
      <title>Kafka 高吞吐量怎么实现的</title>
      <link>https://kunzhao.org/docs/programmer-interview/java/kafka-high-throughput/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/programmer-interview/java/kafka-high-throughput/</guid>
      <description>Kafka 高吞吐量怎么实现的 顺序读写 Producer 发送的消息顺序追加到文件中，Consumer 从 Broker 自带偏移量读取消息。这两者可以充分利用磁盘的顺序写和顺序读性能，速度远快于随机读写。
   零拷贝 mmap 持久化文件 Broker 写入数据，并非真正的 flush 到磁盘上了，而是写入到 mmap 中。
sendfile 读取 Customer 从 Broker 读取数据，采用 sendfile，将磁盘文件读到 OS 内核缓冲区后，直接转到 socket buffer 进行网络发送。
分区 Kafka 将消息分成多个 partition，增加了并行处理的能力。
批量发送 Producer 发送多个消息到同一分区，通过批量发送可以减少系统性能开销。
 batch.size：默认积压到 16K 就会批量发送 linger.ms：设置一定延迟来收集更多消息。默认 0ms ，即有消息就立马发送。  上述两个条件有任一条件满足，就会触发批量发送。
数据压缩 Kafka 支持三种压缩算法：
 gzip snappy lz4  /*compressType有四种取值:none lz4 gzip snappy*/ props.put(ProducerConfig.COMPRESSION_TYPE_CONFIG, compressType); 参考  Kafka为什么吞吐量大、速度快？  </description>
    </item>
    
    <item>
      <title>WordLadder</title>
      <link>https://kunzhao.org/docs/programmer-interview/algorithm/word-ladder/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/programmer-interview/algorithm/word-ladder/</guid>
      <description>WordLadder  微软、阿里巴巴
 // 常见面试题 // 阿里巴巴、微软都问过 // https://leetcode.com/problems/word-ladder/ // public class WordLadder { // Runtime: 135 ms, faster than 39.64% of Java online submissions for Word Ladder.  public int ladderLength(String beginWord, String endWord, List&amp;lt;String&amp;gt; wordList) { Set&amp;lt;String&amp;gt; wordSet = new HashSet&amp;lt;&amp;gt;(wordList); if (!wordSet.contains(endWord)) { return 0; } Queue&amp;lt;String&amp;gt; queue = new LinkedList&amp;lt;&amp;gt;(); queue.offer(beginWord); int level = 0; while (!queue.isEmpty()) { level++; int size = queue.size(); for (int i = 0; i &amp;lt; size; i++) { String curr = queue.</description>
    </item>
    
    <item>
      <title>磁盘 I/O</title>
      <link>https://kunzhao.org/docs/tutorial/unix-optimize/io/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/tutorial/unix-optimize/io/</guid>
      <description>磁盘 I/O  作者：赵坤
 虚拟文件系统 I/O 调度 为了减小不同块设备的差异带来的影响，Linux 通过一个统一的通用块层，来管理各种不同的块设备。通用块层，其实是处在文件系统和磁盘驱动中间的一个块设备抽象层。它会给文件系统和应用程序发来的 I/O 请求排队，并通过重新排序、请求合并等方式，提高磁盘读写的效率。
Linux 内核支持四种 I/O 调度算法，分别是 NONE、NOOP、CFQ 以及 DeadLine。
 NONE，不使用 I/O 调度算法 NOOP，先入先出 CFQ（Completely Fair Scheduler），为每个进程维护了一个 I/O 调度队列，并按照时间片来均匀分布每个进程的 I/O 请求 DeadLine，分别为读、写请求创建了不同的 I/O 队列，可以提高机械磁盘的吞吐量，并确保达到最终期限（deadline）的请求被优先处理  每块磁盘 I/O 性能 $ iostat -d -x 1 Linux 5.4.0-42-generic (zk) 2020年09月02日 _x86_64_	(4 CPU) Device r/s rkB/s rrqm/s %rrqm r_await rareq-sz w/s wkB/s wrqm/s %wrqm w_await wareq-sz d/s dkB/s drqm/s %drqm d_await dareq-sz aqu-sz %util loop0 0.</description>
    </item>
    
    <item>
      <title>秒杀系统设计</title>
      <link>https://kunzhao.org/docs/programmer-interview/java/design-seckilling/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/programmer-interview/java/design-seckilling/</guid>
      <description>秒杀系统设计 秒杀其实主要解决两个问题，一个是并发读，一个是并发写。并发读的核心优化理念是尽量减少用户到服务端来“读”数据，或者让他们读更少的数据；并发写的处理原则也一样，它要求我们在数据库层面独立出来一个库，做特殊的处理。另外，我们还要针对秒杀系统做一些保护，针对意料之外的情况设计兜底方案，以防止最坏的情况发生。
秒杀系统架构原则  数据尽量少: 可以简化秒杀页面的大小，去掉不必要的页面装修效果，等等。 请求数尽量少: 减少请求数最常用的一个实践就是合并 CSS 和 JavaScript 文件，把多个 JavaScript 文件合并成一个文件，在 URL 中用逗号隔开。 路径要尽量短: 缩短访问路径有一种办法，就是多个相互强依赖的应用合并部署在一起，把远程过程调用（RPC）变成 JVM 内部之间的方法调用。 依赖要尽量少: 0 级系统要尽量减少对 1 级系统的强依赖，防止重要的系统被不重要的系统拖垮。例如支付系统是 0 级系统，而优惠券是 1 级系统的话，在极端情况下可以把优惠券给降级，防止支付系统被优惠券这个 1 级系统给拖垮。 不要有单点: 应用无状态化。  动静分离 “动态数据”和“静态数据”的主要区别就是看页面中输出的数据是否和 URL、浏览者、时间、地域相关，以及是否含有 Cookie 等私密数据。所谓“动态”还是“静态”，并不是说数据本身是否动静，而是数据中是否含有和访问者相关的个性化数据。
静态数据 怎样对静态数据做缓存呢？
 第一，你应该把静态数据缓存到离用户最近的地方。 第二，静态化改造就是要直接缓存 HTTP 连接。静态化改造是直接缓存 HTTP 连接而不是仅仅缓存数据，如下图所示，Web 代理服务器根据请求 URL，直接取出对应的 HTTP 响应头和响应体然后直接返回，这个响应过程简单得连 HTTP 协议都不用重新组装，甚至连 HTTP 请求头也不需要解析。   第三，让谁来缓存静态数据也很重要。  动静分离的改造  URL 唯一化。 分离浏览者相关的因素。 分离时间因素。 异步化地域因素。 去掉 Cookie。  动态内容的处理通常有两种方案：ESI（Edge Side Includes）方案和 CSI（Client Side Include）方案。</description>
    </item>
    
    <item>
      <title>JavaScript 继承</title>
      <link>https://kunzhao.org/docs/programmer-interview/front-end/js-extend/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/programmer-interview/front-end/js-extend/</guid>
      <description>JavaScript 继承 原型链 function Parent() {} function Child() {} Child.prototype = new Parent(); Child.prototype.constructor = Child; 构造器 function Parent() {} function Child() { Parent.call(this); } 原型链 + 构造器 function Parent() {} function Child() { Parent.call(this); } Child.prototype = new Parent(); 原型式 function extendObject(obj) { function F() {} F.prototype = obj; return new F(); } 其实上述代码就是 Object.create() 的兼容方法。
寄生组合 function inheritPrototype(child, parent) { var prototype = extendObject(parent.prototype); prototype.constructor = child; child.prototype = prototype; } function Child() { Parent.</description>
    </item>
    
    <item>
      <title>Linux 零拷贝</title>
      <link>https://kunzhao.org/docs/tutorial/unix-optimize/zero-copy/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/tutorial/unix-optimize/zero-copy/</guid>
      <description>Linux 零拷贝 为什么需要零拷贝  传统 read，write I/O 接口，数据拷贝的好处：通过中间缓存的机制，**减少磁盘 I/O **的操作 拷贝的坏处：大量数据的拷贝，用户态和内核态的频繁切换，会消耗大量的 CPU 资源，严重影响数据传输的性能  什么是零拷贝 零拷贝就是这个问题的一个解决方案，通过尽量避免拷贝操作来缓解 CPU 的压力。Linux 下常见的零拷贝技术可以分为两大类：一是针对特定场景，去掉不必要的拷贝；二是去优化整个拷贝的过程。由此看来，零拷贝并没有真正做到“0”拷贝，它更多是一种思想，很多的零拷贝技术都是基于这个思想去做的优化。
零拷贝的几种方法 原始数据拷贝操作 在介绍之前，先看看 Linux 原始的数据拷贝操作是怎样的。如下图，假如一个应用需要从某个磁盘文件中读取内容通过网络发出去，像这样：
while((n = read(diskfd, buf, BUF_SIZE)) &amp;gt; 0) write(sockfd, buf , n); 那么整个过程就需要经历：
 1）read 将数据从磁盘文件通过 DMA 等方式拷贝到内核开辟的缓冲区； 2）数据从内核缓冲区复制到用户态缓冲区； 3）write 将数据从用户态缓冲区复制到内核协议栈开辟的 socket 缓冲区； 4）数据从 socket 缓冲区通过 DMA 拷贝到网卡上发出去。  可见，整个过程发生了至少四次数据拷贝，其中两次是 DMA 与硬件通讯来完成，CPU 不直接参与，去掉这两次，仍然有两次 CPU 数据拷贝操作。
方法一：用户态直接 I/O 这种方法可以使应用程序或者运行在用户态下的库函数直接访问硬件设备，数据直接跨过内核进行传输，内核在整个数据传输过程除了会进行必要的虚拟存储配置工作之外，不参与其他任何工作，这种方式能够直接绕过内核，极大提高了性能。
缺陷：
 1）这种方法只能适用于那些不需要内核缓冲区处理的应用程序，这些应用程序通常在进程地址空间有自己的数据缓存机制，称为自缓存应用程序，如数据库管理系统就是一个代表。 2）这种方法直接操作磁盘 I/O，由于 CPU 和磁盘 I/O 之间的执行时间差距，会造成资源的浪费，解决这个问题需要和异步 I/O 结合使用。  方法二：mmap 这种方法，使用 mmap 来代替 read，可以减少一次拷贝操作，如下：</description>
    </item>
    
    <item>
      <title>为什么阿里要自研 RocketMQ ?</title>
      <link>https://kunzhao.org/docs/programmer-interview/java/why-develop-rocketmq/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/programmer-interview/java/why-develop-rocketmq/</guid>
      <description>为什么阿里要自研 RocketMQ ? 为什么要重写一个类似于 Kafka 的消息队列，而非基于 Kafka 作二次开发？
初衷 Kafka is a distributed streaming platform, which was born from logging aggregation cases. 它并不需要太高的并发. In some large scale cases in alibaba, we found that the original model 无法满足我们的实际需求.
无法支持更多分区  Each partition stores the whole message data. 尽管单个分区是顺序写的, 随着越来越多的针对不同分区的写入, 在操作系统层面已经变为随机写了. Due to the scattered data files, it is difficult to use the Linux IO Group Commit mechanism.  RocketMQ 支持更多分区  所有消息数据都存储在 Commit Log 文件中。所有写入都是完全顺序的，而读取是随机的。对磁盘的访问是完全顺序的，这避免了磁盘锁争用，并且在创建大量队列时不会导致高磁盘 IO 等待。 ConsumeQueue 存储实际的用户消费位置信息，这些信息也以顺序方式刷新到磁盘。  参考  How to Support More Queues in RocketMQ?</description>
    </item>
    
    <item>
      <title>二维数组寻找最长的单调递增序列</title>
      <link>https://kunzhao.org/docs/programmer-interview/algorithm/longest-increasing-path-in-a-matrix/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/programmer-interview/algorithm/longest-increasing-path-in-a-matrix/</guid>
      <description>二维数组寻找最长的单调递增序列  微软
 // Input: nums = // [ // [9,9,4], // [6,6,8], // [2,1,1] // ] // Output: 4 // Explanation: The longest increasing path is [1, 2, 6, 9]. // // 微软面试题: 二维数组寻找最长的单调递增序列 // // =========================== // 时间复杂度分析: // 每个单元格，尝试它的四个相邻单元格 // 每个单元格都当做起始单元格，使用一个 Cache 来存储结果 // O(M * N) // =========================== public class LongestIncreasingPathinaMatrix { public int longestIncreasingPath(int[][] matrix) { if (matrix.length == 0) { return 0; } int[][] cached = new int[matrix.</description>
    </item>
    
    <item>
      <title>数组乱序</title>
      <link>https://kunzhao.org/docs/programmer-interview/front-end/array-shuffle/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/programmer-interview/front-end/array-shuffle/</guid>
      <description>数组乱序 Fisher-Yates 乱序算法 /** * Shuffles array in place. * @param {Array} a items An array containing the items. */ function shuffle(a) { var j, x, i; for (i = a.length - 1; i &amp;gt; 0; i--) { j = Math.floor(Math.random() * (i + 1)); x = a[i]; a[i] = a[j]; a[j] = x; } return a; } ES6 /** * Shuffles array in place. ES6 version * @param {Array} a items An array containing the items.</description>
    </item>
    
    <item>
      <title>typeof</title>
      <link>https://kunzhao.org/docs/programmer-interview/front-end/typeof/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/programmer-interview/front-end/typeof/</guid>
      <description>typeof 用法 typeof operand typeof(operand) typeof null &amp;gt; typeof null &amp;#34;object&amp;#34; 为什么 typeof null 是 object 根据 Why is typeof null “object”?，这是 JavaScript 实现上的一个 Bug，如果修正这个 Bug，会导致现有代码出现更多的 Bug。
JavaScript 底层的 object 的 type 是使用 0 来表示的，而 null 在多数平台上也是使用 0 来表示，所以 null 的 type 也是 0，因此返回 object。
null 是 object 吗 null 不是 object，它是 primitive value 。
typeof typeof null &amp;gt; typeof typeof null &amp;#34;string&amp;#34; typeof Array &amp;gt; typeof Array &amp;#34;function&amp;#34; typeof [1,2,3] &amp;gt; typeof [1,2,3] &amp;#34;object&amp;#34; typeof 5 &amp;gt; typeof 5 &amp;#34;number&amp;#34; typeof false &amp;#34;boolean&amp;#34; typeof undefined typeof undefined &amp;#34;undefined&amp;#34; typeof String(&amp;ldquo;asdfasdf&amp;rdquo;) typeof String(&amp;#34;asdfasdf&amp;#34;) &amp;#34;string&amp;#34; 更多 </description>
    </item>
    
    <item>
      <title>数组去重</title>
      <link>https://kunzhao.org/docs/programmer-interview/front-end/array-unique/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/programmer-interview/front-end/array-unique/</guid>
      <description>数组去重 indexOf function onlyUnique(value, index, self) { return self.indexOf(value) === index; } filter var myArray = [&amp;#39;a&amp;#39;, 1, &amp;#39;a&amp;#39;, 2, &amp;#39;1&amp;#39;]; var unique = myArray.filter((v, i, a) =&amp;gt; a.indexOf(v) === i); Set function uniqueArray(a) { return [...new Set(a)]; } 参考  Get all unique values in a JavaScript array (remove duplicates)  </description>
    </item>
    
    <item>
      <title>数组扁平化</title>
      <link>https://kunzhao.org/docs/programmer-interview/front-end/flattern-array/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/programmer-interview/front-end/flattern-array/</guid>
      <description>数组扁平化 递归实现 const flatten = function(arr, result = []) { for (let i = 0, length = arr.length; i &amp;lt; length; i++) { const value = arr[i]; if (Array.isArray(value)) { flatten(value, result); } else { result.push(value); } } return result; }; ES2015 reduce function flatten(arr) { return arr.reduce(function (flat, toFlatten) { return flat.concat(Array.isArray(toFlatten) ? flatten(toFlatten) : toFlatten); }, []); } 示例：
flatten([[1, 2, 3], [4, 5]]); // [1, 2, 3, 4, 5] flatten([[[1, [1.</description>
    </item>
    
    <item>
      <title>new 关键字</title>
      <link>https://kunzhao.org/docs/programmer-interview/front-end/new/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/programmer-interview/front-end/new/</guid>
      <description>new 关键字 new 做了什么  创建一个对象 设置 __proto__ 属性 设置 this 指向这个对象 执行构造函数 返回对象  function New(func) { var res = {}; if (func.prototype !== null) { res.__proto__ = func.prototype; } var ret = func.apply(res, Array.prototype.slice.call(arguments, 1)); if ((typeof ret === &amp;#34;object&amp;#34; || typeof ret === &amp;#34;function&amp;#34;) &amp;amp;&amp;amp; ret !== null) { return ret; } return res; } 参考  What is the &amp;lsquo;new&amp;rsquo; keyword in JavaScript?  </description>
    </item>
    
    <item>
      <title>数据类型</title>
      <link>https://kunzhao.org/docs/programmer-interview/front-end/data-types/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/programmer-interview/front-end/data-types/</guid>
      <description>数据类型 8 种数据类型  Primitive values 原始类型: Boolean、Null、Undefined、Number、BigInt、String、Symbol Object：Object  null vs undefined undefined 指已经声明，但是未赋值：
let testVar; alert(testVar); // undefined null 是已经赋值的变量：
let tetVar = null; alert(testVar); // null </description>
    </item>
    
    <item>
      <title>instanceof</title>
      <link>https://kunzhao.org/docs/programmer-interview/front-end/instanceof/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/programmer-interview/front-end/instanceof/</guid>
      <description>instanceof 作用 检测构造器函数的 prototype 是否位于某个对象的 __proto__ 原型链上。
原理 function instance_of(V, F) { var O = F.prototype; V = V.__proto__; while (true) { if (V === null) return false; if (O === V) return true; V = V.__proto__; } } 为什么下列 instanceof 返回 false console.log(true instanceof Boolean); // false console.log(0 instanceof Number); // false console.log(&amp;#34;&amp;#34; instanceof String); // false console.log(new Boolean(true) instanceof Boolean); // true console.log(new Number(0) instanceof Number); // true console.</description>
    </item>
    
    <item>
      <title>let、var、const</title>
      <link>https://kunzhao.org/docs/programmer-interview/front-end/let-vs-const-vs-var/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/programmer-interview/front-end/let-vs-const-vs-var/</guid>
      <description>let、var、const var  var 作用域：在整个 function 内有效 在声明之前就可以引用  function run() { console.log(foo) // 声明之前就可以引用，值：undefined 	var foo = &amp;#34;Foo&amp;#34;; }  function 外定义会创建全局对象  var foo = &amp;#34;Foo&amp;#34;; console.log(window.foo) // Foo，附着在 window 对象  可以再次定义相同变量  &amp;#39;use strict&amp;#39; var foo = &amp;#34;foo1&amp;#34; var foo = &amp;#34;foo2&amp;#34; // foo 值替换为 foo2  闭包引用问题  // 打印 3 次 3 for (var i = 0; i &amp;lt; 3; i++) { setTimeout(() =&amp;gt; console.</description>
    </item>
    
    <item>
      <title>柯里化 - Currying</title>
      <link>https://kunzhao.org/docs/programmer-interview/front-end/currying/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/programmer-interview/front-end/currying/</guid>
      <description>柯里化 - Currying 作用 将 f(a, b, c) 调用形式转为 f(a)(b)(c) 调用形式，它对函数只做转换，不做执行。
实现 function curry(func) { return function curried(...args) { if (args.length &amp;gt;= func.length) { return func.apply(this, args); } else { return function(...args2) { return curried.apply(this, args.concat(args2)); } } }; } 优点  多参数复用性 函数式编程  参考  Currying  </description>
    </item>
    
    <item>
      <title>setTimeout</title>
      <link>https://kunzhao.org/docs/programmer-interview/front-end/settimeout/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/programmer-interview/front-end/settimeout/</guid>
      <description>setTimeout 用 setTimeout 实现 setInterval { const intervals = new Map(); function setInterval(fn, time, context, ...args) { // 随机生成一个 ID  const id = Math.floor(Math.random() * 10000); intervals.set(id, setTimeout(function next() { intervals.set(id, setTimeout(next, time)); fn.apply(context, args); }, time)); return id; } function clearInterval(id) { clearTimeout(intervals.get(id)); } } 如何使用：
const interval = setInterval(console.log, 100, console, &amp;#34;hi&amp;#34;); clearInterval(interval); requestAnimationFrame  作用：告诉浏览器在下一次 repaint 的时候，更新你的动画，也就是说这个是转为动画设计的 API requestAnimationFrame 的调用时机：浏览器的 repaint 阶段 使用 requestAnimationFrame，只有你的网站页面的 Tab 页处于 visible 的时候，浏览器才会去运行你的动画。更省 CPU、更省 GPU、更省内存、更节约电量。 动画至少 60帧/秒，看起来才更流畅：  setInterval(function() { // animiate something }, 1000/60); </description>
    </item>
    
    <item>
      <title>Strict Mode</title>
      <link>https://kunzhao.org/docs/programmer-interview/front-end/strict-mode/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/programmer-interview/front-end/strict-mode/</guid>
      <description>Strict Mode 作用  Strict Mode is a new feature in ECMAScript 5 that allows you to place a program, or a function, in a &amp;ldquo;strict&amp;rdquo; operating context. 这种严格的上下文能够禁掉一些行为以及抛出更多地错误.
 为什么需要它  Strict mode makes it easier to write &amp;ldquo;secure&amp;rdquo; JavaScript.
 如何开启  文件顶部：  // File: myscript.js  &amp;#39;use strict&amp;#39;; var a = 2; ...  function 顶部：  function doSomething() { &amp;#39;use strict&amp;#39;; ... } 约束  禁止全局变量  &amp;#39;use strict&amp;#39;; // Assignment to a non-writable global var undefined = 5; // throws a TypeError var Infinity = 5; // throws a TypeError  delete 不可删除的属性，会抛出异常。例如尝试 delete Object.</description>
    </item>
    
    <item>
      <title>实现 sleep 函数</title>
      <link>https://kunzhao.org/docs/programmer-interview/front-end/implement-sleep/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/programmer-interview/front-end/implement-sleep/</guid>
      <description>实现 sleep 函数 const sleep = (milliseconds) =&amp;gt; { return new Promise(resolve =&amp;gt; setTimeout(resolve, milliseconds)) } 如何使用：
sleep(500).then(() =&amp;gt; { //do stuff }) 在 async 函数中使用：
const doSomething = async () =&amp;gt; { await sleep(2000) //do stuff } doSomething() </description>
    </item>
    
    <item>
      <title>JS 深浅拷贝</title>
      <link>https://kunzhao.org/docs/programmer-interview/front-end/js-copy/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/programmer-interview/front-end/js-copy/</guid>
      <description>JS 深浅拷贝 浅拷贝 ES6 Object assign var A1 = { a: &amp;#34;2&amp;#34; }; var A2 = Object.assign({}, A1); Object assign 的兼容写法 if (!Object.assign) { Object.defineProperty(Object, &amp;#39;assign&amp;#39;, { enumerable: false, configurable: true, writable: true, value: function(target) { &amp;#39;use strict&amp;#39;; if (target === undefined || target === null) { throw new TypeError(&amp;#39;Cannot convert first argument to object&amp;#39;); } var to = Object(target); for (var i = 1; i &amp;lt; arguments.length; i++) { var nextSource = arguments[i]; if (nextSource === undefined || nextSource === null) { continue; } nextSource = Object(nextSource); var keysArray = Object.</description>
    </item>
    
    <item>
      <title>实现 Promise.all</title>
      <link>https://kunzhao.org/docs/programmer-interview/front-end/implement-promise-all/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/programmer-interview/front-end/implement-promise-all/</guid>
      <description>实现 Promise.all 借助 async/await Promise.all = async (promises) =&amp;gt; { const results = []; for (p of promises) { results.push(await p); } return results; } 不借助 async/await Promise.all = (promises) =&amp;gt; { let resolved = 0; let results = []; return new Promise((resolve, reject) =&amp;gt; { for (let promise of promises) { promise .then((result) =&amp;gt; { results.push(result); if (++resolved === promises.length) resolve(results); }) .catch((e) =&amp;gt; { reject(e); }); } }) } 参考  How to Implement Promise.</description>
    </item>
    
    <item>
      <title>实现 retry</title>
      <link>https://kunzhao.org/docs/programmer-interview/front-end/implement-retry/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/programmer-interview/front-end/implement-retry/</guid>
      <description>实现 retry 只要没有 resolve，就一直 retry
方法 const wait = ms =&amp;gt; new Promise(r =&amp;gt; setTimeout(r, ms)); const retryOperation = (operation, delay, times) =&amp;gt; new Promise((resolve, reject) =&amp;gt; { return operation() .then(resolve) .catch((reason) =&amp;gt; { if (times - 1 &amp;gt; 0) { return wait(delay) .then(retryOperation.bind(null, operation, delay, times - 1)) .then(resolve) .catch(reject); } return reject(reason); }); }); 如何使用：
如果没有 resolve 或 reject，那么就每隔 1 秒重试一次，最多重试 5 秒：
retryOperation(func, 1000, 5) .then(console.log) .catch(console.log); 参考  Promise Retry Design Patterns  </description>
    </item>
    
    <item>
      <title>PancakeSorting</title>
      <link>https://kunzhao.org/docs/programmer-interview/algorithm/pancake-sorting/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/programmer-interview/algorithm/pancake-sorting/</guid>
      <description>PancakeSorting 煎饼排序  微软
 // 微软面试题 // https://leetcode.com/problems/pancake-sorting/ // // https://www.1point3acres.com/bbs/forum.php?mod=viewthread&amp;amp;tid=518795&amp;amp;extra=page%3D1%26filter%3Dsortid%26sortid%3D327%26sortid%3D327 // 给出算法题，完成一个只能flip subarray的sort功能。 // 然后面试官提示看代码XX行，可以优化。 然后在她的提示下进行了两次优化。 // 然后要写flip的功能，时间来不及了，就匆匆用python的 reverse()完成了个简单的flip。 // 然后面试官说能不能不用reverse，我说可以，用forloop和stack就行了。她说可以用swap。 // 然后说时间到了，问我有没有想问的，我就问了能不能有更快的算法完成这个sort，她说没有了。 // // 看起来 flip 的意思是指只能从 0 ~ index 的位置整体翻转 // // Any valid answer that sorts the array within 10 * A.length flips will be judged as correct. // A[i] is a permutation of [1, 2, ..., A.length] public class PancakeSorting { public List&amp;lt;Integer&amp;gt; pancakeSort(int[] A) { List&amp;lt;Integer&amp;gt; res = new ArrayList&amp;lt;&amp;gt;(); int end = A.</description>
    </item>
    
    <item>
      <title>Sentinel 与 Hystrix 的对比</title>
      <link>https://kunzhao.org/docs/programmer-interview/java/sentinel-vs-hystrix/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/programmer-interview/java/sentinel-vs-hystrix/</guid>
      <description>Sentinel 与 Hystrix 的对比 对比     Sentinel Hystrix     隔离策略 信号量隔离 线程池隔离/信号量隔离   熔断降级策略 基于响应时间或失败比率 基于失败比率   实时指标实现 滑动窗口 滑动窗口（基于 RxJava）   规则配置 支持多种数据源 支持多种数据源   扩展性 多个扩展点 插件的形式   基于注解的支持 支持 支持   限流 基于 QPS，支持基于调用关系的限流 有限的支持   流量整形 支持慢启动、匀速器模式 不支持   系统负载保护 支持 不支持   控制台 开箱即用，可配置规则、查看秒级监控、机器发现等 不完善   常见框架的适配 Servlet、Spring Cloud、Dubbo、gRPC 等 Servlet、Spring Cloud Netflix    参考  Sentinel 与 Hystrix 的对比  </description>
    </item>
    
    <item>
      <title>同步/异步与阻塞/非阻塞</title>
      <link>https://kunzhao.org/docs/tutorial/unix-optimize/async_block/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/tutorial/unix-optimize/async_block/</guid>
      <description>同步/异步与阻塞/非阻塞  两组概念不在同一个纬度
 同步/异步 同步：操作者主动完成了这件事情，需要自己完成的操作都是同步操作。
异步：调用指令发出，操作马上返回，处理完成后，再通过通知的手段来告诉操作者结果，不是调用者自己完成的。
阻塞/非阻塞 阻塞：从头到尾只做这一件事情，不能做其他事情：
非阻塞：无需等待在这里，反复过来检查：
总结  POSIX defines these two terms as follows: A synchronous I/O operation causes therequesting process to be blocked until that I/O operation completes. An asynchronous I/O operation does not cause the requesting process to be blocked. Using these definitions, the first four I/O modes - blocking, nonblocking, I/O multiplexing, and signal-driven I/O - are all synchronous because the actual I/O operation (recvfrom) blocks the process.</description>
    </item>
    
    <item>
      <title>跨域</title>
      <link>https://kunzhao.org/docs/programmer-interview/front-end/cors/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/programmer-interview/front-end/cors/</guid>
      <description>跨域 定义 跨域：指一个 domain 下的 HTML 或脚本试图去请求另一个 domain 下的资源。
同源策略 同源策略 （Same origin policy）：两个 URL 的协议、域名、端口相同。
同源限制访问资源  Cookie、LocalStorage 和 IndexDB 无法读取 DOM 和 Js 对象无法获得 AJAX 请求不能发送  JSONP &amp;lt;script&amp;gt; var script = document.createElement(&amp;#39;script&amp;#39;); script.type = &amp;#39;text/javascript&amp;#39;; // 传参一个回调函数名给后端，方便后端返回时执行这个在前端定义的回调函数  script.src = &amp;#39;http://www.domain2.com:8080/login?user=admin&amp;amp;callback=handleCallback&amp;#39;; document.head.appendChild(script); // 回调执行函数  function handleCallback(res) { alert(JSON.stringify(res)); } &amp;lt;/script&amp;gt; 后端返回的内容如下所示，即返回后立即执行 handleCallback：
handleCallback({&amp;#34;status&amp;#34;: true, &amp;#34;user&amp;#34;: &amp;#34;admin&amp;#34;})  JSONP 只能进行 GET 调用
 跨域资源共享 (CORS) 服务端设置 Access-Control-Allow-Origin:* 头即可，前端无须设置。如果想要进行 cookie 的读写，那么前端需要设置这个属性为 true：</description>
    </item>
    
    <item>
      <title>堆排序</title>
      <link>https://kunzhao.org/docs/programmer-interview/algorithm/heap-sort/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/programmer-interview/algorithm/heap-sort/</guid>
      <description>堆排序 // - 建堆，不同节点运行 heapify 的时间与节点所处的高度相关 // https://www.cnblogs.com/LzyRapx/p/9565305.html // // 树高 h = lgn // // 第 0 层，只有根节点，它需要最多向下调整 h * 2^0 次 // 第 1 层，有 2 个节点，它需要向下调整 (h - 1) * 2^1 次 // 第 2 层，有 4 个节点，它需要向下调整 (h - 2) * 2^2 次 // // 第 h 层，有 2^h 个节点，它需要向下调整 (h - h) * 2^h 次 // // O(n) = h * 2^0 + (h - 1) * 2^1 + (h - 2) * 2^2 + .</description>
    </item>
    
    <item>
      <title>线程和进程</title>
      <link>https://kunzhao.org/docs/tutorial/unix-optimize/thread_process/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/tutorial/unix-optimize/thread_process/</guid>
      <description>线程和进程 线程 线程通信方式  POSIX 信号量 互斥锁 (互斥量)：独占方式访问关键代码段。 条件变量：某个共享数据达到某个值的时候，唤醒等待这个共享数据的线程。  线程的数据 生命周期 另外一副 Java 线程的状态转换图：
另外一副更为详细的：
何时可以响应中断  线程在运行态是不响应中断的。
    状态 中断效果 描述     NEW 无    RUNNABLE 设置中断标志位 用户自己判断是否中断，以及如何处理   BLOCKED 设置中断标志位 用户自己判断是否中断，以及如何处理   WAITING 抛InterruptedException异常，并清空中断标志位    TIMED_WAITING 抛InterruptedException异常，并清空中断标志位    TERMINATED 无     自发性上下文切换 自发性上下文切换指线程由 Java 程序调用导致切出，在多线程编程中，执行调用以下方法或关键字，常常就会引发自发性上下文切换。sleep()、wait()、yield()、join()、park()、synchronized、lock。
停止线程 (1) volatile 标志位
// set this to true to stop the thread volatile boolean shutdown = false; .</description>
    </item>
    
    <item>
      <title>节流和防抖</title>
      <link>https://kunzhao.org/docs/programmer-interview/front-end/throttle-and-debounce/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/programmer-interview/front-end/throttle-and-debounce/</guid>
      <description>节流和防抖 作用 解决页面卡顿等性能问题
节流函数 一定时间内，某个函数只执行一次。By using throttle function, we don&amp;rsquo;t allow to our function to execute more than once every X milliseconds.
function throttle (callback, limit) { var waiting = false; // 一开始，处于非等待状态  return function () { // 返回一个节流函数  if (!waiting) { // 如果没有等待  callback.apply(this, arguments); // 执行函数  waiting = true; // 等待置位 true  setTimeout(function () { // limit 时间之后  waiting = false; // 重新置位 false  }, limit); } } }  callback 函数：哪个函数需要节流？ limit：多长时间之后可以重新调用  也可以基于时间判断来实现：</description>
    </item>
    
    <item>
      <title>链表归并排序</title>
      <link>https://kunzhao.org/docs/programmer-interview/algorithm/linkedlist-mergesort/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/programmer-interview/algorithm/linkedlist-mergesort/</guid>
      <description>链表归并排序 // ============================= // MergeSort // // 切分为三部分: // - small // - equal // - large // ============================= public class SortList { public ListNode sortList(ListNode head) { if (head == null || head.next == null) { return head; } ListNode lessOrEqualThanPivot = new ListNode(-1); ListNode pivot = head; ListNode greatThanPivot = new ListNode(-1); ListNode equalPivot = new ListNode(-1); ListNode p = head; ListNode pLess = lessOrEqualThanPivot; ListNode pGreat = greatThanPivot; ListNode pEqual = equalPivot; while (p !</description>
    </item>
    
    <item>
      <title>快排序</title>
      <link>https://kunzhao.org/docs/programmer-interview/algorithm/quicksort/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/programmer-interview/algorithm/quicksort/</guid>
      <description>快排序 // T(n) = T(n - 1) + T(0)，每次都分为 n - 1 个和 0 个元素 // T(n - 1) = T(n - 2) + T(0) // ... // 迭代想加 // T(n) = O(n^2) // // - 最坏情况: // T(n) = 2T(n / 2) + O(n) // T(n / 2) = 2T(n / 4) + O(n) // // 画出树，整颗树高 log2^n 然后每次都是 O(n) 所以 nlogn // // n.................O(n) // n/2 n/2.............O(n) // n/4 n/4 n/4 n/4.</description>
    </item>
    
    <item>
      <title>归并排序</title>
      <link>https://kunzhao.org/docs/programmer-interview/algorithm/mergesort/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/programmer-interview/algorithm/mergesort/</guid>
      <description>归并排序 public class MergeSort { public void sort(int[] array) { sort(array, 0, array.length - 1); } private void sort(int[] array, int begin, int end) { if (end &amp;gt; begin) { int middle = begin + ((end - begin) &amp;gt;&amp;gt; 1); // ===========================  // begin ~ middle  // ===========================  sort(array, begin, middle); // ===========================  // middle + 1 ~ end  // ===========================  sort(array, middle + 1, end); merge(array, begin, middle, end); } } private void merge(int[] array, int begin, int middle, int end) { int[] temp = new int[end - begin + 1]; int i = begin; int j = middle + 1; int k = 0; while (i &amp;lt;= middle &amp;amp;&amp;amp; j &amp;lt;= end) { if (array[i] &amp;lt; array[j]) { temp[k++] = array[i++]; } else { temp[k++] = array[j++]; } } while (i &amp;lt;= middle) { temp[k++] = array[i++]; } while (j &amp;lt;= end) { temp[k++] = array[j++]; } k = 0; while (k &amp;lt; temp.</description>
    </item>
    
    <item>
      <title>栈排序</title>
      <link>https://kunzhao.org/docs/programmer-interview/algorithm/sort-stack/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/programmer-interview/algorithm/sort-stack/</guid>
      <description>栈排序 // 美团面试题: https://www.nowcoder.com/discuss/268612?type=2&amp;amp;order=0&amp;amp;pos=49&amp;amp;page=1 public class SortStack { public static void stackSorting(Stack&amp;lt;Integer&amp;gt; stack) { Stack&amp;lt;Integer&amp;gt; t = new Stack&amp;lt;&amp;gt;(); while(!stack.isEmpty()) { int item = stack.pop(); while(!t.isEmpty() &amp;amp;&amp;amp; t.peek() &amp;gt; item) stack.push(t.pop()); t.push(item); } while(!t.isEmpty()) stack.push(t.pop()); } } </description>
    </item>
    
    <item>
      <title>磁盘多路归并排序</title>
      <link>https://kunzhao.org/docs/programmer-interview/algorithm/disk-merge-sort/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/programmer-interview/algorithm/disk-merge-sort/</guid>
      <description>磁盘多路归并排序 // 磁盘多路归并排序 // https://mp.weixin.qq.com/s?__biz=MzI0MzQyMTYzOQ==&amp;amp;mid=2247484900&amp;amp;idx=1&amp;amp;sn=a120748f4c1229dbb851732e4cd5f47c&amp;amp;pass_ticket=TEG93hpjf7gdkxzIPcHay9NH%2FprQkpCtcZYYI4NcTDeNiCpFQAsK%2Bh4x9M1mviQ8 // // 1 2 3 4 5 (文件 1 2 3 4 5) // ---------- // 2 5 5 7 12 // 3 6 5 8 13 // 4 6 6 9 13 // // 内存中维护的数组变化，方括号内代表这个数字属于哪个文件 // 2[1] 5[2] 5[3] 7[4] 12[5] // 3[1] 5[2] 5[3] 7[4] 12[5] // 4[1] 5[2] 5[3] 7[4] 12[5] // 5[2] 5[3] 6[2] 7[4] 12[5] // 5[3] 6[2] 6[2] 7[4] 12[5] // .</description>
    </item>
    
    <item>
      <title>求解逆波兰表达式</title>
      <link>https://kunzhao.org/docs/programmer-interview/algorithm/evaluate-reverse-polish-notation/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/programmer-interview/algorithm/evaluate-reverse-polish-notation/</guid>
      <description>求解逆波兰表达式 - 写一个计算器  微软
 // https://leetcode.com/problems/evaluate-reverse-polish-notation/submissions/ // // Input: [&amp;#34;2&amp;#34;, &amp;#34;1&amp;#34;, &amp;#34;+&amp;#34;, &amp;#34;3&amp;#34;, &amp;#34;*&amp;#34;] // Output: 9 // Explanation: ((2 + 1) * 3) = 9 // // Input: [&amp;#34;4&amp;#34;, &amp;#34;13&amp;#34;, &amp;#34;5&amp;#34;, &amp;#34;/&amp;#34;, &amp;#34;+&amp;#34;] // Output: 6 // Explanation: (4 + (13 / 5)) = 6 // // 微软面试题: 写一个计算器 // 这个原题，给你的已经是一个逆波兰表达式了 public class EvaluateReversePolishNotation { public int evalRPN(String[] tokens) { Stack&amp;lt;Integer&amp;gt; numStack = new Stack&amp;lt;&amp;gt;(); for (int i = 0; i &amp;lt; tokens.</description>
    </item>
    
    <item>
      <title>浏览器缓存</title>
      <link>https://kunzhao.org/docs/programmer-interview/front-end/cache/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/programmer-interview/front-end/cache/</guid>
      <description>浏览器缓存 强缓存 HTTP 1.0 Expires Expires: Wed, 11 May 2018 07:20:00 GMT  缺点：时间是绝对时间，很难保证用户计算机时间和服务器时间一致
 HTTP 1.1 Cache-Control Cache-Control: max-age=315360000  优先级高于 Expires
 Cache-Control 取值如下：
 no-store：不缓存到本地 public：多用户共享 private：只能被终端浏览器缓存 no-cache：缓存到本地，但是使用这个缓存之前，必须与服务器进行新鲜度验证  （1）禁用缓存
Cache-Control: no-store （2）缓存静态资源
Cache-Control: public, max-age=604800, immutable （3）重新校验资源
Cache-Control: no-cache Cache-Control: no-cache, max-age=0 协商缓存 当浏览器对某个资源的请求没有命中强缓存，就会发一个请求到服务器，验证协商缓存是否命中，如果协商缓存命中，请求响应返回的 HTTP 状态为 304 并且会显示一个 Not Modified 的字符串。
那么浏览器如何询问服务器？
If-Modified-Since 浏览器请求服务器的时候带上这个头 If-Modified-Since，它的值是这个文件上一次服务器返回来的时候携带的 Last-Modified 的 HTTP 头的值。如果服务器有新的资源，那么会返回新的资源，否则响应 304。
If-None-Match If-Modified-Since 是根据文件的修改时间定的，而 If-None-Match 携带的值是这个文件的指纹，即上一次服务器返回这个文件携带的 ETag HTTP 头的值。浏览器将这个信息发送给服务器，可以更为精确地知道这个文件有没有变化。如果服务器有新的资源，返回新的，否则响应 304 状态码。</description>
    </item>
    
    <item>
      <title>MinStack</title>
      <link>https://kunzhao.org/docs/programmer-interview/algorithm/minstack/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/programmer-interview/algorithm/minstack/</guid>
      <description>MinStack 使用两个栈 // 使用了两个栈 // 占用内存大 // // 使用一个栈的解法见 MinStack_Solution_1.java public class MinStack { private Stack&amp;lt;Integer&amp;gt; stack = new Stack&amp;lt;Integer&amp;gt;(); private Stack&amp;lt;Integer&amp;gt; minStack = new Stack&amp;lt;Integer&amp;gt;(); /** initialize your data structure here. */ public MinStack() { } public void push(int x) { stack.push(x); if (minStack.isEmpty()) { minStack.push(x); } else { minStack.push(x &amp;lt; minStack.peek() ? x : minStack.peek()); } } public void pop() { stack.pop(); minStack.pop(); } public int top() { return stack.</description>
    </item>
    
    <item>
      <title>事件循环</title>
      <link>https://kunzhao.org/docs/programmer-interview/front-end/eventloop/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/programmer-interview/front-end/eventloop/</guid>
      <description>事件循环 Event Loop JS 是单线程的。在 JavaScript 引擎里，取 task 和执行 task 的代码封装在一个死循环里面，JavaScript 引擎等待 tasks 的出现，有则执行，无则 sleep。异步任务分为宏任务和微任务。
Macro Task 宏任务 宏任务示例：&amp;lt;script&amp;gt;、setTimeout、setInterval、setImmediate、requestAnimationFrame、I/O、UI 渲染
Micro Task 微任务 微任务示例：process.nextTick、Promises、queueMicrotask、MutationObserver
 Micro is like macro but with higher priority.
 Event Loop 算法 while (true) { // 执行宏任务  let task = macroTaskQueue.getOldestTask(); execute(task); // 执行微任务  while (microTaskQueue.length &amp;gt; 0) { execute(microTaskQueue.getOldestTask()) } // 渲染  if (isRenderTime()) { render(); } } Node EventLoop vs 浏览器 EventLoop  microtask 的执行时机不同。</description>
    </item>
    
    <item>
      <title>浏览器存储</title>
      <link>https://kunzhao.org/docs/programmer-interview/front-end/storage/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/programmer-interview/front-end/storage/</guid>
      <description>浏览器存储 Web Storage  Web Storage 也叫 DOM Storage.
 浏览器提供了两种支持 Web Storage 的对象：
 window.localStorage：数据没有过期时间 window.sessionStorage：仅仅会话期间有效，关闭当前浏览器 Tab 页面的时候，数据消失  注意，这两个 Storage 对象存储的 value 只支持 String 类型，你存储其他类型，浏览器也会自动转为 String 类型存储进去。
sessionStorage.setItem(&amp;#39;key&amp;#39;, &amp;#39;value&amp;#39;) localStorage.setItem(&amp;#39;key&amp;#39;, &amp;#39;value&amp;#39;) 存储大小  Cookie 允许 4KB Opera 10.50+ 允许 5MB Safari 8 允许 5MB Firefox 34 允许 10MB Chrome 允许 10MB IE 允许 10MB  数据可见性 （1）LocalStorage
只有相同协议、相同 Host、相同端口，这三个都相同，才能算作是同一个 Origin。 只要两个页面处于同一 Origin ，那么存储在这一 Origin 的 LocalStorage 数据便可以自由访问。
（2）SessionStorage</description>
    </item>
    
    <item>
      <title>DOM 操作 API</title>
      <link>https://kunzhao.org/docs/programmer-interview/front-end/dom-operate-api/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/programmer-interview/front-end/dom-operate-api/</guid>
      <description>JavaScript 常见原生 DOM 操作 API 总结 节点查找 API    方法 示例 描述     querySelector var el = document.querySelector(&amp;quot;.myclass&amp;quot;); 返回第一个匹配 selector 的元素   querySelectorAll var matches = document.querySelectorAll(&amp;quot;p&amp;quot;); 返回一个匹配的 NodeList 数组   getElementById var elem = document.getElementById(&#39;para&#39;); 返回匹配 ID 的 Element   getElementsByClassName document.getElementsByClassName(&#39;red test&#39;) 返回匹配 class 的一个 array-like 的元素数组   getElementsByTagName var allParas = document.getElementsByTagName(&#39;p&#39;); 返回指定 Tag 的 HTMLCollection   getElementsByName var up_names = document.</description>
    </item>
    
    <item>
      <title>Event</title>
      <link>https://kunzhao.org/docs/programmer-interview/front-end/event/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/programmer-interview/front-end/event/</guid>
      <description>Event target 和 currentTarget  target：哪个元素触发了事件？ currentTarget：哪个元素监听了这个事件  事件代理/委托 原因 添加的事件监听器数量，影响页面的整体运行性能，因为访问 DOM 的次数越多，引起浏览器的重绘和重排的次数也就越多。通过事件委托，可以减少添加的事件监听器数量，提高页面性能。
原理 利用事件冒泡。
示例 &amp;lt;ul id=&amp;#34;list&amp;#34;&amp;gt; &amp;lt;li id=&amp;#34;item1&amp;#34;&amp;gt;item1&amp;lt;/li&amp;gt; &amp;lt;li id=&amp;#34;item2&amp;#34;&amp;gt;item2&amp;lt;/li&amp;gt; &amp;lt;li id=&amp;#34;item3&amp;#34;&amp;gt;item3&amp;lt;/li&amp;gt; &amp;lt;li id=&amp;#34;item4&amp;#34;&amp;gt;item4&amp;lt;/li&amp;gt; &amp;lt;/ul&amp;gt; 目的：点击 li 然后弹出这个 li 的内容：
window.onload=function(){ var ulNode=document.getElementById(&amp;#34;list&amp;#34;); ulNode.addEventListener(&amp;#39;click&amp;#39;,function(e){ if(e.target &amp;amp;&amp;amp; e.target.nodeName.toUpperCase() == &amp;#34;LI&amp;#34;){/*判断目标事件是否为li*/ alert(e.target.innerHTML); } },false); }; </description>
    </item>
    
    <item>
      <title>冒泡捕获</title>
      <link>https://kunzhao.org/docs/programmer-interview/front-end/event-bubble-capture/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/programmer-interview/front-end/event-bubble-capture/</guid>
      <description>冒泡捕获 冒泡 &amp;lt;style&amp;gt; body * { margin: 10px; border: 1px solid blue; } &amp;lt;/style&amp;gt; &amp;lt;form onclick=&amp;#34;alert(&amp;#39;form&amp;#39;)&amp;#34;&amp;gt;FORM &amp;lt;div onclick=&amp;#34;alert(&amp;#39;div&amp;#39;)&amp;#34;&amp;gt;DIV &amp;lt;p onclick=&amp;#34;alert(&amp;#39;p&amp;#39;)&amp;#34;&amp;gt;P&amp;lt;/p&amp;gt; &amp;lt;/div&amp;gt; &amp;lt;/form&amp;gt;  冒泡：点击 p 元素，首先 alert p，其次 alert div，最后 alert form。从最内层的元素冒泡到最外层的元素。
 阻止冒泡 stopPropagation 阻止向父元素冒泡：
event.stopPropagation() 示例：
&amp;lt;body onclick=&amp;#34;alert(`the bubbling doesn&amp;#39;t reach here`)&amp;#34;&amp;gt; &amp;lt;button onclick=&amp;#34;event.stopPropagation()&amp;#34;&amp;gt;Click me&amp;lt;/button&amp;gt; &amp;lt;/body&amp;gt; 阻止冒泡 stopImmediatePropagation 阻止向父元素冒泡，并且当前元素绑定的其它事件也不会执行：
event.stopImmediatePropagation() 举例：
$(&amp;#39;p&amp;#39;).click(event =&amp;gt; event.stopImmediatePropagation()) $(&amp;#39;p&amp;#39;).click(event =&amp;gt; console.log(&amp;#39;这个事件不会执行&amp;#39;)) 但是如果你调整一下顺序，这个事件就会执行了：
$(&amp;#39;p&amp;#39;).click(event =&amp;gt; console.log(&amp;#39;这个事件会执行&amp;#39;)) $(&amp;#39;p&amp;#39;).click(event =&amp;gt; event.stopImmediatePropagation()) 捕获 事件传播的三个阶段 DOM Events 描述了事件传播的三个阶段：</description>
    </item>
    
    <item>
      <title>重绘和重排</title>
      <link>https://kunzhao.org/docs/programmer-interview/front-end/repaint-reflow/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/programmer-interview/front-end/repaint-reflow/</guid>
      <description>重绘和重排 网页渲染  &amp;ldquo;生成布局&amp;rdquo;（flow）和&amp;quot;绘制&amp;quot;（paint）这两步，合称为&amp;quot;渲染&amp;quot;（render）。
 重绘 repint 重绘：某种操作改变了某个元素的外观，但并未改变这个元素的布局，从而需要重新绘制。例如对 outline、visibility、background、color 的改变。重绘不一定会引起重排。
重排/回流 reflow 重排/回流：某种操作改变了某个元素、网页的一部分或整个网页的布局，其对于性能的影响更为严重。重排必会导致重绘。
重排触发机制 重排发生的根本原理就是元素的几何属性发生了改变，那么我们就从能够改变元素几何属性的角度入手
 添加或删除可见的 DOM 元素 元素位置改变 元素本身的尺寸发生改变 内容改变 页面渲染器初始化 浏览器窗口大小发生改变  如何优化 浏览器自身优化 现代浏览器大多都是通过队列机制来批量更新布局，浏览器会把修改操作放在队列中，至少一个浏览器刷新（即16.6ms）才会清空队列，但当你获取布局信息的时候，队列中可能有会影响这些属性或方法返回值的操作，即使没有，浏览器也会强制清空队列，触发回流与重绘来确保返回正确的值。
主要包括以下属性或方法：
offsetTop、offsetLeft、offsetWidth、offsetHeight scrollTop、scrollLeft、scrollWidth、scrollHeight clientTop、clientLeft、clientWidth、clientHeight width、height getComputedStyle() getBoundingClientRect() 所以，我们应该避免频繁的使用上述的属性，他们都会强制渲染刷新队列。
合并读操作/写操作 不要这样：
// bad div.style.left = div.offsetLeft + 10 + &amp;#34;px&amp;#34;; div.style.top = div.offsetTop + 10 + &amp;#34;px&amp;#34;; 读写分离合并：
// good var left = div.offsetLeft; var top = div.offsetTop; div.style.left = left + 10 + &amp;#34;px&amp;#34;; div.</description>
    </item>
    
    <item>
      <title>浏览器如何渲染页面 ?</title>
      <link>https://kunzhao.org/docs/programmer-interview/front-end/how-browser-render-html/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/programmer-interview/front-end/how-browser-render-html/</guid>
      <description>浏览器如何渲染页面 ? 渲染主流程 Webkit 渲染流程  Mozilla 的 Gecko 渲染流程   构建 DOM 树 &amp;lt;!DOCTYPE html&amp;gt; &amp;lt;html&amp;gt; &amp;lt;head&amp;gt; &amp;lt;meta name=&amp;#34;viewport&amp;#34; content=&amp;#34;width=device-width,initial-scale=1&amp;#34;&amp;gt; &amp;lt;link href=&amp;#34;style.css&amp;#34; rel=&amp;#34;stylesheet&amp;#34;&amp;gt; &amp;lt;title&amp;gt;Critical Path&amp;lt;/title&amp;gt; &amp;lt;/head&amp;gt; &amp;lt;body&amp;gt; &amp;lt;p&amp;gt;Hello &amp;lt;span&amp;gt;web performance&amp;lt;/span&amp;gt; students!&amp;lt;/p&amp;gt; &amp;lt;div&amp;gt;&amp;lt;img src=&amp;#34;awesome-photo.jpg&amp;#34;&amp;gt;&amp;lt;/div&amp;gt; &amp;lt;/body&amp;gt; &amp;lt;/html&amp;gt; 对于上述 HTML 片段，浏览器从磁盘或网络读取 HTML 的原始字节，并根据文件的指定编码（例如 UTF-8）将它们转换成各个字符，然后分析出各个 HTML 标签、各个标签对应的属性等。最后，根据标签之间的关系，构建 DOM 树。
构建 CSSOM 树 在浏览器构建我们这个简单页面的 DOM 时，在文档的 head 部分遇到了一个 link 标记，该标记引用一个外部 CSS 样式表：style.css。由于预见到需要利用该资源来渲染页面，它会立即发出对该资源的请求，并返回以下内容：
body { font-size: 16px } p { font-weight: bold } span { color: red } p span { display: none } img { float: right } 与处理 HTML 时一样，我们需要将收到的 CSS 规则转换成某种浏览器能够理解和处理的东西。因此，我们会重复 HTML 过程，不过是为 CSS 而不是 HTML：</description>
    </item>
    
    <item>
      <title>Web 安全</title>
      <link>https://kunzhao.org/docs/programmer-interview/front-end/web_security/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/programmer-interview/front-end/web_security/</guid>
      <description>Web 安全 点击劫持 点击劫持 (Clickjacking) 技术又称为界面伪装攻击 (UI redress attack )，是一种视觉上的欺骗手段。攻击者使用一个或多个透明的 iframe 覆盖在一个正常的网页上，然后诱使用户在该网页上进行操作，当用户在不知情的情况下点击透明的 iframe 页面时，用户的操作已经被劫持到攻击者事先设计好的恶意按钮或链接上。攻击者既可以通过点击劫持设计一个独立的恶意网站，执行钓鱼攻击等；也可以与 XSS 和 CSRF 攻击相结合，突破传统的防御措施，提升漏洞的危害程度。
Cross-site request forgery (CSRF) CSRF（Cross-site request forgery）跨站请求伪造：攻击者诱导受害者进入第三方网站，在第三方网站中，向被攻击网站发送跨站请求。利用受害者在被攻击网站已经获取的注册凭证，绕过后台的用户验证，达到冒充用户对被攻击的网站执行某项操作的目的。
一个典型的CSRF攻击有着如下的流程：
 受害者登录 a.com，并保留了登录凭证（Cookie）。 攻击者引诱受害者访问了 b.com。 b.com 向 a.com 发送了一个请求：a.com/act=xx。浏览器会默认携带 a.com 的 Cookie。 a.com 接收到请求后，对请求进行验证，并确认是受害者的凭证，误以为是受害者自己发送的请求。 a.com 以受害者的名义执行了 act=xx。 攻击完成，攻击者在受害者不知情的情况下，冒充受害者，让 a.com 执行了自己定义的操作。  CSRF 的特点  攻击一般发起在第三方网站，而不是被攻击的网站。被攻击的网站无法防止攻击发生。 攻击利用受害者在被攻击网站的登录凭证，冒充受害者提交操作；而不是直接窃取数据。 整个过程攻击者并不能获取到受害者的登录凭证，仅仅是“冒用”。 跨站请求可以用各种方式：图片URL、超链接、CORS、Form提交等等。部分请求方式可以直接嵌入在第三方论坛、文章中，难以进行追踪。  CSRF通常是跨域的，因为外域通常更容易被攻击者掌控。但是如果本域下有容易被利用的功能，比如可以发图和链接的论坛和评论区，攻击可以直接在本域下进行，而且这种攻击更加危险。
防护策略 （1）同源检测（Origin 和 Referer 验证）
既然 CSRF 大多来自第三方网站，那么我们就**直接禁止外域（或者不受信任的域名）**对我们发起请求。在HTTP协议中，每一个异步请求都会携带两个Header，用于标记来源域名：origin 和 referer。
（2）CSRF Token
CSRF 攻击之所以能够成功，是因为服务器误把攻击者发送的请求当成了用户自己的请求。那么我们可以要求所有的用户请求都携带一个 CSRF 攻击者无法获取到的 Token。服务器通过校验请求是否携带正确的 Token，来把正常的请求和攻击的请求区分开，也可以防范 CSRF 的攻击。具体步骤：</description>
    </item>
    
    <item>
      <title>VUE 生命周期</title>
      <link>https://kunzhao.org/docs/programmer-interview/front-end/vue-lifecycle/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/programmer-interview/front-end/vue-lifecycle/</guid>
      <description>VUE 生命周期 </description>
    </item>
    
    <item>
      <title>找出最多 K 个不同字符的最长子串</title>
      <link>https://kunzhao.org/docs/programmer-interview/algorithm/longest-substring-with-at-most-k-distinct-characters/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/programmer-interview/algorithm/longest-substring-with-at-most-k-distinct-characters/</guid>
      <description>找出最多 K 个不同字符的最长子串  微软、网易
 // https://www.lintcode.com/problem/longest-substring-with-at-most-k-distinct-characters/description // 网易 // 微软面试题 // // 给定字符串S，找到最多有k个不同字符的最长子串 T // // 输入: S = &amp;#34;eceba&amp;#34; 并且 k = 3 // 输出: 4 // 解释: T = &amp;#34;eceb&amp;#34; public class LongestSubstringwithAtMostKDistinctCharacters { public int lengthOfLongestSubstringKDistinct(String s, int k) { if (k == 0 || s.length() == 0) { return 0; } Map&amp;lt;Character, Integer&amp;gt; map = new HashMap&amp;lt;&amp;gt;(); int longest = 0; int right = 0; int left = 0; while (right &amp;lt; s.</description>
    </item>
    
    <item>
      <title>Vue.nextTick</title>
      <link>https://kunzhao.org/docs/programmer-interview/front-end/nexttick/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/programmer-interview/front-end/nexttick/</guid>
      <description>Vue.nextTick 作用 在 DOM 更新后，执行一个回调。
// DOM 还没有更新 Vue.nextTick(function () { // DOM 更新了 }) Vue 何时更新 DOM Vue 在修改数据后，DOM 不会立刻更新，而是等同一事件循环中的所有数据变化完成之后，再统一进行 DOM 更新。
应用场景 created/mounted 操作 DOM mounted: function () { this.$nextTick(function () { // Code that will run only after the  // entire view has been rendered  }) } 显示输入框并获取焦点 showInput() { this.show = true this.$nextTick(function () { // DOM 更新了  document.getElementById(&amp;#34;keywords&amp;#34;).focus() }) } </description>
    </item>
    
    <item>
      <title>两个字符串整数相加</title>
      <link>https://kunzhao.org/docs/programmer-interview/algorithm/add-strings/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/programmer-interview/algorithm/add-strings/</guid>
      <description>两个字符串整数相加  微软
 // https://leetcode.com/problems/add-strings/ // 没有 leading zeros // 微软面试题 public class AddStrings { // 1 2 3 4  // 7 8 9  public String addStrings(String num1, String num2) { if (num1 == null) { return num2; } if (num2 == null) { return num1; } final StringBuilder sb = new StringBuilder(Math.max(num1.length(), num2.length()) + 1); int index1 = num1.length() - 1; int index2 = num2.length() - 1; int remainder = 0; while (index1 &amp;gt;= 0 &amp;amp;&amp;amp; index2 &amp;gt;= 0) { char a = num1.</description>
    </item>
    
    <item>
      <title>二维矩阵数值和最小的路径</title>
      <link>https://kunzhao.org/docs/programmer-interview/algorithm/minimum-path-sum/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/programmer-interview/algorithm/minimum-path-sum/</guid>
      <description>二维矩阵数值和最小的路径  微软
 // 微软面试题: 二维矩阵，没有负值，找出从左上角到右下角，使得路径上的数值和最小的路径 // https://leetcode.com/problems/minimum-path-sum/ // public class MinimumPathSum { public int minPathSum(int[][] grid) { int m = grid.length; int n = grid[0].length; int[][] minSum = new int[m][n]; minSum[0][0] = grid[0][0]; for (int i = 0; i &amp;lt; m; i++) { for (int j = 0; j &amp;lt; n; j++) { if (i == 0 &amp;amp;&amp;amp; j == 0) { continue; } if (i - 1 &amp;lt; 0) { minSum[i][j] = minSum[i][j - 1] + grid[i][j]; } else if (j - 1 &amp;lt; 0) { minSum[i][j] = minSum[i - 1][j] + grid[i][j]; } else { // =======================  // 这一个公式就可以了  // =======================  minSum[i][j] = Math.</description>
    </item>
    
    <item>
      <title>最小火车票费用</title>
      <link>https://kunzhao.org/docs/programmer-interview/algorithm/minimum-cost-for-tickets/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/programmer-interview/algorithm/minimum-cost-for-tickets/</guid>
      <description>最小火车票费用 // 亚马逊电面 // 最小火车票费用 // // 一年有 365 天，第一天编号为 1 // days = [1,4,6,7,8,20] 你的旅游时间必须覆盖到1、4、6、... // costs = [2,7,15] 旅游有 1 日游、7 日游、30 日游 // 问覆盖到所有天数的最小 cost // // https://leetcode.com/problems/minimum-cost-for-tickets/ public class MinimumCostForTickets { public int mincostTickets(int[] days, int[] costs) { Set&amp;lt;Integer&amp;gt; set = new HashSet&amp;lt;&amp;gt;(); for (int i = 0; i &amp;lt; days.length; i++) { set.add(days[i]); } int[] dp = new int[366]; for (int i = 1; i &amp;lt; 366; i++) { if (!</description>
    </item>
    
    <item>
      <title>最长递增子序列 (LIS)</title>
      <link>https://kunzhao.org/docs/programmer-interview/algorithm/lis/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/programmer-interview/algorithm/lis/</guid>
      <description>最长递增子序列 (LIS) 方法一 // 未排序 // [10,9,2,5,3,7,101,18] =&amp;gt; [2,3,7,101], length = 4 public class LongestIncreasingSubsequence { public int lengthOfLIS(int[] array) { if (array.length == 0) { return 0; } // [10,9,2,5,3,7,101,18]  // 1(10)  // 1(9)  // 1(2)  // 2(5)  // 2(3)  // 3(7)  // 4(101)  // 4(18)  //  // 每个长度 i + 1 的最小值  // 这是一个有序序列  int[] lisLength = new int[array.</description>
    </item>
    
    <item>
      <title>链表是否有环</title>
      <link>https://kunzhao.org/docs/programmer-interview/algorithm/linkedlist-has-cycle/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/programmer-interview/algorithm/linkedlist-has-cycle/</guid>
      <description>链表是否有环  微软
 // https://leetcode.com/problems/linked-list-cycle/discuss/44669/Fully-Explained!-why-fast-and-slow-can-meet-in-the-cycle // https://www.cnblogs.com/wuyuegb2312/p/3183214.html // // 解释: 为什么快指针、慢指针能够相遇 // // 在任意时刻，p1 和 p2都在环上。由于 p1 每次向前 1 步，p2 每次向前两步， // 用相对运动的观点来看，把 p1 看作静止，那么 p2 每次相对 p1 向前 1 步， // 二者在顺时针方向上的距离每经过一个时刻就减少 1，直到变为 0，也即二者恰好相遇。 // 这样就证明了在离散情况下，对于有环链表，二者也是必然在某一时刻相遇在某个节点上的。 public class LinkedListCycle { public boolean hasCycle(ListNode head) { if (head == null) { return false; } ListNode slower = head; ListNode faster = head.next; while (slower != null &amp;amp;&amp;amp; faster != null) { if (slower == faster) { return true; } slower = slower.</description>
    </item>
    
    <item>
      <title>找出链表环的入口节点</title>
      <link>https://kunzhao.org/docs/programmer-interview/algorithm/find-linkedlist-cycle-start-node/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/programmer-interview/algorithm/find-linkedlist-cycle-start-node/</guid>
      <description>找出链表环的入口节点  微软
 // 1 -&amp;gt; 2 -&amp;gt; 3 -&amp;gt; 4 -&amp;gt; 1 -&amp;gt; 2 -&amp;gt; 3 // ↑_________| // // 假设链表长度为 L = 4 // 假设环长度为 C = 3 // 假设相遇时的点，距离环的入口 [逆时针顺序] 长度为 K // // 最终相遇: // - 快指针走了 L + m * C + K 步骤 // - 慢指针走了 L + n * C + K 步骤 // // L + m * C + K = 2 * (L + n * C + K) // // 化简得到 m * C = L + 2n * C + K // 化简得到 (m - 2n) * C = L + K // 化简得到 K = (m - 2n) * C - L = n&amp;#39; * C - L // // 即 K 是常数 // // 此时，相遇点 K 的位置是 n&amp;#39; * C - L，它再走 L 步就能到链表入口处 // 而此时慢指针从头开始走，也需要 L 步才能到链表入口处，所以这个是可以找到入口的 // // 还有就是如下这个代码，faster 从头开始移动 C 个，因为总长度是 L + C 个，所以全程还剩余 L 个 // 慢指针也需要走 L 步，所以还是会相遇 public class LinkedListCycle2 { public ListNode detectCycle(ListNode head) { // 是否有环  ListNode meetNode = hasCycle(head); if (meetNode == null) { return null; } // 求出环的个数  int cycleLen = lengthOfCycle(meetNode); // 先移动 cycleLen 个  ListNode faster = head; while (cycleLen &amp;gt; 0) { faster = faster.</description>
    </item>
    
    <item>
      <title>5 个线程读 1 个线程写</title>
      <link>https://kunzhao.org/docs/programmer-interview/algorithm/5-read-1-write/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/programmer-interview/algorithm/5-read-1-write/</guid>
      <description>5 个线程读 1 个线程写  微软
 /** * 微软三面面试题: * * - 一个线程写，如果 5 个读线程没有读完，那么等待 * - 5 个线程【同时】读，如果已经读过，那么等待 * * @author zk */ public class ReaderWriter { public static void main(String[] args) { final int READ_COUNT = 5; final ReaderWriter rw = new ReaderWriter(READ_COUNT); Thread writer = new Thread(new Runnable() { @Override public void run() { AtomicInteger atomicInteger = new AtomicInteger(); while (true) { rw.write(atomicInteger.getAndIncrement()); } } }); writer.</description>
    </item>
    
    <item>
      <title>Linux 性能分析</title>
      <link>https://kunzhao.org/docs/tutorial/unix-optimize/analyze/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/tutorial/unix-optimize/analyze/</guid>
      <description>Linux 性能分析 CPU 性能 内存性能分析 磁盘和文件 I/O 问题 工具 strace strace 可以分析系统调用情况：
$ strace -p 12280 strace: Process 12280 attached select(0, NULL, NULL, NULL, {tv_sec=0, tv_usec=567708}) = 0 (Timeout) stat(&amp;#34;/usr/local/lib/python3.7/importlib/_bootstrap.py&amp;#34;, {st_mode=S_IFREG|0644, st_size=39278, ...}) = 0 stat(&amp;#34;/usr/local/lib/python3.7/importlib/_bootstrap.py&amp;#34;, {st_mode=S_IFREG|0644, st_size=39278, ...}) = 0 filetop filetop 它是 bcc 软件包的一部分，基于 Linux 内核的 eBPF（extended Berkeley Packet Filters）机制，主要跟踪内核中文件的读写情况，并输出线程 ID（TID）、读写大小、读写类型以及文件名称。
# -C 选项表示输出新内容时不清空屏幕  $ ./filetop -C filetop 只给出了文件名称，却没有文件路径，还得继续找啊。我再介绍一个好用的工具，opensnoop 。它同属于 bcc 软件包，可以动态跟踪内核中的 open 系统调用。这样，我们就可以找出这些 txt 文件的路径。
$ opensnoop 12280 python 6 0 /tmp/9046db9e-fe25-11e8-b13f-0242ac110002/650.</description>
    </item>
    
    <item>
      <title>VUE 面试题</title>
      <link>https://kunzhao.org/docs/programmer-interview/front-end/vue/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/programmer-interview/front-end/vue/</guid>
      <description>VUE 面试题 整理 VUE 相关的常见面试题
介绍一下 VUE 介绍一下 VUEX VUE 2.X 和 3.0 的区别 （1）数据监听方式变化
VUE 2.X 使用 ES5 的 Object.defineProperty() 的 get() 和 set(newValue) 实现，VUE 3.0 基于 Proxy 监听实现，同时更为强大：
 可以检测属性的新增和删除 可以检测数组索引的变化和 length 的变化 支持 Map、Set、WeakMap 和 WeakSet   优点：速度加倍，内存占用减半。
 （2）体积更小
支持 Tree Shaking，内置组件、内置指令按需引入。
（3）速度更快
参考：vue3.0和vue2.x的区别、Vue 3.0 和 Vue 2.0的对比以及Vue 2.0精讲以及Vue全家桶精讲
VUE 的生命周期 VUE 数据双向绑定原理 VUE 采用发布者-订阅者模式的方式来实现双向绑定。
（1）视图更新数据：
input 标签监听 input 事件即可。
（2）数据更新视图：
Object.defineProperty() 监听数据变化，通过消息订阅器发布消息，订阅者收到消息执行相应的操纵 DOM 的函数，从而更新视图。</description>
    </item>
    
  </channel>
</rss>
