'use strict';(function(){const indexCfg={cache:true};indexCfg.doc={id:'id',field:['title','content'],store:['title','href'],};const index=FlexSearch.create('balance',indexCfg);window.bookSearchIndex=index;index.add({'id':0,'href':'/posts/war/','title':"War 文件格式",'content':"WAR file (Web Application Resource or Web application ARchive)。WAR 组织文件的标准方式：\nWEB-INF 存储在这个文件夹内的文件，默认情况下浏览器访问不到。\nweb.xml Tomcat 需要\nclasses 所有编译的 class 文件\nlib 包含项目依赖的所有的 JAR 库\ntags 包含 Tag 文件\n参考  Web Modules  "});index.add({'id':1,'href':'/posts/jsp/','title':"JSP",'content':"JSP 脚本 脚本程序可以包含任意量的Java语句、变量、方法或表达式，只要它们在脚本语言中是有效的。\n\u0026lt;% 代码片段 %\u0026gt;\rJSP 声明 \u0026lt;%! int i = 0; %\u0026gt; \u0026lt;%! int a, b, c; %\u0026gt; \u0026lt;%! Circle a = new Circle(2.0); %\u0026gt; JSP 表达式 \u0026lt;p\u0026gt; 今天的日期是: \u0026lt;%= (new java.util.Date()).toLocaleString()%\u0026gt; \u0026lt;/p\u0026gt; JSP 注释 \u0026lt;%-- 该部分注释在网页中不会被显示--%\u0026gt; JSP 指令 \u0026lt;%@ directive attribute=\u0026quot;value\u0026quot; %\u0026gt;\r三种 directive：\n   指令 描述     \u0026lt;%@ page \u0026hellip; %\u0026gt; 定义页面的依赖属性，比如脚本语言、error页面、缓存需求等等   \u0026lt;%@ include \u0026hellip; %\u0026gt; 包含其他文件   \u0026lt;%@ taglib \u0026hellip; %\u0026gt; 引入标签库的定义，可以是自定义标签    \u0026lt;%@ page import=\u0026quot;java.io.*,java.util.*\u0026quot; %\u0026gt;\rJSP 隐含对象 JSP支持九个自动定义的变量：\n   对象 描述     request HttpServletRequest类的实例   response HttpServletResponse类的实例   out PrintWriter类的实例，用于把结果输出至网页上   session HttpSession类的实例   application ServletContext类的实例，与应用上下文有关   config ServletConfig类的实例   pageContext PageContext类的实例，提供对JSP页面所有对象以及命名空间的访问   page 类似于Java类中的this关键字   Exception Exception类的对象，代表发生错误的JSP页面中对应的异常对象    IF \u0026hellip; ELSE \u0026hellip; \u0026lt;% if (day == 1 | day == 7) { %\u0026gt;\r\u0026lt;p\u0026gt;今天是周末\u0026lt;/p\u0026gt;\r\u0026lt;% } else { %\u0026gt;\r\u0026lt;p\u0026gt;今天不是周末\u0026lt;/p\u0026gt;\r\u0026lt;% } %\u0026gt;\r\u0026lt;/body\u0026gt; WHILE \u0026lt;%! int fontSize; %\u0026gt; \u0026lt;%for ( fontSize = 1; fontSize \u0026lt;= 3; fontSize++){ %\u0026gt;\r\u0026lt;font color=\u0026quot;green\u0026quot; size=\u0026quot;\u0026lt;%= fontSize %\u0026gt;\u0026quot;\u0026gt;\r菜鸟教程\r\u0026lt;/font\u0026gt;\u0026lt;br /\u0026gt;\r\u0026lt;%}%\u0026gt;\r中文编码 如果我们要在页面正常显示中文，我们需要在 JSP 文件头部添加以下代码：\n\u0026lt;%@ page language=\u0026quot;java\u0026quot; contentType=\u0026quot;text/html; charset=UTF-8\u0026quot; pageEncoding=\u0026quot;UTF-8\u0026quot;%\u0026gt;\r参考  JSP 语法  "});index.add({'id':2,'href':'/posts/ibmmq/','title':"IBM MQ",'content':"整体教程参考：Writing IBM MQ classes for Java applications\nQueue Manager // declare an object of type queue manager MQQueueManager queueManager = new MQQueueManager(); MQQueueManager queueManager = new MQQueueManager(\u0026#34;qMgrName\u0026#34;); ... // do something... ... // disconnect from the queue manager queueManager.disconnect(); MQEnvironment MQEnvironment.hostname = \u0026#34;host.domain.com\u0026#34;; MQEnvironment.channel = \u0026#34;java.client.channel\u0026#34;; // 默认 port 是 1414 MQEnvironment.port = nnnn; MQEnvironment.CCSID = 1381;//这个是编码格式的代号,UTF-8为1381 MQEnvironment.userID = \u0026#34;MUSR_MQADMIN\u0026#34;;//这个是登录MQ服务器用的用户名，需要在MQ服务器上设置 MQEnvironment.password = \u0026#34;123456\u0026#34;;//这个是登录MQ服务器用的密码 Queue // 打开队列 MQQueue queue = queueManager.accessQueue(\u0026#34;qName\u0026#34;,CMQC.MQOO_OUTPUT); queue.close(); "});index.add({'id':3,'href':'/posts/springboot/','title':"Spring Boot",'content':"Spring Boot 提供了两个接口 CommandLineRunner 和 ApplicationRunner，用以当 Spring Boot 应用程序完全启动之前运行指定的代码。\nCommandLineRunner @Component public class CommandLineAppStartupRunner implements CommandLineRunner { private static final Logger logger = LoggerFactory.getLogger(CommandLineAppStartupRunner.class); @Override public void run(String...args) throws Exception { logger.info(\u0026#34;Application started with command-line arguments: {} . \\n To kill this application, press Ctrl + C.\u0026#34;, Arrays.toString(args)); } } ApplicationRunner 将参数封装为一个对象，可以调用 getOptionNames()、getOptionValues() 和 getSourceArgs() 等便捷的方法。\n@Component public class AppStartupRunner implements ApplicationRunner { private static final Logger logger = LoggerFactory.getLogger(AppStartupRunner.class); @Override public void run(ApplicationArguments args) throws Exception { logger.info(\u0026#34;Your application started with option names : {}\u0026#34;, args.getOptionNames()); } } 排序 你可以注册任意多的 Runners，可以使用 @Order 注解来声明它们运行的顺序。\n参考  Spring Boot: ApplicationRunner and CommandLineRunner  "});index.add({'id':4,'href':'/posts/jax-ws/','title':"JAX-WS",'content':"JAX-WS JAX-WS 代表 Java API for XML Web Service。\nWebService  @WebService 用来将**某个类(一个 Interface)**声明为一个 Web Service EndPoint，这个类的实现类也得需要声明 @WebService 接口类的方法必须 public，并且不能使用 static 或 final 来修饰 接口类的方法必须声明 @WebMethod 实现类必须有一个默认的 public 构造器 实现类不要定义 finalize 方法  Apache CXF 定义 Endpoint，此处的 endpointInterface 非常重要，指向的是 Interface 类全称。\n@WebService(endpointInterface = \u0026#34;com.baeldung.cxf.introduction.Baeldung\u0026#34;) public class BaeldungImpl implements Baeldung {} 查看 WSDL 信息 URL 后面往往跟一个 ?wsdl 字符串。\n底层数据传输 GET WSDL 发送 POST 请求 接受 POST 响应 阅读更多 java 实现WebService 以及不同的调用方式、JAX-WS Web 服务开发调用和数据传输分析\nSOAP SOAP 是 Simple Object Access Protocol 的简称，是基于 XML 的简易协议，可使应用程序在 HTTP 之上进行信息交换。\n参考  Java WS Tutorial Introduction to Apache CXF  "});index.add({'id':5,'href':'/posts/oracle/','title':"Oracle",'content':"内置数据类型    分类 数据类型 介绍     字符 CHAR [(size [BYTE | CHAR])] 定长字符串，占据 n 字节    NCHAR[(size)] 定长字符串，占据 2n 字节    VARCHAR2(size) 可变长度的字符串    NVARCHAR2(size) 可变长度的 UNICODE 字符串   数值 NUMBER(p,s) p 代表精度(1 - 38)，s 代表 scale (-84 - 127)    FLOAT [(p)] 小数，精度不高    LONG 仅仅为了兼容   日期 DATE 大小固定占用 7 bytes    TIMESTAMP    字节 RAW(size) 定长    LONG RAW 变长，图像、声音、文档、数组，建议使用 LOB    LOB     ROWID 伪列 SELECT ROWID from your_table;  ROWID 不能被用作主键。\n ROWNUM 伪列 ROWNUM 是 Oracle 对查询结果自动添加的一个伪列，编号从 1 开始，每一次查询动态生成。\n非排序查询 Top N SELECT stu_no, stu_name, score FROM student WHERE ROWNUM \u0026lt;= 5; 排序查询 Top N SELECT stu_no, stu_name, score FROM ( SELECT stu_no, stu_name, score FROM student ORDER BY score DESC ) WHERE ROWNUM \u0026lt;= 5; 分页查询 SELECT rn, stu_no, stu_name, score FROM ( SELECT ROWNUM rn, stu_no, stu_name, score FROM ( SELECT stu_no, stu_name, score FROM student ORDER BY score DESC ) t1 ) t2 WHERE rn \u0026gt;= 4 AND rn \u0026lt;= 6; 参考自 ORACLE中的TOP-N查询（TOP-N分析）、分页查询\n参考  Data Types ROWID Pseudocolumn  "});index.add({'id':6,'href':'/posts/ant/','title':"Ant",'content':"Ant 官方教程 官方教程链接\nAnt Properties 提供一些键值对，使用 ${key} 来获取其 value。官网 列举了很多内置的 properties。\nAnt Classpath 定义 classpath：\n\u0026lt;project name=\u0026#34;HelloWorld\u0026#34; basedir=\u0026#34;.\u0026#34; default=\u0026#34;main\u0026#34;\u0026gt; \u0026lt;path id=\u0026#34;classpath\u0026#34;\u0026gt; \u0026lt;fileset dir=\u0026#34;${lib.dir}\u0026#34; includes=\u0026#34;**/*.jar\u0026#34;/\u0026gt; \u0026lt;/path\u0026gt; \u0026lt;target name=\u0026#34;compile\u0026#34;\u0026gt; \u0026lt;mkdir dir=\u0026#34;${classes.dir}\u0026#34;/\u0026gt; \u0026lt;javac srcdir=\u0026#34;${src.dir}\u0026#34; destdir=\u0026#34;${classes.dir}\u0026#34; classpathref=\u0026#34;classpath\u0026#34;/\u0026gt; \u0026lt;/target\u0026gt; \u0026lt;target name=\u0026#34;run\u0026#34; depends=\u0026#34;jar\u0026#34;\u0026gt; \u0026lt;java fork=\u0026#34;true\u0026#34; classname=\u0026#34;${main-class}\u0026#34;\u0026gt; \u0026lt;classpath\u0026gt; \u0026lt;path refid=\u0026#34;classpath\u0026#34;/\u0026gt; \u0026lt;path location=\u0026#34;${jar.dir}/${ant.project.name}.jar\u0026#34;/\u0026gt; \u0026lt;/classpath\u0026gt; \u0026lt;/java\u0026gt; \u0026lt;/target\u0026gt; \u0026lt;/project\u0026gt; Ant Targets Target 是多个 tasks 的容器，这个 Target 用来完成在整个 build 过程中的某个任务，使之达到某个状态。\n\u0026lt;target name=\u0026#34;A\u0026#34;/\u0026gt; \u0026lt;target name=\u0026#34;B\u0026#34; depends=\u0026#34;A\u0026#34;/\u0026gt; \u0026lt;target name=\u0026#34;C\u0026#34; depends=\u0026#34;B\u0026#34;/\u0026gt; \u0026lt;target name=\u0026#34;D\u0026#34; depends=\u0026#34;C,B,A\u0026#34;/\u0026gt; 调用链：\nCall-Graph: A → B → C → D\r \u0026lt;Target\u0026gt; 示例：\n\u0026lt;project\u0026gt; \u0026lt;target name=\u0026#34;clean\u0026#34;\u0026gt; \u0026lt;delete dir=\u0026#34;build\u0026#34;/\u0026gt; \u0026lt;/target\u0026gt; \u0026lt;target name=\u0026#34;compile\u0026#34;\u0026gt; \u0026lt;mkdir dir=\u0026#34;build/classes\u0026#34;/\u0026gt; \u0026lt;javac srcdir=\u0026#34;src\u0026#34; destdir=\u0026#34;build/classes\u0026#34;/\u0026gt; \u0026lt;/target\u0026gt; \u0026lt;target name=\u0026#34;jar\u0026#34;\u0026gt; \u0026lt;mkdir dir=\u0026#34;build/jar\u0026#34;/\u0026gt; \u0026lt;jar destfile=\u0026#34;build/jar/HelloWorld.jar\u0026#34; basedir=\u0026#34;build/classes\u0026#34;\u0026gt; \u0026lt;manifest\u0026gt; \u0026lt;attribute name=\u0026#34;Main-Class\u0026#34; value=\u0026#34;oata.HelloWorld\u0026#34;/\u0026gt; \u0026lt;/manifest\u0026gt; \u0026lt;/jar\u0026gt; \u0026lt;/target\u0026gt; \u0026lt;target name=\u0026#34;run\u0026#34;\u0026gt; \u0026lt;java jar=\u0026#34;build/jar/HelloWorld.jar\u0026#34; fork=\u0026#34;true\u0026#34;/\u0026gt; \u0026lt;/target\u0026gt; \u0026lt;/project\u0026gt; 参考 Targets\nAnt 所有支持的 Tasks 参考 Overview of Apache Ant Tasks\n"});index.add({'id':7,'href':'/posts/struts2/','title':"Struts 2",'content':"Action 访问 Servlet API 使用 ActionContext 来访问 Servlet API。\n    Servlet API JSP 对象     HttpServletRequest request   HttpSession session   ServletContext application     操作 Session：\nActionContext.getContext().getSession().put(\u0026#34;user\u0026#34;, userName); 在 JSP 页面中可以通过\n${sessionScope.user}\r来输出userName。\n数据校验 ActionSupport 是一个工具类，已经实现了 Action 接口，实现了 Validatable 接口，提供数据校验功能。\n@Override public void validate() { if (getUserName() == null || getUserName().trim().equals(\u0026#34;\u0026#34;)) { addFieldError(\u0026#34;username\u0026#34;, getText(\u0026#34;user.required\u0026#34;)); } } struts.xml 配置文件 分为多个配置文件：\n\u0026lt;struts\u0026gt; \u0026lt;include file=\u0026#34;struts-part1.xml\u0026#34; /\u0026gt; \u0026lt;/struts\u0026gt;  Struts 2 不支持为单独的 Action 设置命名空间，而是通过为包指定 namespace 属性来为包下面的所有 Action 指定共同的命名空间。\n\u0026lt;package name=\u0026#34;book\u0026#34; extends=\u0026#34;struts-default\u0026#34; namespace=\u0026#34;/book\u0026#34;\u0026gt; 当指定了命名空间后，该包下所有的 Action 处理的 URL 应该是命名空间 + Action 名。\nhttp://localhost:8888/namespace/book/getBooks.action\r 默认的命名空间是 \u0026quot;\u0026rdquo;\n Action Action 类是一个普通的 POJO 类，来封装 HTTP 请求参数，并为请求参数对应的属性封装对应的 setter 和 getter 方法。\n在 JSP 中输出：\n\u0026lt;s:property value=\u0026#34;tip\u0026#34;\u0026gt;  不推荐在 \u0026lt;action name=\u0026quot;xxx\u0026quot;\u0026gt; 的 name 属性中包含 . 或 -，可能引发未知异常。\n 通过指定 \u0026lt;action method=\u0026quot;login\u0026quot; /\u0026gt; 就可以让 Action 类调用指定方法，而非 execute 方法来处理用户请求。\nname 属性支持通配符：\n\u0026lt;action name=\u0026#34;*Pro\u0026#34; class=\u0026#34;com.zk.LoginAction\u0026#34; method=\u0026#34;{1}\u0026#34;\u0026gt; 另外一个示例：\n\u0026lt;action name=\u0026#34;*_*\u0026#34; method=\u0026#34;{2}\u0026#34; class=\u0026#34;actions.{1}\u0026#34;\u0026gt; 类型转换 类 Struts 2 内建类型转换器可以完成基本数据类型转换、Date 与字符串之间的转换。\n\u0026lt;form method=\u0026#34;post\u0026#34; action=\u0026#34;regist\u0026#34;\u0026gt; \u0026lt;input type=\u0026#34;text\u0026#34; name=\u0026#34;user.name\u0026#34; /\u0026gt;\u0026lt;br /\u0026gt; \u0026lt;input type=\u0026#34;password\u0026#34; name=\u0026#34;user.pass\u0026#34; /\u0026gt; \u0026lt;/form\u0026gt; 对应的 User 类：\nprivate User user; User 类必须提供无参构造器。\nMap private Map\u0026lt;String, User\u0026gt; users; 设置 map：\n读取 map：\nList 设置 List：\n读取 List：\n参考  Struts 2.x权威指南  "});index.add({'id':8,'href':'/posts/maintaining-cache-consistency/','title':"如何维持缓存的一致性？",'content':"Phil Karlton 曾经说过，“计算机科学中只有两件困难的事情：缓存失效和命名问题。” 这句话还有其他很好的举例。我个人最喜欢 Jeff Atwood 的一句话：“计算机科学中有两件困难的事情：缓存失效、命名和一个错误就关闭。”显然，缓存是困难的。就像分布式系统中的几乎所有东西一样，它甚至可能一眼就看不清。我将介绍分布式系统中几种常见的缓存方法，这些方法应该涵盖您将使用的绝大多数缓存系统。具体来说，我将关注如何维护缓存一致性。\n缓存 \u0026amp; 缓存一致性 在讨论不同的缓存方式之前，我们需要非常精确地说明缓存和缓存一致性的含义，特别是因为一致性是一个严重超载的术语。\n这里我们将缓存定义为：\n 一个单独的系统，它存储一个视图，这个视图是底层完整数据存储的一部分。\n 注意，这是一个非常笼统和轻松的定义。它包括通常被认为是缓存的内容，它存储与（通常是持久的）数据存储相同的值。它甚至包括一些人们通常不认为是缓存的东西。例如，数据库的非聚集二级索引。在我们的定义中，它也可以是一个缓存，保持缓存的一致性很重要。\n这里我们称缓存为一致的：\n 如果 k 存在于缓存中，则键 k 的值最终应与基础数据存储相同。\n 有了这个定义，如果缓存不存储任何内容，它总是一致的。但那根本没什么意思，因为它完全没用。\n为什么使用缓存 通常部署缓存是为了提高读写性能。这里的性能可以是延迟、吞吐量、资源利用率等，并且通常是相关的。保护数据库通常也是构建缓存的一个非常重要的动机。但你可以说这也是它正在解决的一个性能问题。\n不同类型的缓存 Look-aside / demand-fill 缓存 对于 look aside 缓存，客户端将在查询数据存储之前首先查询缓存。如果命中，它将返回缓存中的值。如果是未命中，它将从数据存储返回值。它没有说明缓存应该如何填充。它只是指定如何查询它。但通常情况下，是 demand-fill (按需填充)。Demand-fill 意味着在未命中的情况下，客户端不仅使用数据存储中的值，而且还将该值放入缓存中。通常，如果您看到一个look-aside 缓存，它也是一个 demand-fill 缓存。但这不一定。例如，你可以让缓存和数据存储订阅同一个日志（如Kafka）并独立实现。这是一个非常合理的设置。在本例中，缓存是一个 look-aside 缓存，而不是 demand-fill。而且缓存甚至可以拥有比持久数据存储更新鲜的数据。\n很简单，对吧？不过，简单的 Look aside/demand fill 缓存可能会有永久的不一致性！由于 look aside 缓存的简单性，这常常被人们忽略。根本上是因为当客户端将一些值放入缓存时，该值可能已经过时。具体来说\n- client gets a MISS (客户端未命中) - client reads DB get value `A` (客户端从数据库读取值：A) - someone updates the DB to value `B` and invalidates the cache entry (某人刷新了数据库，值变为了 B) - client puts value `A` into cache (客户端将 A 放入了缓存) 从那时起，客户端将继续从缓存中获取A，而不是B，后者是最新的值。取决于您的用例，这可能是正常的，也可能不是。它还取决于缓存条目是否有 TTL。但在使用 look aside/demand fill 缓存之前，您应该知道这一点。\n这个问题可以解决。Memcache使用 lease 来解决这个问题。因为从根本上讲，客户端在缓存上执行read-modify-write操作，而不使用原语来保证操作的安全性。在此设置中，read 从缓存中读取。modify 从数据库中读取。write 就是写回缓存。执行read-modify-write的一个简单解决方案是保留某种 “ticket” 来表示 read 时的缓存的状态，并比较 write 时的“ticket”。这就是 Memcache 解决问题的有效方法。Memcache 将其称为 lease，您可以将其作为简单的计数器，在每次缓存改变时都会碰到它。因此，在 read 时，它从 Memcache 主机获取 lease，在 write 时，客户端将 lease 一起传递。如果主机上的 lease 已更改，Memcache 将无法写入。现在回到前面的例子：\n- client gets a MISS with lease `L0` (客户端未命中，租约: L0) - client reads DB get value `A` (客户端从数据库读取值: A) - someone updates the DB to value `B` and invalidates the cache entry, which sets lease to `L1` (某人更新了数据库，最新值：B，租约：L1) - client puts value `A` into cache and fails due to lease mismatch (客户端放入 A 值到缓存失败，因为租约不匹配) 事情维持了一致：）\nWrite-through / read-through 缓存 Write-through 缓存方式意味着变异，客户端直接写入缓存。缓存负责同步写入到数据库中。它没有提到如何读取值的问题。客户端可以执行 look-aside 读或 read-through。\nRead-through 缓存意味着读取，客户端直接从缓存中读取。如果是未命中，cache 负责填充数据存储中的数据并回复客户端的查询。它没有提到写作。客户端可以 demand-fill 写入缓存或 write-through。\n现在你得到一张表格 (TAO: Facebook’s Distributed Data Store for the Social Graph)：\n同时有 write-through 和 look-aside 缓存并不常见。既然您已经构建了一个位于客户端和数据存储中间的服务，知道如何与数据存储对话，那么为什么不同时为读写操作这样做呢。也就是说，在有限的缓存大小下，根据查询模式的不同，write-through 和 look-aside 缓存可能是命中率的最佳选择。例如，如果大多数读操作在写操作之后立即执行，那么 write-through 和 look-aside 缓存可能提供最佳命中率。Read-through 和 demand-fill 的结合没有意义。\n现在让我们来看看 write-through 和 read-through 缓存的一致性。对于单个问题，只要正确获取 write 的 update lock 和 read 的 fill-lock，就可以序列化对同一个 key 的读写操作，并且不难看出缓存的一致性将得到维护。如果存在多个缓存副本，这将成为一个分布式系统问题，可能存在一些潜在的解决方案。保持缓存的多个副本一致的最直接的解决方案是拥有一个突变/事件日志，并基于该日志更新缓存。此日志用于单点序列化。它可以是 Kafka 甚至 MySQL binlog。只要突变是以易于重放这些事件的方式进行了全局的排序，就可以保持最终的缓存一致性。注意，这背后的推理与分布式系统中的同步相同。\nWrite-back / memory-only 缓存 还有一类缓存会遭受数据丢失的影响。例如，Write-back 缓存会在写入持久数据存储之前确认写入，如果在两者之间崩溃，则很明显会遭受数据丢失。这种类型的缓存有自己的使用场景，通常用于非常高的吞吐量和qps。但不一定太在意持久性和一致性。关闭持久性的 Redis 就属于这一类。\n译文来源  Different ways of caching and maintaining cache consistency  扫描下面二维码在手机端阅读：\n"});index.add({'id':9,'href':'/posts/help-the-world-by-healing-your-nginx-configuration/','title':"如何改进 NGINX 配置文件节省带宽？",'content':"2014年，Admiral William H. McRaven 在得克萨斯大学发表了著名的演讲，他说，如果你想改变世界，就从整理床铺开始。有时候小事情会有很大的影响——不管是在早上整理床铺，还是对网站的HTTP服务器配置做一些更改。\n这是不是有点言过其实了？2020年的头几个月，我们对世界上正常和合理的事物的所有定义都付之东流。由于COVID-19大流行，地球上几乎一半的人口被锁在家里，互联网已经成为他们唯一的交流、娱乐、购买食物、工作和教育方式。每周互联网的网络流量和服务器负载都比以往任何时候都要高。根据BroadbandNow在3月25日发表的一份报告，“在我们分析的200个城市中，有88个（44%）在过去一周内，相比之前的十周，经历了某种程度的网络退化”。\n为了保护网络链接，Netflix 和 YouTube 等主要媒体平台正在限制其传输质量，为人们工作、与家人交流或在学校上虚拟课程提供更多带宽。但这仍然不够，因为网络质量逐渐恶化，许多服务器变得过载。\n你可以通过优化你的网站来提供帮助 如果您拥有一个网站并可以管理其HTTP服务器配置，则可以提供帮助。一些小的更改可以减少用户生成的网络带宽和服务器上的负载。这是一个双赢的局面：如果你的网站目前负载很重，你可以减少它，使你能够为更多的用户服务，并可能降低你的成本。如果不是在高负载下，更快的加载可以改善用户的体验（有时会对你在谷歌搜索结果中的位置产生积极影响）。\n如果你有一个每月拥有数百万用户的应用程序，或者一个有烤菜谱的小博客，那就没什么关系了——每千字节的网络流量，你就消除了那些迫切需要在线检查医疗检测结果或创建包裹标签以向亲属发送重要信息的人的空闲容量。\n在这个博客中，我们提供了一些简单但强大的更改，您可以对您的 NGINX 配置。作为一个真实世界的例子，我们使用了 Rogalove 的朋友的电子商务网站，Rogalove 是一家位于波兰的生态化妆品制造商。该网站是一个相当标准的 woomerce 安装，运行 NGINX 1.15.9 作为其web服务器。为了便于我们的计算，我们假设网站每天有100个独立用户，30%的用户是经常访问的，每个用户在会话期间平均访问4个页面。\n这些技巧是您可以立即采取的简单步骤，以提高性能和减少网络带宽。如果要处理大量流量，可能需要实现更复杂的更改以产生重大影响，例如调整操作系统和 NGINX、提供正确的硬件容量，以及（最重要的）启用和调整缓存。查看以下博客文章了解详细信息：\n 调整 NGINX 的性能 性能调整-提示和技巧 10倍应用程序性能的10个技巧 在裸机服务器上部署 NGINX Plus 的大小调整指南 NGINX 和 NGINX Plus 缓存指南 NGINX 微缓存的优点  为HTML、CSS和JavaScript文件启用Gzip压缩 如您所知，用于在现代网站上构建页面的HTML、CSS和JavaScript文件可能非常庞大。在大多数情况下，web服务器可以动态压缩这些和其他文本文件，以节省网络带宽。\n查看web服务器是否正在压缩文件的一种方法是使用浏览器的开发工具。对于许多浏览器，可以使用F12键访问工具，相关信息位于“网络”选项卡上。下面是一个例子：\n正如您在左下角看到的，没有压缩：文本文件的大小为1.15 MB，并且传输了这么多数据。\n默认情况下，NGINX 中禁用压缩，但根据安装或Linux发行版的不同，可以在默认的 nginx.conf 文件中启用某些设置。在这里，我们在 NGINX 配置文件中启用 gzip 压缩：\ngzip on; gzip_types application/xml application/json text/css text/javascript application/javascript; gzip_vary on; gzip_comp_level 6; gzip_min_length 500; 正如您在下面的屏幕截图中看到的，通过压缩，数据传输仅下降到260kb，降幅约为80%！对于页面上的每个新用户，您可以节省大约917KB的数据传输。对于我们的 Woocomerce 安装，每天62MB，每月1860MB。\n设置缓存头 当浏览器检索网页的文件时，它会将副本保存在本地磁盘缓存中，这样当您再次访问该网页时，它就不必从服务器重新提取该文件。每个浏览器都使用自己的逻辑来决定何时使用文件的本地副本，以及在服务器上发生更改时何时再次获取该文件。但是作为网站所有者，您可以在发送的HTTP响应中设置缓存控制和过期头，以使浏览器的缓存行为更加高效。从长远来看，不必要的HTTP请求要少得多。\n一个好的开始，您可以为字体和图像设置一个很长的缓存过期时间，这些字体和图像可能不会经常更改（即使更改，它们通常也会得到一个新的文件名）。在下面的示例中，我们指示客户端浏览器将字体和图像保存在本地缓存中一个月：\nlocation ~* \\.(?:jpg|jpeg|gif|png|ico|woff2)$ { expires 1M; add_header Cache-Control \u0026#34;public\u0026#34;; } 启用 HTTP/2 协议支持 HTTP/2 是下一代网页服务协议，旨在提高网络和主机服务器的利用率。根据Google文档，它可以更快地加载页面：\n 由此产生的协议对网络更友好，因为与HTTP/1.x相比，使用的TCP连接更少。这意味着与其他流和存活时间更久的连接的竞争更少，进而导致可用网络容量的更好利用。\n NGINX 1.9.5 及更高版本（以及 NGINX Plus R7 及更高版本）支持 HTTP/2 协议，您只需启用它😀. 为此，请在 NGINX 配置文件的 listen 指令中包含 http2 参数：\nlisten 443 ssl http2; 注意，在大多数情况下，还需要启用 TLS 以使用HTTP/2。\n您可以使用 HTTP2.Pro 服务验证您的（或任何）站点是否支持HTTP/2：\n优化日志记录 给自己准备一杯你最喜欢的饮料，舒舒服服地坐着，想想：你最后一次查看访问日志文件是什么时候？上周，上个月，从来没有？即使您将它用于站点的日常监视，您可能只关注错误（400 和 500 状态代码，等等），而不是成功的请求。\n通过减少或消除不必要的日志记录，可以节省服务器上的磁盘存储、CPU和I/O操作。这不仅使您的服务器更快—如果您部署在云环境中，释放的I/O吞吐量和CPU周期可以更好地服务驻留在同一物理机上的另一个虚拟机或应用程序。\n有几种不同的方法可以减少和优化日志记录。在这里我们强调三点。\n方法1:禁用页面资源请求的日志记录\n如果不需要记录检索普通页面资源（如图像、JavaScript文件和CSS文件）的请求，这是一个快速而简单的解决方案。您只需创建一个与这些文件类型匹配的新位置块，并禁用其中的日志记录。（您也可以将此访问日志指令添加到上面设置缓存控制头的位置块中。）\nlocation ~* \\.(?:jpg|jpeg|gif|png|ico|woff2|js|css)$ { access_log off; } 方法2:禁用成功请求的日志记录\n这是一个更强大的方法，因为它放弃了带有2xx或3xx响应代码的查询，只记录错误。它比方法1稍微复杂一些，因为它取决于NGINX日志的配置方式。在我们的例子中，我们使用包含在Ubuntu服务器发行版中的标准nginx.conf文件，因此不管虚拟主机是什么，所有请求都会记录到/var/log/nginx/access.log.\n使用官方NGINX文档中的一个示例，我们打开条件日志记录。创建一个变量$loggable，对于带有2xx和3xx响应代码的请求，将其设置为0，否则设置为1。然后在access_log指令中将此变量作为条件引用。\n下面是位于 /etc/nginx/nginx.conf 文件中的 http 上下文的的原始指令：\naccess_log /var/log/nginx/access.log; 添加一个映射块并从 access_log 指令中引用它：\nmap $status $loggable { ~^[23] 0; default 1; } access_log /var/log/nginx/access.log combined if=$loggable; 注意，尽管 combined 是默认的日志格式，但是在包含 if 参数时需要显式地指定它。\n方法3：使用缓冲以减少I/O操作\n即使要记录所有请求，也可以通过打开访问日志缓冲来减少I/O操作。使用此指令，NGINX 将暂时不将日志数据写入磁盘，直到512KB缓冲区被填满或自上次刷新以来已过1分钟（以先发生者为准）。\naccess_log /var/log/nginx/access.log combined buffer=512k flush=1m; 限制特定URL的带宽 如果您的服务器提供了较大的文件（或较小但非常流行的文件，如表单或报表），则设置客户端下载这些文件的最大速度可能会很有用。如果您的站点已经处于高网络负载，限制下载速度会留下更多带宽，以保持应用程序的关键部分响应。这是硬件制造商使用的一个非常流行的解决方案-虽然有成千上万的其他人同时下载，您仍然可以获得您的下载，只是您可能需要等待更长的时间才能为打印机下载3GB驱动程序。😉\n使用 limit_rate 指令来限制特定URL的带宽。在这里，我们将每个文件在/download 下的传输速率限制为每秒50kb。\nlocation /download/ { limit_rate 50k; } 您可能还希望只对较大的文件进行速率限制，可以使用 limit-rate-after 指令执行此操作。在本例中，每个文件（从任何目录）的前500kb传输没有速度限制，之后的所有文件都限制在50kb/s。这样可以加快网站关键部分的传输速度，同时减慢其他部分的传输速度。\nlocation / { limit_rate_after 500k; limit_rate 50k; } 请注意，速率限制适用于浏览器和 NGINX 之间的各个HTTP连接，因此不要阻止用户使用下载管理器绕过速率限制。\n最后，还可以限制到服务器的并发连接数或请求速率。有关详细信息，请参阅我们的文档。\n总结 我们希望这五个技巧有助于优化您的网站的性能。速度和带宽增益因网站而异。即使优化 NGINX 配置似乎并没有显著地释放带宽或提高速度，数千个网站单独调整 NGINX 配置的总体影响也会增加。我们的全球网络使用效率更高，这意味着在需要时提供最关键的服务。\n如果您在您的网站上对 NGINX 有任何问题，我们将提供帮助！在COVID-19大流行期间，NGINX 员工和社区正在监视 Stackoverflow 网站上的 Nginx 板块，并尽快响应问题和请求。\n如果您在流行病前线的组织工作，并且有高级需求，那么您可以获得最多5个免费的NGINX Plus许可证以及更高级别的F5 DNS负载平衡器云服务。有关详细信息，请参阅受COVID-19影响的网站的免费资源。\n还可以查看上述链接，了解其他简单的方法，使用NGINX和F5的免费资源来提高网站性能。\n译文来源  Help the World by Healing Your NGINX Configuration "});index.add({'id':10,'href':'/docs/it-zone/2020-06/','title':"2020-06 文章收录",'content':"2020-06 文章收录 "});index.add({'id':11,'href':'/docs/programmer-interview/algorithm/best-time-to-buy-and-sell-stock/','title':"Best Time to Buy and Sell Stock",'content':"Best Time to Buy and Sell Stock 题目 LeetCode 地址：Best Time to Buy and Sell Stock\n有一个数组，第 i 个元素的值代表第 i 天的股票价格，如果你最多只能进行一次交易（某天买入一支股票，然后过几天卖掉），请问你能收获的最大利润是多少？\n分析 这道题有两个简单做法：状态机和动态规划。\n使用状态机的做法的好处是，这种思路可以延续到其它几个买卖股票的问题上。关键是要想清楚，某一天有几种状态，在这道题是三种：\n 状态 s0: 不买也不卖，无操作。s0 的值只能有一个来源，就是和昨天保持一致，不买也不卖 状态 s1: 买入了股票。s1 的值有两个来源：1. 与昨天一致，即已经买入了，且只能买一次，所以不能再买了，s1 = s1；2. 买入今天的股票，花了 price[i] 钱，s1 = s0 - price[i] 状态 s2: 卖出了股票。s2 的值有两个来源：1. 之前已经卖出了，所以维持卖出状态，不能再次卖了，s2 = s1；2. 卖出之前买入的股票，挣 price[i] 钱，s2 = s1 + price[i]  所以，我们可以得到如下状态转移关系：\n s0 = s0 s1 = s1 s1 = s0 - price[i] s2 = s2 s2 = s1 + price[i]  在这整个过程中，我们都要保证每一天的 s0、s1、s2 都是 max 状态，s2 是最终卖完后的收益，所以返回这个结果就行。\n 动态规划的想法：\n我们不要考虑每一天的价格，只需要考虑今天与昨天的价格之差：diff[i]。最终的收益是从这个 diff 数组中取出连续的一段，这一段累加起来的和最大。\n对于股票这道题而言，如果累加起来的最大值为负数，那么我们还不如全程不买卖股票，这样收益至少不是负值，也就是0。所以当 currMax 的值变为负数的时候，我们就废弃掉之前的结果，从此刻开始进行新的累加。\n答案 // MaximumSubarray public class BestTimetoBuyandSellStock { // 状态机 State Machine 做法  public int maxProfit(int[] prices) { if (prices == null || prices.length \u0026lt;= 1) { return 0; } //  // Buy Sell  // s0 ----\u0026gt; s1 ------\u0026gt; s2 (end)  // ↑__| ↑___|  //  int s0 = 0; // 初始状态  int s1 = -prices[0]; // 买入这支股票，花费 prices[i] 钱  int s2 = 0; // 一开始也是 0  for (int i = 1; i \u0026lt; prices.length; i++) { // ====================  // s0: 自始至终从未有过买卖  // ====================  s0 = s0; /** 维持自身 */ // ====================  // s1: 买入某支股票。我们只能买一次，然后一直维持。而每一次买都让我们花费了 prices[i] 元  // ====================  s1 = Math.max(s1 /** 维持自身 */, s0 - prices[i] /** 花费 prices[i] 买入这支股票 */); // ====================  // s2: 卖出某支股票。我们只能卖一次，然后一直维持。而每一次卖都让我们盈利 s1 + prices[i] 元  // ====================  s2 = Math.max(s2 /** 维持自身 */, s1 + prices[i] /** 卖掉这支股票，赚取 prices[i] */); } return s2; } public int maxProfit0(int[] prices) { if (prices == null || prices.length == 0) { return 0; } int max = 0; int currMax = 0; // 股票每天都在降低的话，那么最大利润为 0  // 也就是说这个地方每一次都可以不买  //  // 但是 MaximumSubarray 这道题，每次都必须选择一个，所以这个 MaximumSubarray 可以是负数  for (int i = 1; i \u0026lt; prices.length; i++) { currMax = Math.max(currMax + (prices[i] - prices[i - 1]) /** 当前累加的总收益 */, 0); max = Math.max(currMax, max); /** 在这个中间过程中，记录最大的值 */ } return max; } } 扫描下面二维码，在手机上阅读这篇文章：\n"});index.add({'id':12,'href':'/docs/tutorial/zipkin/brave/','title':"Brave 收集数据",'content':"Brave 收集数据 在 Java 生态世界中，Zipkin 团队官方提供了 Brave 用来收集数据到 Zipkin Server 中。其它的用来收集数据的框架还有 cassandra-zipkin-tracing、Dropwizard Zipkin、htrace、Spring Cloud Sleuth 以及 Wingtips 等。\n示例代码 配置 Tracer 配置 Tracer 以向 Zipkin Server 上传数据。\n// Configure a reporter, which controls how often spans are sent // (this dependency is io.zipkin.reporter2:zipkin-sender-okhttp3) sender = OkHttpSender.create(\u0026#34;http://127.0.0.1:9411/api/v2/spans\u0026#34;); // (this dependency is io.zipkin.reporter2:zipkin-reporter-brave) zipkinSpanHandler = AsyncZipkinSpanHandler.create(sender); // Create a tracing component with the service name you want to see in Zipkin. tracing = Tracing.newBuilder() .localServiceName(\u0026#34;my-service\u0026#34;) .addSpanHandler(zipkinSpanHandler) .build(); // Tracing exposes objects you might need, most importantly the tracer tracer = tracing.tracer(); // Failing to close resources can result in dropped spans! When tracing is no // longer needed, close the components you made in reverse order. This might be // a shutdown hook for some users. tracing.close(); zipkinSpanHandler.close(); sender.close(); 进程内跟踪 // Start a new trace or a span within an existing trace representing an operation ScopedSpan span = tracer.startScopedSpan(\u0026#34;encode\u0026#34;); try { // The span is in \u0026#34;scope\u0026#34; meaning downstream code such as loggers can see trace IDs  return encoder.encode(); } catch (RuntimeException | Error e) { span.error(e); // Unless you handle exceptions, you might not know the operation failed!  throw e; } finally { span.finish(); // always finish the span } 也可以通过如下更为高级、更为灵活的方式跟踪数据：\n// Start a new trace or a span within an existing trace representing an operation Span span = tracer.nextSpan().name(\u0026#34;encode\u0026#34;).start(); // Put the span in \u0026#34;scope\u0026#34; so that downstream code such as loggers can see trace IDs try (SpanInScope ws = tracer.withSpanInScope(span)) { return encoder.encode(); } catch (RuntimeException | Error e) { span.error(e); // Unless you handle exceptions, you might not know the operation failed!  throw e; } finally { span.finish(); // note the scope is independent of the span. Always finish a span. } 主要类讲解 Span Span 是存储跟踪数据的容器，其主要属性和行为如下：\n// 主要属性 public abstract TraceContext context(); @Override public abstract Span name(String name); @Override public abstract Span annotate(String value); @Override public abstract Span tag(String key, String value); // 主要行为 public abstract Span start(); public abstract void finish(); public abstract void abandon(); public abstract void flush(); 跟踪器 Tracer Tracer 可以创建各种各样的 Span。其主要字段：\npublic class Tracer { final Clock clock; final Propagation.Factory propagationFactory; final SpanHandler spanHandler; // only for toString  final PendingSpans pendingSpans; final Sampler sampler; final CurrentTraceContext currentTraceContext; final boolean traceId128Bit, supportsJoin, alwaysSampleLocal; final AtomicBoolean noop; } 下面以伪代码说明执行 tracer.startScopedSpan(\u0026quot;encode\u0026quot;) 做了哪些事情：\n// 获取 parent 上下文 TraceContext parent = currentTraceContext.get(); // 装饰 parent 上下文或创建新的 root 上下文 TraceContext context = parent != null ? decorateContext(parent, parent.spanId()) : newRootContext(0); // 创建 RealScopedSpan Scope scope = currentTraceContext.newScope(context); PendingSpan pendingSpan = pendingSpans.getOrCreate(parent, context, true); Clock clock = pendingSpan.clock(); MutableSpan state = pendingSpan.state(); state.name(name); return new RealScopedSpan(context, scope, state, clock, pendingSpans); 上述建立 Context 的过程，spanId 和 traceId 等 id 的生成方式如下：\n// 创建 64-bit spanId if (spanId == 0L) spanId = nextId(); // 创建 TraceId if (traceId == 0L) { // make a new trace ID  traceIdHigh = traceId128Bit ? Platform.get().nextTraceIdHigh() : 0L; traceId = spanId; } // localRootId if (localRootId == 0L) { localRootId = spanId; } /** Generates a new 64-bit ID, taking care to dodge zero which can be confused with absent */ long nextId() { long nextId = Platform.get().randomLong(); while (nextId == 0L) { nextId = Platform.get().randomLong(); } return nextId; } 上下文 CurrentTraceContext 采样器 Sampler 采集上来的跟踪数据，要每一条都要发送到服务器吗？量会不会特别大？会不会有许多冗余重复的数据？采样器 Sampler 让你自主选择哪些数据需要发送，哪些不需要发送。\npublic abstract class Sampler { // 这条 traceId 对应的数据，是否需要统计  public abstract boolean isSampled(long traceId); } Brave 自带的几个采样器：\n跟踪监听器 SpanHandler public abstract class SpanHandler { public boolean begin(TraceContext context, MutableSpan span, @Nullable TraceContext parent) { return true; } public boolean end(TraceContext context, MutableSpan span, Cause cause) { return true; } } 计时器 Clock public interface Clock { long currentTimeMicroseconds(); } 其只提供了一个实现 TickClock：\nfinal class TickClock implements Clock { final long baseEpochMicros; final long baseTickNanos; TickClock(long baseEpochMicros, long baseTickNanos) { this.baseEpochMicros = baseEpochMicros; this.baseTickNanos = baseTickNanos; } @Override public long currentTimeMicroseconds() { return ((System.nanoTime() - baseTickNanos) / 1000) + baseEpochMicros; } } Propagation "});index.add({'id':13,'href':'/docs/cloud-plus-bbs/bilibili-high-availability/','title':"B站高可用架构实践",'content':"B站高可用架构实践 流量洪峰下要做好高服务质量的架构是一件具备挑战的事情，从Google SRE的系统方法论以及实际业务的应对过程中出发，分享一些体系化的可用性设计。对我们了解系统的全貌上下游的联防有更进一步的了解。\n负载均衡 BFE 就是指边缘节点，BFE 选择下游 IDC 的逻辑权衡：\n 离 BFE 节点比较近的 基于带宽的调度策略 某个 IDC 的流量已经过载，选择另外一个 IDC  当流量走到某个 IDC 时，这个流量应该如何进行负载均衡？\n问题：RPC 定时发送的 ping-pong，也即 healthcheck，占用资源也非常多。服务 A 需要与账号服务维持长连接发送 ping-pong，服务 B 也需要维持长连接发送 ping-pong。这个服务越底层，一般依赖和引用这个服务的资源就越多，一旦有任何抖动，那么产生的这个故障面是很大的。那么应该如何解决？\n解决：以前是一个 client 跟所有的 backend 建立连接，做负载均衡。现在引入一个新的算法，子集选择算法，一个 client 跟一小部分的 backend 建立连接。图片中示例的算法，是从《Site Reliability Engineering》这本书里看的。\n如何规避单集群抖动带来的问题？多集群。\n如上述图片所示，如果采用的是 JSQ 负载均衡算法，那么对于 LBA 它一定是选择 Server Y 这个节点。但如果站在全局的视角来看，就肯定不会选择 Server Y 了，因此这个算法缺乏一个全局的视角。\n如果微服务采用的是 Java 语言开发，当它处于 GC 或者 FullGC 的时候，这个时候发一个请求过去，那么它的 latency 肯定会变得非常高，可能会产生过载。\n新启动的节点，JVM 会做 JIT，每次新启动都会抖动一波，那么就需要考虑如何对这个节点做预热？\n如上图所示，采用 \u0026ldquo;the choice-of-2\u0026rdquo; 算法后，各个机器的 CPU 负载趋向于收敛，即各个机器的 CPU 负载都差不多。Client 如何拿到后台的 Backend 的各项负载？是采用 Middleware 从 Rpc 的 Response 里面获取的，有很多 RPC 也支持获取元数据信息等。\n还有就是 JVM 在启动的时候做 JIT，以前的预热做法：手动触发预热代码，然后再引入流量，再进行服务发现注册等，不是非常通用。通过改进负载均衡算法，引入惩罚值的方式，慢慢放入流量进行预热。\n限流 用 QPS 限制的陷阱：\n 不同的参数，请求的数据量是不同的，对一个进程的一个吞吐是有影响的。 业务是经常迭代的，配一个静态的阈值，这个非常困难。能否按照每一个服务用多少个 CPU 来做限流？  每一个 API 都是有重要性的：非常重要、次重要，这样配置限流、做过载保护的时候，可以使用不同的阈值。\n每个服务都要配一个限流，是非常烦人的，需要压测，是不是可以自适应去限流？\n每个 Client 如何知道自己这一次需要申请多少 Quota ？基于历史数据窗口的 QPS。\n节点与节点之间是有差异的，分配算法不够好，会导致某些节点产生饥饿。那么可以采用最大最小公平算法，尽可能地比较公平地去分配资源，来解决这个问题。\n当量再大一点的时候，如果 Backend 一直忙着拒绝请求，比如发送 503，那么它还是会挂掉。这种情况就要考虑从 Client 去截流。此处，又提到了 Google 《Site Reliability Engineering》这本书里面的一个算法，即 Client 是按照一定概率去截流。那么这个概率怎么计算？一个是总请求量：requests，一个是成功的请求量：accepts。如果服务报错率比较高，意味着 accepts 不怎么增长，requests 一直增长，最终这个公式求极限，它会等于 1，所以它的丢弃概率是非常高的。基于这么一个简单的公式，不需要依赖什么 ZooKeeper，什么协调器之类的，就可以得到一个概率丢弃一些请求。它尽可能的在服务不挂掉的情况下，放更多的流量进去，而不是像 Netflix 一样全部拒掉。\n连锁故障通常都是某一个节点过载了挂掉，流量又会去剩下的 n - 1 个节点，又扛不住，又挂掉，所以最终一个一个挨着雪崩。所以过载保护的目的是为了自保。\nB 站参考了阿里的 Sentinel 框架、Netflix 的一些文章等，最终采用的是类似于 TCP BBR 探测的思路和算法。简单说：当 CPU 达到 80% 的时候，这个时候我们认为流量过载，如果此时吞吐量比如 100，用它作为阈值，瞬时值的请求比如是 110，那就可以丢掉 10 个流量。这样就可以实现一个限流算法。\nCPU 抖来抖去，使用 CPU 滑动均值（绿色线）可以跳动的没有这么厉害。这个 CPU 针对不同接口的优先级，例如低优先级 80% 触发，高优先级 90% 触发，可以定为一个阈值。\n那么吞吐如何计算？利特尔法则。当前的 QPS * 延迟 = 吞吐，可以用过去的一个窗口作为指标。一旦丢弃流量，CPU 立马下来，算法抖动非常厉害。图二右侧黄色线表示抖动非常高，绿色线表示放行的流量也是抖动非常高，所以又加了冷却时间，比如持续几秒钟，再重新判断。\n重试  BFE: 动态 CDN SLB: LVS + Nginx 实现，四七层负载均衡 BFF: 业务逻辑组装、编排  问题：每一层都重试，这一层 3 次，那一层 3 次，会指数级的放大。解决：只在失败这一层重试，如果重试之后失败，请返回一个全局约定好的错误码，比如说：过载，无需重试，发现这个错误码，通通放行，避免级联重试。\n重试都应该无脑的重试三次吗？API 级别的重试需要考虑集群的过载情况。是不是可以约定一个重试比例呢？比如只允许 10% 的流量进行重试，Client 端做统计，当发现有 10% 都是重试，那么剩下的都拒绝掉。这样最多产生 1.1 倍的放大，重试 3 次，极端情况下，会产生 3 倍放大。还有在重试的时候，尽量引入随机、指数递增的一个重试周期，大家不要都重试 1 秒钟，有可能会堆砌一个重试的波峰。\n重试的统计图和记录 QPS 的图分开。问题诊断的时候，可以知道它是来自流量重试导致的问题放大。\n某个服务不可用的时候，用户总是会猛点，那么这个时候，需要去限制它的频次，一个短周期内不允许发重复请求。这种策略，有可能会根据不同的过载情况经常调这种策略，那么可以挂载到每一个 API 里面。\n超时 大部分的故障都是因为超时控制不合理导致的。\n 某个高延迟服务可能会导致 Client 堆积，Client 线程会阻塞，上游流量不断进来，下游的消费速度跟不上上游的流入速度，进程会堆积越来越多请求，可能会 OOM。 超时的策略本质是就是为了丢弃或者消耗掉请求。 下游 2 秒返回，上游配置了 1 秒，上游超时已经返回给用户，下游还在执行，浪费资源。  某个服务需要在 1 秒返回，内部可能需要访问 Redis，需要访问 RPC，需要访问数据库，时间加起来就超过 1 秒，那么访问完每一层，应该计算供下一层使用的超时时间还剩多少可用。在 go 语言里，可能会使用 Context，每一个网络请求开始的阶段，都要根据配置文件配置的超时时间，和当前剩余多少，取一个最小值，最终整个超时时间不会超过 1 秒。\n通过 RPC 的元数据传递，类似 HTTP 的 request header，带给其它服务。例如在图中，就是把 700ms 这个配额传递给 Service B。\n下游服务作为服务提供者，在他的 RPC.IDL 文件中把自己的超时要配上，那么用 IDL 文件的时候，就知道是 200 ms，不用去问。\n应对连锁故障 优雅降级：一开始千人千面，后来只返回热门的\n参考 QA  Q: 请问负载均衡依据的 metric 是什么？ A: 服务端主要用 CPU，客户端用的是健康度，指连接的成功率，延迟也很重要，每个 Client 往不同的 Backend 发了多少个请求，四个指标归一，写一个线性方程，进行打分。    Q: BFE 到 SLB 走公网还是专线？ A: 既有公网，又有专线。    Q: Client 几千量级，每 10 秒 ping-pong 一下，会不会造成蛮高的 CPU？ A: 如果 Backend 很多的话，那么这个的确会造成。    Q: 多集群切换是否有阻塞的点？ A: 一个 Client 连接到各个集群，subset 算法，每个集群都有 Cache    Q: 负载均衡的探针是怎么做的？ A: 惩罚值，比如 5 秒，慢慢放流量    Q: Quota-Server 限流有开源实现吗？ A: 目前看到的都是针对单节点的。    Q: 客户端统计是否有点太多？ A: 可以做到 Sidecar、Service Mesh 里面    Q: 超时传递是不是太严格？ A: 有些情况下即便超时也要运行，可以通过 RPC Context 管控    Q: 每个 RPC 都获取 CPU 会不会很昂贵？ A: 后台开启线程定时计算 CPU 平滑均值    Q: 线上压测和测试环境压测 CPU 不一致 A: RPC 路由加影子库    Q: CC 攻击 A: 边缘节点或者核心机房都有防止 CC 攻击的一些手段，只要不是分布式搞你，都能找到流量特征进行管控  "});index.add({'id':14,'href':'/docs/tutorial/devops/intro/','title':"DevOps 简介",'content':"DevOps 简介 DevOps (Development 与 Operations) 是一种文化，这种文化旨在建立一个使得软件构建、测试、发布等得以快速、稳定，实施交付的环境。\n那么如何做到快速？如何做到稳定？答案是自动化工具。开发到测试到上线之间的所有需要手动处理的环节，都是可以尝试优化的点。\nDevOps 能力成熟度模型 全球首个 DevOps 标准，即《研发运营一体化（DevOps）能力成熟度模型》，由中国信息通信研究院牵头，云计算开源产业联盟、高效运维社区、 DevOps 时代社区联合 Google、BATJ、清华大学、南京大学、通信及金融等行业顶尖企事业单位专家共同制定。\n目前很多公司都在参考这套模型进行实践。\nDevOps 工具集锦 信通院整理的的 DevOps 工具集锦（看不清的话，图片上右击，在新标签页中打开图像）：\n持续集成  每次提交代码，就会触发完整的流水线。这需要打通版本控制系统和持续集成系统，例如 GitLab 和 Jenkins 集成。 每次流水线，触发自动化测试。 出了问题，第一时间修复。  推荐书籍  《持续交付 2.0》 《DevOps 实践指南》  "});index.add({'id':15,'href':'/docs/tutorial/network/dhcp/','title':"DHCP",'content':"DHCP DHCP 是 Dynamic Host Configuration Protocol (动态主机配置协议) 的缩写。\n作用 手机、电脑或其它网络设备想要与其它计算机进行通讯，就需要配置 IP 地址，DHCP 协议就是为网络设备动态分配 IP 地址的一种协议。DHCP 底层基于 UDP 传输层协议，端口 67 是 DHCP Server 端使用的端口，端口 68 是 DHCP Client 端使用的接口。\n工作方式 DHCP 协议分配 IP 地址可以分为 4 个步骤：\nDiscovery 网络中新加入的某个设备（DHCP 客户端），会使用 IP 地址 0.0.0.0 向该网络发送一个广播包，这个包的目的 IP 地址是 255.255.255.255。这个 UDP 包封装的内容如下所示：\n   头 内容     MAC 头 源 MAC：设备自身的 MAC 地址，目的 MAC 地址：FF:FF:FF:FF:FF:FF   IP 头 源 IP: 0.0.0.0，目的 IP: 255.255.255.255   UDP 头 源端口：68，目的端口：67   BOOTP 头 DHCP Discover    Offer DHCP Server 接受到这个包以后，\n"});index.add({'id':16,'href':'/docs/it-zone/2020-06/fastjson-high-risk-vulnerability/','title':"fastjson 又现高危漏洞！",'content':"fastjson 又现高危漏洞！ 日期：2020-06-01\n 5 月 28 日，据 360 网络安全响应中心发布《Fastjson远程代码执行漏洞通告》显示，由阿里巴巴开源的 fastjson 库 又现高危漏洞，该漏洞可导致不法分子远程执行服务器命令等严重后果。\nfastjson 是阿里巴巴的开源JSON解析库，它可以解析JSON格式的字符串，支持将Java Bean序列化为JSON字符串，也可以从JSON字符串反序列化到 JavaBean。\nfastjson 存在远程代码执行漏洞，autotype 开关的限制可以被绕过，链式的反序列化攻击者精心构造反序列化利用链，最终达成远程命令执行的后果。此漏洞本身无法绕过 fastjson 的黑名单限制，需要配合不在黑名单中的反序列化利用链才能完成完整的漏洞利用。\n该漏洞影响的版本：\u0026lt;= 1.2.68\n该漏洞修复建议：\n 升级到 fastjson 1.2.69/1.2.70 版本，下载地址为 Releases · alibaba/fastjson 或者通过配置以下参数开启 SafeMode 来防护攻击：ParserConfig.getGlobalInstance().setSafeMode(true);（safeMode 会完全禁用 autotype，无视白名单，请注意评估对业务影响）  "});index.add({'id':17,'href':'/docs/tutorial/git/config-user-and-email/','title':"Git 配置用户名和邮箱",'content':"Git 配置用户名和邮箱 假设你的用户名是 zk，邮箱账号是 xxx@163.com，那么需要提前配置 Git 的用户名和邮箱帐号：\ngit config --global user.name \u0026#34;zk\u0026#34; git config --global user.email \u0026#34;xxx@163.com\u0026#34; Git 需要知道谁对代码做出了变更，对代码做出变更的这个人的邮件联系方式是什么，以方便追踪。\nGit Config 有三个作用域：\n git config --local：只对某个仓库有效 git config --global：对当前用户所有仓库有效 git config --system：对系统所有登录的用户有效  如何查看当前设置的 Git 配置？\ngit config --list --local git config --list --global git config --list --system  --local 针对的是某个仓库，配置 --local 作用域的时候，需要进入到项目所在的目录才能配置或显示。\n "});index.add({'id':18,'href':'/docs/tutorial/unix-command/grep/','title':"grep",'content':"grep grep 命令如何使用？grep 命令的常见用法？\n简介 grep 命令用于搜索文本。它在给定文件中搜索包含与给定字符串或单词匹配的行。它是 Linux 和类 Unix 系统中最有用的命令之一。让我们看看如何在 Linux 或类 Unix 系统上使用 grep。\ngrep 命令是一个包含 grep、egrep 和 fgrep 命令的大家族，都用于搜索文本。\n常见用法 下面是一些标准的 grep 命令，通过示例说明了如何在Linux、macOS和Unix上使用 grep：\n（1）在文件 foo.txt 中搜索单词 word\ngrep \u0026#39;word\u0026#39; foo.txt （2）在文件 foo.txt 中搜索单词 word，并且忽略大小写\ngrep -i \u0026#39;word\u0026#39; foo.txt 上述命令会把位于 foo.txt 文件中的 WORD、Word、word 等忽略大小写的 word 全部搜索出来。\n（3）在当前目录以及所有子目录中查找单词 word\ngrep -R \u0026#39;word\u0026#39; .  注意：最后面有一个点，代表当前目录。-r 命令也是递归搜索，只是 -r 不会搜索符号链接文件。\n （4）搜索并显示单词 word 出现的次数\ngrep -c \u0026#39;word\u0026#39; foo.txt （5）只匹配单词 word\ngrep -w \u0026#39;word\u0026#39; foo.txt 这意味着 fooword、word123 等单词不会被搜索出来，而只会将 a word 这种类型的 word 搜索出来。\n（6）搜索单词 word1 或 word2\negrep -w \u0026#39;word1|word2\u0026#39; foo.txt （7）结果显示行号\ngrep -n \u0026#39;root\u0026#39; /etc/passwd （8）反匹配搜索\ngrep -v word foo.txt foo.txt 文件中，不包含 word 的行，会被搜索出来。\n（9）显示匹配行的上下文\n当展示结果行的时候，顺便将 word 所在行的前面 3 行，也显示出来：\ngrep -B 3 \u0026#39;word\u0026#39; foo.txt 将 word 所在航的后 4 行，显示出来：\ngrep -A 4 \u0026#39;word\u0026#39; foo.txt 使用 -C 命令同时展示出前 3 行和后 4 行：\ngrep -C 3 \u0026#39;word\u0026#39; foo.txt （10）与其它 Shell 命令结合\n显示 CPU 型号：\ncat /proc/cpuinfo | grep -i \u0026#39;Model\u0026#39; （11）仅显示匹配的文件名\ngrep -l \u0026#39;main\u0026#39; *.c （12）搜索结果高亮显示\ngrep --color vivek /etc/passwd （13）搜索多个文件\ngrep word *.txt （14）排除/引入某些文件\n只在 rootdir 文件夹内的 *.cpp 和 *.h 文件中搜索 abc 这个关键字：\ngrep \u0026#39;abc\u0026#39; -r --include=\u0026#34;*.{cpp,h}\u0026#34; rootdir # 或 grep \u0026#39;abc\u0026#39; -r --include=*.cpp --include=*.h rootdir 在当前文件夹，只搜索 *.js 文件，但是排除 *js/lib/* 路径和 *.min.js 这些文件：\ngrep \u0026#34;z-index\u0026#34; . --include=*.js --exclude=*js/lib/* --exclude=*.min.js 排除多个模式，比如 --exclude=pattern1 --exlucde=pattern2 ，可以使用 {} 把多个 pattern 包括起来：\n--exclude={pattern1,pattern2,pattern3} 正则表达式 grep 支持三种类型的正则表达式语法：\n basic (BRE) extended (ERE) perl (PCRE)  （1）匹配行的开头\ngrep ^vivek /etc/passwd vivek 仅作为行的开头的时候，才会被搜索出来。\n（2）匹配行结尾\ngrep \u0026#39;foo$\u0026#39; filename foo 仅作为行的结尾的时候，才会被搜索出来。\n（3）点需要被转义\n在 grep 中，. 有特殊含义，它可以匹配任何字符，所以如果需要匹配 .，那么需要使用反斜杠 \\ 对其进行转义：\ngrep \u0026#39;192\\.168\\.1\\.254\u0026#39; hosts （4）搜索多个字符串\ngrep -E \u0026#39;word1|word2\u0026#39; filename # 或 egrep \u0026#39;word1|word2\u0026#39; filename （5）搜索带有横杠的字符串\ngrep -e \u0026#39;--test--\u0026#39; filename  如果不加 -e 选项，那么 --test 将会按照 grep 命令的参数 –test– 来处理\n 参考  How To Use grep Command In Linux / UNIX Regular expressions in grep ( regex ) with examples Use grep \u0026ndash;exclude/\u0026ndash;include syntax to not grep through certain files  扫描下面二维码，在手机端阅读：\n"});index.add({'id':19,'href':'/docs/rocketmq/rocketmq-send-message-flow/','title':"RocketMQ 消息发送流程",'content':"RocketMQ 消息发送流程 本文讲述 RocketMQ 发送一条普通消息的流程。\n一、服务器启动 我们可以参考官方文档来启动服务:\n 启动 Name 服务器:  sh bin/mqnamesrv  启动 Broker 服务器:  sh bin/mqbroker -n localhost:9876 二、构建消息体 一条消息体最少需要指定两个值:\n 所属话题 消息内容  如下就是创建了一条话题为 “Test”，消息体为 “Hello World” 的消息:\nMessage msg = new Message( \u0026#34;Test\u0026#34;, \u0026#34;Hello World\u0026#34;.getBytes() ); 三、启动 Producer 准备发送消息 如果我们想要发送消息呢，我们还需要再启动一个 DefaultProducer (生产者) 类来发消息:\nDefaultMQProducer producer = new DefaultMQProducer(); producer.start(); 现在我们所启动的服务如下所示:\n四、Name 服务器的均等性 注意我们上述开启的是单个服务，也即一个 Broker 和一个 Name 服务器，但是实际上使用消息队列的时候，我们可能需要搭建的是一个集群，如下所示:\n在 RocketMQ 的设计中，客户端需要首先询问 Name 服务器才能确定一个合适的 Broker 以进行消息的发送:\n然而这么多 Name 服务器，客户端是如何选择一个合适的 Name 服务器呢?\n首先，我们要意识到很重要的一点，Name 服务器全部都是处于相同状态的，保存的都是相同的信息。在 Broker 启动的时候，其会将自己在本地存储的话题配置文件 (默认位于 $HOME/store/config/topics.json 目录) 中的所有话题加载到内存中去，然后会将这些所有的话题全部同步到所有的 Name 服务器中。与此同时，Broker 也会启动一个定时任务，默认每隔 30 秒来执行一次话题全同步:\n五、选择 Name 服务器 由于 Name 服务器每台机器存储的数据都是一致的。因此我们客户端任意选择一台服务器进行沟通即可。\n其中客户端一开始选择 Name 服务器的源码如下所示:\npublic class NettyRemotingClient extends NettyRemotingAbstract implements RemotingClient { private final AtomicInteger namesrvIndex = new AtomicInteger(initValueIndex()); private static int initValueIndex() { Random r = new Random(); return Math.abs(r.nextInt() % 999) % 999; } private Channel getAndCreateNameserverChannel() throws InterruptedException { // ...  for (int i = 0; i \u0026lt; addrList.size(); i++) { int index = this.namesrvIndex.incrementAndGet(); index = Math.abs(index); index = index % addrList.size(); String newAddr = addrList.get(index); this.namesrvAddrChoosed.set(newAddr); Channel channelNew = this.createChannel(newAddr); if (channelNew != null) return channelNew; } // ...  } } 以后，如果 namesrvAddrChoosed 选择的服务器如果一直处于连接状态，那么客户端就会一直与这台服务器进行沟通。否则的话，如上源代码所示，就会自动轮寻下一台可用服务器。\n六、寻找话题路由信息 当客户端发送消息的时候，其首先会尝试寻找话题路由信息。即这条消息应该被发送到哪个地方去。\n客户端在内存中维护了一份和话题相关的路由信息表 topicPublishInfoTable，当发送消息的时候，会首先尝试从此表中获取信息。如果此表不存在这条话题的话，那么便会从 Name 服务器获取路由消息。\npublic class DefaultMQProducerImpl implements MQProducerInner { private TopicPublishInfo tryToFindTopicPublishInfo(final String topic) { TopicPublishInfo topicPublishInfo = this.topicPublishInfoTable.get(topic); if (null == topicPublishInfo || !topicPublishInfo.ok()) { this.topicPublishInfoTable.putIfAbsent(topic, new TopicPublishInfo()); this.mQClientFactory.updateTopicRouteInfoFromNameServer(topic); topicPublishInfo = this.topicPublishInfoTable.get(topic); } // ...  } } 当尝试从 Name 服务器获取路由信息的时候，其可能会返回两种情况:\n(1) 新建话题 这个话题是新创建的，Name 服务器不存在和此话题相关的信息：\n(2) 已存话题 话题之前创建过，Name 服务器存在此话题信息：\n服务器返回的话题路由信息包括以下内容:\n“broker-1”、”broker-2” 分别为两个 Broker 服务器的名称，相同名称下可以有主从 Broker，因此每个 Broker 又都有 brokerId 。默认情况下，BrokerId 如果为 MixAll.MASTER_ID （值为 0） 的话，那么认为这个 Broker 为 MASTER 主机，其余的位于相同名称下的 Broker 为这台 MASTER 主机的 SLAVE 主机。\npublic class MQClientInstance { public String findBrokerAddressInPublish(final String brokerName) { HashMap\u0026lt;Long/* brokerId */, String/* address */\u0026gt; map = this.brokerAddrTable.get(brokerName); if (map != null \u0026amp;\u0026amp; !map.isEmpty()) { return map.get(MixAll.MASTER_ID); } return null; } } 每个 Broker 上面可以绑定多个可写消息队列和多个可读消息队列，客户端根据返回的所有 Broker 地址列表和每个 Broker 的可写消息队列列表会在内存中构建一份所有的消息队列列表。之后客户端每次发送消息，都会在消息队列列表上轮循选择队列 (我们假设返回了两个 Broker，每个 Broker 均有 4 个可写消息队列):\npublic class TopicPublishInfo { public MessageQueue selectOneMessageQueue() { int index = this.sendWhichQueue.getAndIncrement(); int pos = Math.abs(index) % this.messageQueueList.size(); if (pos \u0026lt; 0) pos = 0; return this.messageQueueList.get(pos); } } 七、给 Broker 发送消息 在确定了 Master Broker 地址和这个 Broker 的消息队列以后，客户端才开始真正地发送消息给这个 Broker，也是从这里客户端才开始与 Broker 进行交互:\n这里我们暂且先忽略消息体格式的具体编/解码过程，因为我们并不想一开始就卷入这些繁枝细节中，现在先从大体上了解一下整个消息的发送流程，后续会写专门的文章来说明。\n八、Broker 检查话题信息 刚才说到，如果话题信息在 Name 服务器不存在的话，那么会使用默认话题信息进行消息的发送。然而一旦这条消息到来之后，Broker 端还并没有这个话题。所以 Broker 需要检查话题的存在性:\npublic abstract class AbstractSendMessageProcessor implements NettyRequestProcessor { protected RemotingCommand msgCheck(final ChannelHandlerContext ctx, final SendMessageRequestHeader requestHeader, final RemotingCommand response) { // ...  TopicConfig topicConfig = this.brokerController .getTopicConfigManager() .selectTopicConfig(requestHeader.getTopic()); if (null == topicConfig) { // ...  topicConfig = this.brokerController .getTopicConfigManager() .createTopicInSendMessageMethod( ... ); } } } 如果话题不存在的话，那么便会创建一个话题信息存储到本地，并将所有话题再进行一次同步给所有的 Name 服务器:\npublic class TopicConfigManager extends ConfigManager { public TopicConfig createTopicInSendMessageMethod(final String topic, /** params **/) { // ...  topicConfig = new TopicConfig(topic); this.topicConfigTable.put(topic, topicConfig); this.persist(); // ...  this.brokerController.registerBrokerAll(false, true); return topicConfig; } } 话题检查的整体流程如下所示:\n九、消息存储 当 Broker 对消息的一些字段做过一番必要的检查之后，便会存储到磁盘中去:\n十、整体流程 发送消息的整体流程:\n扫描下面二维码，在手机端阅读：\n"});index.add({'id':20,'href':'/docs/programmer-interview/front-end/vue/','title':"VUE 面试题",'content':"VUE 面试题 整理 VUE 相关的常见面试题\n介绍一下 VUE 介绍一下 VUEX VUE 2.X 和 3.0 的区别 （1）数据监听方式变化\nVUE 2.X 使用 ES5 的 Object.defineProperty() 的 get() 和 set(newValue) 实现，VUE 3.0 基于 Proxy 监听实现，同时更为强大：\n 可以检测属性的新增和删除 可以检测数组索引的变化和 length 的变化 支持 Map、Set、WeakMap 和 WeakSet   优点：速度加倍，内存占用减半。\n （2）体积更小\n支持 Tree Shaking，内置组件、内置指令按需引入。\n（3）速度更快\n参考：vue3.0和vue2.x的区别、Vue 3.0 和 Vue 2.0的对比以及Vue 2.0精讲以及Vue全家桶精讲\nVUE 的生命周期 VUE 数据双向绑定原理 VUE 采用发布者-订阅者模式的方式来实现双向绑定。\n（1）视图更新数据：\ninput 标签监听 input 事件即可。\n（2）数据更新视图：\nObject.defineProperty() 监听数据变化，通过消息订阅器发布消息，订阅者收到消息执行相应的操纵 DOM 的函数，从而更新视图。\nVUE 的路由机制  hash 和 history 区别  v-if 和 v-show 的区别  v-show：无论值是 true 还是 false，元素都会存在于 HTML 代码中。 v-if：只有值为 true 的时候，元素才会存在于 HTML 代码中。  VUE 组件通信方式  引申：如果有多层的父子组件，用什么通信  VUE 的 v-for 中的 key 的作用 一句话回答：为了高效的更新虚拟 DOM。\nnextTick 原理与应用场景 Vue 在修改数据后，视图不会立刻更新，而是等同一事件循环中的所有数据变化完成之后，再统一进行视图更新。\n//改变数据 vm.message = \u0026#39;changed\u0026#39; //想要立即使用更新后的DOM。这样不行，因为设置message后DOM还没有更新 console.log(vm.$el.textContent) // 并不会得到\u0026#39;changed\u0026#39;  //这样可以，nextTick里面的代码会在DOM更新后执行 Vue.nextTick(function(){ console.log(vm.$el.textContent) //可以得到\u0026#39;changed\u0026#39; }) 应用场景：需要在 DOM 视图更新之后，基于新的 DOM 视图进行操作。\n参考：Vue.nextTick 的原理和用途\nVUE 的虚拟 DOM  VUE 是如何实现 VDOM 的 vue中keep-alive缓存的真实结点还是虚拟结点 vue改变组件的key值, 原来的组件会被销毁么 为什么要用虚拟结点 diff 原理  vue 从 data 改变到页面渲染的过程 参考  诚意满满的前端面试总结（回馈牛客）  "});index.add({'id':21,'href':'/docs/programmer-interview/front-end/','title':"前端",'content':"前端面试题 "});index.add({'id':22,'href':'/docs/tutorial/front-end-optimization-guide/','title':"前端优化指南",'content':"前端优化指南  图片优化 HTML 优化 CSS 优化 JS 优化  "});index.add({'id':23,'href':'/docs/tutorial/front-end-optimization-guide/image-optimization/','title':"图片优化",'content':"图片优化 图片在网页数据的传输中占据了非常大的流量，如何优化图片，对于前端页面加载的性能极其重要。本文讲述了比较常见的几种优化图片的技巧。\n图片格式介绍 （1）JPEG\nJPEG 是 Joint Photographic Experts Group 的缩写，不支持透明度，常用于网站的 Banner 图。JPEG 使用的是一种有损图像质量的压缩算法，压缩的越狠，图片的质量损失也就越大，图片的尺寸也就越小。根据你网站所能忍受的图片质量，来相应的选择压缩比：\n（2）PNG\n支持透明度，支持无损压缩，一般图片的尺寸都比较大。\n（3）GIF\n适合放动画图片。\n（4）WebP\n🔥Google 2010 年提出的新的图像压缩格式算法，在 2013 年又推出 Animated WebP，即支持动画的 Webp。优点：更优的图像数据压缩算法、拥有肉眼识别无差异的图像质量、具备了无损和有损的压缩模式、Alpha 透明以及动画的特性。\nPNG、JPG、WebP 压缩对比：\nGIF 和 WebP 对比：\n不同网络环境，加载不同尺寸图片 如下是京东网站首页占据 C 位的宣传图：\n它的 URL 地址如下，你任意改变这张图片的 URL 里面的宽、高，放到浏览器里面重新进行请求，就可以得到相应大小的图片：\n响应式图片 不同平台设备加载不同大小、甚至不同内容的图片！\nCSS 媒体查询 @media all and (max-width: 600px) { img { width: 300px; } } @media all and (min-width: 600px) and (max-width: 1200px) { img { width: 900px; } } srcset、sizes、picture 和 source （1）srcset 属性\nimg 标签的 srcset 属性定义了我们允许浏览器选择的图像集，以及每个图像的大小：\n\u0026lt;img srcset=\u0026#34;images/team-photo.jpg 1x, images/team-photo-retina.jpg 2x, images/team-photo-full.jpg 2048w, images/team-photo-default.jpg\u0026#34; src=\u0026#34;team-photo.jpg\u0026#34;\u0026gt; 上述代码，srcset 属性给出了四个图像的 URL。1x 或 2x 这个 x 代表 pixel density descriptor，代表当当前设备的像素密度是标准像素密度的 1 倍或 2 倍时，去加载对应的图片，这个值可以是浮点数。2048w 的 w 代表 width descriptor，也就是图片的以像素为单位的宽度，当浏览器的渲染器需要去渲染宽度为 2048 像素的图片的时候，就会使用这张图片，这个值必须是正整数。\n最后一个图像 URL images/team-photo-default.jpg 没有带 x 或者 w，这表示这张图片是一张候选图片，当 srcset 其它图片都没有匹配上的时候，那么就会使用这种图片。当然，候选图片是可选的，如果不提供，就会选择使用 src 图片作为默认图片。\n（2）sizes 属性\nsrcset 提供了一个图片的候选集，但是选择哪个图片是浏览器决定的，我们无法灵活控制。如果想要自己根据屏幕的大小，来告诉渲染器去渲染多大尺寸的图片，可以引入 sizes 属性。\n\u0026lt;img src=\u0026#34;/files/16870/new-york-skyline-wide.jpg\u0026#34; srcset=\u0026#34;/files/16870/new-york-skyline-wide.jpg 3724w, /files/16869/new-york-skyline-4by3.jpg 1961w, /files/16871/new-york-skyline-tall.jpg 1060w\u0026#34; sizes=\u0026#34;((min-width: 50em) and (max-width: 60em)) 50em, ((min-width: 30em) and (max-width: 50em)) 30em, (max-width: 30em) 20em\u0026#34;\u0026gt; sizes 的格式：媒体查询条件 目标值。\n上述的 sizes 属性表示，当屏幕宽度位于 50em ~ 60em 的时候，渲染所需图片宽度为 50em，当屏幕宽度位于 30em ~ 50em 的时候，渲染所需图片宽度为 30em，当屏幕宽度小于 30em，渲染所需图片宽度为 20em。当渲染器所需渲染的图片宽度确定的时候，再去 srcset 中去匹配最接近该宽度的图片 URL 即可。\n目标值的单位可以是：\n 相对字体大小的单位：em 或 ex 绝对单位：px 或 cm Viewport(窗口) 百分比单位：vw  （3）picture 和 source\nsrcset 和 sizes 可以让网站根据屏幕大小来加载**内容相同的（虽然也可以不同，但不应该这样用）**不同大小的图片，如果还想根据不同的屏幕，显示不同内容的图片，例如电脑上显示如下比较宽的图：\n而手机上为了突出人物，显示比较瘦的图：\n可以使用 \u0026lt;picture\u0026gt; 和 \u0026lt;source\u0026gt; 标签来解决这个问题：\n\u0026lt;picture\u0026gt; \u0026lt;source media=\u0026#34;(max-width: 799px)\u0026#34; srcset=\u0026#34;elva-480w-close-portrait.jpg\u0026#34;\u0026gt; \u0026lt;source media=\u0026#34;(min-width: 800px)\u0026#34; srcset=\u0026#34;elva-800w.jpg\u0026#34;\u0026gt; \u0026lt;img src=\u0026#34;elva-800w.jpg\u0026#34; alt=\u0026#34;Chris standing up holding his daughter Elva\u0026#34;\u0026gt; \u0026lt;/picture\u0026gt; 上述代码的 \u0026lt;img\u0026gt; 标签是必须提供，否则不会显示任何图片，当 \u0026lt;source\u0026gt; 的媒体查询条件都不满足的时候，\u0026lt;img\u0026gt; 将会显示 src 所指向的 URL 图片。\n除此之外，\u0026lt;picture\u0026gt; 标签还可以根据浏览器所能渲染的图片格式来选择不同的图片：\n\u0026lt;picture\u0026gt; \u0026lt;source type=\u0026#34;image/svg+xml\u0026#34; srcset=\u0026#34;pyramid.svg\u0026#34;\u0026gt; \u0026lt;source type=\u0026#34;image/webp\u0026#34; srcset=\u0026#34;pyramid.webp\u0026#34;\u0026gt; \u0026lt;img src=\u0026#34;pyramid.png\u0026#34; alt=\u0026#34;regular pyramid built from four equilateral triangles\u0026#34;\u0026gt; \u0026lt;/picture\u0026gt; 当浏览器按照 \u0026lt;source\u0026gt; 出现的顺序，依次探测是否满足条件，如果满足，就加载相应图片。\n懒加载 有很多库可以实现懒加载图片，例如 lazysizes。对于每一张图片，需要确定在其原图内容还未被浏览器渲染出来之前，这张图应该显示什么占位符，目前有两个库可以生成图像的占位符。当然，如果对于所有图片，都像是用一个统一的图片作为占位符，也未尝不可。\nLQIP LQIP 就是 Low Quality Image Placeholders (低质量图像占位符) 的缩写。\nSQIP 上述 LQIP 是基于像素的解决方案，而 SQIP 是 SVG-based LQIP (基于 SVG 的低质量图像占位符) 的缩写，其实基于 SVG 的，在任何设备上都看起来很清晰。\n下图展示的是一个效果图：\n换一种方式来表达图片 Data URL 对于一些较小的图片，可以将内容直接内嵌在 URL 中，常见格式如下：\ndata:[\u0026lt;mediatype\u0026gt;][;base64],\u0026lt;data\u0026gt; mediatype 标识图片的格式，例如 image/jpeg 等。\nImage sprites (雪碧图) 对于 HTTP 1.X 协议，雪碧图（即多张小图片合成一张大图）的加载方式，是很多网站都会采用的技巧，这种方式的缺点是，如果某个应用图标需要更新，那么整张大图都需要替换。\n然而对于 HTTP 2.0 协议的到来，加载多张小图是比较推荐的做法，因为多张图片本身的下载都会复用同一个连接。\n参考  HTMLImageElement.srcset Responsive images Essential Image Optimization  扫描下面二维码，在手机端阅读：\n"});index.add({'id':24,'href':'/docs/books/beauty_of_mathematics/','title':"数学之美",'content':"数学之美 2000多年前，古埃及人在罗塞塔石碑上，用三种文字记录了托勒密五世登基的诏书，这帮助后人破解了古埃及的象形文字，让我们了解了5000年前古埃及的历史。可见信息冗余是信息安全的保障，这对于信息编码具有重要指导意义。\n犹太人为了避免抄错《圣经》，发明了一种校验码的方法，他们把每一个希伯来字母对应于一个数字，这样每行文字加起来便得到一个特殊的数字，这样的数字变成为了这一行的校验码。\n隐含马尔可夫链成功应用在机器翻译、拼写纠错、手写体识别、图像处理、基因序列分析、股票预测和投资等方面。\n如何准确的识别出一个快递地址，写一个分析器去分析这些描述恐怕是不行的，因为地址是比较复杂的上下文有关的文法。答案是使用有限状态机。当用户输入的地址不太标准或有错别字的时候，有限状态机会束手无措，因为有限状态机是严格匹配的，所以科学家提出了基于概率的有限状态机。\n2002 年，Google 想要做一个全新的中、日、韩搜索算法，吴军写的算法比较简单，但是占用内存比较多，Google 服务器数量还没有那么多。辛格提出，用一个拟合函数替换很耗内存的语言模型，无需增加任何服务器，但是搜索质量会降到 80%。辛格指出，这样可以提早两个月将这个新算法提供给中国的用户，用户体验会有质的提高。辛格做事情的哲学，先帮助用户解决 80% 的问题，再慢慢解决剩下的 20% 的问题，是在工业界成功的秘诀之一。\n新闻分类的关键在于计算出两篇新闻的相似度，每篇新闻变成一个向量，最后余弦定理可以计算出来相似度。但两两计算的迭代次数太多，如何一次性就把所有新闻的相关性计算出来呢？答案是矩阵运算中的奇异值分解。\n如何判断两个集合是否相同？一种答案是双层 for 循环一一比较，复杂度 O(N^2)；稍好一点的办法是对集合进行排序，然后顺序比较，时间复杂度 O(NlogN)；还可以将一个集合的元素放到散列表里面，另外一个与之一一对比，时间复杂度 O(N)，但是额外使用了 O(N) 的空间，不完美；最完美的是计算这两个集合的指纹，对一个集合中的元素分别计算指纹，然后一一相加。\n如何判断两个集合基本相同？答案是 Simhash。判断两个网页是否重复，也没有必要完全从头比到尾，只需要每个网页挑选出几个词 (IDF 最大的几个词)，构成特征词，然后计算信息指纹即可。判断一篇文章是否抄袭另外一篇文章，每篇文章切成小的片段，挑选特征词，并计算指纹。YouTuBe 如何从上百万视频中找出一个视频是否另外一个视频的盗版？其核心在于关键帧的提取和特征的提取。关键帧对于视频的重要性，就如同主题词对于新闻的重要性一样。\n最大熵原理指出，对一个随机事件的概率分布进行预测时，我们的预测应当满足全部已知的条件，而对未知的情况不要做任何主观假设，这种情况下，概率分布最均匀，预测的风险最小。例如拼音输入法，Wang-Xiao-Bo 转换为王晓波和王小波，唯一确定用户需要的是哪一个，非常难。\n"});index.add({'id':25,'href':'/docs/tutorial/sentinel/architecture/','title':"架构",'content':"架构 随着微服务的流行，服务和服务之间的稳定性变得越来越重要。Sentinel 是面向分布式服务架构的流量控制组件，主要以流量为切入点，从限流、流量整形、熔断降级、系统负载保护、热点防护等多个维度来帮助开发者保障微服务的稳定性。\n有关 Sentinel 更为详细的使用文档和介绍请移至 Sentinel Github Wiki。\n主要特性 流量控制 流量控制在网络传输中是一个常用的概念，它用于调整网络包的发送数据。然而，从系统稳定性角度考虑，在处理请求的速度上，也有非常多的讲究。任意时间到来的请求往往是随机不可控的，而系统的处理能力是有限的。我们需要根据系统的处理能力对流量进行控制。Sentinel 作为一个调配器，可以根据需要把随机的请求调整成合适的形状，如下图所示：\n熔断降级 除了流量控制以外，及时对调用链路中的不稳定因素进行熔断也是 Sentinel 的使命之一。由于调用关系的复杂性，如果调用链路中的某个资源出现了不稳定，可能会导致请求发生堆积，进而导致级联错误。\n网关限流 Sentinel 支持对 Spring Cloud Gateway、Zuul 等主流的 API Gateway 进行限流。\n架构 另外一幅更为漂亮的图：\n可扩展性 开源生态 参考  Sentinel Wiki  "});index.add({'id':26,'href':'/docs/javascript/understand-this-keyword/','title':"理解 This 关键字",'content':"理解 This 关键字 JavaScript 中的 this 所指向的对象，取决于上下文以及函数被调用的方式，本文列举了几种常见的情况，帮助大家理解。\n一、全局上下文 当直接在一个全局的上下文中，使用 this 指针的时候，this 指针会指向到全局对象上。例如在浏览器的调试工具栏中直接打印 this 指针，其指向的是 Window 对象：\n在 node 中打印 this 指针，其指向的是 node 提供的全局对象，其中包含了进程信息等：\n二、Function 上下文 在 Function 上下文中，this 的值取决于 function 是如何被调用的。\n(1) Function 调用 当 this 指针定义在一个 function 中，那么此 this 仍然会指向全局对象：\nfunction foo() { console.log(this) } foo(); // Window {parent: Window, postMessage: ƒ, blur: ƒ, focus: ƒ, close: ƒ, …} (2) 严格模式下的 Function 调用 如果在严格模式下定义的 function 的话，this 指针的值将会是 undefined：\nfunction foo() { \u0026#39;use strict\u0026#39;; console.log(this) } foo(); // undefined (3) Method 调用 Method 调用指的是，function 作为一个对象的属性而存在。当 this 指针被定义在一个对象内的时候，那么其将会指向紧紧包裹自己的这个对象。\nvar obj = { name: \u0026#39;outerObj\u0026#39;, innerObj: { name: \u0026#39;innerObj\u0026#39;, foo: function() { console.log(this.name) } } }; console.log(obj.innerObj.foo()) // innerObj (4) 构造器调用 当 function 被用于构造器的时候，那么定义在构造器内部的 this 指针将会指向此构造器新 new 出来的实例对象。\nfunction Person(name) { this.name = name console.log(this) } console.log(new Person(\u0026#34;Tom\u0026#34;)) // Person {name: \u0026#34;Tom\u0026#34;} (5) call()、apply()、bind() 调用 这三个函数最大的特点就是，你可以通过参数为他们指定 this 指针所需要指向的对象：\nfunction add(inc1, inc2) { var value = this.a + inc1 + inc2; console.log(this) return value; } var o = { a : 4 }; console.log(add.call(o, 5, 6)) // {a: 4} console.log(add.apply(o, [5, 6])) // {a: 4}  var g = add.bind(o, 5, 6) console.log(g()) // {a: 4} (6) ES6 箭头函数调用 当你使用 ES6 箭头函数的时候，this 指针返回的总是箭头函数定义所在位置的上一级的函数作用域的 this 对象，是箭头函数被 function() { } 包裹的作用域中的 this 对象。如下面示例，this 指向的是 log() 函数内部的 this 指针的值：\nclass Student { log() { // 这个地方的 this 的值  setTimeout(() =\u0026gt; console.log(this === student), 100) } } const student = new Student() student.log() // true 但是如果上一级并不是位于函数作用域中，而是位于 Object 对象嵌套层级中，则需要继续向上找函数作用域，因为 Object 嵌套层级不构成单独的作用域。如下所示 this 指针指向的是 Window 对象，而非 o 对象：\nvar o = { b: () =\u0026gt; { console.log(\u0026#39;this is\u0026#39;, this); // this is Window  } } o.b(); 三、参考  How does the “this” keyword work? Gentle Explanation of \u0026ldquo;this\u0026rdquo; in JavaScript MDN this 箭头函数this的指向问题  扫描下面二维码，在手机端阅读：\n"});index.add({'id':27,'href':'/docs/tutorial/awk/intro/','title':"简介",'content':"简介 AWK 是一门编程语言。\n开始 假设您有一个名称为 emp.data 文件，里面存储的内容包含姓名、每小时的薪资、工作的小时，如下所示：\nBeth 4.00 0 Dan 3.75 0 Kathy 4.00 10 Mark 5.00 20 Mary 5.50 22 Susie 4.25 18 现在你想要打印工作超过 0 小时的员工的姓名和薪资，对于 AWK 而言，这相当简单：\nawk `$3 \u0026gt; 0 { print $1, $2 * $3 }` emp.data 你会得到如下输出：\nKathy 40 Mark 100 Mary 121 Susie 76.5 位于引号中的内容就是 AWK 的完整代码。$3 \u0026gt; 0，会匹配文件的每一行，看这每一行的第 3 列是否大于 0。{ print $1, $2 * $3 } 打印第一列，以及第二列和第三列的乘积。\n如果你想要打印出工作小时数是 0 的员工姓名：\nawk `$3 == 0 { print $1 }` emp.data AWK 程序结构 pattern { action } pattern { action } ... 程序中 pattern 会对文件的每一行进行测试，测试为 true，才会对这一行执行后面的 action。\n运行 AWK awk `program` input_file 如果 AWK 代码太长，假设你将其代码存储到了 progfile 文件中，那么可以这样运行：\nawk -f progfile input_file "});index.add({'id':28,'href':'/docs/programmer-interview/algorithm/','title':"算法",'content':"算法面试题 本专栏的面试题来自于牛客网、一亩三分地、LeetCode、LintCode等网站，覆盖了一线互联网如BAT、TMD、微软、亚马逊等巨头，在校招或者社招的时候最容易出的算法面试题。\n回溯题  组合总和  "});index.add({'id':29,'href':'/docs/tutorial/','title':"💡教程",'content':"💡教程  前端优化指南 UNIX 常用命令大全 Git 教程  "});index.add({'id':30,'href':'/posts/half-life-of-information/','title':"信息的半衰期",'content':"今天，我想与您讨论一下信息能存活多久的问题，这个问题又会如何影响我们工作的方式。\n信息衰减 你可能不止一遍地听闻我们生活在一个“信息时代”，信息无所不在，无论是个人还是公司，掌握了信息就能让你事半功倍。而与此同时，随着信息被源源不断的生产出来，其又会很快变为过时信息，对人们能够起到的帮助越来越少。\n对于公司而言，有许多因素都会加速信息衰减的速度：员工离职、文档过时、1对1的知识分享等。而采用远程办公进行协作的团队，他们更为担心这个问题，员工可能不在一个时区，彼此之间也不能进行面对面的鼓励，知识分享也存在一些额外地物理限制。\n所以，我们应该如何避免或减缓知识衰减的速度呢？\n信息的半衰期 在核物理学中，放射性物质的半衰期是指它将衰变减少到一半所需的时间。同样，知识、信息或事实的半衰期是指知识的一半变得不相关或过时所需的时间。\n让我举几个例子来解释这一点。一家公司的新闻稿或投资者最新消息通常会有几个星期的半衰期。另一方面，你公司的 WIKI 或作业指导书的半衰期约为 0.5 - 1 年。\n信息的类型 这篇文章将知识分为三种不同的形式：\n 无意识知识：员工主动使用但可能没有意识到的知识（例如，使用工具或特定工作流的特定方式） 有意识的知识：员工知道的方法、过程、标准操作程序等 记录的知识：以可访问和有形形式捕获的所有信息  你可能已经猜到记录的知识半衰期最高，而无意识的知识半衰期最低。\n有效的知识转移与提高知识半衰期 因此，我们的目标应该是促进知识的流动或转移，主要是从无意识到有记录。实际上，这将增加知识的半衰期，并确保贵公司的信息长期保持相关和更新。\n下面是一些可以立即实现的功能：\n 默认为异步  即时消息或聊天的半衰期通常较短，约为5-10分钟，而长格式消息的半衰期至少为几个小时。另外，当您默认使用异步长格式对话时，您反过来会鼓励更周到的响应，并减少来回的次数。\n 跨团队共享知识  这是扩大公司记录知识的第一步。单个团队通常拥有大量的数据和洞察，如果在公司内部共享这些数据和洞察，可以帮助建立坚实的知识库。\n 开始建立学习型组织  更进一步，你应该致力于在你的组织中建立一种学习的文化。HBR的这篇文章很好地解释了什么是学习型组织，以及它如何促进员工的持续学习。\n 使用协作工作管理工具  像Slack这样的即时消息工具是很好的，并且是您的技术栈的重要组成部分。但是，您还应该投资于协作工作管理工具，如Notion或Slite，以存储、维护、优先排序和共享知识。\n译文来源  Knowledge Decays and Half-life of Information "});index.add({'id':31,'href':'/docs/programmer-interview/algorithm/best-time-to-buy-and-sell-stock-2/','title':"Best Time to Buy and Sell Stock Ⅱ",'content':"Best Time to Buy and Sell Stock Ⅱ 题目 LeetCode 地址：Best Time to Buy and Sell Stock Ⅱ\n有一个数组，第 i 个元素的值代表第 i 天的股票价格，如果你可以进行无限次交易（某天买入一支股票，然后过几天卖掉），请问你能收获的最大利润是多少？\n分析 这道题就一个想法，只要今天 price[i] 比昨天 price[i - 1] 的价格涨了，就可以算作是有效的利润，累加到最后的结果中。\n答案 // 假设有一个数组，它的第i个元素是一个给定的股票在第i天的价格。 // 设计一个算法来找到最大的利润。你可以完成尽可能多的交易(多次买卖股票)。 // 然而,你不能同时参与多个交易(你必须在再次购买前出售股票)。 // // https://www.lintcode.com/problem/best-time-to-buy-and-sell-stock-ii/description public class BestTimetoBuyandSellStockII { public int maxProfit(int[] prices) { int max = 0; for (int i = 1; i \u0026lt; prices.length; i++) { int diff = prices[i] - prices[i - 1]; if (diff \u0026gt; 0) { max += diff; } } return max; } } 扫描下面二维码，在手机上阅读这篇文章：\n"});index.add({'id':32,'href':'/docs/tutorial/unix-command/find/','title':"find",'content':"find find 命令的常见用法有哪些？find 命令的例子。\n简介 Linux Find命令是类Unix操作系统中最重要、最常用的命令行实用程序之一。find 命令可以，根据不同的查找条件，来查询匹配不同的文件或目录列表。\nfind 可用于根据各种条件查找，例如您可以按权限、用户、组、文件类型、日期、大小和其他可能的条件查找文件。\n通过本文，我们将以示例的形式分享我们的日常Linux find命令体验及其使用。\n格式 find [path...] [test...] [action...]  path：find 命令的第一件事，查看每个路径 test：对于遇到的每个文件，find 应用测试条件 action：一旦搜索完成，find 对每个文件执行相应的操作  路径示例：\n find /usr/bin find / find . find ~  测试示例：\n -name pattern：包含 pattern 的文件名 -iname pattern：包含 pattern 的文件名（忽略大小写） -type [df]：文件类型，d 代表目录，f 代表文件 -perm mode：设置为 mode 的文件权限 -user userid：用户为 userid -group groupid：组为 groupid -size [-+]n[cbkMG]：大小为 n[字符(字节)、块、千字节、兆字节、吉字节] -empty：空文件 -amin [-+]n：n 分钟之前访问 -anewer file：file 文件之后访问 -atime [-+]n：n 天之前访问 -cmin [-+]n：n 分钟之前状态改变 -cnewer file：file 文件之后状态改变 -ctime [-+]n：n 天状态之前改变 -mmin [-+]n：n 分钟之前修改 -mtime [-+]n：n 天之前修改 -newer file：file 文件之后修改   - 代表：小于，+ 代表：大于\n 另外对于测试条件而言，可以使用 ! 对测试条件求反：\n# 显示扩展名不是 jpg 的文件 find ~ -type f \\! -name \u0026#39;*.jpg\u0026#39; -print 动作示例：\n -print：路径名写入到标准输出 -fprint file：同 -print，将输出写入到 file 中 -ls：显示长目录列表 -fls file：同 -ls，将输出写入到 file 中 -delete：删除文件 -exec command {} \\;：执行 command，{} 代表匹配的文件名 -ok command {} \\;：同 -exec，但是在执行 command 之前进行确认  示例 （1）在当前目录查找文件全名为 \u0026lsquo;abc.txt\u0026rsquo; 的文件\nfind . -name abc.txt  点 . 代表当前目录\n 在 /home 目录查找就是：\nfind /home -name abc.txt （2）忽略文件名的大小写\nfind . -iname abc.txt 可能查找出来的有：abc.txt、Abc.txt\n（3）查找名称为 abc 的文件夹\nfind / -type d -name abc -type 的值代表文件类型，可能的值如下所示：\n b：block special c：character special d：目录 f：普通文件 l：symbolic link p：FIFO s：socket  （4）查找当前目录的所有 Java 文件\nfind . -type f -name \u0026#39;*.java\u0026#39; （5）查找权限不是 777 的文件\nfind / -type f ! -perm 777  感叹号 ! 表示反匹配\n （6）查找权限为 777 的文件，并改为 644 文件\nfind / -type f -perm 0777 -print -exec chmod 644 {} \\; -print 代表匹配的文件打印到命令行中\n（7）查找文件并将其删除\nfind . -type f -name \u0026#39;*.txt\u0026#39; -exec rm -f {} \\; （8）查找所有空文件\nfind /tmp -type f -empty （9）查找所有隐藏文件\nfind /tmp -type f -name \u0026#39;.*\u0026#39; （10）查找 abc.txt 并且是用户 tom 拥有的文件\nfind / -user tom -name abc.txt （11）查找所有过去 50 天内修改过的文件\nfind / -mtime 50 （12）查找所有过去 50 - 100 天内修改过的文件\nfind / -mtime +50 -mtime -100 （13）查找所有过去 50 天内访问过的文件\nfind / -atime 50 （14）找到过去 1 小时之内修改过的文件\nfind / -cmin -60  -cmin 代表 change 的文件（单位：分钟） -mmin 代表 modified 的文件（单位：分钟） -amin 代表 assessed 的文件（单位：分钟）  （15）找到 50MB 大小的文件\nfind . -size 50M （16）找到文件位于 50MB - 100MB\nfind . -size +50M -size -100M exec 命令简介 上述有几个例子，在搜索到指定文件后，使用 exec 命令对这些文件做了一些其它操作：比如删除、修改权限等操作。以下面命令为例：\nfind . -type f -name \u0026#39;*.txt\u0026#39; -exec rm -f \u0026#39;{}\u0026#39; \\;  exec 命令，可以对与 find 表达式匹配的每个对象执行命令 {} 是 find 搜索到的文件的占位符 exec 命令以 ; 结束，但是呢需要使用 \\ 来对其进行转义，以防止 ; 被转义 {} 最好使用单引号括起来：'{}'，以避免由于文件的名字格式等问题出现错误  参考  35 Practical Examples of Linux Find Command Find Files in Linux, Using the Command Line  扫描下面二维码，在手机端阅读：\n"});index.add({'id':33,'href':'/docs/tutorial/front-end-optimization-guide/html-optimization/','title':"HTML 优化",'content':"HTML 优化 本文通过一些案例讲述了常见的优化 HTML 的几种小技巧：减少 DOM 树、精简 HTML 文件大小等。\n优化 DOM 节点树 去除页面除首屏外的对于用户不可见的信息区块，可以让页面的 DOM 节点数更少，DOM 树结构更简单，然后再使用懒加载异步化请求，去动态加载这些不可见的信息区块。\n在《大型网站性能优化实战》这本书中，作者为了优化搜索页面的渲染瓶颈问题，将首屏以下的 33 各搜索结果对应的 HTML 代码放到 \u0026lt;textarea\u0026gt; 节点中，当该区域处于可见状态时，再从 TextArea 中取出 HTML 代码，恢复到 DOM 树中进行渲染。这样一来，页面首次渲染的 DOM 树所包含的节点数大幅度减少，从而有效提高了首次渲染速度。\n多个空格合并为一个空格 通过将多个空格合并为一个空格，可以减少 HTML 的大小，从而缩短传输 HTML 文件所需的时间。通常在编写 HTML 文件的时候，总是倾向于格式化它，以方便我们人类阅读，所以这个文件中填充了许多空格，但这些空格对于浏览器来说是用不到的。在替换空格的时候，需要保留 \u0026lt;pre\u0026gt;、\u0026lt;textarea\u0026gt;、\u0026lt;script\u0026gt;、\u0026lt;style\u0026gt; 中的空格。\n不过，如果你的网页中使用了 white-space: pre 这个 CSS 属性就要小心了，这个属性可以避免让多个空格压缩为一个，在实际开发网站的时候，其实也很少用到这个属性。如果确实需要，那么就放弃把 HTML 的多个空格合并为一个空格吧。\n\u0026lt;html\u0026gt; \u0026lt;head\u0026gt; \u0026lt;title\u0026gt;Hello, world! \u0026lt;/title\u0026gt; \u0026lt;script\u0026gt; var x = \u0026#39;Hello, world!\u0026#39;;\u0026lt;/script\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; Hello, World! \u0026lt;pre\u0026gt; Hello, World! \u0026lt;/pre\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; 转为：\n\u0026lt;html\u0026gt; \u0026lt;head\u0026gt; \u0026lt;title\u0026gt;Hello, world!\u0026lt;/title\u0026gt; \u0026lt;script\u0026gt; var x = \u0026#39;Hello, world!\u0026#39;;\u0026lt;/script\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; Hello, World! \u0026lt;pre\u0026gt; Hello, World! \u0026lt;/pre\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; 精简属性 \u0026lt;button\u0026gt; 按钮的 disabled 属性：\n\u0026lt;button name=\u0026#34;ok\u0026#34; disabled=\u0026#34;disabled\u0026#34;\u0026gt; 可以写为\n\u0026lt;button name=\u0026#34;ok\u0026#34; disabled\u0026gt; 而 \u0026lt;form\u0026gt; 表单：\n\u0026lt;form method=\u0026#34;get\u0026#34;\u0026gt; 可以写为：\n\u0026lt;form\u0026gt; 即许多 HTML 节点的属性都有默认值，如果指定的属性值等于默认属性的值，那么就可以移除掉。\n移除注释 如下的 HTML 片段带有注释，去除注释，可以减少 HTML 文件的体积：\n\u0026lt;i class=\u0026#34;service_ico\u0026#34;\u0026gt; \u0026lt;!-- 常态 icon --\u0026gt; \u0026lt;img class=\u0026#34;service_ico_img\u0026#34; src=\u0026#34;service_ico_img.png\u0026#34;/\u0026gt; \u0026lt;!-- hover 态 icon --\u0026gt; \u0026lt;img class=\u0026#34;service_ico_img_hover\u0026#34; src=\u0026#34;service_ico_img_hover.png\u0026#34;/\u0026gt; \u0026lt;/i\u0026gt; 移除引号 \u0026lt;html\u0026gt; \u0026lt;head\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;img src=\u0026#34;BikeCrashIcn.png\u0026#34; align=\u0026#39;left\u0026#39; alt=\u0026#34;\u0026#34; border=\u0026#34;0\u0026#34; width=\u0026#39;70\u0026#39; height=\u0026#39;30\u0026#39; \u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; 转变为\n\u0026lt;html\u0026gt; \u0026lt;head\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;img src=BikeCrashIcn.png align=left alt=\u0026#34;\u0026#34; border=0 width=70 height=30 \u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; 一方面去除了无关的引用，另外一方面也有利于 Gzip 算法的压缩。\n精简 URL 链接 如果 URL 的协议头与当前页面的协议头一致，那么可以删除协议头；在表达 URL 路径的时候，如果 HOST 与本网页一致，那么此 URL 也没必要使用绝对 URL 路径，使用相对 URL 路径即可。\n\u0026lt;html\u0026gt; \u0026lt;head\u0026gt; \u0026lt;base href=\u0026#34;http://www.example.com/\u0026#34;\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;a href=\u0026#34;http://www.example.com/bar\u0026#34;\u0026gt;Link with long URL\u0026lt;/a \u0026gt; \u0026lt;img src=\u0026#34;http://www.othersite.example.org/image.jpg\u0026#34;\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; 转变为：\n\u0026lt;html\u0026gt; \u0026lt;head\u0026gt; \u0026lt;base href=\u0026#34;http://www.example.com/\u0026#34;\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;a href=\u0026#34;bar\u0026#34;\u0026gt;Link with long URL\u0026lt;/a \u0026gt; \u0026lt;img src=\u0026#34;//www.othersite.example.org/image.jpg\u0026#34;\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; 参考  OptimizeHtml 《大型网站性能优化实战》  扫描下面二维码，在手机端阅读本文：\n"});index.add({'id':34,'href':'/docs/javascript/javascript-array/','title':"JavaScript 数组",'content':"JavaScript 数组 使用 JavaScript 在编程的时候，我们有很大一部分时间都是在与数组打交道，因此对数组常见的方法做到灵活的运用至关重要。本文整理了和 JavaScript 数组相关的，日常经常需要的功能和使用技巧，供大家参阅。\n从数组中移除指定元素 查阅 JavaScript 的数组 API，发现其并没有提供一个像 remove(obj) 或 removeAll(obj) 此类的方法，供我们方便的删除对象，因此我们需要通过使用其它的 API 来达到我们移出元素的目的。\n(1) 使用 splice 方法 splice 方法可以从指定索引处，向数组中添加元素或者删除元素，其会直接在原数组上改变，因此通过此方法可以达到我们的目的。但是在移除元素之前，我们必须首先通过 indexOf 方法找到我们的元素在数组中处于的索引位置。\nconst array = [2, 5, 9]; const index = array.indexOf(5); if (index \u0026gt; -1) { array.splice(index, 1); // 1 代表删除 1 个元素 } console.log(array) 当然，如果你不想使用 indexOf 的话，也可以直接从后向前遍历整个数组，对每个符合要求的元素都使用 splice 方法：\nconst array = [2, 5, 9]; for (var i = array.length; i--; ) { if (array[i] === 5) { array.splice(i, 1) } } console.log(array) 之所以需要从后向前移除，是因为在移除过程中，数组的 length 和 index 索引都是会改变的。\n(2) 使用 filter 方法 在 ES6 中，你可以使用 filter 函数遍历数组，对不符合元素值的对象进行过滤。filter 方法会返回一个新的数组，并不会直接在原数组上进行操作。\nlet value = 3; let array = [1, 2, 3, 4, 5, 3]; console.log(array.filter(item =\u0026gt; item !== value)) 如何遍历数组元素 JavaScript 数组提供了非常多的方法，这些方法都可以用来遍历数组：\n(1) 使用 forEach 方法 var a = [\u0026#34;a\u0026#34;, \u0026#34;b\u0026#34;, \u0026#34;c\u0026#34;]; a.forEach(function(entry) { console.log(entry) }) (2) 使用 for 遍历 var a = [\u0026#34;a\u0026#34;, \u0026#34;b\u0026#34;, \u0026#34;c\u0026#34;]; for (var index = 0; index \u0026lt; a.length; ++index) { console.log(a[index]) } (3) 使用 for 反向遍历 for (var i = array.length; i--; ) { // ... } 上述反向遍历的原理是：i-- 是属于测试条件的一部分，在每一次开始执行方法体之前，i 的值已经提前执行了 -- 这个操作了。当最后一次迭代，发现 i 等于 0 的时候，这个循环自然会停下来。\n(4) 使用 for-of 遍历 ES6 添加了迭代器的概念，当你使用 for-of 遍历的时候，其实已经隐形的在使用迭代器了：\nvar a = [\u0026#34;a\u0026#34;, \u0026#34;b\u0026#34;, \u0026#34;c\u0026#34;]; for (const val of a) { console.log(val); } (5) 不要使用 for-in 遍历 你或许听到过一些其它人的观点告诉你，使用 for-in 同样可以做到遍历数组。但是 for-in 是为了遍历对象用的，它并不保证按照数组的索引顺序来一一地遍历元素。所以在遍历数组的时候不推荐使用这种做法。\nfor (key in obj) { if (obj.hasOwnProperty(key)) { // ...  } } 如何清空数组 (1) 直接赋值一个空数组 如果你确实不在使用这个数组的话，也能保证其它地方没有引用这个数组，那么完全可以通过为其赋上一个新的空数组，从而置位空。\narr = [] (2) 将长度置为 0 arr.length = 0 (3) 使用 splice 方法 arr.splice(0, arr.length) (4) 使用 pop 方法 一一将元素 pop 出去，可能是最慢的一个方法了。\nwhile (arr.length) { arr.pop(); } 从头部插入元素 (1) 使用 unshift 方法  unshift 方法从头部插入一个元素到数组中 shift 方法从头部删除一个元素 push 方法从尾部插入一个元素到数组中 pop 方法从尾部删除一个元素  JavaScript 提供的从头部删除元素的方法名叫做 unshift，而不是叫做 insertAtHead 之类的，的确是在用到的时候不太容易想到这个名称。之所以这样命名，是因为 JavaScript 的数组的命名方式参考了 C 语言的栈的命名方式:\n array_unshift() array_shift() array_push() array_pop()  (2) 使用 concat 方法 concat() 方法可以用来连接两个数组：\nvar arr = [1, 2, 3, 4, 5, 6, 7]; console.log([0].concat(arr)); (3) 使用 Spread 操作符 在 ES6 中，可以使用 Spread 操作符 \u0026hellip; 来新增元素：\nvar arr = [23, 45, 12, 67]; arr = [34, ...arr]; 提前 break 数组循环 (1) 使用 Exception 对于 forEach 而言，使用 break 是不管用的，需要抛出异常强制终止循环，最好的建议是如果你需要 break 循环，在这种情况下就不要使用 forEach 来循环数组了：\nvar BreakException = {}; try { [1, 2, 3].forEach(function(el) { console.log(el); if (el === 2) throw BreakException; }); } catch (e) { if (e !== BreakException) throw e; } (2) 使用 for-of for (const [index, el] of arr.entries()) { if ( index === 5 ) break; } (3) 使用普通的循环 var array = [1, 2, 3]; for (var i = 0; i \u0026lt; array.length; i++) { if (array[i] === 1){ break; } } 数组去重 (1) 使用 filter 方法 var myArray = [\u0026#39;a\u0026#39;, 1, \u0026#39;a\u0026#39;, 2, \u0026#39;1\u0026#39;]; var unique = myArray.filter((value, index, arr) =\u0026gt; arr.indexOf(value) === index); (2) 使用 Set 构造器 var myArray = [\u0026#39;a\u0026#39;, 1, \u0026#39;a\u0026#39;, 2, \u0026#39;1\u0026#39;]; // unique = Array.from(new Set(myArray)) let unique = [...new Set(myArray)]; 参考  How do I remove a particular element from an array in JavaScript For-each over an array in JavaScript How do I empty an array in JavaScript How can I add new array elements at the beginning of an array in Javascript? Short circuit Array.forEach like calling break Get all unique values in a JavaScript array  扫描下面二维码，在手机端阅读：\n"});index.add({'id':35,'href':'/docs/tutorial/sentinel/leaparray/','title':"LeapArray",'content':"LeapArray Sentinel 底层采用高性能的滑动窗口数据结构 LeapArray 来统计实时的秒级指标数据，可以很好地支撑写多于读的高并发场景。\n主要数据结构 protected int windowLengthInMs; protected int sampleCount; protected int intervalInMs; protected final AtomicReferenceArray\u0026lt;WindowWrap\u0026lt;T\u0026gt;\u0026gt; array;  intervalInMs 代表滑动窗口的总时间长度 sampleCount 表示要将 intervalInMs 切割成多少份，也就是滑动窗口中有多少个 bucket windowLengthInMs 表示每一份代表多长时间 array 表示的是底层的数组，即这么多份 bucket 构成的数组  根据时间戳定位某个 Bucket （1）获取对应的索引\nlong timeId = timeMillis / windowLengthInMs; // Calculate current index so we can map the timestamp to the leap array. return (int)(timeId % array.length()); （2）计算当前 Bucket 开始的时间\nlong windowStart = timeMillis - timeMillis % windowLengthInMs; （3）如果此 Bucket 不存在，创建并 CAS 更新\nWindowWrap\u0026lt;T\u0026gt; old = array.get(idx); if (old == null) { /* * B0 B1 B2 NULL B4 * ||_______|_______|_______|_______|_______||___ * 200 400 600 800 1000 1200 timestamp * ^ * time=888 * bucket is empty, so create new and update * * If the old bucket is absent, then we create a new bucket at {@code windowStart}, * then try to update circular array via a CAS operation. Only one thread can * succeed to update, while other threads yield its time slice. */ WindowWrap\u0026lt;T\u0026gt; window = new WindowWrap\u0026lt;T\u0026gt;(windowLengthInMs, windowStart, newEmptyBucket(timeMillis)); if (array.compareAndSet(idx, null, window)) { // Successfully updated, return the created bucket.  return window; } } （4）如果存在，且 start 一致\nif (windowStart == old.windowStart()) { /* * B0 B1 B2 B3 B4 * ||_______|_______|_______|_______|_______||___ * 200 400 600 800 1000 1200 timestamp * ^ * time=888 * startTime of Bucket 3: 800, so it\u0026#39;s up-to-date * * If current {@code windowStart} is equal to the start timestamp of old bucket, * that means the time is within the bucket, so directly return the bucket. */ return old; } （5）如果存在，且原 start 已经落后\nif (windowStart \u0026gt; old.windowStart()) { /* * (old) * B0 B1 B2 NULL B4 * |_______||_______|_______|_______|_______|_______||___ * ... 1200 1400 1600 1800 2000 2200 timestamp * ^ * time=1676 * startTime of Bucket 2: 400, deprecated, should be reset * * If the start timestamp of old bucket is behind provided time, that means * the bucket is deprecated. We have to reset the bucket to current {@code windowStart}. * Note that the reset and clean-up operations are hard to be atomic, * so we need a update lock to guarantee the correctness of bucket update. * * The update lock is conditional (tiny scope) and will take effect only when * bucket is deprecated, so in most cases it won\u0026#39;t lead to performance loss. */ if (updateLock.tryLock()) { try { // Successfully get the update lock, now we reset the bucket.  return resetWindowTo(old, windowStart); } finally { updateLock.unlock(); } } } "});index.add({'id':36,'href':'/docs/tutorial/awk/patterns/','title':"Patterns",'content':"Patterns Patterns 控制是否执行 actions，只有当 pattern 匹配的时候，才会执行 action。\n本文介绍六种常用的 pattern：\n BEGIN { statements }：所有行处理之前执行一次 BEGIN END { statements }：所有行处理完了执行一次 END expression { statements }：普通的表达式 /正则表达式/ { statements }：匹配正则 组合表达式 { statements }：使用 \u0026amp;\u0026amp; 或 || 或 ! 进行组合 pattern1, pattern2 { statements }：范围匹配  BEGIN 和 END BEGIN 和 END 只会执行一次，BEGIN 是在开始执行前执行，END 是在结束前执行。\n一种常见的使用 BEGIN 的用法是改变默认的列分割符，列分割符默认被一个内置变量 FS 所控制，这个变量的默认值是空格或者tabs。如下示例在 BEGIN 中设置了 FS 为 \\t，同时打印了表头。在 END 块中打印了面积和人口的总和。\nBEGIN { FS = \u0026#34;\\t\u0026#34; printf(\u0026#34;%10s %6s %5s %s\\n\\n\u0026#34;, \u0026#34;COUNTRY\u0026#34;, \u0026#34;AREA\u0026#34;, \u0026#34;POP\u0026#34;, \u0026#34;CONTINENT\u0026#34;) } { printf(\u0026#34;%10s %6d %5d %s\\n\u0026#34;, $1, $2, $3, $4) area = area + $2 pop = pop + $3 } END { printf(\u0026#34;\\n%10s %6d %5d\\n\u0026#34;, \u0026#34;TOTAL\u0026#34;, area, pop) } expression 表达式示例：\n$3 / $2 \u0026gt;= 0.5 $0 \u0026gt;= \u0026#34;M\u0026#34; $1 \u0026lt; $4 可用的比较符号：\n ~ 和 !~ 是专门用于比较字符串的符号\n 如果表达式返回的是一个布尔值，那么根据此布尔值来决定是否匹配这一行；如果表达式返回的是一个数字，那么数字如果是非 0 数字，会匹配这一行；如果表达式返回的是一个字符串，那么非空字符串，会匹配这一行。\n当比较操作符的两个比较对象，均为数字，那么使用数字的比较原则进行大小比较；否则任何数字将会被转为字符串，使用字符串的方式按照 ASCII 顺序进行比较。\n"});index.add({'id':37,'href':'/docs/rocketmq/rocketmq-message-store-flow/','title':"RocketMQ 消息存储流程",'content':"RocketMQ 消息存储流程 本文讲述 RocketMQ 存储一条消息的流程。\n一、存储位置 当有一条消息过来之后，Broker 首先需要做的是确定这条消息应该存储在哪个文件里面。在 RocketMQ 中，这个用来存储消息的文件被称之为 MappedFile。这个文件默认创建的大小为 1GB。\n一个文件为 1GB 大小，也即 1024 * 1024 * 1024 = 1073741824 字节，这每个文件的命名是按照总的字节偏移量来命名的。例如第一个文件偏移量为 0，那么它的名字为 00000000000000000000；当当前这 1G 文件被存储满了之后，就会创建下一个文件，下一个文件的偏移量则为 1GB，那么它的名字为 00000000001073741824，以此类推。\n默认情况下这些消息文件位于 $HOME/store/commitlog 目录下，如下图所示:\n二、文件创建 当 Broker 启动的时候，其会将位于存储目录下的所有消息文件加载到一个列表中:\n当有新的消息到来的时候，其会默认选择列表中的最后一个文件来进行消息的保存:\npublic class MappedFileQueue { public MappedFile getLastMappedFile() { MappedFile mappedFileLast = null; while (!this.mappedFiles.isEmpty()) { try { mappedFileLast = this.mappedFiles.get(this.mappedFiles.size() - 1); break; } catch (IndexOutOfBoundsException e) { //continue;  } catch (Exception e) { log.error(\u0026#34;getLastMappedFile has exception.\u0026#34;, e); break; } } return mappedFileLast; } } 当然如果这个 Broker 之前从未接受过消息的话，那么这个列表肯定是空的。这样一旦有新的消息需要存储的时候，其就得需要立即创建一个 MappedFile 文件来存储消息。\nRocketMQ 提供了一个专门用来实例化 MappedFile 文件的服务类 AllocateMappedFileService。在内存中，也同时维护了一张请求表 requestTable 和一个优先级请求队列 requestQueue 。当需要创建文件的时候，Broker 会创建一个 AllocateRequest 对象，其包含了文件的路径、大小等信息。然后先将其放入 requestTable 表中，再将其放入优先级请求队列 requestQueue 中:\npublic class AllocateMappedFileService extends ServiceThread { public MappedFile putRequestAndReturnMappedFile(String nextFilePath, String nextNextFilePath, int fileSize) { // ...  AllocateRequest nextReq = new AllocateRequest(nextFilePath, fileSize); boolean nextPutOK = this.requestTable.putIfAbsent(nextFilePath, nextReq) == null; if (nextPutOK) { // ...  boolean offerOK = this.requestQueue.offer(nextReq); } } } 服务类会一直等待优先级队列是否有新的请求到来，如果有，便会从队列中取出请求，然后创建对应的 MappedFile，并将请求表 requestTable 中 AllocateRequest 对象的字段 mappedFile 设置上值。最后将 AllocateRequest 对象上的 CountDownLatch 的计数器减 1 ，以标明此分配申请的 MappedFile 已经创建完毕了:\npublic class AllocateMappedFileService extends ServiceThread { public void run() { // 一直运行  while (!this.isStopped() \u0026amp;\u0026amp; this.mmapOperation()) { } } private boolean mmapOperation() { req = this.requestQueue.take(); if (req.getMappedFile() == null) { MappedFile mappedFile; // ...  mappedFile = new MappedFile(req.getFilePath(), req.getFileSize()); // 设置上值  req.setMappedFile(mappedFile); } // ...  // 计数器减 1  req.getCountDownLatch().countDown(); // ...  return true; } } 其上述整体流程如下所示:\n等待 MappedFile 创建完毕之后，其便会从请求表 requestTable 中取出并删除表中记录:\npublic class AllocateMappedFileService extends ServiceThread { public MappedFile putRequestAndReturnMappedFile(String nextFilePath, String nextNextFilePath, int fileSize) { // ...  AllocateRequest result = this.requestTable.get(nextFilePath); if (result != null) { // 等待 MappedFile 的创建完成  boolean waitOK = result.getCountDownLatch().await(waitTimeOut, TimeUnit.MILLISECONDS); if (!waitOK) { return null; } else { // 从请求表中删除  this.requestTable.remove(nextFilePath); return result.getMappedFile(); } } } } 然后再将其放到列表中去:\npublic class MappedFileQueue { public MappedFile getLastMappedFile(final long startOffset, boolean needCreate) { MappedFile mappedFile = null; if (this.allocateMappedFileService != null) { // 创建 MappedFile  mappedFile = this.allocateMappedFileService .putRequestAndReturnMappedFile(nextFilePath, nextNextFilePath, this.mappedFileSize); } if (mappedFile != null) { // ...  // 添加至列表中  this.mappedFiles.add(mappedFile); } return mappedFile; } } 至此，MappedFile 已经创建完毕，也即可以进行下一步的操作了。\n三、文件初始化 在 MappedFile 的构造函数中，其使用了 FileChannel 类提供的 map 函数来将磁盘上的这个文件映射到进程地址空间中。然后当通过 MappedByteBuffer 来读入或者写入文件的时候，磁盘上也会有相应的改动。采用这种方式，通常比传统的基于文件 IO 流的方式读取效率高。\npublic class MappedFile extends ReferenceResource { public MappedFile(final String fileName, final int fileSize) throws IOException { init(fileName, fileSize); } private void init(final String fileName, final int fileSize) throws IOException { // ...  this.fileChannel = new RandomAccessFile(this.file, \u0026#34;rw\u0026#34;).getChannel(); this.mappedByteBuffer = this.fileChannel.map(MapMode.READ_WRITE, 0, fileSize); // ...  } } 四、消息文件加载 前面提到过，Broker 在启动的时候，会加载磁盘上的文件到一个 mappedFiles 列表中。但是加载完毕后，其还会对这份列表中的消息文件进行验证 (恢复)，确保没有错误。\n验证的基本想法是通过一一读取列表中的每一个文件，然后再一一读取每个文件中的每个消息，在读取的过程中，其会更新整体的消息写入的偏移量，如下图中的红色箭头 (我们假设最终读取的消息的总偏移量为 905):\n当确定消息整体的偏移量之后，Broker 便会确定每一个单独的 MappedFile 文件的各自的偏移量，每一个文件的偏移量是通过取余算法确定的:\npublic class MappedFileQueue { public void truncateDirtyFiles(long offset) { for (MappedFile file : this.mappedFiles) { long fileTailOffset = file.getFileFromOffset() + this.mappedFileSize; if (fileTailOffset \u0026gt; offset) { if (offset \u0026gt;= file.getFileFromOffset()) { // 确定每个文件的各自偏移量  file.setWrotePosition((int) (offset % this.mappedFileSize)); file.setCommittedPosition((int) (offset % this.mappedFileSize)); file.setFlushedPosition((int) (offset % this.mappedFileSize)); } else { // ...  } } } // ...  } } 在确定每个消息文件各自的写入位置的同时，其还会删除起始偏移量大于当前总偏移量的消息文件，这些文件可以视作脏文件，或者也可以说这些文件里面一条消息也没有。这也是上述文件 1073741824 被打上红叉的原因:\npublic void truncateDirtyFiles(long offset) { List\u0026lt;MappedFile\u0026gt; willRemoveFiles = new ArrayList\u0026lt;MappedFile\u0026gt;(); for (MappedFile file : this.mappedFiles) { long fileTailOffset = file.getFileFromOffset() + this.mappedFileSize; if (fileTailOffset \u0026gt; offset) { if (offset \u0026gt;= file.getFileFromOffset()) { // ...  } else { // 总偏移量 \u0026lt; 文件起始偏移量  // 加入到待删除列表中  file.destroy(1000); willRemoveFiles.add(file); } } } this.deleteExpiredFile(willRemoveFiles); } 五、写入消息 一旦我们获取到 MappedFile 文件之后，我们便可以往这个文件里面写入消息了。写入消息可能会遇见如下两种情况，一种是这条消息可以完全追加到这个文件中，另外一种是这条消息完全不能或者只有一小部分只能存放到这个文件中，其余的需要放到新的文件中。我们对于这两种情况分别讨论:\n(1) 文件可以完全存储消息 MappedFile 类维护了一个用以标识当前写位置的指针 wrotePosition，以及一个用来映射文件到进程地址空间的 mappedByteBuffer:\npublic class MappedFile extends ReferenceResource { protected final AtomicInteger wrotePosition = new AtomicInteger(0); private MappedByteBuffer mappedByteBuffer; } 由这两个数据结构我们可以看出来，单个文件的消息写入过程其实是非常简单的。首先获取到这个文件的写入位置，然后将消息内容追加到 byteBuffer 中，然后再更新写入位置。\npublic class MappedFile extends ReferenceResource { public AppendMessageResult appendMessagesInner(final MessageExt messageExt, final AppendMessageCallback cb) { // ...  int currentPos = this.wrotePosition.get(); if (currentPos \u0026lt; this.fileSize) { ByteBuffer byteBuffer = writeBuffer != null ? writeBuffer.slice() : this.mappedByteBuffer.slice(); // 更新 byteBuffer 位置  byteBuffer.position(currentPos); // 写入消息内容  // ...  // 更新 wrotePosition 指针的位置  this.wrotePosition.addAndGet(result.getWroteBytes()); return result; } } } 示例流程如下所示:\n(2) 文件不可以完全存储消息 在写入消息之前，如果判断出文件已经满了的情况下，其会直接尝试创建一个新的 MappedFile:\npublic class CommitLog { public PutMessageResult putMessage(final MessageExtBrokerInner msg) { // 文件为空 || 文件已经满了  if (null == mappedFile || mappedFile.isFull()) { mappedFile = this.mappedFileQueue.getLastMappedFile(0); } // ...  result = mappedFile.appendMessage(msg, this.appendMessageCallback); } } 如果文件未满，那么在写入之前会先计算出消息体长度 msgLen，然后判断这个文件剩下的空间是否有能力容纳这条消息。在这个地方我们还需要介绍下每条消息的存储方式。\n每条消息的存储是按照一个 4 字节的长度来做界限的，这个长度本身就是整个消息体的长度，当读完这整条消息体的长度之后，下一次再取出来的一个 4 字节的数字，便又是下一条消息的长度:\n围绕着一条消息，还会存储许多其它内容，我们在这里只需要了解前两位是 4 字节的长度和 4 字节的 MAGICCODE 即可:\nMAGICCODE 的可选值有:\n CommitLog.MESSAGE_MAGIC_CODE CommitLog.BLANK_MAGIC_CODE  当这个文件有能力容纳这条消息体的情况下，其便会存储 MESSAGE_MAGIC_CODE 值；当这个文件没有能力容纳这条消息体的情况下，其便会存储 BLANK_MAGIC_CODE 值。所以这个 MAGICCODE 是用来界定这是空消息还是一条正常的消息。\n当判定这个文件不足以容纳整个消息的时候，其将消息体长度设置为这个文件剩余的最大空间长度，将 MAGICCODE 设定为这是一个空消息文件 (需要去下一个文件去读)。由此我们可以看出消息体长度 和 MAGICCODE 是判别一条消息格式的最基本要求，这也是 END_FILE_MIN_BLANK_LENGTH 的值为 8 的原因:\n// CommitLog.java class DefaultAppendMessageCallback implements AppendMessageCallback { // File at the end of the minimum fixed length empty  private static final int END_FILE_MIN_BLANK_LENGTH = 4 + 4; public AppendMessageResult doAppend(final long fileFromOffset, final ByteBuffer byteBuffer, final int maxBlank, final MessageExtBrokerInner msgInner) { // ...  if ((msgLen + END_FILE_MIN_BLANK_LENGTH) \u0026gt; maxBlank) { // ...  // 1 TOTALSIZE  this.msgStoreItemMemory.putInt(maxBlank); // 2 MAGICCODE  this.msgStoreItemMemory.putInt(CommitLog.BLANK_MAGIC_CODE); // 3 The remaining space may be any value  byteBuffer.put(this.msgStoreItemMemory.array(), 0, maxBlank); return new AppendMessageResult(AppendMessageStatus.END_OF_FILE, /** other params **/ ); } } } 由上述方法我们看出在这种情况下返回的结果是 END_OF_FILE。当检测到这种返回结果的时候，CommitLog 接着又会申请创建新的 MappedFile 并尝试写入消息。追加方法同 (1) 相同，不再赘述:\n 注: 在消息文件加载的过程中，其也是通过判断 MAGICCODE 的类型，来判断是否继续读取下一个 MappedFile 来计算整体消息偏移量的。\n 六、消息刷盘策略 当消息体追加到 MappedFile 以后，这条消息实际上还只是存储在内存中，因此还需要将内存中的内容刷到磁盘上才算真正的存储下来，才能确保消息不丢失。一般而言，刷盘有两种策略: 异步刷盘和同步刷盘。\n(1) 异步刷盘 当配置为异步刷盘策略的时候，Broker 会运行一个服务 FlushRealTimeService 用来刷新缓冲区的消息内容到磁盘，这个服务使用一个独立的线程来做刷盘这件事情，默认情况下每隔 500ms 来检查一次是否需要刷盘:\nclass FlushRealTimeService extends FlushCommitLogService { public void run() { // 不停运行  while (!this.isStopped()) { // interval 默认值是 500ms  if (flushCommitLogTimed) { Thread.sleep(interval); } else { this.waitForRunning(interval); } // 刷盘  CommitLog.this.mappedFileQueue.flush(flushPhysicQueueLeastPages); } } } 在追加消息完毕之后，通过唤醒这个服务立即检查以下是否需要刷盘:\npublic class CommitLog { public void handleDiskFlush(AppendMessageResult result, PutMessageResult putMessageResult, MessageExt messageExt) { // Synchronization flush  if (FlushDiskType.SYNC_FLUSH == this.defaultMessageStore.getMessageStoreConfig().getFlushDiskType()) { // ...  } // Asynchronous flush  else { if (!this.defaultMessageStore.getMessageStoreConfig().isTransientStorePoolEnable()) { // 消息追加成功后，立即唤醒服务  flushCommitLogService.wakeup(); } else { // ...  } } } } (2) 同步刷盘 当配置为同步刷盘策略的时候，Broker 运行一个叫做 GroupCommitService 服务。在这个服务内部维护了一个写请求队列和一个读请求队列，其中这两个队列每隔 10ms 就交换一下“身份”，这么做的目的其实也是为了读写分离:\n在这个服务内部，每隔 10ms 就会检查读请求队列是否不为空，如果不为空，则会将读队列中的所有请求执行刷盘，并清空读请求队列:\nclass GroupCommitService extends FlushCommitLogService { private void doCommit() { // 检查所有读队列中的请求  for (GroupCommitRequest req : this.requestsRead) { // 每个请求执行刷盘  CommitLog.this.mappedFileQueue.flush(0); req.wakeupCustomer(flushOK); } this.requestsRead.clear(); } } 在追加消息完毕之后，通过创建一个请求刷盘的对象，然后通过 putRequest() 方法放入写请求队列中，这个时候会立即唤醒这个服务，写队列和读队列的角色会进行交换，交换角色之后，读请求队列就不为空，继而可以执行所有刷盘请求了。而在这期间，Broker 会一直阻塞等待最多 5 秒钟，在这期间如果完不成刷盘请求的话，那么视作刷盘超时:\npublic class CommitLog { public void handleDiskFlush(AppendMessageResult result, PutMessageResult putMessageResult, MessageExt messageExt) { // Synchronization flush  if (FlushDiskType.SYNC_FLUSH == this.defaultMessageStore.getMessageStoreConfig().getFlushDiskType()) { // ...  if (messageExt.isWaitStoreMsgOK()) { GroupCommitRequest request = new GroupCommitRequest(result.getWroteOffset() + result.getWroteBytes()); service.putRequest(request); // 等待刷盘成功  boolean flushOK = request.waitForFlush(this.defaultMessageStore.getMessageStoreConfig().getSyncFlushTimeout()); if (!flushOK) { // 刷盘超时  putMessageResult.setPutMessageStatus(PutMessageStatus.FLUSH_DISK_TIMEOUT); } } else { // ...  } } // Asynchronous flush  else { // ...  } } } 通过方法 putRequest 放入请求后的服务执行流程:\n七、消息刷盘理念 我们在这里已经知道消息刷盘有同步刷盘和异步刷盘策略，对应的是 GroupCommitService 和 FlushRealTimeService 这两种不同的服务。\n这两种服务都有定时请求刷盘的机制，但是机制背后最终调用的刷盘方式全部都集中在 flush 这个方法上:\npublic class MappedFileQueue { public boolean flush(final int flushLeastPages) { // ...  } } 再继续向下分析这个方法之前，我们先对照着这张图说明一下使用 MappedByteBuffer 来简要阐述读和写文件的简单过程：\n操作系统为了能够使多个进程同时使用内存，又保证各个进程访问内存互相独立，于是为每个进程引入了地址空间的概念，地址空间上的地址叫做虚拟地址，而程序想要运行必须放到物理地址上运行才可以。地址空间为进程营造出了一种假象：”整台计算机只有我一个程序在运行，这台计算机内存很大”。一个地址空间内包含着这个进程所需要的全部状态信息。通常一个进程的地址空间会按照逻辑分成好多段，比如代码段、堆段、栈段等。为了进一步有效利用内存，每一段又细分成了不同的页 (page)。与此相对应，计算机的物理内存被切成了页帧 (page frame)，文件被分成了块 (block)。既然程序实际运行的时候还是得依赖物理内存的地址，那么就需要将虚拟地址转换为物理地址，这个映射关系是由**页表 (page table)**来完成的。\n另外在操作系统中，还有一层磁盘缓存 (disk cache)的概念，它主要是用来减少对磁盘的 I/O 操作。磁盘缓存是以页为单位的，内容就是磁盘上的物理块，所以又称之为页缓存 (page cache)。当进程发起一个读操作 （比如，进程发起一个 read() 系统调用），它首先会检查需要的数据是否在页缓存中。如果在，则放弃访问磁盘，而直接从页缓存中读取。如果数据没在缓存中，那么内核必须调度块 I/O 操作从磁盘去读取数据，然后将读来的数据放入页缓存中。系统并不一定要将整个文件都缓存，它可以只存储一个文件的一页或者几页。\n如图所示，当调用 FileChannel.map() 方法的时候，会将这个文件映射进用户空间的地址空间中，注意，建立映射不会拷贝任何数据。我们前面提到过 Broker 启动的时候会有一个消息文件加载的过程，当第一次开始读取数据的时候:\n// 首次读取数据 int totalSize = byteBuffer.getInt(); 这个时候，操作系统通过查询页表，会发现文件的这部分数据还不在内存中。于是就会触发一个缺页异常 (page faults)，这个时候操作系统会开始从磁盘读取这一页数据，然后先放入到页缓存中，然后再放入内存中。在第一次读取文件的时候，操作系统会读入所请求的页面，并读入紧随其后的少数几个页面（不少于一个页面，通常是三个页面），这时的预读称为同步预读 (如下图所示，红色部分是需要读取的页面，蓝色的那三个框是操作系统预先读取的):\n当然随着时间推移，预读命中的话，那么相应的预读页面数量也会增加，但是能够确认的是，一个文件至少有 4 个页面处在页缓存中。当文件一直处于顺序读取的情况下，那么基本上可以保证每次预读命中:\n下面我们来说文件写，正常情况下，当尝试调用 writeInt() 写数据到文件里面的话，其写到页缓存层，这个方法就会返回了。这个时候数据还没有真正的保存到文件中去，Linux 仅仅将页缓存中的这一页数据标记为“脏”，并且被加入到脏页链表中。然后由一群进程（flusher 回写进程）周期性将脏页链表中的页写会到磁盘，从而让磁盘中的数据和内存中保持一致，最后清理“脏”标识。在以下三种情况下，脏页会被写回磁盘:\n 空闲内存低于一个特定阈值 脏页在内存中驻留超过一个特定的阈值时 当用户进程调用 sync() 和 fsync() 系统调用时  可见，在正常情况下，即使不采用刷盘策略，数据最终也是会被同步到磁盘中去的:\n但是，即便有 flusher 线程来定时同步数据，如果此时机器断电的话，消息依然有可能丢失。RocketMQ 为了保证消息尽可能的不丢失，为了最大的高可靠性，做了同步和异步刷盘策略，来手动进行同步:\n八、消息刷盘过程 在介绍完上述消息刷盘背后的一些机制和理念后，我们再来分析刷盘整个过程。首先，无论同步刷盘还是异步刷盘，其线程都在一直周期性的尝试执行刷盘，在真正执行刷盘函数的调用之前，Broker 会检查文件的写位置是否大于 flush 位置，避免执行无意义的刷盘：\n其次，对于异步刷盘来讲，Broker 执行了更为严格的刷盘限制策略，当在某个时间点尝试执行刷盘之后，在接下来 10 秒内，如果想要继续刷盘，那么脏页面数量必须不小于 4 页，如下图所示:\n下面是执行刷盘前最后检查的刷盘条件：\npublic class MappedFile extends ReferenceResource { private boolean isAbleToFlush(final int flushLeastPages) { int flush = this.flushedPosition.get(); int write = getReadPosition(); if (this.isFull()) { return true; } if (flushLeastPages \u0026gt; 0) { // 计算当前脏页面算法  return ((write / OS_PAGE_SIZE) - (flush / OS_PAGE_SIZE)) \u0026gt;= flushLeastPages; } // wrotePosition \u0026gt; flushedPosition  return write \u0026gt; flush; } } 当刷盘完毕之后，首先会更新这个文件的 flush 位置，然后再更新 MappedFileQueue 的整体的 flush 位置:\n当刷盘完毕之后，便会将结果通知给客户端，告知发送消息成功。至此，整个存储过程完毕。\n扫描下面二维码，在手机端阅读：\n"});index.add({'id':38,'href':'/docs/it-zone/2020-06/rust-enter-top-20/','title':"Rust 语言首次进入 Tiobe 前 20 名",'content':"Rust 语言首次进入 Tiobe 前 20 名 日期：2020-06-02\n Rust 在 Tiobe 上的排名已大大提高，从去年的38位上升到今天的20位。Tiobe 的索引基于主要搜索引擎上对某种语言的搜索，因此这并不意味着更多的人正在使用 Rust，但是它表明更多的开发人员正在搜索有关该语言的信息。\n在 Stack Overflow 的2020年调查中， Rust 被开发人员连续第五年票选为最受欢迎的编程语言。今年，有86％的开发人员表示他们热衷于使用Rust，但只有5％的开发人员实际将其用于编程。\n另一方面，由于Microsoft已公开预览其针对Windows运行时（WinRT）的 Rust 库，因此它可能会得到更广泛的使用 ，这使开发人员可以更轻松地在Rust中编写Windows，跨平台应用程序和驱动程序。\nTiobe软件首席执行官Paul Jansen说，Rust的崛起是因为它是一种“正确的”系统编程语言。\n然而，Rust 项目的2020年开发人员调查发现，由于其陡峭的学习曲线以及很少有公司使用它，用户难以采用该语言。 Google 在新的Fuchsia OS 排除了 Rust 语言，因为很少有开发人员对此感到熟悉。\n"});index.add({'id':39,'href':'/docs/tutorial/unix-command/','title':"UNIX 常用命令大全",'content':"UNIX 常用命令大全  grep find ls ssh top cat  "});index.add({'id':40,'href':'/docs/books/history_of_quantum_physics/','title':"上帝掷骰子吗",'content':"上帝掷骰子吗-量子物理史话 1887年德国，赫兹在实验室证实了电磁波的存在，也证实了光其实是电磁波的一种，两者具有共同的波的特性，古老的光学终于可以被完全包容于新兴的电磁学里面。1901年，赫兹死后的第 7 年，无线电报已经可以穿越大西洋，实现两地的实时通讯了。\n赫兹铜环接收器的缺口之间不停地爆发着电火花，明白无误地昭示着电磁波的存在。但偶然间，赫兹又发现了一个奇怪的现象：当有光照射到这个缺口上的时候，似乎火花就出现得更容易一些。\n 量子就是能量的最小单位，就是能量里的一美分。一切能量的传输，都只能以这个量为单位来进行，它可以传输一个量子，两个量子，任意整数个量子，但却不能传输1 又1/2 个量子，那个状态是不允许的，就像你不能用现钱支付1 又1/2 美分一样。这个值，现在已经成为了自然科学中最为 重要的常数之一，以它的发现者命名，称为“普朗克常数”，用 h 来表示。\n在后来十几年的时间里，普朗克一直认为量子的假设并不是一个物理真实，而纯粹是一个为了方便而引入的假设而已。他不断地告诫人们，在引用普朗克常数 h 的时候，要尽量小心谨慎，不到万不得已千万不要胡思乱想。\n"});index.add({'id':41,'href':'/docs/tutorial/git/create-repository/','title':"创建 Git 仓库",'content':"创建 Git 仓库 （1）已有项目使用 Git 管理\n假设你的项目所在文件夹叫做：abc_project\ncd abc_project git init （2）新建项目直接使用 Git 管理\n假设新建的项目名为 xxx_project\ngit init xxx_project "});index.add({'id':42,'href':'/docs/cloud-plus-bbs/suikang-mini-program-design/','title':"穗康小程序口罩预约前后端架构及产品设计",'content':"穗康小程序口罩预约前后端架构及产品设计 在战“疫”期间，腾讯与广州市政府合作，在小程序“穗康”上，2天内上线了全国首款口罩预约功能，上线首日访问量1.7亿，累计参与口罩预约人次1400万+。那么，它是如何在2天内开发上线，扛住了超大并发量呢？其背后的前后端架构是怎样的？\n无损服务设计 整个流程下来需要 3 个实时接口：\n 药店当前口罩的库存情况 哪个时间段有名额 提交预约实时返回结果  有损服务设计 结果，口罩预约关注度远超预期：\n下面展示的 UI 的设计：\n为什么有 “损” 平衡的理论就是 CAP 理论、BASE 最终一致性：\n牺牲强一致换取高可用 两个机房需要同步，并发性差。以下是优化后的代码，引入计时器：\n降低了专线依赖。\n怎么 \u0026ldquo;损\u0026rdquo;  放弃绝对一致，追求高可用和快速响应 万有一失，用户重试 伸缩调度，降级服务  （1）穗康小程序 引入消息队列，最终一致：\n（2）QQ 相册负载高 选择扩容？带宽和存储成本高。\n（3）转账 用户重试极少量消息。再想一下微信的红色感叹号，点一下重新发送。\n（4）穗康的预约重试 （5）QQ 相册降级 "});index.add({'id':43,'href':'/docs/hire/','title':"👉招聘",'content':"👉招聘 收录全网最新互联网公司校园招聘、社会招聘！每日更新！更多招聘、咨询等事宜请联系 igozhaokun@163.com 👍👍👍\n私企 阿里巴巴  阿里巴巴2021届毕业生招聘正式启动！  腾讯  【2020.08.06 - 2020.09.16】腾讯2021校园招聘全球启动 微信事业群2021校园招聘正式启动！  百度  【2020.10.09 截止】百度2021校园招聘正式启动  华为  华为2021届应届生招聘启动  字节跳动  【2020.10.31 截止】字节跳动2021校园招聘正式启动！  美团点评  【2020.10.16 截止】美团2021届秋季校园招聘全面启动  滴滴  【2020.08.03 - 2020.09.20】滴滴2021届校招正式开启！快来加入旅程~  快手  快手2021校园招聘启动  京东  【09.15 截止】京东2021校园招聘燃力开启！  网易  【2020.08.05 - 2020.09.07】2021届网易互联网校招全面开启！  小米  【12月底截止】小米集团2021全球校园招聘全面开启！  拼多多  【08.30 截止】拼多多2021届校招提前批正式启动！  哔哩哔哩  【11月中旬截止】哔哩哔哩2021秋季校园招聘正式启动！  搜狐  【09.30 截止】搜狐集团2021校园招聘正式启动  搜狗  搜狗2021校园招聘网申全面开放！  新浪 \u0026amp; 微博  【09.09 截止】新浪\u0026amp;微博2021届校园招聘正式启动！  外企 亚马逊  亚马逊中国2021校园招聘正式启动！  微软  【08.12 - 09.16】微软2021校园招聘正式启动  FreeWheel  Software Engineer - 2021 Campus-北京-00763  🏦银行 中国农业银行研发中心  中国农业银行研发中心2021年校园招聘启事 中国农业银行研发中心2020年社会招聘启事  中国交通银行  交行总行金融科技板块2021校园招聘  "});index.add({'id':44,'href':'/posts/consistency-problem-of-the-distrubuted-system/','title':"分布式系统一致性问题",'content':"描述解决分布式系统一致性问题的典型思路!\n一致性问题 思考下面几个分布式系统中可能存在的一致性问题:\n (1) 先下订单还是先扣库存?下订单成功扣库存失败则超卖;下订单失败扣库存成功则多卖。 (2) 系统 A 同步调用系统 B 服务超时后，这个时候系统 A 应该做什么? (3) 系统 B 异步回调系统 A 超时后，系统 A 迟迟没有收到回调结果怎么办? (4) 某个订单在系统 A 中能查询到，但是系统 B 中不存在。 (5) 系统间都存在请求，只是状态不一致。 (6) 交易系统依赖于数据库的 ACID，缓存和数据库之间如何保持一致性?强一致性还是弱一致性? (7) 多个节点上缓存的内容不一致怎么办?请求恰好在这个时间窗口进来了。 (8) 缓存数据结构不一致。某个数据由多个数据元素组成，如果其中某个子数据依赖于从其它服务中获取数据，假设这部分数据获取失败，那么就会导致数据不完整，可能会出现 NullPointerException 等。  酸碱平衡理论 ACID 具有 ACID 特性的数据库支持强一致性。这意味着每个事务都是原子的，或者成功或者失败，事物间是隔离的，互相完全不受影响，而且最终状态是持久落盘的。Oracle、MySQL、DB2 都能保证强一致性。一般而言，强一致性通常是通过多版本控制协议 (MVCC) 来实现的。\n交易系统只考虑: 关系型数据库 + 强悍硬件。 NoSQL完全不适合交易场景，一般用来作数据分析、ETL、报表、数据挖掘、推荐、日志处理、调用链分析等非核心交易场景。 ACID 是数据库事务完整性的理论。\nCAP 分布式系统设计理论  C (Consistency): A read is guaranteed to return the most recent write for a given client. 读操作保证能够返回最新的写操作结果。 A (Availability): A non-failing node will return a reasonable response within a reasonable amount of time (no error or no timeout). 合理时间返回合理响应。 P (Partition Tolerance): The system will continue to function when network partitions occur. 当出现网络分区后，系统能够继续“履行职责”。 虽然 CAP 理论定义是三个要素中只能取两个，但放到分布式环境下来思考，我们会发现必须选择 P（分区容忍）要素，因为网络本身无法做到 100% 可靠，有可能出故障，所以分区是一个必然的现象。如果我们选择了 CA 而放弃了 P，那么当发生分区现象时，为了保证 C，系统需要禁止写入，当有写入请求时，系统返回 error（例如，当前系统不允许写入），这又和 A 冲突了，因为 A 要求返回 no error 和 no timeout。因此，分布式系统理论上不可能选择 CA 架构，只能选择 CP 或者 AP 架构。  1.CP - Consistency/Partition Tolerance\n如下图所示，为了保证一致性，当发生分区现象后，N1 节点上的数据已经更新到 y，但由于 N1 和 N2 之间的复制通道中断，数据 y 无法同步到 N2，N2 节点上的数据还是 x。这时客户端 C 访问 N2 时，N2 需要返回 Error，提示客户端 C“系统现在发生了错误”，这种处理方式违背了可用性（Availability）的要求，因此 CAP 三者只能满足 CP。\n2.AP - Availability/Partition Tolerance\n如下图所示，为了保证可用性，当发生分区现象后，N1 节点上的数据已经更新到 y，但由于 N1 和 N2 之间的复制通道中断，数据 y 无法同步到 N2，N2 节点上的数据还是 x。这时客户端 C 访问 N2 时，N2 将当前自己拥有的数据 x 返回给客户端 C 了，而实际上当前最新的数据已经是 y 了，这就不满足一致性（Consistency）的要求了，因此 CAP 三者只能满足 AP。注意：这里 N2 节点返回 x，虽然不是一个“正确”的结果，但是一个“合理”的结果，因为 x 是旧的数据，并不是一个错乱的值，只是不是最新的数据而已。\nBASE - CAP 理论中 AP 方案的延伸  BA (Basically Available): 出现故障时，允许损失部分可用性，保证核心可用，例如登录功能大于注册功能。 S (Soft State): 允许存在中间状态，中间状态不会影响系统整体可用性。 E (Eventual Consistency): 所有数据副本经过一段时间后，最终能够达到一致的状态。  牺牲强一致性而获得可用性，一般应用于服务化系统的应用层或者大数据处理系统中，通过达到最终一致性来尽量满足业务的绝大多数需求。由于不保证强一致性，因此系统在处理请求的过程中可以存在短暂的不一致，在这个时间窗口内，请求的每一步操作，都需要记录下来，以便在出现故障的时候可以从这些中间状态恢复过来。\n下面是解决一致性问题的三条实践经验:\n 单个数据库能够保证强一致性 将数据库进行水平伸缩和分片，相关数据分到数据库的同一个片上 记录每一步操作  CAP 理论实践 CAP 关注的粒度是数据，而不是整个系统 在实际设计过程中，每个系统不可能只处理一种数据，而是包含多种类型的数据，有的数据必须选择 CP，有的数据必须选择 AP。而如果我们做设计时，从整个系统的角度去选择 CP 还是 AP，就会发现顾此失彼，无论怎么做都是有问题的。\n以一个最简单的用户管理系统为例，用户管理系统包含用户账号数据（用户 ID、密码）、用户信息数据（昵称、兴趣、爱好、性别、自我介绍等）。通常情况下，用户账号数据会选择 CP，而用户信息数据会选择 AP，如果限定整个系统为 CP，则不符合用户信息数据的应用场景；如果限定整个系统为 AP，则又不符合用户账号数据的应用场景。\n所以在 CAP 理论落地实践时，我们需要将系统内的数据按照不同的应用场景和要求进行分类，每类数据选择不同的策略（CP 还是 AP），而不是直接限定整个系统所有数据都是同一策略。\nCAP 是忽略网络延迟的 这是一个非常隐含的假设，布鲁尔在定义一致性时，并没有将延迟考虑进去。也就是说，当事务提交时，数据能够瞬间复制到所有节点。但实际情况下，从节点 A 复制数据到节点 B，总是需要花费一定时间的。如果是相同机房，耗费时间可能是几毫秒；如果是跨地域的机房，例如北京机房同步到广州机房，耗费的时间就可能是几十毫秒。这就意味着，CAP 理论中的 C 在实践中是不可能完美实现的，在数据复制的过程中，节点 A 和节点 B 的数据并不一致。\n不要小看了这几毫秒或者几十毫秒的不一致，对于某些严苛的业务场景，例如和金钱相关的用户余额，或者和抢购相关的商品库存，技术上是无法做到分布式场景下完美的一致性的。而业务上必须要求一致性，因此单个用户的余额、单个商品的库存，理论上要求选择 CP 而实际上 CP 都做不到，只能选择 CA。也就是说，只能单点写入，其他节点做备份，无法做到分布式情况下多点写入。\n需要注意的是，这并不意味着这类系统无法应用分布式架构，只是说“单个用户余额、单个商品库存”无法做分布式，但系统整体还是可以应用分布式架构的。例如，下面的架构图是常见的将用户分区的分布式架构:\n我们可以将用户 id 为 0 ~ 100 的数据存储在 Node 1，将用户 id 为 101 ~ 200 的数据存储在 Node 2，Client 根据用户 id 来决定访问哪个 Node。对于单个用户来说，读写操作都只能在某个节点上进行；对所有用户来说，有一部分用户的读写操作在 Node 1 上，有一部分用户的读写操作在 Node 2 上。\n这样的设计有一个很明显的问题就是某个节点故障时，这个节点上的用户就无法进行读写操作了，但站在整体上来看，这种设计可以降低节点故障时受影响的用户的数量和范围，毕竟只影响 20% 的用户肯定要比影响所有用户要好。这也是为什么挖掘机挖断光缆后，支付宝只有一部分用户会出现业务异常，而不是所有用户业务异常的原因。\n正常运行情况下，不存在 CP 和 AP 的选择，可以同时满足 CA CAP 理论告诉我们分布式系统只能选择 CP 或者 AP，但其实这里的前提是系统发生了“分区”现象。如果系统没有发生分区现象，也就是说 P 不存在的时候（节点间的网络连接一切正常），我们没有必要放弃 C 或者 A，应该 C 和 A 都可以保证，这就要求架构设计的时候既要考虑分区发生时选择 CP 还是 AP，也要考虑分区没有发生时如何保证 CA。\n同样以用户管理系统为例，即使是实现 CA，不同的数据实现方式也可能不一样：用户账号数据可以采用“消息队列”的方式来实现 CA，因为消息队列可以比较好地控制实时性，但实现起来就复杂一些；而用户信息数据可以采用“数据库同步”的方式来实现 CA，因为数据库的方式虽然在某些场景下可能延迟较高，但使用起来简单。\n放弃并不等于什么都不做，需要为分区恢复后做准备 我们可以在分区期间进行一些操作，从而让分区故障解决后，系统能够重新达到 CA 的状态。\n最典型的就是在分区期间记录一些日志，当分区故障解决后，系统根据日志进行数据恢复，使得重新达到 CA 状态。同样以用户管理系统为例，对于用户账号数据，假设我们选择了 CP，则分区发生后，节点 1 可以继续注册新用户，节点 2 无法注册新用户（这里就是不符合 A 的原因，因为节点 2 收到注册请求后会返回 error），此时节点 1 可以将新注册但未同步到节点 2 的用户记录到日志中。当分区恢复后，节点 1 读取日志中的记录，同步给节点 2，当同步完成后，节点 1 和节点 2 就达到了同时满足 CA 的状态。\n而对于用户信息数据，假设我们选择了 AP，则分区发生后，节点 1 和节点 2 都可以修改用户信息，但两边可能修改不一样。例如，用户在节点 1 中将爱好改为“旅游、美食、跑步”，然后用户在节点 2 中将爱好改为“美食、游戏”，节点 1 和节点 2 都记录了未同步的爱好数据，当分区恢复后，系统按照某个规则来合并数据。例如，按照“最后修改优先规则”将用户爱好修改为“美食、游戏”，按照“字数最多优先规则”则将用户爱好修改为“旅游，美食、跑步”，也可以完全将数据冲突报告出来，由人工来选择具体应该采用哪一条。\n分布式一致性协议 两阶段提交协议 二阶段提交的算法思路可以概括为：协调者询问参与者是否准备好了提交，并根据所有参与者的反馈情况决定向所有参与者发送 commit 或者 rollback 指令（协调者向所有参与者发送相同的指令）。\n三阶段提交协议 三阶段提交协议是两阶段提交协议的改进版本。它通过超时机制解决了阻塞的问题，并且把两个阶段增加为三个阶段。\n不同点:\n 增加询问阶段:尽可能早地发现无法执行操作而需要中止的行为。 准备阶段以后，协调者和参与者执行任务中都增加了超时，一旦超时，则协调者和参与者都会继续提交事务，默认为成功，这也是根据概率统计超时后默认为成功的正确性最大。  存在问题:\n 在 doCommit 阶段，如果参与者没有及时接收到来自协调者的 doCommit 或者 rebort 请求时，会在等待超时之后，会继续进行事务的提交。所以，由于网络原因，协调者发送的 abort 响应没有及时被参与者接收到，那么参与者在等待超时之后执行了 commit 操作。这样就和其他接到 abort 命令并执行回滚的参与者之间存在数据不一致的情况。  TCC 协议 上述两个协议实现复杂，操作步骤多，性能也是一个很大问题，因此在互联网高并发系统中，鲜有使用两阶段提交和三阶段提交协议的场景。\nTCC 协议将一个任务拆分为 Try、Confirm、Cancel 三个步骤，没有单独的准备阶段， Try 操作兼备资源操作与准备能力，另外 Confirm 操作和 Cancel 操作要满足幂等性。虽然没有解决极端情况下不一致和脑裂的问题，然而 TCC 通过自动化补偿，将需要人工处理的不一致情况降低到最少，也是一种非常有用的解决方案。\nTCC 协议相比其它两个协议更简单且更容易实现。\n保证最终一致性的模式 一致性在现实系统实践中，仅仅需要达到最终一致性，并不需要专业的、复杂的一致性协议。实现最终一致性有一些有效、简单的模式如下:\n查询模式 通过查询模式，我们可以清楚地知道某个任务或者操作处于一个什么样的状态，是执行成功还是失败，还是正在执行，这样也方便其他系统依据当前返回的状态进行下一步操作。为了能够实现查询，每个服务操作都需要唯一的流水号标识，例如请求流水号、订单号等。\n补偿模式 我们修正系统以让其达到最终一致状态的过程，称之为补偿。而支持补偿模式，那么这个服务针对特定任务需要提供重试操作和取消操作:\n定期校对模式 在分布式系统中构建了唯一 ID、调用链等基础设施后，我们很容易对系统间的不一致进行核对，发现不一致，则利用补偿来修复即可。定期校对模式多用于金融系统中，涉及资金安全的，需要保证准确性。\n超时处理模式 超时补偿原则 超时补偿原则确定的是调用方和被调用方谁应该负责重试或补偿的问题。\n被调用方补偿:\n如果服务 2 告诉服务 1 消息已经接受，那么服务 1 任务就已经结束了，如果服务 2 处理失败，那么服务 2 应该负责重试或者补偿。\nvoid service2() { while (i \u0026lt; tryTimes) { // 任务没有执行成功，则自己补偿  if (!doTask()) { i++; continue; } break; } } 调用方补偿:\n如果服务 2 无明确接受响应，那么服务 1 应该持续进行重试，直到服务 2 明确表示已经接受消息:\nvoid service1() { while (true) { try { scheduleTaskToService2(); // 保证幂等性  } catch (TimeOutException e) { continue; // 无明确接受响应，调用方负责重试  } break; } } 解决 (1) 扣库存问题\n数据量小，可以利用关系数据库的强一致性解决，也就是把订单和库存表放到一个关系型数据库中。单机难以满足的话，就分片，尽量保证订单和库存放入同一个数据库分片中。\n(2) 超时无结果\n需要依据操作 ID 来主动查询任务的当前状态，以便决定下一步做什么。\n(3) 回调无结果\n需要依据操作 ID 来主动查询任务的当前状态，以便决定下一步做什么。\n(4) 订单不存在\n查询处理情况，定期校对，补偿修复。\n(5) 状态不一致\n查询处理情况，定期校对，补偿修复。\n(6) 缓存一致性\n为了提高性能，数据库与缓存只需要保持弱一致性，而不需要保持强一致性，否则违背了使用缓存的初衷。\n(7) 缓存时间窗口\n如果性能要求不是非常高，则尽量使用分布式缓存，而不要使用本地缓存。另外读的顺序是先读缓存，再读数据库；写的顺序是先写数据库，再写缓存。\n(8) 数据完整性\n写缓存时数据一定要完整，如果缓存数据的一部分有效，另一部分无效，则能可在需要时回源数据库，也不要把部分数据放入缓存中。\nboolean cacheData() { Object o1 = readFromDB1(); Object o2 = readFromDB2(); // 确保缓存数据完整性，不要缓存一部分数据  if (o1 != null \u0026amp;\u0026amp; o2 != null) { return cacheData(o1, o2); } return false; } 参考  《分布式服务架构：原理、设计与实战》 极客时间订阅:从0开始学架构 "});index.add({'id':45,'href':'/docs/programmer-interview/algorithm/best-time-to-buy-and-sell-stock-3/','title':"Best Time to Buy and Sell Stock Ⅲ",'content':"Best Time to Buy and Sell Stock Ⅲ 题目 LeetCode 地址：Best Time to Buy and Sell Stock Ⅲ\n有一个数组，第 i 个元素的值代表第 i 天的股票价格，如果你最多只能进行两次交易（某天买入一支股票，然后过几天卖掉），请问你能收获的最大利润是多少？\n分析 参考 Best Time to Buy and Sell Stock 思路上状态机，状态机应用两次即可。\n答案 // 最多两次交易 // 且不能同时持有，必须卖掉这个，然后持有另外一个 // https://leetcode.com/problems/best-time-to-buy-and-sell-stock-iii/ // public class BestTimetoBuyandSellStockIII { // Buy Sell Buy Sell  // s0 ----\u0026gt; s1 -----\u0026gt; s2 -----\u0026gt; s3 ------\u0026gt; s4 (end)  // ↑___| ↑__| ↑____| ↑___|  //  public int maxProfit(int[] prices) { if (prices == null || prices.length \u0026lt;= 1) { return 0; } int s0 = 0; int s1 = -prices[0]; int s2 = 0; int s3 = -prices[0]; int s4 = 0; for (int i = 1; i \u0026lt; prices.length; i++) { s0 = s0; s1 = Math.max(s1, s0 - prices[i]); s2 = Math.max(s2, s1 + prices[i]); s3 = Math.max(s3, s2 - prices[i]); s4 = Math.max(s4, s3 + prices[i]); } return s4; } } 扫描下面二维码，在手机上阅读这篇文章：\n"});index.add({'id':46,'href':'/docs/tutorial/front-end-optimization-guide/css-optimization/','title':"CSS 优化",'content':"CSS 优化 本文讲述在实际工作中如何优化 CSS，提升页面加载的性能！\n避免使用 @import @import url(\u0026#34;base.css\u0026#34;); @import url(\u0026#34;layout.css\u0026#34;); @import url(\u0026#34;carousel.css\u0026#34;); 由于 @import 属性允许相互之间嵌套引入，因此浏览器必须串行的去下载每一个 @import 引入的文件，因此会增加下载 CSS 文件的时间，而使用 \u0026lt;link\u0026gt; 就可以并行下载 CSS 文件，可有效提升 CSS 加载的性能：\n\u0026lt;link rel=\u0026#34;stylesheet\u0026#34; href=\u0026#34;base.css\u0026#34;\u0026gt; \u0026lt;link rel=\u0026#34;stylesheet\u0026#34; href=\u0026#34;layout.css\u0026#34;\u0026gt; \u0026lt;link rel=\u0026#34;stylesheet\u0026#34; href=\u0026#34;carousel.css\u0026#34;\u0026gt; 简化 CSS 选择器 浏览器是从右向左逐步解析选择器表达式的，例如 #id .class \u0026gt; ul a 。首先找到页面上所有匹配 a 的节点，然后找到所有 ul 元素，并且将 a 元素恰好是 ul 元素子节点的元素过滤出来，直至解析到最左侧的选择器 #id 。\n如下是在网站上针对 50000 个元素使用不同 CSS 选择器选择元素的时间对比：\n   选择器 查询时间(ms)     div 4.8740   .box 3.625   .box \u0026gt; .title 4.4587   .box .title 4.5161   .box ~ .box 4.7082   .box + .box 4.6611   .box:last-of-type 3.944   .box:nth-of-type(2n - 1) 16.8491   .box:not(:last-of-type) 5.8947   .box:not(:empty):last-of-type .title 8.0202   .box:nth-last-child(n+6) ~ div 20.8710    最慢的选择器接近 20ms，而最快的仅需 3.5ms 左右，由此可见 CSS 选择器越短，解析速度越快！\n避免使用 CSS 表达式 IE5 引入了 CSS 表达式，或者称之为 \u0026ldquo;动态属性\u0026rdquo;，这样可以让开发人员以更为紧凑的方式在 CSS 中就可以完成高级样式处理。然而，CSS 表达式带来的性能损失是相当大的，因为每当触发任何事件（如窗口大小调整、鼠标移动等）时，浏览器都会重新运行每个表达式，这也是它在 IE8 被弃用的原因之一。如果在页面中使用了 CSS 表达式，则应尽一切努力删除它们，并使用其他方法来实现相同的功能。\n避免使用 expensive 的属性 有些属性生来渲染速度就慢于其它属性，下面这些属性在绘制之前可能会导致其它计算，因此尽量避免使用！\n border-radius box-shadow opacity transform filter position: fixed  精简 CSS 代码 精简 CSS 代码意味着对 CSS 源文件，采取移除无关的空白字符、换行符、注释、去除不必要的单位、去除不必要的零等方法。其可以有效压缩 CSS 文件的大小，减少浏览器下载和执行文件所需的时间。\n通过使用近几年来出现的新的页面布局方式，例如 Flexbox 和 Grid 布局，可以有效减少达到之前使用 float 属性进行的相同布局所需要的代码量，以前自己需要做的事情，现在浏览器在底层可以更快的帮你完成。\n在引入 CSS 库的时候，也要去仔细对比，在满足要求的条件下，应该尽量选择 size 比较小的库。\n优化 CSS 动画  同时进行多个 CSS 动画可能不会工作地很好，极有可能导致延迟出现，适当地给一些动画增加 transition-delay 属性以避免同时运行多个动画。 浏览器加载网页地时候非常忙，因此尽可能地将所有动画延迟到初始加载事件之后的几百毫秒，可以有效提升页面的整体性能。 SVG 非常适合动画，因为它们可以在不降低分辨率的情况下进行缩放。 只在最后才考虑使用 will-change 属性，毕竟它也消耗资源！  参考  20 Tips for Optimizing CSS Performance Tips for Improving CSS and JS Animation Performance PageSpeed: Avoid CSS expressions (deprecated)  扫描下面二维码，在手机端阅读本文：\n"});index.add({'id':47,'href':'/docs/tutorial/git/','title':"Git 教程",'content':"Git 教程 目录  Git 配置用户名和邮箱 创建 Git 仓库 Git 查看文件差异 Git 重置 Git checkout Git 保存当前进度 Git 多次提交合并成一次提交 Git 分支 Git 分支合并 Git 解决冲突 Git tag Git add 和 Git rm Git push 和 Git pull Git commit Git .ignore 文件  Git 的四个区 "});index.add({'id':48,'href':'/docs/tutorial/git/check-file-diff/','title':"Git 查看文件差异",'content':"Git 查看文件差异 Git 三个区 Git 有三个区：工作区、Stage 区（暂存区）、版本库。这意味着，一个文件可能在这三个区都有所不同。如下图所示，一个文件使用 git add 命令之后，这个文件就转移到了暂存区，继续使用 git commit 之后就转移到了版本库。git diff 使用不同的命令参数可以查看文件在这三个区域中的两两对比的差异。\n本地代码（工作区）与暂存区中的差异 git diff 示例结果如下所示：\ndiff 输出的格式介绍 下面解释上述 git diff 输出的格式：\n 第一行，展示了使用什么命令做的比较 第二行，100644 代表这是一个普通文件 --- 表示原始文件，即这个文件没有修改前的内容 +++ 表示新文件，即这个文件修改后的内容 -1,5 中的 - 表示原始文件，1,5 表示从第 1 行到第 4 行做了改动 +1,5 中的 + 表示新文件，1,5 表示从第 1 行到第 4 行做了改动 @@ -1,5 +1,5 @@ 表示这个文件的第 1 行到第 4 行，变更为了新文件的第 1 行到第 4 行  本地代码（工作区）和版本库的差异 git diff HEAD  HEAD 指：当前工作分支的版本库\n 如果你当前分支是 master，那么上述命令与下面这行命令是等价的：\ngit diff master 暂存区和版本库的差异 git diff --cached # 或 git diff --staged Git diff 命令与版本库关系图 参考  How to read the output from git diff? Git权威指南  扫描下面二维码，在手机端阅读：\n"});index.add({'id':49,'href':'/docs/it-zone/','title':"IT 圈",'content':"IT 圈 IT 圈：每日收录最新编程、IT、软件、互联网等热门焦点新闻，让您实时掌握 IT 届最新动态！\n 06-09 | 谷歌修改 Chromium 源码中的“黑白名单”术语 06-02 | Rust 语言首次进入 Tiobe 前 20 名 06-01 | fastjson 又现高危漏洞！  "});index.add({'id':50,'href':'/docs/tutorial/unix-command/ls/','title':"ls",'content':"ls ls 命令教程，ls 命令的常见使用方法介绍。\n简介 ls 命令是一个命令行实用程序，用于列出通过标准输入提供给它的一个或多个目录的内容。它将结果写入标准输出。ls 命令支持显示关于文件的各种信息、对一系列选项进行排序和递归列表。\n示例 （1）显示目录中的文件\nls /home/zk （2）显示隐藏的文件和文件夹\nls -a /home/zk 结果：\nls -a /home/george . .goobook .tmux.conf .. .goobook_auth.json .urlview .asoundrc .inputrc .vim .asoundrc.asoundconf .install.sh .viminfo .asoundrc.asoundconf.bak .irbrc .viminfo.tmp ... （3）列出来的文件，标识上文件的类型\nls -F 显示结果如下所示：\nbin@ dotfiles/ file.txt irc/ src/ code/ Downloads/ go/ logs/ 不同文件类型显示的后缀不同：\n /：目录 @：symbolic link |：FIFO =：socket \u0026gt;：door 什么也不显示，代表正常文件  （4）显示更多信息\nls -l 显示结果：\n-rwxrw-r-- 10 root root 2048 Jan 13 07:11 afile.exe 每一列的含义：\n 文件权限 link 的数量 owner 名称 owner 组 文件大小 上次修改时间 文件/文件夹名称  （5）根据文件大小进行排序\nls -lS 排序结果如下（从大到小开始排序）：\nls -lS total 56 drwxr-xr-x 2 george users 32768 Oct 4 09:15 logs drwxr-xr-x 6 george users 4096 Oct 4 20:27 code drwxr-xr-x 10 george users 4096 Oct 4 09:13 dotfiles drwx------ 3 george users 4096 Oct 4 11:31 Downloads drwxr-xr-x 5 george users 4096 Sep 25 08:30 go （6）按照修改时间排序\nls -lt 排序结果如下：\nls -lt total 56 -rw-r--r-- 1 george users 0 Oct 4 20:42 file.txt drwxr-xr-x 6 george users 4096 Oct 4 20:27 code drwx------ 3 george users 4096 Oct 4 11:31 Downloads drwxr-xr-x 2 george users 32768 Oct 4 09:15 logs drwxr-xr-x 10 george users 4096 Oct 4 09:13 dotfiles （7）根据访问时间排序\nls -lu 排序结果如下：\nls -lu total 56 lrwxrwxrwx 1 george users 25 Oct 4 09:01 bin -\u0026gt; /home/george/dotfiles/bin drwxr-xr-x 6 george users 4096 Oct 4 20:23 code drwxr-xr-x 10 george users 4096 Oct 4 11:21 dotfiles drwx------ 3 george users 4096 Oct 4 11:24 Downloads （8）以人类可读的格式显示文件大小\nls -lh （9）递归显示文件\nls -R my_folder 参考  Linux and Unix ls command tutorial with examples  扫描下面二维码，在手机端阅读：\n"});index.add({'id':51,'href':'/docs/rocketmq/rocketmq-message-receive-flow/','title':"RocketMQ 消息接受流程",'content':"RocketMQ 消息接受流程 本篇讲述 RocketMQ 消息接受流程\n一、消费者注册 生产者负责往服务器 Broker 发送消息，消费者则从 Broker 获取消息。消费者获取消息采用的是订阅者模式，即消费者客户端可以任意订阅一个或者多个话题来消费消息:\npublic class Consumer { public static void main(String[] args) throws InterruptedException, MQClientException { /* * 订阅一个或者多个话题 */ consumer.subscribe(\u0026#34;TopicTest\u0026#34;, \u0026#34;*\u0026#34;); } } 当消费者客户端启动以后，其会每隔 30 秒从命名服务器查询一次用户订阅的所有话题路由信息:\npublic class MQClientInstance { private void startScheduledTask() { this.scheduledExecutorService.scheduleAtFixedRate(new Runnable() { @Override public void run() { // 从命名服务器拉取话题信息  MQClientInstance.this.updateTopicRouteInfoFromNameServer(); } }, 10, this.clientConfig.getPollNameServerInterval(), TimeUnit.MILLISECONDS); } } 我们由 RocketMQ 消息发送流程 这篇文章知道 RocketMQ 在发送消息的时候，每条消息会以轮循的方式均衡地分发的不同 Broker 的不同队列中去。由此，消费者客户端从服务器命名服务器获取下来的便是话题的所有消息队列:\n在获取话题路由信息的时候，客户端还会将话题路由信息中的所有 Broker 地址保存到本地:\npublic class MQClientInstance { public boolean updateTopicRouteInfoFromNameServer(final String topic, boolean isDefault, DefaultMQProducer defaultMQProducer) { // ...  if (changed) { TopicRouteData cloneTopicRouteData = topicRouteData.cloneTopicRouteData(); // 更新 Broker 地址列表  for (BrokerData bd : topicRouteData.getBrokerDatas()) { this.brokerAddrTable.put(bd.getBrokerName(), bd.getBrokerAddrs()); } return true; } // ...  } } 当消费者客户端获取到了 Broker 地址列表之后，其便会每隔 30 秒给服务器发送一条心跳数据包，告知所有 Broker 服务器这台消费者客户端的存在。在每次发送心跳包的同时，其数据包内还会捎带这个客户端消息订阅的一些组信息，比如用户订阅了哪几个话题等，与此相对应，每台 Broker 服务器会在内存中维护一份当前所有的消费者客户端列表信息:\npublic class ConsumerManager { private final ConcurrentMap\u0026lt;String/* Group */, ConsumerGroupInfo\u0026gt; consumerTable = new ConcurrentHashMap\u0026lt;String, ConsumerGroupInfo\u0026gt;(1024); } 消费者客户端与 Broker 服务器进行沟通的整体流程如下图所示：\n二、消息队列负载均衡 我们知道无论发送消息还是接受消息都需要指定消息的话题，然而实际上消息在 Broker 服务器上并不是以话题为单位进行存储的，而是采用了比话题更细粒度的队列来进行存储的。当你发送了 10 条相同话题的消息，这 10 条话题可能存储在了不同 Broker 服务器的不同队列中。由此，我们说 RocketMQ 管理消息的单位不是话题，而是队列。\n当我们讨论消息队列负载均衡的时候，就是在讨论服务器端的所有队列如何给所有消费者消费的问题。在 RocketMQ 中，客户端有两种消费模式，一种是广播模式，另外一种是集群模式。\n我们现在假设总共有两台 Broker 服务器，假设用户使用 Producer 已经发送了 8 条消息，这 8 条消息现在均衡的分布在两台 Broker 服务器的 8 个队列中，每个队列中有一个消息。现在有 3 台都订阅了 Test 话题的消费者实例，我们来看在不同消费模式下，不同的消费者会收到哪几条消息。\n(1) 广播模式 广播模式是指所有消息队列中的消息都会广播给所有的消费者客户端，如下图所示，每一个消费者都能收到这 8 条消息:\n(2) 集群模式 集群模式是指所有的消息队列会按照某种分配策略来分给不同的消费者客户端，比如消费者 A 消费前 3 个队列中的消息，消费者 B 消费中间 3 个队列中的消息等等。我们现在着重看 RocketMQ 为我们提供的三个比较重要的消息队列分配策略:\n1. 平均分配策略 平均分配策略下，三个消费者的消费情况如下所示：\n Consumer-1 消费前 3 个消息队列中的消息 Consumer-2 消费中间 3 个消息队列中的消息 Consumer-3 消费最后 2 个消息队列中的消息  2. 平均分配轮循策略 平均分配轮循策略下，三个消费者的消费情况如下所示：\n Consumer-1 消费 1、4、7消息队列中的消息 Consumer-2 消费 2、5、8消息队列中的消息 Consumer-3 消费 3、6消息队列中的消息  3. 一致性哈希策略 一致性哈希算法是根据这三台消费者各自的某个有代表性的属性(我们假设就是客户端ID)来计算出三个 Hash 值，此处为了减少由于 Hash 函数选取的不理想的情况， RocketMQ 算法对于每个消费者通过在客户端ID后面添加 1、2、3 索引来使每一个消费者多生成几个哈希值。那么现在我们需要哈希的就是九个字符串:\n Consumer-1-1 Consumer-1-2 Consumer-1-3 Consumer-2-1 Consumer-2-2 Consumer-2-3 Consumer-3-1 Consumer-3-2 Consumer-3-3  计算完这 9 个哈希值以后，我们按照从小到大的顺序来排列成一个环 (如图所示)。这个时候我们需要一一对这 8 个消息队列也要计算一下 Hash 值，当 Hash 值落在两个圈之间的时候，我们就选取沿着环的方向的那个节点作为这个消息队列的消费者。如下图所示 (注意: 图只是示例，并非真正的消费情况):\n在一致性哈希策略下，三个消费者的消费情况如下所示：\n Consumer-1 消费 1、2、3、4消息队列中的消息 Consumer-2 消费 5、8消息队列中的消息 Consumer-3 消费 6、7消息队列中的消息  消息队列的负载均衡是由一个不停运行的均衡服务来定时执行的:\npublic class RebalanceService extends ServiceThread { // 默认 20 秒一次  private static long waitInterval = Long.parseLong(System.getProperty(\u0026#34;rocketmq.client.rebalance.waitInterval\u0026#34;, \u0026#34;20000\u0026#34;)); @Override public void run() { while (!this.isStopped()) { this.waitForRunning(waitInterval); // 重新执行消息队列的负载均衡  this.mqClientFactory.doRebalance(); } } } 接着往下看，会知道在广播模式下，当前这台消费者消费和话题相关的所有消息队列，而集群模式会先按照某种分配策略来进行消息队列的分配，得到的结果就是当前这台消费者需要消费的消息队列:\npublic abstract class RebalanceImpl { private void rebalanceByTopic(final String topic, final boolean isOrder) { switch (messageModel) { // 广播模式  case BROADCASTING: { // 消费这个话题的所有消息队列  Set\u0026lt;MessageQueue\u0026gt; mqSet = this.topicSubscribeInfoTable.get(topic); if (mqSet != null) { // ...  } break; } // 集群模式  case CLUSTERING: { // ...  // 按照某种负载均衡策略进行消息队列和消费客户端之间的分配  // allocateResult 就是当前这台消费者被分配到的消息队列  allocateResult = strategy.allocate( this.consumerGroup, this.mQClientFactory.getClientId(), mqAll, cidAll); // ...  } break; } } } 三、Broker 消费队列文件 现在我们再来看 Broker 服务器端。首先我们应该知道，消息往 Broker 存储就是在向 CommitLog 消息文件中写入数据的一个过程。在 Broker 启动过程中，其会启动一个叫做 ReputMessageService 的服务，这个服务每隔 1 秒会检查一下这个 CommitLog 是否有新的数据写入。ReputMessageService 自身维护了一个偏移量 reputFromOffset，用以对比和 CommitLog 文件中的消息总偏移量的差距。当这两个偏移量不同的时候，就代表有新的消息到来了:\nclass ReputMessageService extends ServiceThread { private volatile long reputFromOffset = 0; private boolean isCommitLogAvailable() { // 看当前有没有新的消息到来  return this.reputFromOffset \u0026lt; DefaultMessageStore.this.commitLog.getMaxOffset(); } @Override public void run() { while (!this.isStopped()) { try { Thread.sleep(1); this.doReput(); } catch (Exception e) { DefaultMessageStore.log.warn(this.getServiceName() + \u0026#34; service has exception. \u0026#34;, e); } } } } 在有新的消息到来之后，doReput() 函数会取出新到来的所有消息，每一条消息都会封装为一个 DispatchRequest 请求，进而将这条请求分发给不同的请求消费者，我们在这篇文章中只会关注利用消息创建消费队列的服务 CommitLogDispatcherBuildConsumeQueue:\nclass ReputMessageService extends ServiceThread { // ... 部分代码有删减  private void doReput() { SelectMappedBufferResult result = DefaultMessageStore.this.commitLog.getData(reputFromOffset); if (result != null) { this.reputFromOffset = result.getStartOffset(); for (int readSize = 0; readSize \u0026lt; result.getSize() \u0026amp;\u0026amp; doNext; ) { // 读取一条消息，然后封装为 DispatchRequest  DispatchRequest dispatchRequest = DefaultMessageStore.this.commitLog.checkMessageAndReturnSize(result.getByteBuffer(), false, false); int size = dispatchRequest.getMsgSize(); if (dispatchRequest.isSuccess()) { // 分发这个 DispatchRequest 请求  DefaultMessageStore.this.doDispatch(dispatchRequest); this.reputFromOffset += size; readSize += size; } // ...  } } } } CommitLogDispatcherBuildConsumeQueue 服务会根据这条请求按照不同的队列 ID 创建不同的消费队列文件，并在内存中维护一份消费队列列表。然后将 DispatchRequest 请求中这条消息的消息偏移量、消息大小以及消息在发送时候附带的标签的 Hash 值写入到相应的消费队列文件中去。\n消费队列文件的创建与消息存储 CommitLog 文件的创建过程是一致的，只是路径不同，这里不再赘述。\n寻找消费队列的代码如下:\npublic class DefaultMessageStore implements MessageStore { private final ConcurrentMap\u0026lt;String/* topic */, ConcurrentMap\u0026lt;Integer/* queueId */, ConsumeQueue\u0026gt;\u0026gt; consumeQueueTable; public void putMessagePositionInfo(DispatchRequest dispatchRequest) { ConsumeQueue cq = this.findConsumeQueue(dispatchRequest.getTopic(), dispatchRequest.getQueueId()); cq.putMessagePositionInfoWrapper(dispatchRequest); } } 向消费队列文件中存储数据的代码如下:\npublic class ConsumeQueue { private boolean putMessagePositionInfo(final long offset, final int size, final long tagsCode, final long cqOffset) { // 存储偏移量、大小、标签码  this.byteBufferIndex.flip(); this.byteBufferIndex.limit(CQ_STORE_UNIT_SIZE); this.byteBufferIndex.putLong(offset); this.byteBufferIndex.putInt(size); this.byteBufferIndex.putLong(tagsCode); // 获取消费队列文件  final long expectLogicOffset = cqOffset * CQ_STORE_UNIT_SIZE; MappedFile mappedFile = this.mappedFileQueue.getLastMappedFile(expectLogicOffset); if (mappedFile != null) { // ...  return mappedFile.appendMessage(this.byteBufferIndex.array()); } return false; } } 以上阐述了消费队列创建并存储消息的一个过程，但是消费队列文件中的消息是需要持久化到磁盘中去的。持久化的过程是通过后台服务 FlushConsumeQueueService 来定时持久化的:\nclass FlushConsumeQueueService extends ServiceThread { private void doFlush(int retryTimes) { // ...  ConcurrentMap\u0026lt;String, ConcurrentMap\u0026lt;Integer, ConsumeQueue\u0026gt;\u0026gt; tables = DefaultMessageStore.this.consumeQueueTable; for (ConcurrentMap\u0026lt;Integer, ConsumeQueue\u0026gt; maps : tables.values()) { for (ConsumeQueue cq : maps.values()) { boolean result = false; for (int i = 0; i \u0026lt; retryTimes \u0026amp;\u0026amp; !result; i++) { // 刷新到磁盘  result = cq.flush(flushConsumeQueueLeastPages); } } } // ...  } } 上述过程体现在磁盘文件的变化如下图所示，commitLog 文件夹下面存放的是完整的消息，来一条消息，向文件中追加一条消息。同时，根据这一条消息属于 TopicTest 话题下的哪一个队列，又会往相应的 consumequeue 文件下的相应消费队列文件中追加消息的偏移量、消息大小和标签码:\n总流程图如下所示:\n四、消息队列偏移量 Broker 服务器存储了各个消费队列，客户端需要消费每个消费队列中的消息。消费模式的不同，每个客户端所消费的消息队列也不同。那么客户端如何记录自己所消费的队列消费到哪里了呢？答案就是消费队列偏移量。\n针对同一话题，在集群模式下，由于每个客户端所消费的消息队列不同，所以每个消息队列已经消费到哪里的消费偏移量是记录在 Broker 服务器端的。而在广播模式下，由于每个客户端分配消费这个话题的所有消息队列，所以每个消息队列已经消费到哪里的消费偏移量是记录在客户端本地的。\n下面分别讲述两种模式下偏移量是如何获取和更新的:\n(1) 集群模式 在集群模式下，消费者客户端在内存中维护了一个 offsetTable 表:\npublic class RemoteBrokerOffsetStore implements OffsetStore { private ConcurrentMap\u0026lt;MessageQueue, AtomicLong\u0026gt; offsetTable = new ConcurrentHashMap\u0026lt;MessageQueue, AtomicLong\u0026gt;(); } 同样在 Broker 服务器端也维护了一个偏移量表:\npublic class ConsumerOffsetManager extends ConfigManager { private ConcurrentMap\u0026lt;String/* topic@group */, ConcurrentMap\u0026lt;Integer, Long\u0026gt;\u0026gt; offsetTable = new ConcurrentHashMap\u0026lt;String, ConcurrentMap\u0026lt;Integer, Long\u0026gt;\u0026gt;(512); } 在消费者客户端，RebalanceService 服务会定时地 (默认 20 秒) 从 Broker 服务器获取当前客户端所需要消费的消息队列，并与当前消费者客户端的消费队列进行对比，看是否有变化。对于每个消费队列，会从 Broker 服务器查询这个队列当前的消费偏移量。然后根据这几个消费队列，创建对应的拉取请求 PullRequest 准备从 Broker 服务器拉取消息，如下图所示:\n当从 Broker 服务器拉取下来消息以后，只有当用户成功消费的时候，才会更新本地的偏移量表。本地的偏移量表再通过定时服务每隔 5 秒同步到 Broker 服务器端:\npublic class MQClientInstance { private void startScheduledTask() { this.scheduledExecutorService.scheduleAtFixedRate(new Runnable() { @Override public void run() { MQClientInstance.this.persistAllConsumerOffset(); } }, 1000 * 10, this.clientConfig.getPersistConsumerOffsetInterval(), TimeUnit.MILLISECONDS); } } 而维护在 Broker 服务器端的偏移量表也会每隔 5 秒钟序列化到磁盘中:\npublic class BrokerController { public boolean initialize() throws CloneNotSupportedException { this.scheduledExecutorService.scheduleAtFixedRate(new Runnable() { @Override public void run() { BrokerController.this.consumerOffsetManager.persist(); } }, 1000 * 10, this.brokerConfig.getFlushConsumerOffsetInterval(), TimeUnit.MILLISECONDS); } } 保存的格式如下所示：\n上述整体流程如下所示，红框框住的是这个话题下面的队列的 ID，箭头指向的分别是每个队列的消费偏移量：\n(2) 广播模式 对于广播模式而言，每个消费队列的偏移量肯定不能存储在 Broker 服务器端，因为多个消费者对于同一个队列的消费可能不一致，偏移量会互相覆盖掉。因此，在广播模式下，每个客户端的消费偏移量是存储在本地的，然后每隔 5 秒将内存中的 offsetTable 持久化到磁盘中。当首次从服务器获取可消费队列的时候，偏移量不像集群模式下是从 Broker 服务器读取的，而是直接从本地文件中读取的:\npublic class LocalFileOffsetStore implements OffsetStore { @Override public long readOffset(final MessageQueue mq, final ReadOffsetType type) { if (mq != null) { switch (type) { case READ_FROM_STORE: { // 本地读取  offsetSerializeWrapper = this.readLocalOffset(); // ...  } } } // ...  } } 当消息消费成功后，偏移量的更新也是持久化到本地，而非更新到 Broker 服务器中。这里提一下，在广播模式下，消息队列的偏移量默认放在用户目录下的 .rocketmq_offsets 目录下:\npublic class LocalFileOffsetStore implements OffsetStore { @Override public void persistAll(Set\u0026lt;MessageQueue\u0026gt; mqs) { // ...  String jsonString = offsetSerializeWrapper.toJson(true); MixAll.string2File(jsonString, this.storePath); // ...  } } 存储格式如下：\n简要流程图如下：\n五、拉取消息 在客户端运行着一个专门用来拉取消息的后台服务 PullMessageService，其接受每个队列创建 PullRequest 拉取消息请求，然后拉取消息:\npublic class PullMessageService extends ServiceThread { @Override public void run() { while (!this.isStopped()) { PullRequest pullRequest = this.pullRequestQueue.take(); if (pullRequest != null) { this.pullMessage(pullRequest); } } } } 每一个 PullRequest 都关联着一个 MessageQueue 和一个 ProcessQueue，在 ProcessQueue 的内部还维护了一个用来等待用户消费的消息树，如下代码所示:\npublic class PullRequest { private MessageQueue messageQueue; private ProcessQueue processQueue; } public class ProcessQueue { private final TreeMap\u0026lt;Long, MessageExt\u0026gt; msgTreeMap = new TreeMap\u0026lt;Long, MessageExt\u0026gt;(); } 当真正尝试拉取消息之前，其会检查当前请求的内部缓存的消息数量、消息大小、消息阈值跨度是否超过了某个阈值，如果超过某个阈值，则推迟 50 毫秒重新执行这个请求:\npublic class DefaultMQPushConsumerImpl implements MQConsumerInner { public void pullMessage(final PullRequest pullRequest) { // ...  final ProcessQueue processQueue = pullRequest.getProcessQueue(); long cachedMessageCount = processQueue.getMsgCount().get(); long cachedMessageSizeInMiB = processQueue.getMsgSize().get() / (1024 * 1024); // 缓存消息数量阈值，默认为 1000  if (cachedMessageCount \u0026gt; this.defaultMQPushConsumer.getPullThresholdForQueue()) { this.executePullRequestLater(pullRequest, PULL_TIME_DELAY_MILLS_WHEN_FLOW_CONTROL); return; } // 缓存消息大小阈值，默认为 100 MB  if (cachedMessageSizeInMiB \u0026gt; this.defaultMQPushConsumer.getPullThresholdSizeForQueue()) { this.executePullRequestLater(pullRequest, PULL_TIME_DELAY_MILLS_WHEN_FLOW_CONTROL); return; } if (!this.consumeOrderly) { // 最小偏移量和最大偏移量的阈值跨度，默认为 2000 偏移量，消费速度不能太慢  if (processQueue.getMaxSpan() \u0026gt; this.defaultMQPushConsumer.getConsumeConcurrentlyMaxSpan()) { this.executePullRequestLater(pullRequest, PULL_TIME_DELAY_MILLS_WHEN_FLOW_CONTROL); return; } } // ...  } } 当执行完一些必要的检查之后，客户端会将用户指定的过滤信息以及一些其它必要消费字段封装到请求信息体中，然后才开始从 Broker 服务器拉取这个请求从当前偏移量开始的消息，默认一次性最多拉取 32 条，服务器返回的响应会告诉客户端这个队列下次开始拉取时的偏移量。客户端每次都会注册一个 PullCallback 回调，用以接受服务器返回的响应信息，根据响应信息的不同状态信息，然后修正这个请求的偏移量，并进行下次请求:\npublic void pullMessage(final PullRequest pullRequest) { PullCallback pullCallback = new PullCallback() { @Override public void onSuccess(PullResult pullResult) { if (pullResult != null) { // ...  switch (pullResult.getPullStatus()) { case FOUND: // ...  break; case NO_NEW_MSG: // ...  break; case NO_MATCHED_MSG: // ...  break; case OFFSET_ILLEGAL: // ...  break; default: break; } } } @Override public void onException(Throwable e) { // ...  } }; } 上述是客户端拉取消息时的一些机制，现在再说一下 Broker 服务器端与此相对应的逻辑。\n服务器在收到客户端的请求之后，会根据话题和队列 ID 定位到对应的消费队列。然后根据这条请求传入的 offset 消费队列偏移量，定位到对应的消费队列文件。偏移量指定的是消费队列文件的消费下限，而最大上限是由如下算法来进行约束的:\nfinal int maxFilterMessageCount = Math.max(16000, maxMsgNums * ConsumeQueue.CQ_STORE_UNIT_SIZE); 有了上限和下限，客户端便会开始从消费队列文件中取出每个消息的偏移量和消息大小，然后再根据这两个值去 CommitLog 文件中寻找相应的完整的消息，并添加到最后的消息队列中，精简过的代码如下所示：\npublic class DefaultMessageStore implements MessageStore { public GetMessageResult getMessage(final String group, final String topic, final int queueId, final long offset, final int maxMsgNums, final MessageFilter messageFilter) { // ...  ConsumeQueue consumeQueue = findConsumeQueue(topic, queueId); if (consumeQueue != null) { // 首先根据消费队列的偏移量定位消费队列  SelectMappedBufferResult bufferConsumeQueue = consumeQueue.getIndexBuffer(offset); if (bufferConsumeQueue != null) { try { status = GetMessageStatus.NO_MATCHED_MESSAGE; // 最大消息长度  final int maxFilterMessageCount = Math.max(16000, maxMsgNums * ConsumeQueue.CQ_STORE_UNIT_SIZE); // 取消息  for (; i \u0026lt; bufferConsumeQueue.getSize() \u0026amp;\u0026amp; i \u0026lt; maxFilterMessageCount; i += ConsumeQueue.CQ_STORE_UNIT_SIZE) { long offsetPy = bufferConsumeQueue.getByteBuffer().getLong(); int sizePy = bufferConsumeQueue.getByteBuffer().getInt(); // 根据消息的偏移量和消息的大小从 CommitLog 文件中取出一条消息  SelectMappedBufferResult selectResult = this.commitLog.getMessage(offsetPy, sizePy); getResult.addMessage(selectResult); status = GetMessageStatus.FOUND; } // 增加下次开始的偏移量  nextBeginOffset = offset + (i / ConsumeQueue.CQ_STORE_UNIT_SIZE); } finally { bufferConsumeQueue.release(); } } } // ...  } } 客户端和 Broker 服务器端完整拉取消息的流程图如下所示：\n六、消费消息 依赖于用户指定的消息回调函数的不同，消息的消费分为两种: 并发消费和有序消费。\n并发消费没有考虑消息发送的顺序，客户端从服务器获取到消息就会直接回调给用户。而有序消费会考虑每个队列消息发送的顺序，注意此处并不是每个话题消息发送的顺序，一定要记住 RocketMQ 控制消息的最细粒度是消息队列。当我们讲有序消费的时候，就是在说对于某个话题的某个队列，发往这个队列的消息，客户端接受消息的顺序与发送的顺序完全一致。\n下面我们分别看这两种消费模式是如何实现的。\n(1) 并发消费 当用户注册消息回调类的时候，如果注册的是 MessageListenerConcurrently 回调类，那么就认为用户不关心消息的顺序问题。我们在上文提到过每个 PullRequest 都关联了一个处理队列 ProcessQueue，而每个处理队列又都关联了一颗消息树 msgTreeMap。当客户端拉取到新的消息以后，其先将消息放入到这个请求所关联的处理队列的消息树中，然后提交一个消息消费请求，用以回调用户端的代码消费消息:\npublic class DefaultMQPushConsumerImpl implements MQConsumerInner { public void pullMessage(final PullRequest pullRequest) { PullCallback pullCallback = new PullCallback() { @Override public void onSuccess(PullResult pullResult) { if (pullResult != null) { switch (pullResult.getPullStatus()) { case FOUND: // 消息放入处理队列的消息树中  boolean dispathToConsume = processQueue .putMessage(pullResult.getMsgFoundList()); // 提交一个消息消费请求  DefaultMQPushConsumerImpl.this .consumeMessageService .submitConsumeRequest( pullResult.getMsgFoundList(), processQueue, pullRequest.getMessageQueue(), dispathToConsume); break; } } } }; } } 当提交一个消息消费请求后，对于并发消费，其实现如下:\npublic class ConsumeMessageConcurrentlyService implements ConsumeMessageService { class ConsumeRequest implements Runnable { @Override public void run() { // ...  status = listener.consumeMessage(Collections.unmodifiableList(msgs), context); // ...  } } } 我们可以看到 msgs 是直接从服务器端拿到的最新消息，直接喂给了客户端进行消费，并未做任何有序处理。当消费成功后，会从消息树中将这些消息再给删除掉:\npublic class ConsumeMessageConcurrentlyService implements ConsumeMessageService { public void processConsumeResult(final ConsumeConcurrentlyStatus status, /** 其它参数 **/) { // 从消息树中删除消息  long offset = consumeRequest.getProcessQueue().removeMessage(consumeRequest.getMsgs()); if (offset \u0026gt;= 0 \u0026amp;\u0026amp; !consumeRequest.getProcessQueue().isDropped()) { this.defaultMQPushConsumerImpl.getOffsetStore() .updateOffset(consumeRequest.getMessageQueue(), offset, true); } } } (2) 有序消费 RocketMQ 的有序消费主要依靠两把锁，一把是维护在 Broker 端，一把维护在消费者客户端。Broker 端有一个 RebalanceLockManager 服务，其内部维护了一个 mqLockTable 消息队列锁表:\npublic class RebalanceLockManager { private final ConcurrentMap\u0026lt;String/* group */, ConcurrentHashMap\u0026lt;MessageQueue, LockEntry\u0026gt;\u0026gt; mqLockTable = new ConcurrentHashMap\u0026lt;String, ConcurrentHashMap\u0026lt;MessageQueue, LockEntry\u0026gt;\u0026gt;(1024); } 在有序消费的时候，Broker 需要确保任何一个队列在任何时候都只有一个客户端在消费它，都在被一个客户端所锁定。当客户端在本地根据消息队列构建 PullRequest 之前，会与 Broker 沟通尝试锁定这个队列，另外当进行有序消费的时候，客户端也会周期性地 (默认是 20 秒) 锁定所有当前需要消费的消息队列:\npublic class ConsumeMessageOrderlyService implements ConsumeMessageService { public void start() { if (MessageModel.CLUSTERING.equals(ConsumeMessageOrderlyService.this.defaultMQPushConsumerImpl.messageModel())) { this.scheduledExecutorService.scheduleAtFixedRate(new Runnable() { @Override public void run() { ConsumeMessageOrderlyService.this.lockMQPeriodically(); } }, 1000 * 1, ProcessQueue.REBALANCE_LOCK_INTERVAL, TimeUnit.MILLISECONDS); } } } 由上述这段代码也能看出，只在集群模式下才会周期性地锁定 Broker 端的消息队列，因此在广播模式下是不支持进行有序消费的。\n而在 Broker 这端，每个客户端所锁定的消息队列对应的锁项 LogEntry 有一个上次锁定时的时间戳，当超过锁的超时时间 (默认是 60 秒) 后，也会判定这个客户端已经不再持有这把锁，以让其他客户端能够有序消费这个队列。\n在前面我们说到过 RebalanceService 均衡服务会定时地依据不同消费者数量分配消费队列。我们假设 Consumer-1 消费者客户端一开始需要消费 3 个消费队列，这个时候又加入了 Consumer-2 消费者客户端，并且分配到了 MessageQueue-2 消费队列。当 Consumer-1 内部的均衡服务检测到当前消费队列需要移除 MessageQueue-2 队列，这个时候，会首先解除 Broker 端的锁，确保新加入的 Consumer-2 消费者客户端能够成功锁住这个队列，以进行有序消费。\npublic abstract class RebalanceImpl { private boolean updateProcessQueueTableInRebalance(final String topic, final Set\u0026lt;MessageQueue\u0026gt; mqSet, final boolean isOrder) { while (it.hasNext()) { // ...  if (mq.getTopic().equals(topic)) { // 当前客户端不需要处理这个消息队列了  if (!mqSet.contains(mq)) { pq.setDropped(true); // 解锁  if (this.removeUnnecessaryMessageQueue(mq, pq)) { // ...  } } // ...  } } } } 消费者客户端每一次拉取消息请求，如果有发现新的消息，那么都会将这些消息封装为 ConsumeRequest 来喂给消费线程池，以待消费。如果消息特别多，这样一个队列可能有多个消费请求正在等待客户端消费，用户可能会先消费偏移量大的消息，后消费偏移量小的消息。所以消费同一队列的时候，需要一把锁以消费请求顺序化:\npublic class ConsumeMessageOrderlyService implements ConsumeMessageService { class ConsumeRequest implements Runnable { @Override public void run() { final Object objLock = messageQueueLock.fetchLockObject(this.messageQueue); synchronized (objLock) { // ...  } } } } RocketMQ 的消息树是用 TreeMap 实现的，其内部基于消息偏移量维护了消息的有序性。每次消费请求都会从消息树中拿取偏移量最小的几条消息 (默认为 1 条)给用户，以此来达到有序消费的目的:\npublic class ConsumeMessageOrderlyService implements ConsumeMessageService { class ConsumeRequest implements Runnable { @Override public void run() { // ...  final int consumeBatchSize = ConsumeMessageOrderlyService.this .defaultMQPushConsumer .getConsumeMessageBatchMaxSize(); List\u0026lt;MessageExt\u0026gt; msgs = this.processQueue.takeMessags(consumeBatchSize); } } } 扫描下面二维码，在手机端阅读：\n"});index.add({'id':52,'href':'/docs/books/clean_code/','title':"代码整洁之道",'content':"代码整洁之道 勒布朗法则：Later equals never.\n随着混乱的增加，团队生产力也持续下降，趋近于零。生产力下降的时候，管理层只能增加更多的人手，期望提高生产力。\n什么是整洁代码  我喜欢优雅和高效的代码。代码逻辑应当直截了当，叫缺陷难以隐藏；尽量减少依赖关系，使之便于维护；依据某种分层战略完善错误处理代码；性能调至最优，省得引诱别人做没规矩的优化，搞出一堆混乱来。整洁的代码只做好一件事。\u0026mdash; Bjarne Stroustrup，C++ 语言发明者\n  整洁的代码应可由作者之外的开发者阅读和增补。它应有单元测试和验收测试。它使用有意义的命名。它只提供一种而非多种做一件事的途径。它只有尽量少的依赖关系，且要明确地定义和提供清晰、尽量少的 API。代码应通过其表面表达含义，因为不同的语言导致并非所有必需信息均可通过代码自身清晰表达。\u0026mdash; Dave Thomas, OTI 公司创始人\n  整洁的代码总是看起来像是某位特别在意它的人写的。几乎没有改进的余地，代码作者什么都想到了。\u0026mdash; 《修改代码的艺术》作者\n 有意义的命名 对于变量，如果其需要注释来补充，那就不算是名副其实。比如你需要定义一个变量，这个变量存储的是消逝的时间，其单位是天，那么下面是一些比较好的命名：\nint elapsedTimeInDays; int daysSinceCreation; int daysSinceModification; int fileAgeInDays; 别用 accountList 来指一组账号，除非它真的是 List 类型，List 一词对于程序员有特殊意义，所以用 accountGroup 或 bunchOfAcounts，甚至用 accounts 都会好一些。\n别说废话，废话都是冗余。假如你有一个 Product 类，如果还有一个 ProductInfo 或 ProductData 类，它们虽然名称不同，意思却无区别。Info 和 Data 就像 a、an 和 the 一样，是意义含混的废话。下面三个函数的命名，我们怎么知道应该调用哪个呢？\ngetActiveAccount(); getActiveAccounts(); getActiveAccountInfo(); 使用常量，WORK_DAYS_PER_WEEK 比数字 5 要好找的多。\n 对于类名，其应该是名词或名词短语，如 Customer、WikiPage、Account 和 AddressParser，避免使用 Manager、Processor、Data 或 Info 这样的类名。类名不应当是动词。\n 对于方法名，其应当是动词或动词短语，如 postPayment、deletePage 或 save。\n 为每一个抽象概念选一个词，并且一以贯之。例如使用 fetch、retrieve 和 get 来给在多个类中的同种方法命名，你怎么记得住哪个类是哪个方法呢？在一堆代码中，有 controller，又有 manager，还有 driver，就会令人困惑。\n多数变量都依赖一个类、一个函数来给读者提供语境，但如果做不到的话，你可能就需要加上前缀。例如 addrFirstName 比 firstName 更能说明，你想表达的是地址的一部分，当然更好的方案是创建一个名为 Address 的类。当然也没必要添加不必要的语境，只要短名称足够清楚，就比长名称好。\n语境不明确的变量  有语境的变量   如何写好函数 函数的第一个规则是短小。第二条规则还是要短小。\n函数应该做一件事，做好这件事，只做这一件事。如何判断函数做了是否不止一件事，看是否能再拆出一个函数。要确保函数只做一件事，函数中的语句都要在同一抽象层级上。getHtml() 位于较高抽象层级，PathParser.render(pagePath) 位于中间抽象层，.append(\u0026quot;\\n\u0026quot;) 位于相当低的抽象层。函数中混杂了不同的抽象层级，往往容易让人迷惑，读者无法判断出某个表达式是基础概念还是细节。\n像如下带有 switch 函数的代码，有几个问题。太长、违反单一原则、违反开放闭合原则（添加新类型，必须修改）等，该问题的解决方案是将 switch 语句埋到抽象工厂底下，不让任何人看到。\nSwitch 语句  用多态封装 Switch 语句   好名称的价值怎么好评都不为过，别害怕长名称，长而具有描述性的名称，要比短而令人费解的名称好，要比描述性的长注释好。别害怕花时间取名字。\n关于函数参数，除非你有足够特殊的理由，才能用三个以上的参数。对于有一个参数的函数，如果要对这个参数进行某种转换操作，那么应该使用返回值来返回转换后的值：StringBuffer transform(StringBuffer in) 要比 void transform(StringBuffer out) 强。\n如果函数看来需要两个、三个或三个以上的参数，说明其中一些参数就需要封装为类了：\nCircle makeCircle(double x, double y, double radius); Circle makeCircle(Point center, double radius); 给函数起一个好名字，能够解释函数意图、参数顺序的名字。writeField(name) 要比 write(name) 强，assertExpectedEqualsActual(expected, actual) 要比 assertEqual 强，这大大减轻了记忆参数的负担。\n确保函数无副作用，函数承诺做这件事，不要在其内部偷偷地做其它事情。\ntry/catch 代码块丑陋不堪，最好把 try 和 catch 代码块的主题部分抽离出来，另外形成函数。错误处理本身就是一件事，这意味着在 try 应该是函数的第一个单词，catch/finally 是这个函数的最后的内容。\n注释 代码在变动，在演化，但注释不能总是随之变动，注释会撒谎。注释不能美化糟糕的代码。\n直接把代码注释掉是讨厌的做法，其他人不敢删除注释掉的代码，他们会想代码依然放在那儿，一定有其原因。\n格式 代码每行展现一个表达式或一个子句，每组代码行展示一条完整的思路。这些思路用空白行区隔开来。每个空白行都是一条线索，标识出新的独立概念。往下读代码时，你的目光总会停留于空白行之后的那一行。\n若某个函数调用了另外一个，就应该把他们放到一起，而且调用者应该尽可能放在被调用者上面，这样，程序有一个自然的顺序。\n对象和数据结构 乱加 set 和 get 时最坏的选择，不要暴露数据细节，而要以抽象形态表述数据。\n暴露了数据细节的车辆  百分比抽象   过程式代码便于在不改动现有数据结构的前提下添加新的函数，面向对象代码便于在不改动现有函数的前提下添加新的类。\nThe Law of Demeter 认为模块不应了解它所操作对象的内部情形，对象应该隐藏数据，暴露操作。下面代码违反了：\nfinal String outputDir = ctxt.getOptions().getScratchDir().getAbsolutePath(); 最为精炼的数据结构，是一个只有公共变量、没有函数的类，这种数据结构就是 DTO（Data Transfer Objects），这种数据结构在与数据库通信、解析套接字传递的消息之类场景中，非常有用。\n错误处理 使用 Checked Exception 的依赖成本要高于收益，每个调用该函数的函数都要捕获它，或者添加合适的 throw 语句，最终得到的时一个从软件最底端贯穿到最高端的修改链，封装被打破，抛出路径上的每个函数都要去了解下一层的异常细节。\n将第三方 API 打包是个良好的实践手段，降低了对它的依赖，未来可以不太痛苦地改用其它代码库，你也可以不必绑死在某个特定厂商的 API 设计上。\n返回 null 的时候，考虑是否可以直接抛出异常，或者返回一个特定的对象，尽量不要返回 null，它在给调用者添乱。返回 null 是糟糕的做法，那么传递 null 值给其它方法就是更糟糕的了。\n单元测试 测试带来一切好处。\n类 系统应该由许多短小的类而不是少量巨大的类组成。\n对类加以组织，可以降低修改的风险。\n一个必须打开修改的类  一组封闭类   "});index.add({'id':53,'href':'/docs/tutorial/sentinel/spi/','title':"可扩展性",'content':"可扩展性 SpiLoader public final class SpiLoader { public static \u0026lt;T\u0026gt; T loadFirstInstanceOrDefault(Class\u0026lt;T\u0026gt; clazz, Class\u0026lt;? extends T\u0026gt; defaultClass) { AssertUtil.notNull(clazz, \u0026#34;SPI class cannot be null\u0026#34;); AssertUtil.notNull(defaultClass, \u0026#34;default SPI class cannot be null\u0026#34;); try { String key = clazz.getName(); // Not thread-safe, as it\u0026#39;s expected to be resolved in a thread-safe context.  ServiceLoader\u0026lt;T\u0026gt; serviceLoader = SERVICE_LOADER_MAP.get(key); if (serviceLoader == null) { serviceLoader = ServiceLoaderUtil.getServiceLoader(clazz); SERVICE_LOADER_MAP.put(key, serviceLoader); } for (T instance : serviceLoader) { if (instance.getClass() != defaultClass) { return instance; } } return defaultClass.newInstance(); } catch (Throwable t) { RecordLog.error(\u0026#34;[SpiLoader] ERROR: loadFirstInstanceOrDefault failed\u0026#34;, t); t.printStackTrace(); return null; } } } "});index.add({'id':54,'href':'/docs/it-zone/2020-06/chrome-change-blacklist-to-blocklist/','title':"谷歌修改 Chromium 源码中的“黑白名单”术语",'content':"谷歌修改 Chromium 源码中的“黑白名单”术语 日期：2020-06-09\n 【为了种族中立，谷歌修改 Chromium 源码中的“黑白名单”术语】\n国外正在进行的 Black Lives Matter 运动，谷歌已表态支持。\n据外媒报道，Google 在修改 Chromium 源码中的有种族歧视色彩的术语，来消除微妙的种族主义形式。\n blacklist 改成 blocklist， whitelist 改成 allowlist；\n 2019 年 10 月，Chromium 开源项目的官方代码风格指南中，新增了如何编写种族中立代码的内容。其中明确指出，Chrome 和 Chromium 开发人员应避免使用“黑名单”和“白名单”一词，而应使用中性术语“阻止名单”和“允许名单”。\n其实早在 2018 年 5 月，Google 已开始着手删除普通用户在 Chrome 浏览器中能看到的“黑名单”和“白名单”。\n但普通用户看不到的 Chrome / Chromium 源码中，还有很多很多，据统计约 2000 多处。\n"});index.add({'id':55,'href':'/posts/java-lock/','title':"Java 并发 - 锁",'content':"Java 世界中都有哪些锁？锁的分类？如何减少锁的竞争等问题。\n线程安全的三种实现方式 互斥同步 (Blocking Synchronization)，属于悲观并发策略:\n非阻塞同步 (Non-Blocking Synchronization)，属于乐观并发策略:\n无同步 - 线程本地存储 (Thread Local Storage):\nJava 主内存与工作内存交互 从主内存读取变量到工作内存:\n将工作内存的变量写入到主内存:\n内置锁 Synchronized Java 提供了一种内置锁 (Intrinsic Lock)机制来支持原子性: 同步代码块 (Synchronized Block)。每个 Java 对象都可以用做一个实现同步的锁，这些锁被称为内置锁 (Instrinsic Lock) 或监视器锁 (Monitor Lock)。Java 的内置锁相当于一种互斥体(或互斥锁)，这意味着最多只有一个线程能持有这种锁。但是，加锁的含义不仅仅局限于互斥行为，还包括内存可见性，为了确保所有线程都能看到共享变量的最新值，所有执行读操作或者写操作的线程都必须在同一个锁上同步。\nJava synchronized 语句 是基于 monitorenter/monitorexit 机制来实现的。当你写下面这段代码的时候:\nstatic void Sort(int [] array) { // synchronize this operation so that some other thread can\u0026#39;t  // manipulate the array while we are sorting it. This assumes that other  // threads also synchronize their accesses to the array.  synchronized(array) { // now sort elements in array  } } 实际上 JVM 可能会生成下面的代码:\n.method static Sort([I)V aload_0 monitorenter ; lock object in local variable 0 ; now sort elements in array aload_0 monitorexit ; finished with object in local variable 0 return .end method monitorenter 在对象的引用上获取了一个 exclusive lock (独占锁)\n 内置锁 synchronized 是可重入的，某个线程试图获取一个已经由它自己持有的锁，那么这个请求就会成功。\n死锁 在数据库系统的设计中考虑了监测死锁以及从死锁中恢复。在执行一个事务 (Transaction) 时可能需要获取多个锁，并一直持有这些锁直到事务提交。当数据库服务器监测到一组事务发生了死锁时 (通过在表示等待关系的有向图中搜索循环)，将 选择一个牺牲者并放弃这个事务。作为牺牲者的事务会释放它所持有的资源，从而让其它事务继续进行。应用程序可以重新执行被强行中止的事务，而这个事务现在也可以成功完成。\n死锁的四大必要条件 (必须全部满足):\n 互斥 持有并等待资源 不可抢占 循环等待  如果所有的线程以固定的顺序来获得锁，那么在程序中就不会出现锁顺序死锁问题:\n// 不要这么做 public class LeftRightDeadlock { private final Object left = new Object(); private final Object right = new Object(); public void leftRight() { synchronized (left) { synchronized (right) { doSomething(); } } } public void rightLeft() { synchronized (right) { synchronized (left) { doSomethingElse(); } } } } 有时候，你并不能清除地知道是否在锁顺序上有足够的控制权来避免死锁的发生:\n// 动态的锁顺序 // Warning: deadlock-prone! public void transferMoney(Account fromAccount, Account toAccount, DollarAmount amount) throws InsufficientFundsException { synchronized (fromAccount) { synchronized (toAccount) { if (fromAccount.getBalance().compareTo(amount) \u0026lt; 0) throw new InsufficientFundsException(); else { fromAccount.debit(amount); toAccount.credit(amount); } } } } 在这里锁的顺序取决于参数顺序，而这些参数顺序又取决于外部输入，考虑下面代码就有可能发生死锁:\nA: transferMoney(myAccount, yourAccount, 10); B: transferMoney(yourAccount, myAccount, 20); 使用 System.identityHashCode 来定义锁的顺序:\nprivate static final Object tieLock = new Object(); public void transferMoney(final Account fromAcct, final Account toAcct, final DollarAmount amount) throws InsufficientFundsException { class Helper { public void transfer() throws InsufficientFundsException { if (fromAcct.getBalance().compareTo(amount) \u0026lt; 0) throw new InsufficientFundsException(); else { fromAcct.debit(amount); toAcct.credit(amount); } } } // 如果 Account 中包含一个唯一的、不可变的，并且具备可比性的键值，例如  // 账号，那么制定锁的顺序就更加容易了。  int fromHash = System.identityHashCode(fromAcct); int toHash = System.identityHashCode(toAcct); if (fromHash \u0026lt; toHash) { synchronized (fromAcct) { synchronized (toAcct) { new Helper().transfer(); } } } else if (fromHash \u0026gt; toHash) { synchronized (toAcct) { synchronized (fromAcct) { new Helper().transfer(); } } } else { // 在极少数情况下，两个对象可能拥有相同的散列值，  // 此时可以通过某种任意的方法来决定锁的顺序，  // 而这有可能重新引入死锁。为了避免这种情况，可以使用  // “加时赛”锁  synchronized (tieLock) { synchronized (fromAcct) { synchronized (toAcct) { new Helper().transfer(); } } } } } 某些获取多个锁的操作并不像 LeftRightDeadLock 或 transferMoney 中那么明显，这两个锁并不一定必须在同一个方法中被获取:\nclass Taxi { @GuardedBy(\u0026#34;this\u0026#34;) private Point location, destination; private final Dispatcher dispatcher; public Taxi(Dispatcher dispatcher) { this.dispatcher = dispatcher; } public synchronized Point getLocation() { return location; } // 先获取 Taxi 锁  // 再获取 Dispatcher 锁  public synchronized void setLocation(Point location) { this.location = location; if (location.equals(destination)) dispatcher.notifyAvailable(this); } } class Dispatcher { @GuardedBy(\u0026#34;this\u0026#34;) private final Set\u0026lt;Taxi\u0026gt; taxis; @GuardedBy(\u0026#34;this\u0026#34;) private final Set\u0026lt;Taxi\u0026gt; availableTaxis; public Dispatcher() { taxis = new HashSet\u0026lt;Taxi\u0026gt;(); availableTaxis = new HashSet\u0026lt;Taxi\u0026gt;(); } public synchronized void notifyAvailable(Taxi taxi) { availableTaxis.add(taxi); } // 先获取 Dispatcher 锁  // 再获取每一个 Taxi 锁  public synchronized Image getImage() { Image image = new Image(); for (Taxi t : taxis) image.drawMarker(t.getLocation()); return image; } } 通过将上述代码修改为开放调用 (调用某个方法时不需要使用锁)，从而消除发生死锁的风险:\n@ThreadSafe class Taxi { @GuardedBy(\u0026#34;this\u0026#34;) private Point location, destination; private final Dispatcher dispatcher; ... public synchronized Point getLocation() { return location; } public synchronized void setLocation(Point location) { boolean reachedDestination; synchronized (this) { this.location = location; reachedDestination = location.equals(destination); } if (reachedDestination) dispatcher.notifyAvailable(this); } } @ThreadSafe class Dispatcher { @GuardedBy(\u0026#34;this\u0026#34;) private final Set\u0026lt;Taxi\u0026gt; taxis; @GuardedBy(\u0026#34;this\u0026#34;) private final Set\u0026lt;Taxi\u0026gt; availableTaxis; ... public synchronized void notifyAvailable(Taxi taxi) { availableTaxis.add(taxi); } public Image getImage() { Set\u0026lt;Taxi\u0026gt; copy; synchronized (this) { copy = new HashSet\u0026lt;Taxi\u0026gt;(taxis); } Image image = new Image(); for (Taxi t : copy) image.drawMarker(t.getLocation()); return image; } } 在程序中应该尽量使用开放调用。与那些在持有锁时调用外部方法的程序相比，更易于对依赖于开放调用的程序进行死锁分析。通过使用定时锁能够有效地应对死锁问题，通过 Thread Dump 能够帮助你识别死锁的发生。\n减少锁的竞争 有三种方式可以降低锁的竞争程度:\n 减少锁的持有时间 降低锁的请求频率 使用带有协调机制的独占锁，这些机制允许更高的并发性  重入锁 ReentrantLock ReentrantLock 的 tryLock 方法为你提供了轮询锁与定时锁的锁获取模式，与无条件的锁获取模式相比，它具有更完善的错误恢复机制。方法 lockInterruptibly 方法能够在获得锁的同时保持对中断的响应。ReentrantLock 的构造函数中提供了两种公平性选择: 创建一个非公平的锁 (默认) 或者一个公平的锁。在公平的锁上，线程将按照它们发出请求的顺序来获得锁，但在非公平的锁上，则允许“插队”。在大多数情况下，非公平锁的性能要高于公平锁的性能。\npublic class ReentrantLock implements Lock, java.io.Serializable { /** Synchronizer providing all implementation mechanics */ private final Sync sync; abstract static class Sync extends AbstractQueuedSynchronizer { } public ReentrantLock(boolean fair) { sync = fair ? new FairSync() : new NonfairSync(); } public boolean tryLock() { return sync.nonfairTryAcquire(1); } public void unlock() { sync.release(1); } } 读写锁 ReadWriteLock public class ReentrantReadWriteLock implements ReadWriteLock, java.io.Serializable { public ReentrantReadWriteLock(boolean fair) { sync = fair ? new FairSync() : new NonfairSync(); readerLock = new ReadLock(this); writerLock = new WriteLock(this); } } 记录锁 Record Locking Record Locking 更好的叫法应该被称为: byte-range locking，目的是为了防止两个进程同时修改一个文件的某块区域。函数原型如下:\n#include \u0026lt;fcntl.h\u0026gt;// 出错返回 -1 int fcntl(int fd, int cmd, ... /* struct flock *flockptr */ ); 其中 flock 结构体定义如下:\nstruct flock { short l_type; /* F_RDLCK, F_WRLCK, or F_UNLCK */ short l_whence; /*SEEK_SET, SEEK_CUR, or SEEK_END */ off_t l_start; /*offset in bytes, relative to l_whence */ off_t l_len; /*length, in bytes; 0 means lock to EOF */ pid_t l_pid; /*returned with F_GETLK */ };  F_RDLCK: 共享读锁 F_WRLCK: 排斥写锁 F_UNLCK: 取消某个区域的锁  锁优化 自旋锁 SpinLock 互斥同步对性能最大的影响就是阻塞的实现，挂起线程和恢复线程的操作都需要转入内核态中完成，这些操作给系统的并发性能带来了很大的压力。同时，虚拟机的开发团队也注意到在许多应用上，共享数据的锁定状态只会持续很短的一段时间，为了这段时间去挂起和恢复线程并不值得。为了能让线程稍微等一会，我们只需让线程执行一个忙循环 (自旋)，这项技术就是所谓的自旋锁。\n现在我们假设硬件上有一种能够保证原子性的 TestAndSet 指令实现函数:\nint TestAndSet(int *x){ register int temp = *x; *x = 1; return temp; } TestAndSet 是一种常用的用于支持并发的原子操作指令。另外一种经常使用的指令是原子 Exchange 操作:\nvoid Exchange(int *a, int *b) { int temp = *a; *a = *b; *b = temp; } 这些所有的原子性操作中最重要的是 CompareAndSwap (CAS) 操作，它经常被用于 lock-free and wait-free algorithms 算法中。\nboolean CAS(int *a, int old, int new) { int temp = *a; if (temp == old) { *a = new; return true; } else return false; } 使用 CAS 来实现 temp++:\nint temp = x; while (!CAS(\u0026amp;x, temp, temp+1)) { temp = x; } 使用 CAS 来实现更链表头插法:\nwhile (1) { Node *q = *head; p-\u0026gt;next = q; if (CAS(head, q, p)) break; } 一般而言，SpinLock 是一种抽象的数据类型，其通常提供三种操作:\n InitLock Lock UnLock  Lock(mutex); Si; UnLock(mutex); 实现 SpinLock 的伪代码如下:\ntypedef int SpinLock; void InitLock(SpinLock *L) { *L = 0; } void Lock(SpinLock *L) { while (TestAndSet(L)) ; } void UnLock(SpinLock *L) { *L = 0; } 一种使用 Exchange 操作的可能实现:\ntypedef int SpinLock; void InitLock(SpinLock *s) { *s = 0; } void Lock (SpinLock *s) { int L = 1; do { Exchange(\u0026amp;L, s); } while (L == 1); } void UnLock (SpinLock *s) { *s = 0; } 另外一种使用 CompareAndSwap 指令的实现:\ntypedef int SpinLock; void InitLock(SpinLock *s) { *s = 0; } void Lock (SpinLock *s) { do { } until (CompareAndSwap(s, 0, 1)); } void UnLock (SpinLock *s) { *s = 0; } 自旋锁最大的问题就是可能会占用比较高的 memory bus 带宽，另外它也不保证公平性，即无法保证先后进入临界区的两个进程 P 和 Q 按照 FIFO 顺序来服务。\n锁消除 Lock Elimination 虚拟机 JIT 在运行时，对一些代码要求同步，但是被检测到不可能存在共享数据竞争的锁进行消除。主要判定依据来自于逃逸分析的数据支持。\n锁粗化 Lock Coarsening 轻量级锁 Lightweight Locking 偏向锁 Biased Locking 偏向锁的\u0026quot;偏\u0026rdquo;，是偏心的\u0026quot;偏\u0026rdquo;，它的意思就是这个锁会偏向于第一个获得它的线程，如果在接下来的执行过程中，该锁没有被其他的线程获取，则持有偏向锁的线程将永远不需要再进行同步。当有另外一个线程去尝试获取这个锁时，偏向模式就宣告结束。\nJDK 1.6 默认开启 -XX:+UseBiasedLocking，使用 -XX:-UseBiasedLocking 来关闭。\n偏向锁转为轻量级锁的流程图:\n锁升级 Lock Escalation 所谓的锁升级（lock escalation），是数据库的一种作用机制，该机制普遍见于各大数据库产品。 为了节约内存的开销，其会将为数众多并占用大量资源的细粒度的锁转化为数量较少的且占用相对较少资源的粗粒度的锁，多数情况下主要指将为数众多的行锁升级为一个表锁。当然，DB2 支持很多粒度的锁，如**表空间（table space），表（table），行（row）以及索引（index）**等。MySQL 的 InnoDB 存储引擎支持事务，默认是行锁。得益于这些特性，数据库支持高并发。\n锁升级与两种事情有关:\n 事务的隔离级别 索引  常用的索引有三类：主键、唯一索引、普通索引。主键 不由分说，自带最高效的索引属性；唯一索引 指的是该属性值重复率为0，一般可作为业务主键，例如学号；普通索引 与前者不同的是，属性值的重复率大于0，不能作为唯一指定条件，例如学生姓名。当“值重复率”低时，甚至接近主键或者唯一索引的效果，“普通索引”依然是行锁；当“值重复率”高时，MySQL 不会把这个“普通索引”当做索引，即造成了一个没有索引的 SQL，此时引发表锁。索引不是越多越好，索引存在一个和这个表相关的文件里，占用硬盘空间，宁缺勿滥，每个表都有主键（id），操作能使用主键尽量使用主键。同 JVM 自动优化 java 代码一样，MySQL 也具有自动优化 SQL 的功能。低效的索引将被忽略，这也就倒逼开发者使用正确且高效的索引。\n参考  《Java 并发编程实战》 Deadlock 《Advanced Programming in the UNIX》 《深入理解 Java 虚拟机》 CIS 4307: Spinlocks and Semaphores enter synchronized region of code 关于 DB2 锁升级 (lock escalation) 相关问题的探讨 MySQL 避免行锁升级为表锁——使用高效的索引 Innodb中的事务隔离级别和锁的关系 MySQL数据库事务各隔离级别加锁情况\u0026ndash;read uncommitted篇 Thread Synchronization "});index.add({'id':56,'href':'/posts/jvm-optimization/','title':"JVM 性能调优",'content':"JVM 如何进行性能调优？\nJava 虚拟机内存模型 JVM 虚拟机将内存数据分为如下这几部分：\npc register  pc register (program counter)： 一个包含当前时刻指令的地址的寄存器  程序寄存器区域是唯一一个在 Java 虚拟机规范中没有规定任何 OutOfMemoryError 情况的区域\nstack 栈会抛出两种异常：StackOverflowError 和 OutOfMemoryError，在 HotSpot 虚拟机栈中，可以使用参数 -Xss1M 来设置栈的大小为 1MB。随着调用函数参数的增加和局部变量的增加，单次函数调用对栈空间的需求也会增加，因此栈的最大递归次数不是一成不变的。函数嵌套调用的次数由栈的大小决定：栈越大，函数嵌套调用次数越多；对一个函数而言，它的参数越多，内部局部变量越多，它的栈帧就越大，其嵌套调用次数就会越少。\n Xss1M: 设置栈的大小  native method stack 与 stack 一样，同样抛出两种异常：StackOverflowError 和 OutOfMemoryError。在 sun 的 HOT SPOT 虚拟机中，不区分本地方法栈和虚拟机栈\nHEAP  -Xmx: 设置堆的最大值 -Xms: 设置堆的最小值，即 JVM 启动时，所占据的操作系统内存大小。JVM 会试图将系统内存尽可能地限制在 -Xms 中，因此当内存使用量触及 -Xms 指定的大小时，会触发 Full GC。因此把 -Xms 值设置为 -Xmx 时，可以在系统运行初期减少 GC 的次数和耗时。 Xmn: 设置新生代大小。等于把 -XX:NewSize 和 -XX:MaxNewSize 设置成了相同的大小。这两个如果设置成不同的值，会导致内存震荡，产生不必要的开销。  -XX:NewSize: 设置新生代的初始大小 -XX:MaxNewSize: 设置新生代的最大值    错误的把 Xmx 参数设置为了 Xmn 参数以后:\n获取当前内存/最大可用内存/最大可用堆:\nRuntime.getRuntime().freeMemory() / 1024 / 1024 Runtime.getRuntime().totalMemory() / 1024 / 1024 Runtime.getRuntime().maxMemory() / 1000 / 1000 逃逸分析 Java 7 开始支持对象的栈分配和逃逸分析机制，这样的机制能够将堆分配对象变成栈分配对象:\nvoid myMethod() { V v = new V(); // use v  v = null; }  -server: server 模式下，才可以启用逃逸分析 -XX:DoEscapeAnalysis: 启用逃逸分析  method area 方法区主要保存的是类的元数据：类型、常量池、字段、方法。在 Hot Spot 虚拟机中，方法区也称为永久区，同样也可以被 GC 回收。持久代的大小直接决定了系统可以支持多少个类定义和多少常量。对于使用 CGLIB 或者 Javassist 等动态字节码生成工具的应用程序而言，设置合理的持久代有利于维持系统稳定。\n方法区的大小直接决定了系统可以保存多少个类，如果系统使用了一些动态代理，那么有可能会在运行时生成大量的类，如果这样，就需要设置一个合理的永久区大小，确保不发生永久区内存溢出。\n -XX:MaxPermSize=4M: 设置持久代的最大值 -XX:PermSize=4M: 设置持久代的初始大小  在 JDK 1.8 中，永久区已经被彻底移除，取而代之的是元数据区 (Metaspace)，元数据区是一块堆外的直接内存，如果不指定元数据区大小的话，默认情况下，虚拟机会耗尽所有的可用系统内存。\n -XX:MaxMetaspaceSize: 指定元数据区大小  直接内存 使用 NIO 之后，直接内存的使用变得非常普遍，直接内存跳过了 Java 堆，可以直接访问原生堆空间。直接内存适合申请次数少、访问较为频繁的场合。如果需要频繁申请，则并不适合使用直接内存。\n -XX:MaxDirectMemorySize: 最大可用直接内存，默认为 -Xmx  区域比例  -XX:SurvivorRatio=8: 设置新生代中 eden 空间 和 S0 空间 的比例关系 -XX:NewRatio=2: 设置老生代和新生代的比例  垃圾回收算法  引用计数法: 无法解决循环引用问题 标记-清除算法 (Mark-Sweep):  标记从根节点开始的可达对象 清除所有未被标记的对象 最大缺点: 回收后的空间是不连续的   复制算法 (新生代):  内存空间分为两块，每次只用一块 存活对象复制到未使用的内存块中 清除正在使用的内存块中的所有对象 交换两个内存的角色 适合于新生代: 垃圾对象通常多于存活对象   标记-压缩算法:  标记从根节点开始的可达对象 将所有存活对象 (未标记的对象) 压缩到内存的一端 清理边界外 (标记和未标记对象的边界) 的对象     分代 (Generational Collecting):  根据每块内存空间特点的不同，使用不同的回收算法。如新生代 (存活对象少，垃圾对象多) 使用复制算法，老年代 (大部分对象是存活对象) 使用标记-压缩算法    为了支持高频率的新生代回收，虚拟机可能使用一种叫做卡表 (Card Table) 的数据结构。卡表为一个比特位集合，每一个比特位可以用来表示老年代的某一区域中的所有对象是否持有新生代对象的引用。这样在新生代 GC 时，只需先扫描卡表，就能快速知道用不用扫描特定的老年代对象，而卡表为 0 的所在区域一定不含有新生代对象的引用。\n谁才是真正的垃圾  可触及性: 根节点可到达 可复活: finalize() 中复活 不可触及: finalize() 中未复活  finalize() 方法只会被调用一次\n@Override protected void finalize() throws Throwable { super.finalize(); obj = this; }  StringBuffer str = new StringBuffer(\u0026#34;Hello world\u0026#34;); 假设以上代码是在函数体内运行的，那么:\n 软引用: java.lang.ref.SoftReference 可被回收的引用\n 弱引用: 发现即回收。由于垃圾回收器的线程通常优先级很大，因此并不一定很快地发现持有弱引用的对象。\n 虚引用: 跟踪垃圾回收过程\n垃圾回收器 串行回收器  新生代垃圾串行收集器，使用 -XX:+UseSerialGC 来指定新生代和老年代都是用串行收集器。这个收集器虽然古老，但却久经考验。使用单线程进行垃圾回收。虚拟机在 Client 模式下运行，它是默认的垃圾收集器。独占式回收。   老年代串行收集器，使用的是标记-压缩算法。  -XX:+UseSerialGC: 新生代、老生代都使用串行回收器 -XX:+UseParNewGC -XX:+UseParallelGC     并行回收器 新生代 ParNew 回收器:\n -XX:+UseParNewGC -XX:+UseConcMarkSweepGC  回收器工作时的线程数量可以使用 -XX:ParallelGCThreads 参数指。一般最好与 CPU 数量相当，避免过多的线程数。默认算法\nint getGCThreadsCount() { if ( countOfCPU \u0026lt; 8 ) return countOfCPU; else return 3 + ( ( 5 * countOfCPU ) / 8 ); }  新生代 ParallelGC 回收器: 关注系统吞吐量\n -XX:+UseParallelGC -XX:+UseParallelOldGC  两个重要参数控制系统吞吐量:\n -XX:MaxGCPauseMillis: 设置最大垃圾收集停顿时间 -XX:GCTimeRatio: 设置吞吐量大小 -XX:+UseAdaptiveSizePolicy: 打开自适应 GC 策略   老年代 ParallelOldGC: 标记压缩算法\n  并行收集器，将串行回收器多线程化。并行回收器工作时的线程数量可以使用 -XX:ParallelGCThreads 参数指定，一般最好与 CPU 数量相当，避免过多的线程数，影响垃圾收集性能。  -XX:+UseParNewGC: 新生代使用并行回收收集器 (ParNew)，老年代使用串行收集器 -XX:+UseConcMarkSweepGC: 新生代使用并行收集器 (ParNew)，老年代使用 CMS   新生代并行回收收集器，使用复制算法  -XX:+UseParallelGC: 新生代使用并行回收收集器 (ParallelGC)，老年代使用串行收集器   老年代并行回收收集器，使用标记-压缩算法  使用 -XX:+UseParallelOldGC: 新生代使用 ParallelGC ，老年代使用 ParallelOldGC     CMS (Concurrent Mark Sweep): 关注系统停顿时间，非独占式\n -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction: 当老年代的空间使用率达到 68% (默认) 时进行一次 CMS 垃圾回收 -XX:+UseCMSCompactAtFullCollection: 在垃圾收集完成之后，进行一次内存碎片整理 CMS 收集器，这是一个关注停顿的垃圾收集器    G1 收集器: JDK 1.7 正式启用  新生代串行收集器和老年代串行收集器都是串行的、独占式的垃圾收集器。不要求整个 eden 区、年轻代或者老年代都连续\n 使用 -XX:+UseSerialGC 打印出的 GC 信息:\n[GC (Allocation Failure) [DefNew: 18954K-\u0026gt;897K(28864K), 0.0020543 secs] 18954K-\u0026gt;897K(93056K), 0.0020917 secs] [Times: user=0.00 sys=0.00, real=0.00 secs] 使用 -XX:+UseParNewGC 打印出的 GC 信息:\n[GC (Allocation Failure) [ParNew: 19468K-\u0026gt;880K(28864K), 0.0033698 secs] 19468K-\u0026gt;880K(93056K), 0.0034037 secs] [Times: user=0.00 sys=0.00, real=0.00 secs] 使用 -XX:+UseParallelOldGC (默认) 打印出的 GC 信息:\n[GC (Allocation Failure) [PSYoungGen: 24485K-\u0026gt;448K(28160K)] 368549K-\u0026gt;344520K(379904K), 0.0039329 secs] [Times: user=0.02 sys=0.00, real=0.01 secs] G1 (Garbage-First) 垃圾收集器 以前的垃圾收集器 (serial, parallel, CMS) 将堆分为固定大小的三个区域: 年轻代、老年代和永久代:\n但是，G1 采取了一种不同的方法:\n堆被分成了一系列相同大小的区域，并且相同角色的区域的大小不再是固定的，这样在内存使用上能够提供更大的灵活性。当垃圾收集开始的时候，G1 和 CMS 执行的操作其实是一样的:\n 并发全局扫描标记检查存活的对象 哪些区域垃圾对象最多，G1 就先收集哪些区域，这也是它为什么称为 Garbage-First 的原因   其他垃圾收集器使用 jvm 内置线程回收，而 G1 采用应用线程承担回收工作。\nG1 垃圾收集器 VS CMS 垃圾收集器 G1 就是计划取代 Concurrent Mark-Sweep Collector (CMS). 与 CMS 相比，G1:\n G1 是一个 compacting collector. G1 compacts sufficiently to completely avoid the use of fine-grained free lists for allocation, and instead relies on regions. This considerably simplifies parts of the collector, and mostly eliminates potential fragmentation issues. G1 提供了更多的可预测的垃圾收集停顿，允许用户指定停顿时间  实用 JVM 参数  获取堆快照。  发生 OutOfMemoryError 时，可以使用 -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=C:\\m.hprof 来保存当前的堆快照到文件中。也可以加上参数 -XX:OnOutOfMemoryError=c:\\reset.bat 来运行一段脚本。\n当发生 OutOfMemoryError (在一个 Windows 32 系统上就发生过) 的时候，应该尝试使用增大可用堆：\njava -Xmn1024M -jar xxx.jar TODO: 思考: 如果知晓程序究竟需要多大内存？\n 获取 GC 信息  使用参数 -verbose:gc 或者 -XX:+PrintGC 来获取简要的 GC 信息，也可以使用 -XX:+PrintGCDetails 来获取更加详细的信息。如果需要在 GC 发生的时刻打印 GC 发生的时间，则可以追加 -XX:+PrintGCTimeStamps 选项以查看相对时间或者 -XX:+PrintGCDateStamps 以查看绝对时间。如果许雅查看新生对象晋升到老年代的实际阈值，可以使用参数 -XX:+PrintTenuringDistribution -XX:MaxTenuringThreshold=18 来运行程序。如果需要在 GC 时，打印详细的堆信息，则可以打开 -XX:+PrintHeapAtGC 开关。\n 控制 GC  -XX:+PrintExplicitGC 选项用于禁止显式的 GC 操作，即禁止在程序中使用 System.gc() 触发的 Full GC。另一个有用的 GC 控制参数是 -Xincgc，一旦启用这个参数，系统便会进行增量式的 GC。\nJVM 调优的主要过程有: 确定堆内存大小 (-Xmx、-Xms)、合理分配新生代和老年代 (-XX:NewRatio、-Xmn、-XX:SurvivorRatio)、确定永久区大小 (-XX:Permsize、-XX:MaxPermSize)、选择垃圾收集器、对垃圾收集器进行合理的设置。除此之外，禁用显式 GC (-XX:+DisableExplicitGC)、禁用类元数据回收 (+Xnoclassgc)、禁用类验证 (-Xverify:none) 等设置，对提升系统性能也有一定的帮助。\n GC 日志示例  使用 -XX:+PrintGC 获取的 GC 日志:\n[GC (Allocation Failure) GC前堆使用量20M-\u0026gt;GC后堆使用量(当前可用堆大小90M), 本次GC花费 0.0028389 秒] [GC (Allocation Failure) 20409K-\u0026gt;432K(92672K), 0.0028389 secs] 同样的代码使用 -X:+PrintGCDetails 获取的 GC 日志:\n[GC (Allocation Failure) [新生代: 从20M-\u0026gt;降为0.4M(可用28M)] 整个堆从20M-\u0026gt;将为0.4M(可用90M), 0.0151333 secs] [Times: 用户态时间耗时，系统态时间耗时，GC 实际经历的时间] 新生代 总大小 28M, 已用 13M [下界，当前上界，上界] [GC (Allocation Failure) [PSYoungGen: 20409K-\u0026gt;448K(28160K)] 20409K-\u0026gt;456K(92672K), 0.0151333 secs] [Times: user=0.00 sys=0.00, real=0.02 secs] Heap PSYoungGen total 28160K, used 13461K [0x00000000e1380000, 0x00000000e4a80000, 0x0000000100000000) eden space 24576K, 52% used [0x00000000e1380000,0x00000000e20356d0,0x00000000e2b80000) from space 3584K, 12% used [0x00000000e2b80000,0x00000000e2bf0020,0x00000000e2f00000) to space 3584K, 0% used [0x00000000e4700000,0x00000000e4700000,0x00000000e4a80000) ParOldGen total 64512K, used 8K [0x00000000a3a00000, 0x00000000a7900000, 0x00000000e1380000) object space 64512K, 0% used [0x00000000a3a00000,0x00000000a3a02000,0x00000000a7900000) Metaspace used 3264K, capacity 4494K, committed 4864K, reserved 1056768K class space used 363K, capacity 386K, committed 512K, reserved 1048576K 如果需要更为全面的堆信息，还可以使用参数 -XX:+PrintHeapAtGC，它会在每次 GC 前后分别打印堆的信息\n{Heap before GC invocations=1 (full 0): ... Heap after GC invocations=1 (full 0): ... } 如果需要分析 GC 发生的时间，还可以使用 -XX:+PrintGCTimeStamps 参数，该输出时间为虚拟机启动后的时间偏移量:\n0.174: [GC (Allocation Failure) 20409K-\u0026gt;504K(92672K), 0.0016586 secs] 0.179: [GC (Allocation Failure) 19415K-\u0026gt;464K(92672K), 0.0031200 secs] 0.186: [GC (Allocation Failure) 19812K-\u0026gt;432K(92672K), 0.0009531 secs] 由于 GC 还会引起应用程序停顿，使用参数 -XX:+PrintGCApplicationConcurrentTime 可以打印应用程序的执行时间，使用参数 -XX:+PrintGCApplicationStoppedTime 可以打印应用程序由于 GC 而产生的停顿时间:\nApplication time: 0.0084849 seconds [GC (Allocation Failure) 20409K-\u0026gt;520K(92672K), 0.0044274 secs] Total time for which application threads were stopped: 0.0045452 seconds, Stopping threads took: 0.0000210 seconds Application time: 0.0033066 seconds [GC (Allocation Failure) 19431K-\u0026gt;440K(117248K), 0.0020202 secs] Total time for which application threads were stopped: 0.0021438 seconds, Stopping threads took: 0.0000258 seconds Application time: 0.0082455 seconds 如果想跟踪系统内的软引用、弱引用、虚引用和 Finalize 队列，则可以使用打开 -XX:+PrintReferenceGC 开关. 使用参数 -Xloggc:log/gc.log 启动虚拟机，将 GC 日志输出到 gc.log 文件中\nJava HotSpot(TM) 64-Bit Server VM (25.111-b14) for linux-amd64 JRE (1.8.0_111-b14), built on Sep 22 2016 16:14:03 by \u0026quot;java_re\u0026quot; with gcc 4.3.0 20080428 (Red Hat 4.3.0-8) Memory: 4k page, physical 6052560k(316636k free), swap 6233084k(4248464k free) CommandLine flags: -XX:InitialHeapSize=96840960 -XX:MaxHeapSize=1549455360 -XX:+PrintGC -XX:+PrintGCApplicationConcurrentTime -XX:+PrintGCApplicationStoppedTime -XX:+PrintGCTimeStamps -XX:+UseCompressedClassPointers -XX:+UseCompressedOops -XX:+UseParallelGC 0.183: Application time: 0.0107645 seconds 0.183: [GC (Allocation Failure) 20409K-\u0026gt;432K(92672K), 0.0033748 secs] 0.187: Total time for which application threads were stopped: 0.0035825 seconds, Stopping threads took: 0.0000191 seconds 0.192: Application time: 0.0054269 seconds 0.193: [GC (Allocation Failure) 19343K-\u0026gt;496K(117248K), 0.0108382 secs] 0.204: Total time for which application threads were stopped: 0.0116746 seconds, Stopping threads took: 0.0000766 seconds 0.212: Application time: 0.0084699 seconds 系统参数查看:\n -XX:+PrintVMOptions: 打印虚拟机接受的命令行显示参数 -XX:+PrintCommandLineFlags: 打印虚拟机的显示和隐式参数 -XX:+PrintFlagsFinal: 打印所有的系统参数的值  # 打印出系统的堆大小 java -XX:+PrintFlagsFinal -version | grep -iE \u0026#39;HeapSize|PermSize|ThreadStackSize\u0026#39; Minor GC、Major GC 和 Full GC  Minor GC: 从年轻代回收垃圾，当 JVM 无法分配新对象的时候会触发 Minor GC，也就是说 Eden 区域已经满了 Major GC: 清除 Tenured 区域 Full GC: 清除整个堆，包括 Yound 和 Tenured 区域  Java 各版本默认垃圾收集器 参考 1 说:\nOn server-class machines running the server VM, the garbage collector (GC) has changed from the previous serial collector [\u0026hellip;] to a parallel collector\nReference 2 says:\nStarting with J2SE 5.0, when an application starts up, the launcher can attempt to detect whether the application is running on a \u0026ldquo;server-class\u0026rdquo; machine and, if so, use the Java HotSpot Server Virtual Machine (server VM) instead of the Java HotSpot Client Virtual Machine (client VM).\nAlso, reference 2 says:\n注意: 对于 Java SE 6, the definition of a server-class machine is one with at least 2 CPUs and at least 2GB of physical memory.\nJava 7 和 Java 8 使用的都是 Parallel GC，Java 9 使用的是 G1 垃圾收集器\nJVM 的工作模式  java -version: 查看 Server VM java -client -version: 查看 Client VM  Client 和 Server 模式下的各种参数可能会有很大不同\nHeap Memory 最佳实践  是否分配了过多实例: 使用 jcmd 8998 GC.class_histogram 来查看各实例有多少个，也可以使用 jmap -histo 8998 来获得相同的结果 分析堆快照: 使用 jhat、jvisualvm、mat 等工具来分析 hprof 文件  jcmd 8998 GC.heap_dump /path/to/heap_dump.hprof jmap -dump:live,file=/path/to/heap_dump.hprof 8998: 引入 live 强制 full GC    Java Monitoring 常用工具 jstack Jstack: Dumps the stacks of a Java 进程\njstack $PID \u0026gt; $DATE_DIR/jstack-$PID.dump 2\u0026gt;\u0026amp;1 jinfo Jinfo: Provides visibility into the system properties of the JVM, and allows some system properties to be set dynamically.\nroot@zk-pc:~# jinfo 18772 Attaching to process ID 18772, please wait... Debugger attached successfully. Server compiler detected. JVM version is 25.144-b01 Java System Properties: com.sun.management.jmxremote.authenticate = false java.runtime.name = Java(TM) SE Runtime Environment java.vm.version = 25.144-b01 ...(省略好多) VM Flags: Non-default VM flags: -XX:CICompilerCount=3 -XX:InitialHeapSize=98566144 -XX:+ManagementServer -XX:MaxHeapSize=1549795328 -XX:MaxNewSize=516423680 -XX:MinHeapDeltaBytes=524288 -XX:NewSize=32505856 -XX:OldSize=66060288 -XX:+UseCompressedClassPointers -XX:+UseCompressedOops -XX:+UseFastUnorderedTimeStamps -XX:+UseParallelGC Command line: -Dcom.sun.management.jmxremote.port=5780 -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false -javaagent:/usr/lib/intellij_idea/idea-IC-172.3968.16/lib/idea_rt.jar=35487:/usr/lib/intellij_idea/idea-IC-172.3968.16/bin -Dfile.encoding=UTF-8 jstat jstat: 提供有关 GC 和类加载活动的相关信息\n显示可用的九个 options:\njstat -options One useful option is -gcutil, which displays the time spent in GC as well as the percentage of each GC area that is currently filled. Other options to jstat will display the GC sizes in terms of KB.\nRemember that jstat takes an optional argument—the number of milliseconds to repeat the command—so it can monitor over time the effect of GC in an application.\njstat -gcutil process_id 1000 打印出的是:\nroot@zk-pc:~# jstat -gcutil 18772 S0 S1 E O M CCS YGC YGCT FGC FGCT GCT 0.00 71.53 97.93 34.02 96.70 93.37 29 0.133 1 0.040 0.172  gccapacity 可以显示 VM 内存中三代（young,old,perm）对象的使用和占用大小\njstat -gccapacity process_id 打印出的是:\nroot@zk-pc:~# jstat -gccapacity 18772 NGCMN NGCMX NGC S0C S1C EC OGCMN OGCMX OGC OC MCMN MCMX MC CCSMN CCSMX CCSC YGC FGC 31744.0 504320.0 30720.0 4608.0 4608.0 21504.0 64512.0 1009152.0 44032.0 44032.0 0.0 1069056.0 22272.0 0.0 1048576.0 2560.0 32 1 jmap (Memory Map) jmap: Provides heap dumps and other information about JVM memory usage.\njmap $PID 打印的是一堆这种东西:\nroot@zk-pc:~# jmap 18772 Attaching to process ID 18772, please wait... Debugger attached successfully. Server compiler detected. JVM version is 25.144-b01 0x0000000000400000\t7K\t/usr/lib/jvm/oracle_jdk8/jdk1.8.0_144/bin/java 0x00007f7072978000\t98K\t/lib/x86_64-linux-gnu/libresolv-2.23.so 0x00007f7072b93000\t26K\t/lib/x86_64-linux-gnu/libnss_dns-2.23.so 0x00007f7072d9a000\t10K\t/lib/x86_64-linux-gnu/libnss_mdns4_minimal.so.2 0x00007f70737a1000\t87K\t/lib/x86_64-linux-gnu/libgcc_s.so.1 0x00007f70739b7000\t251K\t/usr/lib/jvm/oracle_jdk8/jdk1.8.0_144/jre/lib/amd64/libsunec.so ...(省略好多)  Print histogram(直方图；柱状图) of java object heap; if the \u0026ldquo;live\u0026rdquo; suboption is specified, only count live objects:\njmap -histo $PID jmap -histo:live $PID root@zk-pc:~# jmap -F -histo 18772 Object Histogram: num #instances\t#bytes\tClass description -------------------------------------------------------------------------- 1:\t65711\t10183976\tchar[] 2:\t13523\t8919400\tbyte[] 3:\t54732\t2159368\tjava.lang.Object[] 4:\t7341\t1451792\tint[] 5:\t56423\t1354152\tjava.lang.String 6:\t15476\t619040\tjava.util.TreeMap$Entry 7:\t16562\t529984\tjava.io.ObjectStreamClass$WeakClassKey 8:\t11915\t476600\tjava.util.LinkedHashMap$Entry 9:\t9716\t466368\tjava.util.HashMap 10:\t3993\t453312\tjava.lang.Class 11:\t11568\t370176\tjava.util.concurrent.ConcurrentHashMap$Node 12:\t6160\t306952\tjava.util.HashMap$Node[] 13:\t4210\t279856\tjava.util.Hashtable$Entry[] 14:\t8320\t266240\tjava.util.Vector 15:\t8070\t258240\tjava.util.HashMap$Node 16:\t10495\t251880\torg.jsoup.nodes.Attribute 17:\t4181\t200688\tjava.util.Hashtable ...(省略好多)  Print java heap summary:\njmap -heap $PID 打印出的是一堆这种东西:\nroot@zk-pc:~# jmap -heap 18772 Attaching to process ID 18772, please wait... Debugger attached successfully. Server compiler detected. JVM version is 25.144-b01 using thread-local object allocation. Parallel GC with 4 thread(s) Heap Configuration: MinHeapFreeRatio = 0 MaxHeapFreeRatio = 100 MaxHeapSize = 1549795328 (1478.0MB) NewSize = 32505856 (31.0MB) MaxNewSize = 516423680 (492.5MB) OldSize = 66060288 (63.0MB) NewRatio = 2 SurvivorRatio = 8 MetaspaceSize = 21807104 (20.796875MB) CompressedClassSpaceSize = 1073741824 (1024.0MB) MaxMetaspaceSize = 17592186044415 MB G1HeapRegionSize = 0 (0.0MB) Heap Usage: PS Young Generation Eden Space: capacity = 23068672 (22.0MB) used = 11772712 (11.227333068847656MB) free = 11295960 (10.772666931152344MB) 51.03333213112571% used From Space: capacity = 11010048 (10.5MB) used = 2035424 (1.941131591796875MB) free = 8974624 (8.558868408203125MB) 18.48696754092262% used To Space: capacity = 11534336 (11.0MB) used = 0 (0.0MB) free = 11534336 (11.0MB) 0.0% used PS Old Generation capacity = 45088768 (43.0MB) used = 13718432 (13.082916259765625MB) free = 31370336 (29.917083740234375MB) 30.42538665061773% used 8999 interned Strings occupying 836656 bytes. 堆内存使用最佳实践 堆分析 (1) 查看直方图\n// jcmd 命令默认就会进行 full GC jcmd 6808 GC.class_histogram jmap -histo 6808 // 如果指明 live: 选项，将会强制进行一个 full GC jmap -histo:live 6808  num #instances #bytes class name ---------------------------------------------- 1: 12227 1303424 [C 2: 1003 627856 [B 3: 1917 461864 [I 4: 3828 421768 java.lang.Class 5: 11665 279960 java.lang.String 6: 6065 194080 java.util.concurrent.ConcurrentHashMap$Node 7: 2794 173144 [Ljava.lang.Object; 8: 3072 122880 org.apache.lucene.index.FreqProxTermsWriter$PostingList 9: 2760 110400 java.util.LinkedHashMap$Entry 10: 1097 101144 [Ljava.util.HashMap$Node; 11: 5440 87040 java.lang.Object 12: 2680 85760 java.util.HashMap$Node 13: 520 45760 java.lang.reflect.Method 14: 44 44064 [Ljava.util.concurrent.ConcurrentHashMap$Node; 15: 781 43736 java.util.LinkedHashMap 16: 96 41088 [Lorg.apache.lucene.index.RawPostingList; ... (2) Dump 堆\n// 指明 live，强制进行 full GC jmap -dump:live,file=/tmp/heap_dump.hprof 6808 // 或者 jmap -F -dump:format=b,file=filename.hprof 20961 // 或者简单点 jmap -F -dump:file=filename.hprof 20961  注意: 路径一定要显示指明，否则不知道默认保存到哪里去了\n 通常有三种工具能够分析 .hprof 文件：\n jhat jvisualvm mat  (3) 内存溢出\n内存溢出通常发生在:\n Native 内存用光了 permgen(Java 7) 或者 metaspace(Java 8) 内存用光了 Java 堆内存用光了 JVM 进行 GC 的时间太长了  使用更少的内存 (1) 减少对象大小\n(2) 延迟初始化 (3) 不可变对象 (4) String Interning\n对象生命周期管理 JIT (1) 编译还是解释 Languages like C++ and Fortran are called compiled languages because their programs are delivered as binary (compiled) code: the program is written, and then a static compiler produces a binary. The assembly code in that binary is targeted to a particular CPU. Complementary CPUs can execute the same binary: for example, AMD and Intel CPUs share a basic, common set of assembly language instructions, and later versions of CPUs almost always can execute the same set of instructions as previous versions of that CPU.\nLanguages like PHP and Perl, on the other hand, are interpreted. The same program source code can be run on any CPU as long as the machine has the correct interpreter (that is, the program called php or perl). The interpreter translates each line of the program into binary code as that line is executed.\nJava attempts to find a middle ground here. Java applications are compiled—but instead of being compiled into a specific binary for a specific CPU, they are compiled into an idealized assembly language. This assembly language (know as Java bytecodes) is then run by the java binary (in the same way that an interpreted PHP script is run by the php binary). This gives Java the platform independence of an interpreted language. Because it is executing an idealized binary code, the java program is able to compile the code into the platform binary as the code executes. This compilation occurs as the program is executed: it happens “just in time.\n(2) HotSpot 名字的含义 In a typical program, only a small subset of code is executed frequently, and the performance of an application depends primarily on how fast those sections of code are executed. These critical sections are known as the hot spots of the application; the more the section of code is executed, the hotter that section is said to be.\nHence, when the JVM executes code, it does not begin compiling the code immediately. There are two basic reasons for this. First, if the code is going to be executed only once, then compiling it is essentially a wasted effort; it will be faster to interpret the Java bytecodes than to compile them and execute (only once) the compiled code.\nthe more times that the JVM executes a particular method or loop, the more information it has about that code. This allows the JVM to make a number of optimizations when it compiles the code.\n(3) 寄存器和内存 If the value of sum were to be retrieved from (and stored back to) main memory on every iteration of this loop, performance would be dismal. Instead, the compiler will load a register with the initial value of sum, perform the loop using that value in the register, and then (at an indeterminate point in time) store the final result from the register back to main memory.\nRegister usage is a general optimization of the compiler, and when escape analysis is enabled (see the end of this chapter), register use is quite aggressive.\n(4) 选择 Java 编译器  A 32-bit client version (-client) A 32-bit server version (-server) A 64-bit server version (-d64)  For the sake of compatibility, the argument specifying which compiler to use is not rigorously followed. If you have a 64-bit JVM and specify -client, the application will use the 64-bit server compiler anyway. If you have a 32 bit JVM and you specify -d64, you will get an error that the given instance does not support a 64-bit JVM.\nThe client compiler begins compiling sooner than the server compiler does. code produced by the server compiler will be faster than that produced by the client compiler. couldn’t the JVM start with the client compiler, and then use the server compiler as code gets hotter? That technique is known as tiered compilation. With tiered compilation, code is first compiled by the client compiler; as it becomes hot, it is recompiled by the server compiler.\n# Java 7 需要打开, Java 8 默认开启 -server -XX:+TieredCompilation  For GUI programs, uses the client compiler by default. Performance is often all about perception: if the initial startup seems faster, and everything else seems fine, users will tend to view the program that has started faster as being faster overall. For long-running applications, always choose the server compiler, preferably in conjunction with tiered compilation.  查看默认编译器:\njava -version (5) 更多考虑因素 Code Cache: When the JVM compiles code, it holds the set of assembly-language instructions in the code cache. Code Cache 有固定大小, and once it has filled up, the JVM is not able to compile any additional code.\n 编译阈值: The major factor involved here is 多频繁 the code is executed; once it is executed a certain number of times, its compilation threshold is reached, and the compiler deems that it has enough information to compile the code.\nCompilation is based on two counters in the JVM: 方法调用次数, and 方法内循环的实际次数. When the JVM executes a Java method, it checks the sum of those two counters and decides whether or not the method is eligible for compilation. This kind of compilation has no official name but is often called standard compilation (标准编译).\nBut what if the method has a really long loop—or one that never exits and provides all the logic of the program? In that case, the JVM needs to compile the loop without waiting for a method invocation. So every time the loop completes an execution, the branching counter is incremented and inspected. If the branching counter has exceeded its individual threshold, then the loop (and not the entire method) becomes eligible for compilation.\nThis kind of compilation is called on-stack replacement (OSR), because even if the loop is compiled, that isn’t sufficient: the JVM has to have the ability to start executing the compiled version of the loop while the loop is still running. When the code for the has finished compiling, the JVM replaces the code (on-stack), and the next iteration of the loop will execute the much-faster compiled version of the code (下一次循环就是编译版本了).\nStandard compilation is triggered by the value of the -XX:CompileThreshold=N flag. The default value of N for the client compiler is 1,500; for the server compiler it is 10,000.\n 查看编译过程: -XX:+PrintCompilation.\njstat has two options to provide information about the compiler. The -compiler option supplies summary information about 多少方法被编译了 (here 5003 is the process ID of the program to be inspected):\njstat -compiler 5003 lternately, you can use the -printcompilation option to get information about the 最后一个方法 that is compiled. In this example, jstat repeats the information for process ID 5003 every second (1,000 ms):\njstat -printcompilation 5003 1000  编译线程个数:\n 内联:\nOne of the most important optimizations the compiler makes is to inline methods.\npublic class Point { private int x, y; public void getX() { return x; } public void setX(int i) { x = i; } } 当你写这样代码的时候:\nPoint p = getPoint(); p.setX(p.getX() * 2); 编译后的代码执行的将会是:\nPoint p = getPoint(); p.x = p.x * 2; The basic decision about whether to inline a method depends on 多频繁 and 大小. The JVM determines if a method is hot (i.e., called frequently) based on an internal calculation; it is not directly subject to any tunable parameters. If a method is eligible for inlining because it is called frequently, then it will be inlined only if its 字节码大小小于 325 字节 (or whatever is specified as the -XX:MaxFreqInlineSize=N flag). Otherwise, it is eligible for inlining only if it is small: 小于 35 字节 (or whatever is specified as the -XX:MaxInlineSize=N flag)\n 逃逸分析:\nThe server compiler performs some very aggressive optimizations if escape analysis is enabled (-XX:+DoEscapeAnalysis, 默认开启).\npublic class Factorial { private BigInteger factorial; private int n; public Factorial(int n) { this.n = n; } public synchronized BigInteger getFactorial() { if (factorial == null) factorial = ...; return factorial; } } The factorial object is referenced only inside that loop; no other code can ever access that object. Hence, the JVM is free to perform a number of optimizations on that object:\n It needn’t get a synchronization lock when calling the getFactorial() method. It needn’t store the field n in memory; it can keep that value in a register. Similarly it can store the factorial object reference in a register. In fact, it needn’t allocate an actual factorial object at all; it can just keep track of the individual fields of the object.  (6) Deoptimization Deoptimization means that the compiler 不得不撤销一些优化; the effect is that the performance of the application will be reduced—at least until the compiler can recompile the code in question. There are two cases of deoptimization: when code is “made not entrant,” and when code is “made zombie”.\n Not Entrant Code:\nThere are two things that cause code to be made not entrant. One is due to the way classes and interfaces work, and one is an implementation detail of tiered compilation\nStockPriceHistory sph; String log = request.getParameter(\u0026#34;log\u0026#34;); if (log != null \u0026amp;\u0026amp; log.equals(\u0026#34;true\u0026#34;)) { sph = new StockPriceHistoryLogger(...); } else { sph = new StockPriceHistoryImpl(...); } // Then the JSP makes calls to: sph.getHighPrice(); sph.getStdDev(); // and so on If a bunch of calls are made to http://localhost:8080/StockServlet (that is, without the log parameter), the compiler will see that the actual type of the sph object is StockPriceHistoryImpl. It will then inline code and perform other optimizations based on that knowledge. Later, say a call is made to http://localhost:8080/StockServlet?log=true. Now the assumption the compiler made regarding the type of the sph object is false; the previous optimizations are no longer valid. This generates a deoptimization trap, and the previous optimizations are discarded. If a lot of additional calls are made with logging enabled, the JVM will quickly end up compiling that code and making new optimizations.\nIn tiered compilation, code is compiled by the client compiler, and then later compiled by the server compiler (and actually it’s a little more complicated than that, as discussed in the next section). When the code compiled by the server compiler is ready, the JVM must replace the code compiled by the client compiler. It does this by 将旧代码标记为 Not Entrant and using the same mechanism to substitute the newly compiled (and more efficient) code.\n Deoptimizing Zombie Code:\nRecall that the compiled code is held in a fixedsize code cache; when zombie methods are identified, it means that the code in question can be removed from the code cache, making room for other classes to be compiled (or limiting the amount of memory the JVM will need to allocate later).\nThe possible downside here is that if the code for the class is made zombie and then later reloaded and heavily used again, the JVM will need to recompile and reoptimize the code.\nTODO  https://docs.oracle.com/javase/6/docs/technotes/guides/management/jconsole.html https://stackoverflow.com/questions/1058991/how-to-monitor-java-memory-usage  远程 JVisualVM 远程机器上输入 jstatd:\nCould not create remote object access denied (\u0026quot;java.util.PropertyPermission\u0026quot; \u0026quot;java.rmi.server.ignoreSubClasses\u0026quot; \u0026quot;write\u0026quot;) java.security.AccessControlException: access denied (\u0026quot;java.util.PropertyPermission\u0026quot; \u0026quot;java.rmi.server.ignoreSubClasses\u0026quot; \u0026quot;write\u0026quot;) at java.security.AccessControlContext.checkPermission(AccessControlContext.java:472) at java.security.AccessController.checkPermission(AccessController.java:884) at java.lang.SecurityManager.checkPermission(SecurityManager.java:549) at java.lang.System.setProperty(System.java:792) at sun.tools.jstatd.Jstatd.main(Jstatd.java:139) 你需要创建一个安全策略文件: jstatd.all.policy，里面写上这句话:\ngrant codebase \u0026quot;file:/opt/java/jdk1.7.0_21/lib/tools.jar\u0026quot; { permission java.security.AllPermission; }; 然后使用如下命令重新启动:\njstatd -J -Djava.security.policy=/home/user/jstatd.all.policy 在本机测试，是否能够 telnet 到 jstatd 服务:\ntelnet 10.108.112.218 1099 有些时候，jstatd 可能绑定的并不是正确的网卡:\n-J-Djava.rmi.server.hostname=10.1.1.123 强制使用 IPV4:\n-J-Djava.net.preferIPv4Stack=true 查看一些日志输出:\n-J-Djava.rmi.server.logCalls=true 最后的命令:\njstatd -J-Djava.security.policy=./jstatd.all.policy -J-Djava.rmi.server.hostname=10.108.112.218 -J-Djava.rmi.server.logCalls=true GC 日志分析工具  GCeasy  DUMP 什么 以下是 dubbo - dump.sh 备份的内容:\nDUMP_DATE=`date +%Y%m%d%H%M%S` DATE_DIR=$DUMP_DIR/$DUMP_DATE echo -e \u0026#34;Dumping the $SERVER_NAME...\\c\u0026#34; for PID in $PIDS ; do jstack $PID \u0026gt; $DATE_DIR/jstack-$PID.dump 2\u0026gt;\u0026amp;1 echo -e \u0026#34;.\\c\u0026#34; jinfo $PID \u0026gt; $DATE_DIR/jinfo-$PID.dump 2\u0026gt;\u0026amp;1 echo -e \u0026#34;.\\c\u0026#34; jstat -gcutil $PID \u0026gt; $DATE_DIR/jstat-gcutil-$PID.dump 2\u0026gt;\u0026amp;1 echo -e \u0026#34;.\\c\u0026#34; jstat -gccapacity $PID \u0026gt; $DATE_DIR/jstat-gccapacity-$PID.dump 2\u0026gt;\u0026amp;1 echo -e \u0026#34;.\\c\u0026#34; jmap $PID \u0026gt; $DATE_DIR/jmap-$PID.dump 2\u0026gt;\u0026amp;1 echo -e \u0026#34;.\\c\u0026#34; jmap -heap $PID \u0026gt; $DATE_DIR/jmap-heap-$PID.dump 2\u0026gt;\u0026amp;1 echo -e \u0026#34;.\\c\u0026#34; jmap -histo $PID \u0026gt; $DATE_DIR/jmap-histo-$PID.dump 2\u0026gt;\u0026amp;1 echo -e \u0026#34;.\\c\u0026#34; if [ -r /usr/sbin/lsof ]; then /usr/sbin/lsof -p $PID \u0026gt; $DATE_DIR/lsof-$PID.dump echo -e \u0026#34;.\\c\u0026#34; fi done if [ -r /bin/netstat ]; then /bin/netstat -an \u0026gt; $DATE_DIR/netstat.dump 2\u0026gt;\u0026amp;1 echo -e \u0026#34;.\\c\u0026#34; fi if [ -r /usr/bin/iostat ]; then /usr/bin/iostat \u0026gt; $DATE_DIR/iostat.dump 2\u0026gt;\u0026amp;1 echo -e \u0026#34;.\\c\u0026#34; fi if [ -r /usr/bin/mpstat ]; then /usr/bin/mpstat \u0026gt; $DATE_DIR/mpstat.dump 2\u0026gt;\u0026amp;1 echo -e \u0026#34;.\\c\u0026#34; fi if [ -r /usr/bin/vmstat ]; then /usr/bin/vmstat \u0026gt; $DATE_DIR/vmstat.dump 2\u0026gt;\u0026amp;1 echo -e \u0026#34;.\\c\u0026#34; fi if [ -r /usr/bin/free ]; then /usr/bin/free -t \u0026gt; $DATE_DIR/free.dump 2\u0026gt;\u0026amp;1 echo -e \u0026#34;.\\c\u0026#34; fi if [ -r /usr/bin/sar ]; then /usr/bin/sar \u0026gt; $DATE_DIR/sar.dump 2\u0026gt;\u0026amp;1 echo -e \u0026#34;.\\c\u0026#34; fi if [ -r /usr/bin/uptime ]; then /usr/bin/uptime \u0026gt; $DATE_DIR/uptime.dump 2\u0026gt;\u0026amp;1 echo -e \u0026#34;.\\c\u0026#34; fi 从上可知一般统计的都有如下几项:\n jstack: 线程信息 jinfo: 配置信息. The configuration information includes Java system properties and Java Virtual Machine (JVM) command-line flags. jstat -gcutil: 垃圾收集统计 jstat -gccapacity: Displays statistics about the capacities of the generations and their corresponding spaces. jmap: Prints 共享对象内存 maps or 堆内存 details for a process, core file, or remote debug server. jmap -heap: Prints a heap summary of the garbage collection used, the head configuration, and generation-wise heap usage. In addition, the number and size of interned Strings are printed. jmap -histo: Prints a histogram of the heap lsof -p netstat -an iostat: Report Central Processing Unit (CPU) statistics and input/output statistics for devices, partitions and network filesystems (NFS). mpstat: Report 处理器 related statistics. vmstat: vmstat (virtual memory statistics) is a computer system monitoring tool that collects and displays summary information about operating system memory, processes, interrupts, paging and block I/O. free -t: Display amount of 可用/已用内存 in the system. -t: Display a line showing the column totals. sar: In computing, sar (System Activity Report) is a Unix System V-derived system monitor command used to report on various system loads, including CPU 活动, memory/paging, 设备负载, 网络. Linux distributions provide sar through the sysstat package. uptime: uptime gives a one line display of the following information. The 当前时间, 多长时间 the system has been running, 多少用户 are currently logged on, and the 系统平均负载 averages for the past 1, 5, and 15 minutes.  实际运用中如何清晰明了地观察 JVM 的运行过程?  图形工具: JProfiler, JConsole, Java VisualVM 命令: jps, jstack, jmap, jhat, jstat  JVM 如何进阶 问:JVM如何进阶，目前周志明的《深入理解JVM》第2版看了两遍，能够根据目录口述书中大部分内容，还需要了解哪些知识？\n答：周志明的书只能算是 JVM 的入门书籍。接下来你应该去读一读**《Java虚拟机规范》**，周志明的书很多内容是从里面来的，但是规范本身比较详细，注意读英文原版。其次去读一下Oralce的文档：**《Hotspot Memory Management white paper》, 《Java Platform, Standard Edition HotSpot Virtual Machine Garbage Collection Tuning Guide》**。现在你需要进一步修炼关于**内存管理**的部分，阅读比如**《垃圾回收算法与实现》**，如果这本读完还不满足，那么阅读**《自动内存管理艺术——垃圾回收算法手册》**。到了这一步，理论你已经掌握得很好了，是时候把 Hotspot 源码 download 下来编译好之后断点调试玩玩了，这个时候我要推荐你今年阿里人刚出的**《揭秘Java虚拟机》**，不过阅读这本书之前你要是愿意先读完**《深入理解计算机系统》**效果更好。到了这一步，剩下的，自己探索了，我也在探索。\n 问: 线上CPU很高、内存占用很少，有能快速查找到原因的方法吗？\n答: 给一个代码，在 Linux 下保存成 .sh 文件直接执行即可。\n#!/bin/sh ts=$(date +\u0026#34;%s\u0026#34;) jvmPid=$1 defaultLines=100 defaultTop=20 threadStackLines=${2:-$defaultLines} topThreads=${3:-$defaultTop} jvmCapture=$(top -b -n1 | grep java ) threadsTopCapture=$(top -b -n1 -H | grep java ) jstackOutput=$(echo \u0026#34;$(jstack $jvmPid )\u0026#34; ) topOutput=$(echo \u0026#34;$(echo \u0026#34;$threadsTopCapture\u0026#34; | head -n $topThreads | perl -pe \u0026#39;s/\\e\\[?.*?[\\@-~] ?//g\u0026#39; | awk \u0026#39;{gsub(/^ +/,\u0026#34;\u0026#34;);print}\u0026#39; | awk \u0026#39;{gsub(/ +|[+-]/,\u0026#34; \u0026#34;);print}\u0026#39; | cut -d \u0026#34; \u0026#34; -f 1,9 )\\n \u0026#34;) echo \u0026#34;*************************************************************************************************************\u0026#34; uptime echo \u0026#34;Analyzing top $topThreadsthreads\u0026#34; echo \u0026#34;*************************************************************************************************************\u0026#34; printf %s \u0026#34;$topOutput\u0026#34; | while IFS= read line do pid=$(echo $line | cut -d \u0026#34; \u0026#34; -f 1) hexapid=$(printf \u0026#34;%x\u0026#34; $pid) cpu=$(echo $line | cut -d \u0026#34; \u0026#34; -f 2) echo -n $cpu\u0026#34;% [$pid] \u0026#34; echo \u0026#34;$jstackOutput\u0026#34; | grep \u0026#34;tid.*0x$hexapid\u0026#34; -A $threadStackLines | sed -n -e \u0026#39;/0x\u0026#39;$hexapid\u0026#39;/,/tid/ p\u0026#39; | head -n -1 echo \u0026#34;\\n\u0026#34; done echo \u0026#34;\\n\u0026#34; 代码的意思，打印出 JVM 的所有线程以及按照 CPU 占比排序。\n 问: 您好，想问一个 JVM 比较基础的知识，现在的垃圾收集都是分代回收，那么在回收新生代的时候是要同时扫描老年代吗？是全表还是有一种策略，比如 G1 的 Remembered set，这个 set 只是记录了一种引用关系；那其它的分代回收，比如 CMS 和 ParNew 组合时只能是回收新生代的时候扫描老年代吗？那这样效率不就是降低了不少吗？\n答：对于老年代指向新生代的引用，JVM提供了一种叫 card table 的数据结构，所以每次并不需要全量遍历老年代，只需要遍历 card table 就行了。\n 问: 线上定位内存 JVM 内存溢出，除了打印堆栈拿出来分析，还有没有其它的方式？\n答：导出 JVM dump 文件，在本地使用 Eclipse 插件 MAT 分析，可视化的分析最方便、直观、有效。\n垃圾回收器怎么选择  最小化地使用内存和并行开销，请选择 Serial GC 最大化应用程序的吞吐量，请选择Parallel GC 最小化 GC 的中断或者停顿时间，请选择 CMS GC   并发和并行都可以表示两个或者多个任务一起执行，但是偏重点不同。并发偏重于多个任务交替执行，而多个任务之间有可能还是串行的。而并行是真正意义上的“同时执行”。\n内存泄漏代码示例 while (true) { for (int i=0; i\u0026lt;10000; i++) { if (!m.contains(new Key(i))) { m.put(new Key(i), \u0026#34;Number:\u0026#34; + i); } } } Interned Strings String 类型的常量池比较特殊。主要使用方法有两种:\n 直接使用双引号声明出来的 String 对象会直接存储在常量池中。 如果不是双引号声明的 String 对象，可以使用 String 提供的 intern 方法。intern 会先判断是否存在常量池中，如果不存在，则会将当前字符串放入常量池中。  JDK 6的常量池放在 Perm 区中，默认大小只有 4 MB。JDK 7开始，放在堆中。\nMAT 1) The Dominator Tree:\nThe key to understanding your retained heap, is looking at the dominator tree. The dominator tree is a tree produced by the complex object graph in your system. The dominator tree allows you to identify the largest memory graphs. An Object X is said to dominate an Object Y if every path from the Root to Y must pass through X.\nhttps://javaeesupportpatterns.blogspot.jp/2013/03/openjpa-memory-leak-case-study.html\nJVM 诊断示例 1) 健康的 JVM:\n2) 启动内存暴涨:\n3) 激增:\n4) 内存泄露\nJVisualVM 需要安装一个 Visual GC 插件:\n才能显示具体的 GC 过程:\nTODO https://plumbr.eu/handbook/garbage-collection-algorithms-implementations#serial-minor-gc\n如何在生产环境使用 Btrace 进行调试 大多数问题的解决方式都是在本地打断点进行调试，或者在测试环境利用输出日志进行调试，这种方式简单粗暴，但过程比较繁琐，需要各种重新发布，重启应用，还不能保证一次就找到问题的根源。\nBTrace 是 sun 公司推出的一款 Java 动态、安全追踪（监控）工具，可以在不用重启的情况下监控系统运行情况，方便的获取程序运行时的数据信息，如方法参数、返回值、全局变量和堆栈信息等，并且做到最少的侵入，占用最少的系统资源。\n由于 Btrace 会把脚本逻辑直接侵入到运行的代码中，所以在使用上做很多限制：\n 不能创建对象 不能使用数组 不能抛出或捕获异常 不能使用循环 不能使用 synchronized 关键字 属性和方法必须使用 static 修饰  根据官方声明，不恰当的使用 BTrace 可能导致 JVM 崩溃，如在 BTrace 脚本使用错误的 class 文件，所以在上生产环境之前，务必在本地充分的验证脚本的正确性。\nBtrace 可以做什么？  接口性能变慢，分析每个方法的耗时情况； 当在 Map 中插入大量数据，分析其扩容情况； 分析哪个方法调用了 System.gc() 执行某个方法抛出异常时，分析运行时参数； \u0026hellip;  假设服务器端运行的是如下代码:\npublic class BtraceCase { public static Random random = new Random(); public int size; public static void main(String[] args) throws Exception { new BtraceCase().run(); } public void run() throws Exception { while (true) { add(random.nextInt(10), random.nextInt(10)); } } public int add(int a, int b) throws Exception { Thread.sleep(random.nextInt(10) * 100); return a + b; } } 我们想要对 add 方法的传入参数、返回值和执行耗时进行分析:\n通过 jps 获取服务器端的进程ID: 8454，执行命令\nbtrace 8454 Debug.java 实现对运行代码的监控:\n可以发现，Btrace 可以获取每次执行 add 方法时的数据，当然 Btrace 能做的远远不止这些，比如获取当前 jvm 堆使用情况、当前线程的执行栈等等。\n参数说明 // clazz: 需要监控的类 // method: 需要监控的方法 // clazz 和 method 可以使用正则、接口、注解等来指定 // location: 拦截位置 // Kind.ENTRY: 进入方法的时候，调用脚本 // Kind.RETURN: 执行完的时候，调用脚本 // 只有定义为 RETURN，才能获取方法的返回结果 @Return 和 @Duration @OnMethod(clazz=\u0026#34;com.metty.rpc.common.BtraceCase\u0026#34;, method=\u0026#34;add\u0026#34;, location=@Location(Kind.RETURN)) 如何使用 Btrace 定位问题  找出所有耗时超过 1ms 的过滤器 Filter  由于 @Dutation 返回的时间是纳秒级别，需要进行转换。\n 哪个方法调用了 System.gc()，调用栈如何？   统计方法的调用次数，且每隔 1 分钟打印调用次数  Btrace 的 @OnTimer 注解可以实现定时执行脚本中的一个方法\n 方法执行时，查看对象的实例属性值  通过反射机制，可以很方便的得到当前实例的属性值。\n总结 Btrace 能做的事情太多，但使用之前切记检查脚本的可行性，一旦 Btrace 脚本侵入到系统中，只有通过重启才能恢复。\n参考  《Java 程序性能优化》 Java (JVM) Memory Model – Memory Management in Java find which type of garbage collector is running Default garbage collector for Java 8 Getting Started with the G1 Garbage Collector cms Minor GC vs Major GC vs Full GC 《Java Performance: The Definitive Guide》 《大话 Java 性能调优》 《深入理解 JVM \u0026amp; G1 GC》 "});index.add({'id':57,'href':'/docs/programmer-interview/algorithm/best-time-to-buy-and-sell-stock-4/','title':"Best Time to Buy and Sell Stock Ⅳ",'content':"Best Time to Buy and Sell Stock Ⅳ 题目 LeetCode 地址：Best Time to Buy and Sell Stock Ⅳ\n有一个数组，第 i 个元素的值代表第 i 天的股票价格，如果你最多只能进行K次交易（某天买入一支股票，然后过几天卖掉），请问你能收获的最大利润是多少？\n分析 参考 Best Time to Buy and Sell Stock 思路上状态机，状态机应用K次即可。\n答案 // 最多交易 k 次 // https://leetcode.com/problems/best-time-to-buy-and-sell-stock-iv/ // public class BestTimetoBuyandSellStockIV { public int maxProfit(int k, int[] prices) { if (prices == null || prices.length \u0026lt;= 1 || k \u0026lt;= 0) { return 0; } if (k \u0026gt;= prices.length / 2) { // 这就相当于怎样，可交易任意多次  // 问题转为 BestTimetoBuyandSellStockII  return maxProfitQuestion2(prices); } int s0 = 0; int[] sArray = new int[k * 2]; initStateArray(prices, sArray); for (int i = 1; i \u0026lt; prices.length; i++) { s0 = s0; sArray[0] = Math.max(sArray[0], s0 - prices[i]); for (int j = 1; j \u0026lt; sArray.length; j++) { if (j % 2 == 1) { sArray[j] = Math.max(sArray[j - 1] - prices[i], sArray[j]); } else { sArray[j] = Math.max(sArray[j - 1] + prices[i], sArray[j]); } } } return sArray[sArray.length - 1]; } private void initStateArray(int[] prices, int[] sArray) { for (int i = 0; i \u0026lt; sArray.length; i += 2) { sArray[i] = -prices[0]; } } public int maxProfitQuestion2(int[] prices) { int max = 0; for (int i = 1; i \u0026lt; prices.length; i++) { int diff = prices[i] - prices[i - 1]; if (diff \u0026gt; 0) { max += diff; } } return max; } } 扫描下面二维码，在手机上阅读这篇文章：\n"});index.add({'id':58,'href':'/docs/tutorial/git/git-reset/','title':"Git 重置",'content':"Git 重置 git reset 命令是 Git 最危险最容易误用的命令之一！一定要慎用，要清除地知道你自己在做什么！\nGit reset 命令格式 git reset [--soft | --mixed | --hard] [\u0026lt;commit\u0026gt;] Git 提交历史记录 cat .git/refs/heads/master 显示的就是当前版本库的最新的 commitid\nGit 重置与版本变化关系图 上述图，\n 1 代表更新引用指向，即引用指向新的 commit 2 代表暂存区的内容与版本库保持一致 3 代表工作区的内容与暂存区保持一致  使用不同的参数，执行的操作不一样：\n --hard 参数，上图 1、2、3 这三步全部执行 --soft 参数，上图 1 执行 --mixed 参数，上图 1、2 执行 不使用参数，等同于使用了 --mixed 参数  根据上述解释，我们来看几个例子：\n彻底回退到上一次提交 git reset --hard HEAD^  HEAD^ 指：HEAD 的父提交，即上一次提交。注意 --hard 选项会将本地工作区的内容也恢复为上一次提交，且不可恢复，所以此命令慎用！！！\n 彻底回退到某一次 commit 根据 commit id 回退到某一次的提交：\ngit reset --hard 9e8a761  9e8a761 代表完整 commit id 的前 6 位，一般前 6 位就可以定位出一次 commit 了。\n 将文件改动撤出暂存区 git reset # 或 git reset HEAD # 或 git reset -- fileName # 或 git reset HEAD fileName 上述命令，相当于对 git add 命令的反向操作，其可以撤出所有 add 进暂存区的文件，也可以单独针对某个 fileName 文件做出撤出。\n撤出后，你对这个文件的改动依然保留在本地，只不过这个文件没有 add 进暂存区而已，没有什么损失。\n软回退到上一次提交 git reset --soft HEAD^ 工作区和暂存区保持不变，但是引用向前回退一次。当对最新提交的修改、或者提交的修改说明不满意的时候，可以使用这个命令撤销最新的提交，以便重新提交。\n工作中常用的 git commit --amend 命令（用于对最新的提交修改或提交说明进行修改，以便重新进行提交）就是相当于执行了下面两条命令：\ngit reset --soft HEAD^ git commit -e -F .git/COMMIT_EDITMSG 如何恢复 reset 在执行 reset 之前，一定要使用 git log 记录好最近的几次 commitId 记录，当出现问题的时候，还可以恢复到指定的 commitId 提交上。\n不过如果之前忘记记录的话，也可以通过查看 cat .git/logs/HEAD 日志文件内容，来找到有关 commit id 的记录。\nGit 本身也提供了 git reflog 命令，来查看日志信息：\ngit reflog show master 参考  Git权威指南  扫描下面二维码，在手机端阅读：\n"});index.add({'id':59,'href':'/docs/tutorial/front-end-optimization-guide/js-optimization/','title':"JS 优化",'content':"JS 优化 本文介绍常见的优化 JS、提升 JS 加载性能的优化方法！\n提升加载性能 script 放入到 body 中 \u0026lt;script\u0026gt; 标签经常以下面的这种方式引入：\n\u0026lt;script src=\u0026#34;script.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; 当 HTML 解析器看到这一行代码时，就会请求获取脚本，并执行脚本。一旦这个过程完成，解析就可以继续，剩下的 HTML 也可以被分析。所以你可以想象，这个操作会对页面的加载时间产生多么大的影响。如果脚本加载的时间比预期的稍长，例如，如果网络有点慢，或者如果您在移动设备上，并且网速特别慢，则在加载和执行脚本之前，访问者可能会看到一个空白页。\n所以推荐将 script 标签从 \u0026lt;head\u0026gt; 位置挪到 \u0026lt;/body\u0026gt; 标签前。如果你这样做了，脚本在所有页面都被解析和加载之后才会加载和执行，这是对 \u0026lt;head\u0026gt; 替代方案的巨大改进。\n\u0026lt;script defer src=\u0026#34;script.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; Async 和 Defer 如果不考虑兼容旧浏览器，那么 async 和 defer 这两个布尔属性值，会是提升页面加载速度的更好选择：\n\u0026lt;script async src=\u0026#34;script.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;script defer src=\u0026#34;script.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; 这两个属性都可以达到异步加载和执行 script 标签的目的，如果同时指定了两个，那么 async 优先级高一点，老一点的浏览器不支持 async 会降级到 defer。这些属性只有在页面的 \u0026lt;head\u0026gt; 部分使用 \u0026lt;script\u0026gt; 时才有意义，如果像我们上面看到的那样将脚本放在 \u0026lt;body\u0026gt; 中，则这些属性是无用的。\n使用 async 会阻塞 HTML 的解析：\n使用 defer 并不会阻塞 HTML 的解析：\n因此在使用 script 时，要加快页面加载速度，最好的方法是将它们放在 \u0026lt;head\u0026gt; 中，并在 \u0026lt;script\u0026gt; 中添加一个 defer 属性：\n\u0026lt;script defer src=\u0026#34;script.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; JS 变量和函数优化 尽量使用 ID 选择器 使用 ID 选择器来选择元素永远都是最快的！\n不要使用 eval eval 函数的三宗罪：\n 不正确使用 eval 会让代码变得更容易注入攻击 调试可能更具挑战性（没有行号等） eval 代码执行速度较慢（没有机会编译/缓存 eval 代码）  JS 事件节流 假设您有一个滚动事件处理程序，当用户在页面上向下移动时，您想在其中向用户显示新内容。如果我们在用户每次滚动单个像素时就执行回调，那么如果他们快速滚动事件，我们的页面将会变得巨卡无比，因为它将快速连续发送数百或数千个事件。相反，我们对其进行限制，比如仅检查每100毫秒滚动一次的数量，这样每秒仅获得10个回调。用户仍然可以立即感觉到响应，并且计算效率更高。可以看到，通过限制这些回调或者比如频繁的 API 请求等，可以防止应用程序卡住或对服务器不必要的请求。\n节流函数示例：\n// Pass in the callback that we want to throttle and the delay between throttled events const throttle = (callback, delay) =\u0026gt; { // Create a closure around these variables.  // They will be shared among all events handled by the throttle.  let throttleTimeout = null; let storedEvent = null; // This is the function that will handle events and throttle callbacks when the throttle is active.  const throttledEventHandler = event =\u0026gt; { // Update the stored event every iteration  storedEvent = event; // We execute the callback with our event if our throttle is not active  const shouldHandleEvent = !throttleTimeout; // If there isn\u0026#39;t a throttle active, we execute the callback and create a new throttle.  if (shouldHandleEvent) { // Handle our event  callback(storedEvent); // Since we have used our stored event, we null it out.  storedEvent = null; // Create a new throttle by setting a timeout to prevent handling events during the delay.  // Once the timeout finishes, we execute our throttle if we have a stored event.  throttleTimeout = setTimeout(() =\u0026gt; { // We immediately null out the throttleTimeout since the throttle time has expired.  throttleTimeout = null; // If we have a stored event, recursively call this function.  // The recursion is what allows us to run continusously while events are present.  // If events stop coming in, our throttle will end. It will then execute immediately if a new event ever comes.  if (storedEvent) { // Since our timeout finishes:  // 1. This recursive call will execute `callback` immediately since throttleTimeout is now null  // 2. It will restart the throttle timer, allowing us to repeat the throttle process  throttledEventHandler(storedEvent); } }, delay); } }; // Return our throttled event handler as a closure  return throttledEventHandler; }; 如何使用这个节流器呢？\nvar returnedFunction = throttle(function() { // Do all the taxing stuff and API requests }, 500); window.addEventListener(\u0026#39;scroll\u0026#39;, returnedFunction); 事件委托 如下图所示，“+ Add Character” 按钮可以动态地给 DOM 增加复选框，复选框本身又可以进行点击，那么新增的复选框点击的事件如何绑定上？针对此问题，事件委托的解决方案是指将拦截点击的事件监听器绑定在父元素 \u0026lt;ul\u0026gt; 上，而非单个 input 上。\n最好把事件委托看作是负责任的父母和疏忽大意的孩子。父母基本上是神，孩子们必须听父母的话。美妙的是，如果我们增加更多的孩子（更多的输入），父母会保持不变-他们从一开始就在那里（ul 元素在页面加载的时候就存在）。\n事件委托的代码：\n\u0026lt;ul class=”characters”\u0026gt; // PARENT -- 监听器绑定在这个元素上 ! \u0026lt;li\u0026gt; \u0026lt;input type=”checkbox” data-index=”0\u0026#34; id=”char0\u0026#34;\u0026gt; //CHILD 1 \u0026lt;label for=”char0\u0026#34;\u0026gt;Mickey\u0026lt;/label\u0026gt; \u0026lt;/li\u0026gt; \u0026lt;li\u0026gt; \u0026lt;input type=”checkbox” data-index=”1\u0026#34; id=”char1\u0026#34;\u0026gt; //CHILD 2 \u0026lt;label for=”char1\u0026#34;\u0026gt;Minnie\u0026lt;/label\u0026gt; \u0026lt;/li\u0026gt; \u0026lt;li\u0026gt; \u0026lt;input type=”checkbox” data-index=”2\u0026#34; id=”char2\u0026#34;\u0026gt; //CHILD 3 \u0026lt;label for=”char2\u0026#34;\u0026gt;Goofy\u0026lt;/label\u0026gt; \u0026lt;/li\u0026gt; \u0026lt;/ul\u0026gt; \u0026lt;script\u0026gt; //Event Delegation function toggleDone (event) { if (!event.target.matches(‘input’)) return console.log(event.target) //We now have the correct input - we can manipulate the node here } const characterList = document.querySelector(\u0026#39;.characters\u0026#39;); characterList.addEventListener(\u0026#39;click\u0026#39;, toggleDone); \u0026lt;/script\u0026gt; 上述，当点击任意一个 input 的时候，event.target 的值指向的是哪个元素发生了点击：\n而 event.currentTarget 代表的是事件监听器绑定在哪个元素上：\n更进一步，当点击 input 元素的时候，这个事件会沿着自己的父链向上传递，所以任何一个父节点都能感受到这个事件，这称之为事件冒泡。\n如果没有事件委托，则必须将单击事件监听器重新绑定到加载到页面的每个新输入，这是复杂和繁重的编码任务。首先，它会大幅增加页面上事件监听器的数量，更多的事件监听器会增加页面的总内存占用。内存占用量越大，性能越差……这是一件坏事。其次，可能存在与绑定和解除绑定事件监听器以及从 DOM 中删除元素相关联的内存泄漏问题。\nJS 动画优化 尽量使用 CSS 动画 如果 CSS 动画能够满足要求，那么尽量使用 CSS 动画，因为其可以充分利用浏览器提供的优化、甚至可以使用 GPU 来提高性能。而 JS 动画涉及到导入库、JS 执行、学习 JS 动画库提供的 API 等，成本高。\n使用 requestAnimationFrame  浏览器可以优化它，所以动画看起来更流畅 当页面不可见的时候，动画自动停止运行，让 CPU 歇会儿 比较省电  JavaScript 函数应该保持简洁 将大量 JS 动画添加到页面中，一定要想好。如果你的页面开始变卡，代码看起来不太灵活，那么可以使用 Web Workers 来尝试将 JS 动画放到另外一个线程来执行。\n参考  Efficiently load JavaScript with defer and async Why is using the JavaScript eval function a bad idea? Throttle in JavaScript: Improve Your Application’s Performance Part 4: What is Event Delegation in JavaScript? Tips for Improving CSS and JS Animation Performance  扫描下面二维码，在手机端阅读：\n"});index.add({'id':60,'href':'/docs/rocketmq/rocketmq-message-filter-flow/','title':"RocketMQ 消息过滤流程",'content':"RocketMQ 消息过滤流程 讲述 RocketMQ 消息过滤流程\n一、消息过滤类型 Producer 在发送消息的时候可以指定消息的标签类型，还可以为每一个消息添加一个或者多个额外的属性:\n// 指定标签 Message msg = new Message(\u0026#34;TopicTest\u0026#34;, \u0026#34;TagA\u0026#34;, (\u0026#34;Hello RocketMQ\u0026#34;).getBytes(RemotingHelper.DEFAULT_CHARSET)); // 添加属性 a msg.putUserProperty(\u0026#34;a\u0026#34;, 5); 根据标签和属性的不同，RocketMQ 客户端在消费消息的时候有三种消息过滤类型:\n(1) 标签匹配 consumer.subscribe(\u0026#34;TopicTest\u0026#34;, \u0026#34;TagA | TagB | TagC\u0026#34;); (2) SQL 匹配 consumer.subscribe(\u0026#34;TopicTest\u0026#34;, MessageSelector.bySql( \u0026#34;(TAGS is not null and TAGS in (\u0026#39;TagA\u0026#39;, \u0026#39;TagB\u0026#39;))\u0026#34; + \u0026#34;and (a is not null and a between 0 3)\u0026#34;)); (3) 自定义匹配 客户端实现 MessageFilter 类，自定义过滤逻辑:\nClassLoader classLoader = Thread.currentThread().getContextClassLoader(); File classFile = new File(classLoader.getResource(\u0026#34;MessageFilterImpl.java\u0026#34;).getFile()); String filterCode = MixAll.file2String(classFile); consumer.subscribe(\u0026#34;TopicTest\u0026#34;, \u0026#34;org.apache.rocketmq.example.filter.MessageFilterImpl\u0026#34;,filterCode); 对于 MessageFilter 类实现 match 方法即可:\npublic class MessageFilterImpl implements MessageFilter { @Override public boolean match(MessageExt msg, FilterContext context) { String property = msg.getProperty(\u0026#34;SequenceId\u0026#34;); if (property != null) { int id = Integer.parseInt(property); if (((id % 10) == 0) \u0026amp;\u0026amp; (id \u0026gt; 100)) { return true; } } return false; } } 下面我们一一讲解各自背后的机制与实现原理。\n二、标签匹配 当为消息指定消息标签类型的时候，实际上所指定的标签例如 TagA 是作为一个属性放入到了这条消息中的:\npublic class Message implements Serializable { public void setTags(String tags) { this.putProperty(MessageConst.PROPERTY_TAGS, tags); } } 当这条消息到达 Broker 服务器端后，用户设置的标签会计算为标签码，默认的计算方式采用的标签字符串的 hashCode() 作为计算结果的:\npublic class CommitLog { public DispatchRequest checkMessageAndReturnSize(java.nio.ByteBuffer byteBuffer, final boolean checkCRC, final boolean readBody) { // ...  String tags = propertiesMap.get(MessageConst.PROPERTY_TAGS); if (tags != null \u0026amp;\u0026amp; tags.length() \u0026gt; 0) { tagsCode = MessageExtBrokerInner .tagsString2tagsCode(MessageExt.parseTopicFilterType(sysFlag), tags); } // ...  } } 当计算出来标签码之后，这条消息的标签码会被存放至消费队列文件中，用来与消费者客户端消费队列的标签码进行匹配。消费者客户端订阅消费话题的时候，会指定想要匹配的标签类型:\nconsumer.subscribe(\u0026#34;TopicTest\u0026#34;, \u0026#34;TagA | TagB | TagC\u0026#34;); 这段代码在内部实现中利用 FilterAPI 构建了一个 SubscriptionData 对象:\npublic class DefaultMQPushConsumerImpl implements MQConsumerInner { public void subscribe(String topic, String subExpression) throws MQClientException { SubscriptionData subscriptionData = FilterAPI .buildSubscriptionData(this.defaultMQPushConsumer.getConsumerGroup(), topic, subExpression); // ...  } } 当用户未指定标签或者指定为星号标签的时候，则代表用户接受所有标签的消息。如果用户指定了一个或者多个标签，那么会将每一个标签取其 hashCode() 放入到 codeSet 中。SubscriptionData 还有一个 expressionType 字段，在使用标签匹配的时候，其不会设置这个这个字段的值，因此其保留为 null。在这些信息设置好以后，当客户端发送心跳包的时候，会将这些话题的注册信息一并上传至 Broker 服务器端，方便在 Broker 端进行匹配。\npublic class SubscriptionData implements Comparable\u0026lt;SubscriptionData\u0026gt; { public final static String SUB_ALL = \u0026#34;*\u0026#34;; private Set\u0026lt;String\u0026gt; tagsSet = new HashSet\u0026lt;String\u0026gt;(); private Set\u0026lt;Integer\u0026gt; codeSet = new HashSet\u0026lt;Integer\u0026gt;(); private String expressionType; } 当 Broker 端服务器在取消息的时候，每取出来一条消息，都会执行两道过滤机制:\n ConsumeQueue 文件匹配 CommitLog 文件匹配  任一检查没有通过后，绝不会放行这条消息给客户端:\npublic class DefaultMessageStore implements MessageStore { public GetMessageResult getMessage(final String group, /** 其他参数 **/) { for (; i \u0026lt; bufferConsumeQueue.getSize() \u0026amp;\u0026amp; i \u0026lt; maxFilterMessageCount; i += ConsumeQueue.CQ_STORE_UNIT_SIZE) { // ConsumeQueue 文件匹配  if (messageFilter != null \u0026amp;\u0026amp; !messageFilter.isMatchedByConsumeQueue(isTagsCodeLegal ? tagsCode : null, extRet ? cqExtUnit : null)) { if (getResult.getBufferTotalSize() == 0) { status = GetMessageStatus.NO_MATCHED_MESSAGE; } continue; } // CommitLog 文件匹配  if (messageFilter != null \u0026amp;\u0026amp; !messageFilter.isMatchedByCommitLog(selectResult.getByteBuffer().slice(), null)) { if (getResult.getBufferTotalSize() == 0) { status = GetMessageStatus.NO_MATCHED_MESSAGE; } // release...  selectResult.release(); continue; } } } } 消息过滤器的默认实现是 ExpressionMessageFilter ，消息过滤的默认实现策略就是看这个话题的标签码集合中是否包括当前这条消息的标签码:\npublic class ExpressionMessageFilter implements MessageFilter { @Override public boolean isMatchedByConsumeQueue(Long tagsCode, ConsumeQueueExt.CqExtUnit cqExtUnit) { // ...  if (ExpressionType.isTagType(subscriptionData.getExpressionType())) { if (tagsCode == null) { return true; } if (subscriptionData.getSubString().equals(SubscriptionData.SUB_ALL)) { return true; } return subscriptionData.getCodeSet().contains(tagsCode.intValue()); } // ...  return true; } @Override public boolean isMatchedByCommitLog(ByteBuffer msgBuffer, Map\u0026lt;String, String\u0026gt; properties) { if (ExpressionType.isTagType(subscriptionData.getExpressionType())) { return true; } // ...  } } 下图是一幅标签匹配的简要流程图:\n三、SQL 匹配 在发送消息的时候，可以为每一条消息附带一个或者多个属性值，SQL 匹配指的就是依据这些属性值和 TAG 标签 是否满足一定的 SQL 语句条件，来过滤消息。用户如果想要开启 SQL 匹配，那么需要在 Broker 启动的时候，启用如下几个配置信息:\nbrokerConfig.setEnablePropertyFilter(true); brokerConfig.setEnableCalcFilterBitMap(true); messageStoreConfig.setEnableConsumeQueueExt(true); (1) 注册过滤信息 我们在消费者如何接受消息一文中提到过，消费者启动之后，会通过心跳包定时给 Broker 服务器汇报自己的信息。而 Broker 服务器在收到消费者的心跳包之后，会产生一个注册事件，如下所示:\npublic class ConsumerManager { public boolean registerConsumer(final String group, /** 其他参数 **/) { // ...  this.consumerIdsChangeListener.handle(ConsumerGroupEvent.REGISTER, group, subList); // ...  } } DefaultConsumerIdsChangeListener 是默认的消费者列表注册事件通知器的实现类，其在收到注册事件以后，会将用户在消费者端订阅的话题信息注册到 ConsumerFilterManager 中:\npublic class DefaultConsumerIdsChangeListener implements ConsumerIdsChangeListener { @Override public void handle(ConsumerGroupEvent event, String group, Object... args) { switch (event) { case REGISTER: Collection\u0026lt;SubscriptionData\u0026gt; subscriptionDataList = (Collection\u0026lt;SubscriptionData\u0026gt;) args[0]; this.brokerController.getConsumerFilterManager().register(group, subscriptionDataList); break; // ...  } } } ConsumerFilterData 中包含了消费者客户端注册的 SQL 表达式，由上图我们可以看到对于每一个话题所对应的 FilterDataMapByTopic ，可以注册多个 SQL 表达式。但是这里需要注意的是，这多个 SQL 表达式是按照组来做区分的，就是说一个组只能有一个 SQL 表达式，客户端如果在一个组中注册了多个不同的 SQL 表达式，那么后注册的会覆盖掉前注册的。因此，如果想要对同一个组使用不同的 SQL 语句来过滤自己想要的信息，这些不同的 SQL 语句必须划分到不同的组里面才可行。\n(2) 生成 BloomFilterData 布隆过滤器 (BloomFilter) 是一种空间效率很高的数据结构，其可以用来判断某个元素是否可能存在于某个集合中。当判断结果返回 true 的时候，表示可能存在，当返回 false 的时候，表示这个元素一定不存在于这个集合中。\n它的原理是当一个元素被加入集合时，通过 k 个 Hash 函数将这个元素映射成一个长度为 m 位数组（Bit array）中的 k 个点，把它们置为 1。检索时，我们只要看看这些点是不是都是 1 就（大约）知道集合中有没有它了：\n 如果这些点有任何一个 0，则被检索元素一定不在。 如果都是 1， 则被检索元素很可能在。  如下是一个采用位数组长度为 m=18 以及哈希函数个数为 k=3 实现的布隆过滤器，”x,y,z” 每一个字母都需要经过 3 次哈希函数的计算，然后映射到 3 个不同的槽中。由于字母 “w” 在经过 3 次哈希函数计算后，其中一次产生的哈希值并未命中已有的槽，因此可以确定的是 “w” 肯定不存在于这个集合中。\n在 RocketMQ 的实现中，其有四个最关键的值:\npublic class BloomFilter { // 最大错误率  private int f; // 可能插入 n 个元素  private int n; // k 个哈希函数  private int k; // 数组总共 m 位  private int m; } RocketMQ 实现的布隆过滤器是根据错误率 f 和可能插入的元素数量 n 计算出来的 k 和 m，在默认配置情况下，即如下 n = 32 和 f = 20，计算出来需要 k = 3 个哈希函数和 m = 112 位的数组。\npublic class BrokerConfig { // Expect num of consumers will use filter.  private int expectConsumerNumUseFilter = 32; // Error rate of bloom filter, 1~100.  private int maxErrorRateOfBloomFilter = 20; } 我们这里大致了解以下布隆过滤器的一个基本想法即可，具体算法比较复杂，也不在讨论范畴以内。当客户端注册过滤信息的时候，其会根据 “组#话题” 这个字符串计算出相应的位映射数据，也即这个字符串经过布隆过滤器中的若干个哈希函数得到的几个不同的哈希值:\npublic class ConsumerFilterManager extends ConfigManager { public boolean register(final String topic, /** 其它参数 **/) { // ...  BloomFilterData bloomFilterData = bloomFilter.generate(consumerGroup + \u0026#34;#\u0026#34; + topic); // ...  } } ConsumerFilterManager 中的话题过滤信息数据，每隔 10 秒进行一次磁盘持久化:\npublic class BrokerController { public boolean initialize() throws CloneNotSupportedException { this.scheduledExecutorService.scheduleAtFixedRate(new Runnable() { @Override public void run() { BrokerController.this.consumerFilterManager.persist(); } }, 1000 * 10, 1000 * 10, TimeUnit.MILLISECONDS); } } 磁盘文件 consumerFilter.json 中保存的数据信息如下示例:\n上述大致流程图如下所示：\n(3) 编译 SQL 语句 JavaCC (Java Compiler Compiler) 是一个能生成语法和词法分析器的生成程序，它通过阅读一个自定义的语法标准文件 (通常以 jj 为后缀名) ，然后就能生成能够解析该语法的扫描器和解析器的代码。\n通过执行 javacc SelectorParser.jj 命令以后，其会生成如下七个 Java 文件，用以解析 SQL 语法:\n过滤器工厂 FilterFactory 在初次使用的时候，会注册一个 SqlFilter 类，这个类能够将消费者端指定的 SQL 语句编译解析为 Expression 表达式对象，方便后续消息的快速匹配与过滤。\npublic class SqlFilter implements FilterSpi { @Override public Expression compile(final String expr) throws MQFilterException { return SelectorParser.parse(expr); } } (4) 计算位映射 当 Broker 服务器接收到新的消息到来之后，一直在后台运行的 ReputMessageService 会负责将这条消息封装为一个 DispatchRequest 分发请求，这个请求会传递给提前构建好的分发请求链。在 DefaultMessageStore 的构造函数中，我们看到依次添加了构建消费队列和构建索引的分发请求服务:\npublic class DefaultMessageStore implements MessageStore { public DefaultMessageStore(final MessageStoreConfig messageStoreConfig, /** 其它参数 **/) throws IOException { this.dispatcherList = new LinkedList\u0026lt;\u0026gt;(); this.dispatcherList.addLast(new CommitLogDispatcherBuildConsumeQueue()); this.dispatcherList.addLast(new CommitLogDispatcherBuildIndex()); } } 而在 Broker 初始化的时候，我们看到其又添加了计算位映射的分发请求服务，并且将此分发服务放在链表的第一个位置:\npublic class BrokerController { public boolean initialize() throws CloneNotSupportedException { this.messageStore.getDispatcherList() .addFirst(new CommitLogDispatcherCalcBitMap(this.brokerConfig, this.consumerFilterManager)); } } 由此，在每次收到新的消息之后，分发请求的需要经过如下三个分发请求服务进行处理:\n我们在这部分只介绍计算位映射的服务类实现。如下，dispatch 方法用来分发请求里面的消息，对于这每一条消息，首先根据话题取得所有的消费过滤数据。这每一条数据代表的就是一条 SQL 过滤语句信息。我们在这个地方，需要一一遍历这些过滤信息，从而完成计算位服务的需求:\npublic class CommitLogDispatcherCalcBitMap implements CommitLogDispatcher { @Override public void dispatch(DispatchRequest request) { Collection\u0026lt;ConsumerFilterData\u0026gt; filterDatas = consumerFilterManager.get(request.getTopic()); Iterator\u0026lt;ConsumerFilterData\u0026gt; iterator = filterDatas.iterator(); while (iterator.hasNext()) { ConsumerFilterData filterData = iterator.next(); // ...  } } } 在拿到 ConsumerFilterData 信息之后，其会根据这条信息内的 SQL 语句编译后的表达式来对这条消息进行检查匹配 (evaluate)，看这条消息是否满足 SQL 语句所设置的条件。如果满足，那么会将先前在客户端注册阶段计算好的 BloomFilterData 中的映射位信息设置到 filterBitMap 中，即将相应的位数组 BitsArray 中的相应位设置为 1 。在验证完所有的 SQL 语句之后，会将这些所有的字节数组放置到 request 请求之中，以便交由下一个请求分发服务进行使用:\n@Override public void dispatch(DispatchRequest request) { BitsArray filterBitMap = BitsArray.create(this.consumerFilterManager.getBloomFilter().getM()); while (iterator.hasNext()) { ConsumerFilterData filterData = iterator.next(); MessageEvaluationContext context = new MessageEvaluationContext(request.getPropertiesMap()); Object ret = filterData.getCompiledExpression().evaluate(context); // eval true  if (ret != null \u0026amp;\u0026amp; ret instanceof Boolean \u0026amp;\u0026amp; (Boolean) ret) { consumerFilterManager .getBloomFilter() .hashTo(filterData.getBloomFilterData(), filterBitMap); } } request.setBitMap(filterBitMap.bytes()); } (5) 存储位映射 MessageStore 在开启扩展消费队列的配置之后，每一个消费队列在创建的时候，都会额外创建一个扩展消费队列。每一个扩展消费队列文件的大小默认为 48MB:\npublic class ConsumeQueue { public ConsumeQueue(final String topic, /** 其它参数 **/) { // ...  if (defaultMessageStore.getMessageStoreConfig().isEnableConsumeQueueExt()) { this.consumeQueueExt = new ConsumeQueueExt(topic, /** 其它参数 **/); } } } 在计算位映射一节中，计算好位字节数组之后，我们这里需要通过第二个分发请求服务 CommitLogDispatcherBuildConsumeQueue 来存储这些字节信息。通过如下代码，我们知道它将请求中的位映射信息、消息存储时间、标签码这三条信息封装为 ConsumeQueueExt.CqExtUnit ，然后放入到扩展消费队列文件中。\npublic class ConsumeQueue { public void putMessagePositionInfoWrapper(DispatchRequest request) { long tagsCode = request.getTagsCode(); if (isExtWriteEnable()) { ConsumeQueueExt.CqExtUnit cqExtUnit = new ConsumeQueueExt.CqExtUnit(); cqExtUnit.setFilterBitMap(request.getBitMap()); cqExtUnit.setMsgStoreTime(request.getStoreTimestamp()); cqExtUnit.setTagsCode(request.getTagsCode()); long extAddr = this.consumeQueueExt.put(cqExtUnit); if (isExtAddr(extAddr)) { tagsCode = extAddr; } } } } 我们注意到在上述代码中，put 函数返回的是一个 long 类型的扩展地址，当这个数值满足 isExtAddr 要求后，其会将当前的标签码设置为刚才返回的扩展地址。那么这是为什么呢?\n我们首先来看 ConsumeQueueExt 文件在存放数据成功后是如何返回信息的:\npublic class ConsumeQueueExt { public static final long MAX_ADDR = Integer.MIN_VALUE - 1L; public long put(final CqExtUnit cqExtUnit) { if (mappedFile.appendMessage(cqExtUnit.write(this.tempContainer), 0, size)) { return decorate(wrotePosition + mappedFile.getFileFromOffset()); } return 1; } public long decorate(final long offset) { if (!isExtAddr(offset)) { return offset + Long.MIN_VALUE; } return offset; } public static boolean isExtAddr(final long address) { return address \u0026lt;= MAX_ADDR; } } MAX_ADDR 是一个很小很小的值，为 -2147483649， 即写入位置如果不小于这个值，那么我们就认定为它不是扩展地址。需要将修正后的 写入偏移量 + Long.MIN_VALUE 确定为扩展地址。当读取信息的时候，其先读取 ConsumeQueue 文件中的最后的 Hash 标签码值，如果其通过 isExtAddr() 函数返回的是 true，那么我们就可以使用这个地址，再通过一个叫做 unDecorate() 函数将其修正为正确的 ConsumeQueueExt 文件的写入地址，从而接着读取想要的信息:\npublic long unDecorate(final long address) { if (isExtAddr(address)) { return address - Long.MIN_VALUE; } return address; } 这个地方，我们发现 ConsumeQueue 中的最后一个 long 型数值，可能存储的是标签 Hash 码，也可能存储的是扩展消费队列的写入地址，所以需要通过 isExtAddr() 来分情况判断。\n下图为 ConsumeQueue 文件和 ConsumeQueueExt 文件中存取信息的不同:\n(6) 消息过滤 在上小节我们提到了有关扩展消费队列地址和标签 Hash 码存储的不同，所以当在取消息的时候，先得从消费队列文件中取出 tagsCode，然后检查是否是扩展消费队列地址，如果是，那么就需要从扩展消费队列文件中读取正确的标签 Hash 码，如下代码所示：\npublic class DefaultMessageStore implements MessageStore { public GetMessageResult getMessage(final String group, /** 其它参数 **/) { ConsumeQueueExt.CqExtUnit cqExtUnit = new ConsumeQueueExt.CqExtUnit(); for (; i \u0026lt; bufferConsumeQueue.getSize() \u0026amp;\u0026amp; i \u0026lt; maxFilterMessageCount; i += ConsumeQueue.CQ_STORE_UNIT_SIZE) { long tagsCode = bufferConsumeQueue.getByteBuffer().getLong(); boolean extRet = false, isTagsCodeLegal = true; if (consumeQueue.isExtAddr(tagsCode)) { extRet = consumeQueue.getExt(tagsCode, cqExtUnit); if (extRet) { tagsCode = cqExtUnit.getTagsCode(); } else { isTagsCodeLegal = false; } } } } } 当获取到这条消息在扩展消费队列文件中存取的信息后，就会和标签匹配一节所讲述的一致，会进行两道过滤机制。我们先来看第一道 ConsumeQueue 文件匹配:\npublic class ExpressionMessageFilter implements MessageFilter { @Override public boolean isMatchedByConsumeQueue(Long tagsCode, ConsumeQueueExt.CqExtUnit cqExtUnit) { byte[] filterBitMap = cqExtUnit.getFilterBitMap(); BloomFilter bloomFilter = this.consumerFilterManager.getBloomFilter(); BitsArray bitsArray = BitsArray.create(filterBitMap); return bloomFilter.isHit(consumerFilterData.getBloomFilterData(), bitsArray); } } ExpressionMessageFilter 依据 CqExtUnit 中存储的位数组重新创建了比特数组 bitsArray，这个数组信息中已经存储了不同 SQL 表达式是否匹配这条消息的结果。isHit() 函数会一一检查 BloomFilterData 中存储的位信息是否映射在 BitsArray 中。只要有任何一位没有映射，那么就可以立刻判断出这条消息肯定不符合 SQL 语句的条件。\n因为布隆过滤器有一定的错误率，其只能精确的判断消息是否一定不在集合中，返回成功的只能确定为消息可能在集合中。因此通过布隆过滤器检查后还需要经过第二道过滤机制，即 SQL 编译后的表达式亲自验证是否匹配:\npublic class ExpressionMessageFilter implements MessageFilter { @Override public boolean isMatchedByCommitLog(ByteBuffer msgBuffer, Map\u0026lt;String, String\u0026gt; properties) { MessageEvaluationContext context = new MessageEvaluationContext(tempProperties); Object ret = realFilterData.getCompiledExpression().evaluate(context); if (ret == null || !(ret instanceof Boolean)) { return false; } return (Boolean) ret; } } 通过在验证 SQL 表达式是否满足之前，提前验证是否命中布隆过滤器，可以有效的避免许多不必要的验证:\n四、自定义匹配 消息的自定义匹配需要开启过滤服务器、上传过滤类、过滤服务器委托过滤消息等步骤，下面我们一一进行说明。\n(1) 过滤服务器 在启动 Broker 服务器的时候，如果指定了下面一行设置:\nbrokerConfig.setFilterServerNums(int filterServerNums); 即将过滤服务器的数量设定为大于 0，那么 Broker 服务器在启动的时候，将会启动 filterServerNums 个过滤服务器。过滤服务器是通过调用 shell 命令的方式，启用独立进程进行启动的。\npublic class FilterServerManager { public void createFilterServer() { int more = this.brokerController.getBrokerConfig().getFilterServerNums() - this.filterServerTable.size(); String cmd = this.buildStartCommand(); for (int i = 0; i \u0026lt; more; i++) { FilterServerUtil.callShell(cmd, log); } } } 过滤服务器在初始化的时候，会启动定时器每隔 10 秒注册一次到 Broker 服务器:\npublic class FiltersrvController { public boolean initialize() { this.scheduledExecutorService.scheduleAtFixedRate(new Runnable() { @Override public void run() { FiltersrvController.this.registerFilterServerToBroker(); } }, 3, 10, TimeUnit.SECONDS); } } Broker 服务器在收到来自过滤服务器的注册信息之后，会把过滤服务器的地址信息、注册时间等放到过滤服务器表中:\npublic class FilterServerManager { private final ConcurrentMap\u0026lt;Channel, FilterServerInfo\u0026gt; filterServerTable = new ConcurrentHashMap\u0026lt;Channel, FilterServerInfo\u0026gt;(16); } 同样，Broker 服务器也需要定时将过滤服务器地址信息同步给所有 Namesrv 命名服务器，上述整个流程如下图所示:\n(2) 过滤类 当消费者通过使用自定义匹配过滤消息的时候，这个时候会将存储订阅信息的 SubscriptionData 中的 filterClassSource 设置为 true，以表征这个客户端需要过滤类来进行消息的匹配和过滤。\n消费者客户端在启动过程中，还会定时地上传本地的过滤类源码到过滤服务器:\npublic class MQClientInstance { private void startScheduledTask() { this.scheduledExecutorService.scheduleAtFixedRate(new Runnable() { @Override public void run() { MQClientInstance.this.sendHeartbeatToAllBrokerWithLock(); } }, 1000, this.clientConfig.getHeartbeatBrokerInterval(), TimeUnit.MILLISECONDS); } public void sendHeartbeatToAllBrokerWithLock() { // ...  this.uploadFilterClassSource(); } } 其中过滤服务器的地址列表是在从 Namesrv 服务器获取话题路由信息的时候取得的，话题路由信息不光存储了消息队列数据，还存储了各个 Broker 所关联的过滤服务器列表:\npublic class TopicRouteData extends RemotingSerializable { // ...  private HashMap\u0026lt;String/* brokerAddr */, List\u0026lt;String\u0026gt;/* Filter Server */\u0026gt; filterServerTable; } 当过滤服务器接收到来自消费者客户端的源码之后，其会首先首先生成一个键为 话题@组 的字符串来查阅过滤类信息是否已经存在于内存里面的 filterClassTable 表中且文件通过 CRC 校验。如果没有存在或校验失败，那么就需要先编译并加载这个类:\npublic class DynaCode { public void compileAndLoadClass() throws Exception { String[] sourceFiles = this.uploadSrcFile(); this.compile(sourceFiles); this.loadClass(this.loadClass.keySet()); } } 默认情况下，编译后的类存放于 $HOME/rocketmq_filter_class/$PID 目录下，类的源文件和类的字节码文件名也会相应的加上当前时间戳来确定:\n上述流程图如下:\n(3) 过滤消息 当消费者客户端启用自定义匹配过滤消息后，发往服务器的数据中也包含了过滤标志位，这样每次拉取消息的服务器也由原来的 Broker 服务器变更为 Filtersrv 过滤服务器，其中过滤服务器地址的选择是随机确定的:\npublic class PullAPIWrapper { public PullResult pullKernelImpl(final MessageQueue mq, /** 其它参数 **/) throws Exception { // ...  if (findBrokerResult != null) { if (PullSysFlag.hasClassFilterFlag(sysFlagInner)) { // 从过滤服务器拉取消息  brokerAddr = computPullFromWhichFilterServer(mq.getTopic(), brokerAddr); } // ...  } } } 过滤服务器在启动的时候，内部还启动了一个 PullConsumer 客户端，用以从 Broker 服务器拉取消息:\npublic class FiltersrvController { private final DefaultMQPullConsumer defaultMQPullConsumer = new DefaultMQPullConsumer(MixAll.FILTERSRV_CONSUMER_GROUP); public void start() throws Exception { this.defaultMQPullConsumer.start(); // ...  } } 当过滤服务器收到真正的消费者发来的消费消息的请求之后，其会委托内部的 PullConsumer 使用包含在请求体内的偏移量去 Broker 服务器拉取所有消息，此时这些消息是完全没有过滤的：\npublic class DefaultRequestProcessor implements NettyRequestProcessor { private RemotingCommand pullMessageForward(final ChannelHandlerContext ctx, final RemotingCommand request) throws Exception { MessageQueue mq = new MessageQueue(); mq.setTopic(requestHeader.getTopic()); mq.setQueueId(requestHeader.getQueueId()); mq.setBrokerName(this.filtersrvController.getBrokerName()); // 设置偏移量和最大数量  long offset = requestHeader.getQueueOffset(); int maxNums = requestHeader.getMaxMsgNums(); // 委托内部消费者从 Broker 服务器拉取消息  pullConsumer.pullBlockIfNotFound(mq, null, offset, maxNums, pullCallback); } } 过滤服务器从 Broker 服务器获取到完整的消息列表之后，会遍历消息列表，然后使用过滤类一一进行匹配，最终将匹配成功的消息列表返回给客户端:\npublic class DefaultRequestProcessor implements NettyRequestProcessor { private RemotingCommand pullMessageForward(final ChannelHandlerContext ctx, final RemotingCommand request) throws Exception { final PullCallback pullCallback = new PullCallback() { @Override public void onSuccess(PullResult pullResult) { switch (pullResult.getPullStatus()) { case FOUND: List\u0026lt;MessageExt\u0026gt; msgListOK = new ArrayList\u0026lt;MessageExt\u0026gt;(); for (MessageExt msg : pullResult.getMsgFoundList()) { // 使用过滤类过滤消息  boolean match = findFilterClass.getMessageFilter().match(msg, filterContext); if (match) { msgListOK.add(msg); } } break; // ...  } } }; // ...  } } 上述流程如下图所示:\n扫描下面二维码，在手机端阅读：\n"});index.add({'id':61,'href':'/docs/rocketmq/','title':"RocketMQ 源码分析",'content':"RocketMQ RocketMQ 是阿里巴巴集团开源的一款分布式消息中间件，其采用纯 Java 语言编写，本博客基于 RocketMQ 4.2.0 版本，为大家分析和讲解其内部几个关键模块的运行原理。\n目录：\n RocketMQ 消息发送流程 RocketMQ 消息存储流程 RocketMQ 消息接受流程 RocketMQ 消息过滤流程 RocketMQ 消息索引流程 RocketMQ 定时消息和重试消息 RocketMQ 主备同步  "});index.add({'id':62,'href':'/docs/tutorial/unix-command/ssh/','title':"ssh",'content':"ssh 本文展示了一些常见的 ssh 命令，了解一些 ssh 技巧将有利于任何系统管理员、网络工程师或安全专业人员。\n连接远程主机 localhost:~$ ssh -v -p 22 -C neo@remoteserver  -v：打印 debug 日志信息，用于打印连接时候的一些日志。 -p 22：指定连接远程主机的哪个端口，默认情况下，不用指定，因为 ssh 默认端口就是 22。编辑 sshd_config 文件，可以修改默认的 ssh 的监听端口。 -C：传输数据的时候，是否对数据启用压缩。 neo@remoteserver：neo 代表远程主机的用户名，remoteserver 代表远程主机的 IP 或者域名。添加 -4 选项，可以只连接 IPv4 连接；添加 -6 选项，只连接 IPv6 连接。  拷贝文件到远程服务器 远程拷贝文件的命令 scp 建立在 ssh 命令之上：\nlocalhost:~$ scp mypic.png neo@remoteserver:/media/data/mypic_2.png  mypic.png：代表本地电脑上的图片 /media/data/mypic_2.png：代表你想把图片拷贝到远程主机的哪个路径  流量代理 SSH 代理特性被放在第1位是有充分理由的。它的功能比许多用户意识到的要强大得多，它允许您使用几乎任何应用程序访问远程服务器可以访问的任何系统。ssh客户机可以仅用一行代码，就可以使用SOCKS代理服务器在连接隧道上通信。\nlocalhost:~$ ssh -D 8888 user@remoteserver localhost:~$ netstat -pan | grep 8888 tcp 0 0 127.0.0.1:8888 0.0.0.0:* LISTEN 23880/ssh 在这里，我们启动在TCP端口8888上运行的socks代理服务器，第二个命令检查端口是否正在监听。127.0.0.1表示服务仅在本地主机上运行。我们可以使用稍微不同的命令来监听所有接口，包括以太网或wifi，这将允许我们网络上的其他应用程序（浏览器或其他）连接到ssh socks代理服务。\nlocalhost:~$ ssh -D 0.0.0.0:8888 user@remoteserver 现在我们可以配置浏览器来连接socks代理。在 Firefox 中选择 preferences | general | network settings。添加浏览器连接到的IP地址和端口。\n生成 SSH Key ssh-keygen 是一个为 ssh 创建新的身份验证密钥对的工具。此类密钥对用于自动登录、单点登录和对主机进行身份验证。\n生成密钥对的最简单方法是不带参数运行 ssh-keygen。在这种情况下，它将提示输入要在其中存储密钥的文件。\nssh-keygen 拷贝 SSH Key 到远程主机 拷贝 ~/.ssh/id_rsa.pub 中的所有内容，追加到远程主机的 ~/.ssh/authorized_keys 这个文件中。这样，下次 ssh 就无需输入密码了。\nlocalhost:~$ ssh-copy-id user@remoteserver 远程执行命令 ssh命令可以链接到其他命令以获得常见的管道乐趣。将要在远程主机上运行的命令添加为引号中的最后一个参数。\nlocalhost:~$ ssh remoteserver \u0026#34;cat /var/log/nginx/access.log\u0026#34; | grep badstuff.php 参考  SSH Examples, Tips \u0026amp; Tunnels SSH Command  扫描下面二维码，在手机端阅读：\n"});index.add({'id':63,'href':'/docs/books/the_transformation_of_enterprise_it_architecture/','title':"企业 IT 架构转型之道",'content':"企业 IT 架构转型之道 共享服务体系搭建 SOA 的主要特性：\n 面向服务的分布式计算。 服务间松散耦合。 支持服务的组装。 服务注册和自动发现。 以服务契约方式定义服务交互方式。  基于 “中心化” 的 ESB 服务调用方式  “去中心化” 服务架构调用方式   数据拆分实现数据库能力线性扩展 数据库的读写分离 读写分离基本原理是让主数据库处理事务性增、改、删（INSERT、UPDATE、DELETE）操作，而从数据库专门负责处理查询（SELECT）操作，在数据库的后台会把事务性操作导致的主数据库中的数据变更同步到集群中的从数据库。\n数据库分库分表 采用分库分表的方式将业务数据拆分后，如果每一条SQL语句中都能带有分库分表键，SQL语句的执行效率最高：\n但不是所有的业务场景在进行数据库访问时每次都能带分库分表键的。比如在买家中心的界面中，要显示买家test1过去三个月的订单列表信息。此时就出现了我们所说的全表扫描，一条SQL语句同时被推送到后端所有数据库中运行。如果是高并发情况下同时请求的话，为了数据库整体的扩展能力，则要考虑下面描述的异构索引手段来避免这样的情况发生。对于在内存中要进行大数据量聚合操作和计算的SQL请求，如果这类SQL的不是大量并发或频繁调用的话，平台本身的性能影响也不会太大，如果这类SQL请求有并发或频繁访问的要求，则要考虑采用其他的平台来满足这一类场景的要求，比如Hadoop这类做大数据量离线分析的产品，如果应用对请求的实时性要求比较高，则可采用如内存数据库或HBase这类平台。\n所谓“异构索引表”，就是采用异步机制将原表内的每一次创建或更新，都换另一个维度保存一份完整的数据表或索引表。本质上这是互联网公司很多时候都采用的一个解决思路：“拿空间换时间”。也就是应用在创建或更新一条按照订单ID为分库分表键的订单数据时，也会再保存一份按照买家ID为分库分表键的订单索引数据。\n基于订单索引表实现买家订单列表查看流程示意：\n实现对数据的异步索引创建有多种实现方式，其中一种就是从数据库层采用 binlog 数据复制的方式实现。\n采用数据异构索引的方式在实战中基本能解决和避免90%以上的跨join或全表扫描的情况，是在分布式数据场景下，提升数据库服务性能和处理吞吐能力的最有效技术手段。但在某些场景下，比如淘宝商品的搜索和高级搜索，因为商品搜索几乎是访问淘宝用户都会进行的操作，所以调用非常频繁，如果采用SQL语句的方式在商品数据库进行全表扫描的操作，则必然对数据库的整体性能和数据库连接资源带来巨大的压力。面对此类场景，我们不建议采用数据库的方式提供这样的搜索服务，而是采用专业的搜索引擎平台来行使这样的职能，如Lucene、Solr、ElasticSearch 等。\n异步化与缓存原则 业务流程异步化 以淘宝的交易订单为例，目前淘宝的订单创建流程需要调用超过200个服务，就算所有服务的调用时间都控制在20ms内返回结果，整个订单创建的时间也会超过4s：\n以异步化方式将上述交易创建过程中，对于有严格先后调用关系的服务保持顺序执行，对于能够同步执行的所有服务均采用异步化方式处理。阿里巴巴内部使用消息中间件的方式实现了业务异步化，提高了服务的并发处理，从而大大减少整个业务请求处理所花的时间。\n数据库事务异步化 扣款是一个要求事务一致性的典型场景，稍微数据不一致带来的后果都可能是成百上千（可能在某些借款项目中达到上百万的金额）的金额差异。所以在传统的实现方式中，整个扣款的逻辑代码都是在一个大的事务中，通过数据库的事务特性来实现这样一个稍显复杂的业务一致性。\n数据库事务的异步化：通俗来说，就是将大事务拆分成小事务，降低数据库的资源被长时间事务锁占用而造成的数据库瓶颈，就能大大提升平台的处理吞吐量和事务操作的响应时间。\n在实际的改造方案中，同样基于消息服务提供的异步机制，将整个还款流程进行异步化的处理：\n事务与柔性事务 不管是业务流程异步化，还是数据库事务异步化，其实都面临一个如何保证业务事务一致性的问题。面对这个问题目前并没有完美的解决方案，本节会介绍淘宝是如何对订单创建场景实现业务一致的实践，以及近一两年来我们在分布式事务上所作出的创新尝试，供各技术同行在解决此类问题时借鉴和参考。\n关于数据库事务，核心是体现数据库ACID（原子性、一致性、隔离性和持久性）属性，即作为一个事务中包含的所有逻辑处理操作在作用到数据库上时，只有这个事务中所有的操作都成功，对数据库的修改才会永久更新到数据库中，任何一个操作失败，对于数据库之前的修改都会失效。在分布式领域，基于CAP理论和在其基础上延伸出的BASE理论，有人提出了“柔性事务”的概念。\n（1）CAP理论\n一个分布式系统最多只能同时满足一致性（Consistency）、可用性（Availability）和分区容错性（Partition tolerance）这三项中的两项。“一致性”指更新操作成功并返回客户端完成后，所有节点在同一时间的数据完全一致。“可用性”指用户在访问数据时可以得到及时的响应。“分区容错性”指分布式系统在遇到某节点或网络分区故障的时候，仍然能够对外提供满足一致性和可用性的服务。\nCAP定理并不意味着所有系统的设计都必须抛弃三个要素之中的一个。CAP三者可以在一定程度上衡量，并不是非黑即白的，例如可用性从0%到100%有不同等级。\n（2）BASE理论\nBASE理论是对CAP理论的延伸，核心思想是即使无法做到强一致性（Strong Consistency, CAP的一致性就是强一致性），但应用可以采用适合的方式达到最终一致性（EventualConsitency）。BASE是指基本可用（Basically Available）、柔性状态（Soft State）、最终一致性（Eventual Consistency）。\n  “基本可用”是指分布式系统在出现故障的时候，允许损失部分可用性，即保证核心可用。电商大促时，为了应对访问量激增，部分用户可能会被引导到降级页面，服务层也可能只提供降级服务。这就是损失部分可用性的体现。\n  “柔性状态”是指允许系统存在中间状态，而该中间状态不会影响系统整体可用性。分布式存储中一般一份数据至少会有三个副本，允许不同节点间副本同步的延时就是柔性状态的体现。MySQLReplication的异步复制也是一种柔性状态体现。\n  “最终一致性”是指系统中的所有数据副本经过一定时间后，最终能够达到一致的状态。弱一致性和强一致性相反，最终一致性是弱一致性的一种特殊情况。\n  对于如何实现高可用，我们认为：\n 高可用=系统构建在多机分布式系统 高性能=分布式系统的副产品  分布式系统内通信和单机内通信最大的区别是：单机系统总线不会丢消息，而网络会。一台向另一台机器通信的结果可能是收到、未收到、不知道收到没收到。消息不可靠带来的副作用是：数据或者状态在多机之间同步的成本很高。大家都知道Paxos协议。在多机间通信不存在伪造或篡改的前提下，可以经由Paxos协议达成一致性。成本是发给Paxos系统的信息（数据）需要至少同步发送到一半以上多数（Quorum）的机器确认后，才能认为是成功。这样大幅增加了信息更新的延迟，因此分布式系统的首选不是这种强同步而是最终一致。\n（3）两阶段提交\n数据在按照业务领域（用户中心、交易中心）的不同被拆分到不同的数据库后，在某些业务场景（比如订单创建）下，就必然会出现同一个事务上下文中，需要协调多个资源（数据库）以保证业务的事务一致性，对于这样的场景，业界早就有基于两阶段提交方式实现的分布式事务，两阶段提交协议包含了两个阶段：第一阶段（也称准备阶段）和第二阶段（也称提交阶段）。\nX/Open组织为基于两阶段协议的分布式事务处理系统提出了标准的系统参考模型（X/Open事务模型）以及不同组件间与事务协调相关的接口，使不同厂商的产品能够互操作。X/Open事务模型如图所示。\n从图中可以看出，X/Open模型定义了两个标准接口：TX接口用于应用程序向事务管理器发起事务、提交事务和回滚事务（即确定事务的边界和结果）; XA接口形成了事务管理器和资源管理器之间的通信桥梁，用于事务管理器将资源管理器（如数据库、消息队列等）加入事务、并控制两阶段提交。\n事务管理器一般由专门的中间件提供，或者在应用服务器中作为一个重要的组件提供。资源管理器如数据库、消息队列等产品一般也会提供对XA接口的支持，通过使用符合X/Open标准的分布式事务处理，能够简化分布式事务类应用的开发。\n两阶段提交协议的关键在于“预备”操作。分布式事务协调者在第一阶段通过对所有的分布式事务参与者请求“预备”操作，达成关于分布式事务一致性的共识。分布式事务参与者在预备阶段必须完成所有的约束检查，并且确保后续提交或放弃时所需要的数据已持久化。在第二队段，分布式事务协调者根据之前达到的提交或放弃的共识，请求所有的分布式事务参与者完成相应的操作。很显然，在提交事务的过程中需要在多个资源节点之间进行协调，而各节点对锁资源的释放必须等到事务最终提交时，这样，比起一阶段提交，两阶段提交在执行同样的事务时会消耗更多时间。\n事务执行时间的延长意味着锁资源发生冲突的概率增加，当事务的并发量达到一定数量的时候，就会出现大量事务积压甚至出现死锁，系统性能和处理吞吐率就会严重下滑，也就是系统处理的吞吐率与资源上的时间消耗成反比（参考阿姆达尔定理）。这就是为什么今天在互联网应用场景中鲜有人会选择这样传统的分布式事务方式，而选择柔性事务处理业务事务的主要原因。\n（4）柔性事务如何解决分布式事务问题\n  引入日志和补偿机制。类似传统数据库，柔性事务的原子性主要由日志保证。事务日志记录事务的开始、结束状态，可能还包括事务参与者信息。参与者节点也需要根据重做或回滚需求记录REDO/UNDO日志。当事务重试、回滚时，可以根据这些日志最终将数据恢复到一致状态。为避免单点，事务日志是记录在分布式节点上的，数据REDO/UNDO日志一般记录在业务数据库上，可以保证日志与业务操作同时成功/失败。通常柔性事务能通过日志记录找回事务的当前执行状态，并根据状态决定是重试异常步骤（正向补偿），还是回滚前序步骤（反向补偿）。\n  可靠消息传递。根据“不知道成功还是失败”状态的处理，消息投递只有两种模式：1）消息仅投递一次，但是可能会没有收到；2）消息至少投递一次，但可能会投递多次。在业务一致性的高优先级下，第一种投递方式肯定是无法接受的，因此只能选择第二种投递方式。由于消息可能会重复投递，这就要求消息处理程序必须实现幂等（幂等=同一操作反复执行多次结果不变）。每种业务场景不同，实现幂等的方法也会有所不同，最简单的幂等实现方式是根据业务流水号写日志，阿里内部一般把这种日志叫做排重表。\n  实现无锁。如何很好地解决数据库锁问题是实现高性能的关键所在。所以选择放弃锁是一个解决问题的思路，但是放弃锁并不意味着放弃隔离性。实现事务隔离的方法有很多，在实际的业务场景中可灵活选择以下几种典型的实现方式。\n 避免事务进入回滚。如果事务在出现异常时，可以不回滚也能满足业务的要求，也就是要求业务不管出现任何情况，只能继续朝事务处理流程的顺向继续处理，这样中间状态即使对外可见，由于事务不会回滚，也不会导致脏读。 辅助业务变化明细表。比如对资金或商品库存进行增减处理时，可采用记录这些增减变化的明细表的方式，避免所有事务均对同一数据表进行更新操作，造成数据访问热点，同时使得不同事务中处理的数据互不干扰，实现对资金或库存信息处理的隔离。 乐观锁。数据库的悲观锁对数据访问具有极强的排他性，也是产生数据库处理瓶颈的重要原因，采用乐观锁则在一定程度上解决了这个问题。乐观锁大多是基于**数据版本（Version）**记录机制实现。例如通过在商品表中增加记录版本号的字段，在事务开始前获取到该商品记录的版本号，在事务处理最后对该商品数据进行数据更新时，可通过在执行最后的修改update语句时进行之前获取版本号的比对，如果版本号一致，则update更新数据成功，修改该数据到新的版本号；如果版本号不一致，则表示数据已经被其他事务修改了，则重试或放弃当前事务。     （5）柔性事务在阿里巴巴内部的几种实现\n 消息分布式事务  基于消息实现的分布式事务仅支持正向补偿，即不会像传统事务方式出现异常时依次进行回滚，会通过消息的不断重试或人工干预的方式让该事务链路继续朝前执行，而避免出现事务回滚。\n 支付宝XTS框架  XTS是TCC（Try/Confirm/Cancel）型事务，属于典型的补偿型事务。\n 阿里巴巴AliWare TXC事务服务  标准模式下无需开发人员自行进行事务回滚或补偿的代码，平台支持自动按事务中事务操作的顺序依次回滚和补偿。关键原理：\n大促秒杀活动催生缓存技术的高度使用 首先一定要让负责秒杀场景的商品中心应用实例（图中“秒杀IC”）与满足普通商品正常访问的商品中心应用实例（图中IC）隔离部署，通过服务分组方式，保持两个运行环境的隔离，避免因为秒杀产生的过大访问流量造成整个商品中心的服务实例均受影响，产生太大范围的影响。\n因为秒杀在正式开始前，一定会有大量的用户停留在商品的详情页（图中Detail）等待着秒杀活动的开始，同时伴随有大量的页面刷新访问（心急或担心页面没有正常刷新的买家们），此时，如果每一次刷新都要从后端的商品数据库（图中ICDB）中获取商品相关信息，则一定会给数据库带来巨大的压力，在淘宝早期举办秒杀活动时就出现了秒杀活动还没开始，因为商品详情页访问太大，造成平台提前进入不可访问状态的情况。所以一定是通过缓存服务器（图中Tair），将商品的详细信息（包括库存信息）保存在缓存服务器上，商品详情页和购买页所有有关商品的信息均是通过缓存服务器获取，则无需访问后端数据库。\n如图中“本地缓存”所示，可通过给网页资源设置Expires和Last-Modified返回头信息进行有效控制，从而尽可能减少对后端服务端的访问次数。\n避免商品出现超卖（即成功下单的订单中商品的库存数量大于商品现有的库存量，则称为商品超卖），核心技术是利用数据库的事务锁机制，即不允许同一商品的库存记录在同一时间被不同的两个数据库事务修改。在前柔性事务介绍中所提到的，用户在进行商品下单操作中，会进行一系列的业务逻辑判断和操作，对于商品库存信息这一访问热点数据，如果采用数据库的悲观锁（比如select语句带for update）模式，则会给订单处理带来很大的性能阻塞，所以会采用乐观锁的方式实现商品库存的操作。实现的方式也比较简单，也就是在最后执行库存扣减操作时，将事务开始前获取的库存数量带入到SQL语句中与目前数据库记录中的库存数量进行判断，如果数量相等，则该条更新库存的语句成功执行；如果不相等，则表示该商品的库存信息在当前事务执行过程中已经被其他事务修改，则会放弃该条update的执行，可以采用重试的机制重新执行该事务，避免商品超卖的发生，具体的SQL语句示意如下：\nupdate auction_auctions set quantity = #inQuantity#, where auction_id = #itemId# and quantity = #dbQuantity# 如果参与大促的商品拥有较大库存数量的时候，需要将之前仅仅作为商品信息浏览的缓存的作用，提升到为库存操作提供事务支持的角色。\n打造数字化运营能力 每一个URL请求都会生成一个全局唯一的ID，鹰眼（类似于 Twitter 的 Zipkin）平台中称为TraceID，这个ID会出现在该请求中所有服务调用、数据库、缓存、消息服务访问时生成的所有日志中。因为上述所有的资源访问均是在分布式环境下进行的，如何将该TraceID平滑地传递到各个服务节点上呢？如果要求应用程序中实现服务链路日志的打印和TraceID的传递，则在程序中有大量的日志打印代码，而且需要将TraceID采用业务数据的方式传递给下一服务节点，这些都给应用带来了非常大的代码侵入。\n阿里巴巴在中间件层面上统一实现了鹰眼的上下文创建以及日志埋点功能，让调用上下文在中间件的网络请求中传递，同时将调用上下文信息保存在了本地ThreadLocal中，从而实现了鹰眼平台所需的调用上下文和日志信息对于应用开发人员完全透明。\n埋点日志一般包含：\n TraceID、RPCID、开始时间、调用类型、对端IP。 处理耗时。 处理结果（ResultCode）。 数据传输量：请求大小/响应大小。  打造平台稳定性能力 限流和降级 淘宝技术团队开发的开源模块nginx-http-sysguard，主要用于当访问负载和内存达到一定的阀值之时，会执行相应的动作，比如直接返回503,504或者其他URL请求返回代码，一直等到内存或者负载回到阀值的范围内，站点恢复可用。\n流量调度 流量调度的核心是通过秒级获取服务器系统运行指标以及业务指标，通过流量调度平台设置的决策算法以及规则，当发现满足规则条件的指标状态发生时，对线上环境的服务器进行下线等操作，以屏蔽这些单点或局部出现故障的应用实例对整体平台产生扩展式的影响。\n业务开关 Switch 平台本身所提供的功能比较简单，但对于业务场景和环境复杂的分布式架构，这个平台确实能大大提升应用适应各种不同场景的自动化能力，比如通过开关的方式将正常环境下的应用逻辑切换到适配秒杀场景；当发现升级后的应用出现问题时，只需通过开关切换的方式就能让升级后的应用秒级切换到升级前的业务代码中。最重要的是在平台处于大促秒杀、应用异常时，业务开关在服务降级中所起的作用，相当于平台的最后一道保护屏障。\n"});index.add({'id':64,'href':'/docs/tutorial/network/','title':"网络协议",'content':"计算机网络协议 "});index.add({'id':65,'href':'/docs/tutorial/awk/','title':"AWK 教程",'content':"AWK 教程  简介 Patterns  "});index.add({'id':66,'href':'/docs/programmer-interview/algorithm/best-time-to-buy-and-sell-stock-with-cooldown/','title':"Best Time to Buy and Sell Stock With Cooldown",'content':"Best Time to Buy and Sell Stock With Cooldown 题目 LeetCode 地址：Best Time to Buy and Sell Stock With Cooldown\n有一个数组，第 i 个元素的值代表第 i 天的股票价格，如果你最多只能进行任意次交易（某天买入一支股票，然后过几天卖掉），你卖出一只股票后，接下来的一天不能买，必须要到后天才能买。也就是说有冷静期1天。请问你能收获的最大利润是多少？\n答案 // https://leetcode.com/problems/best-time-to-buy-and-sell-stock-with-cooldown/ // 交易任意多次，只不过 buy sell 之后的第二天必须 cooldown 隔天才能再次 buy // // https://leetcode.com/problems/best-time-to-buy-and-sell-stock-with-cooldown/discuss/240277/Java-solution-in-Chinese public class BestTimetoBuyandSellStockwithCooldown { public int maxProfit(int[] prices) { if (prices == null || prices.length \u0026lt;= 1) { return 0; } // 买入只能是从前天买入 buy[i] = sell[i - 2] - prices[i];  // 卖出可以昨天卖出 sell[i] = buy[i - 1] + prices[i];  int[] sell = new int[prices.length]; int[] buy = new int[prices.length]; buy[0] = -prices[0]; for (int i = 1; i \u0026lt; prices.length; i++) { // 前天卖出后，剩下 sell 钱，然后又接着买入 sell[i - 2] - prices[1]  // 维持昨天的  buy[i] = Math.max(buy[i - 1] /** 不买 */, (i \u0026gt;= 2 ? sell[i - 2] : 0) - prices[i] /** 从前天卖出的接着买入 */); // 接着买：buy[i - 1] + prices[i]  // 维持昨天的 sell  sell[i] = Math.max(sell[i - 1] /** 不卖 */, buy[i - 1] + prices[i] /** 从昨天接着买入 */); } return sell[prices.length - 1]; } } 扫描下面二维码，在手机上阅读这篇文章：\n"});index.add({'id':67,'href':'/docs/tutorial/git/git-checkout/','title':"Git checkout",'content':"Git checkout git checkout 检出命令，可以用来切换分支、查看某个 commit 的代码等。\ndetached HEAD 当你执行 git checkout [commitId] 时，你会看到下面的文件警告：\nNote: switching to '467dd6520'. You are in 'detached HEAD' state. You can look around, make experimental changes and commit them, and you can discard any commits you make in this state without impacting any branches by switching back to a branch. If you want to create a new branch to retain commits you create, you may do so (now or later) by using -c with the switch command. Example: git switch -c \u0026lt;new-branch-name\u0026gt; Or undo this operation with: git switch - Turn off this advice by setting config variable advice.detachedHead to false HEAD is now at 467dd65 version 3 这代表什么意思？什么叫做 detached HEAD ？执行命令 .git/HEAD 查看一下 HEAD 头指针的指向就会明白。\n$ cat .git/HEAD ref: refs/heads/master # 检出到某一个 commitId $ git checkout 467dd6520 $ cat .git/HEAD 467dd6520221c270098166e2be6389fbb2c3b1b9 原来 detached HEAD 指的是 HEAD 头指针指向了一个具体的 commitId，而不是一个分支（引用）。\n切换分支 切换到 branch-xxx 分支，且暂存区和工作区的文件也会跟着变动：\ngit checkout branch-xxx 撤销本地修改 本地对某个文件做了修改，现在要恢复到修改之前的状态：\ngit checkout -- fileName 撤销本地所有文件的修改：\ngit checkout -- . # 或 git checkout . 创建并切换到新分支 git checkout -b newBranchName  使用 -B 可以强制创建某个分支，并覆盖掉本地已经存在的分支，慎用！\n 扫描下面二维码，在手机端阅读：\n"});index.add({'id':68,'href':'/docs/javascript/','title':"JavaScript 专栏",'content':"JavaScript 专栏 本专栏用于整理在 JavaScript 中最常使用的、必知必会的基础知识点，方便大家温故而知新。\n"});index.add({'id':69,'href':'/docs/books/redis_5_source_code/','title':"Redis 5 设计与源码分析",'content':"Redis 5 设计与源码分析 Redis 5.0 新特性  新增Streams数据类型，这是 Redis 5.0 最重要的改进之一。可以把Streams当作消息队列。 新的模块API、定时器、集群及字典。 RDB中持久化存储LFU和LRU的信息。 将集群管理功能完全用C语言集成到redis-cli中，Redis 3.x 和 Redis4.x 的集群管理是通过Ruby脚本实现的。 有序集合新增命令ZPOPMIN/ZPOPMAX。 改进HyperLogLog的实现。 新增Client Unblock和Client ID。 新增LOLWUT命令。 Redis主从复制中的从不再称为Slave，改称Replicas。 Redis 5.0引入动态哈希，以平衡CPU的使用率和相应性能，可以通过配置文件进行配置。Redis 5.0默认使用动态哈希。 Redis核心代码进行了部分重构和优化。  简单动态字符串 （1） 长度小于 32 的短字符串\nstruct __attribute__ ((__packed__))sdshdr5 { unsigned char flags; // 低 3 位存储类型，高 5 位存储长度  char buf[]; // 柔性数组 } 结构如下：\n（2） 长度大于 31 的字符串\n此处仅展示一个示例：\nstruct __attribute__ ((__packed__))sdshdr8 { uint8_t len; // 已使用长度  uint8_t alloc; // 已分配的字节总长度  unsigned char flags; // 低 3 位存储类型  char buf[]; // 柔性数组 } SDS 读操作的复杂度多为O(1)，直接读取成员变量；涉及修改的写操作，则可能会触发扩容。\n跳跃表 对于有序集合的底层实现，我们可以使用数组、链表、平衡树等结构。数组不便于元素的插入和删除；链表的查询效率低，需要遍历所有元素；平衡树或者红黑树等结构虽然效率高但实现复杂。Redis采用了一种新型的数据结构——跳跃表。跳跃表的效率堪比红黑树，然而其实现却远比红黑树简单。\ntypedef struct zskiplistNode { sds ele; double score; struct zskiplistNode *backward; struct zskiplistLevel { struct zskiplistNode *forward; unsigned int span; } level[]; } zskiplistNode; typedef struct zskiplist { struct zskiplistNode *header, *tail; unsigned long length; int level; } zkiplist; 在Redis中，跳跃表主要应用于有序集合的底层实现（有序集合的另一种实现方式为压缩列表）。zset插入第一个元素时，会判断下面两种条件：\n zset-max-ziplist-entries的值是否等于0； zset-max-ziplist-value小于要插入元素的字符串长度。  满足任一条件Redis就会采用跳跃表作为底层实现，否则采用压缩列表作为底层实现方式。一般情况下，不会将zset-max-ziplist-entries配置成0，元素的字符串长度也不会太长，所以在创建有序集合时，默认使用压缩列表的底层实现。\nzset新插入元素时，会判断以下两种条件：\n zset中元素个数大于zset_max_ziplist_entries； 插入元素的字符串长度大于zset_max_ziplist_value。  当满足任一条件时，Redis便会将zset的底层实现由压缩列表转为跳跃表。值得注意的是，zset在转为跳跃表之后，即使元素被逐渐删除，也不会重新转为压缩列表。\n跳跃表的原理简单，其查询、插入、删除的平均复杂度都为O(logN)。\n压缩列表 压缩列表ziplist本质上就是一个字节数组，是Redis为了节约内存而设计的一种线性数据结构，可以包含多个元素，每个元素可以是一个字节数组或一个整数。\nRedis的有序集合、散列和列表都直接或者间接使用了压缩列表。当有序集合或散列表的元素个数比较少，且元素都是短字符串时，Redis便使用压缩列表作为其底层数据存储结构。\n元素的结构示意图：\n字典 Redis自带客户端就是使用times 33散列函数来计算字符串的Hash值，Redis服务端的Hash函数使用的是siphash算法，主要功能与客户端Hash函数类似，其优点是针对有规律的键计算出来的Hash值也具有强随机分布性，但算法较为复杂。\n整数集合 整数集合（intset）是一个有序的、存储整型数据的结构。\n127.0.0.1:6379\u0026gt; sadd testset 1 2 1 6 (integer) 4 127.0.0.1:6379\u0026gt; object encoding testset \u0026#34;intset\u0026#34; intset是按从小到大有序排列的，所以通过防御性判断之后使用二分法进行元素的查找。\nquicklist的实现 quicklist是Redis底层最重要的数据结构之一，它是Redis对外提供的6种基本数据结构中List的底层实现，在Redis 3.2版本中引入，能够在时间效率和空间效率间实现较好的折中。quicklist由List和ziplist结合而成。quicklist是一个双向链表，链表中的每个节点是一个ziplist结构。quicklist可以看成是用双向链表将若干小型的ziplist连接到一起组成的一种数据结构。\nStream Redis Stream的结构如图所示，它主要由消息、生产者、消费者、消费组4部分组成。\nxadd mystream1 * name zk age 20 mystream1为Stream的名称；*代表由Redis自行生成消息ID;name、age为该消息的field; zk、20则为对应的field的值。\n每个消息都由以下两部分组成。\n 每个消息有唯一的消息ID，消息ID严格递增。 消息内容由多个field-value对组成。  "});index.add({'id':70,'href':'/docs/rocketmq/rocketmq-message-indexing-flow/','title':"RocketMQ 消息索引流程",'content':"RocketMQ 消息索引流程 讲述 RocketMQ 消息索引服务\n一、消息查询方式 对于 Producer 发送到 Broker 服务器的消息，RocketMQ 支持多种方式来方便地查询消息:\n(1) 根据键查询消息 如下所示，在构建消息的时候，指定了这条消息的键为 “OrderID001”:\nMessage msg = new Message(\u0026#34;TopicTest\u0026#34;, \u0026#34;TagA\u0026#34;, \u0026#34;OrderID001\u0026#34;, // Keys  \u0026#34;Hello world\u0026#34;.getBytes(RemotingHelper.DEFAULT_CHARSET)); 那么，当这条消息发送成功后，我们可以使用 queryMsgByKey 命令查询到这条消息的详细信息:\nMQAdminStartup.main(new String[] { \u0026#34;queryMsgByKey\u0026#34;, \u0026#34;-n\u0026#34;, \u0026#34;localhost:9876\u0026#34;, \u0026#34;-t\u0026#34;, \u0026#34;TopicTest\u0026#34;, \u0026#34;-k\u0026#34;, \u0026#34;OrderID001\u0026#34; }); (2) 根据ID(偏移量)查询消息 消息在发送成功之后，其返回的 SendResult 类中包含了这条消息的唯一偏移量 ID (注意此处指的是 offsetMsgId):\n用户可以使用 queryMsgById 命令查询这条消息的详细信息:\nMQAdminStartup.main(new String[] { \u0026#34;queryMsgById\u0026#34;, \u0026#34;-n\u0026#34;, \u0026#34;localhost:9876\u0026#34;, \u0026#34;-i\u0026#34;, \u0026#34;0A6C73D900002A9F0000000000004010\u0026#34; }); (3) 根据唯一键查询消息 消息在发送成功之后，其返回的 SendResult 类中包含了这条消息的唯一 ID:\n用户可以使用 queryMsgByUniqueKey 命令查询这条消息的详细信息:\nMQAdminStartup.main(new String[] { \u0026#34;queryMsgByUniqueKey\u0026#34;, \u0026#34;-n\u0026#34;, \u0026#34;localhost:9876\u0026#34;, \u0026#34;-i\u0026#34;, \u0026#34;0A6C73D939B318B4AAC20CBA5D920000\u0026#34;, \u0026#34;-t\u0026#34;, \u0026#34;TopicTest\u0026#34; }); (4) 根据消息队列偏移量查询消息 消息发送成功之后的 SendResult 中还包含了消息队列的其它信息，如消息队列 ID、消息队列偏移量等信息:\nSendResult [sendStatus=SEND_OK, msgId=0A6C73D93EC518B4AAC20CC4ACD90000, offsetMsgId=0A6C73D900002A9F000000000000484E, messageQueue=MessageQueue [topic=TopicTest, brokerName=zk-pc, queueId=3], queueOffset=24] 根据这些信息，使用 queryMsgByOffset 命令也可以查询到这条消息的详细信息:\nMQAdminStartup.main(new String[] { \u0026#34;queryMsgByOffset\u0026#34;, \u0026#34;-n\u0026#34;, \u0026#34;localhost:9876\u0026#34;, \u0026#34;-t\u0026#34;, \u0026#34;TopicTest\u0026#34;, \u0026#34;-b\u0026#34;, \u0026#34;zk-pc\u0026#34;, \u0026#34;-i\u0026#34;, \u0026#34;3\u0026#34;, \u0026#34;-o\u0026#34;, \u0026#34;24\u0026#34; }); 二、ID (偏移量) 查询 (1) 生成 ID ID (偏移量) 是在消息发送到 Broker 服务器存储的时候生成的，其包含如下几个字段：\n Broker 服务器 IP 地址 Broker 服务器端口号 消息文件 CommitLog 写偏移量  public class CommitLog { class DefaultAppendMessageCallback implements AppendMessageCallback { public AppendMessageResult doAppend(final long fileFromOffset, /** 其它参数 **/) { String msgId = MessageDecoder .createMessageId(this.msgIdMemory, msgInner.getStoreHostBytes(hostHolder), wroteOffset); // ...  } } } (2) 使用 ID 查询 Admin 端查询的时候，首先对 msgId 进行解析，取出 Broker 服务器的 IP 、端口号和消息偏移量:\npublic class MessageDecoder { public static MessageId decodeMessageId(final String msgId) throws UnknownHostException { byte[] ip = UtilAll.string2bytes(msgId.substring(0, 8)); byte[] port = UtilAll.string2bytes(msgId.substring(8, 16)); // offset  byte[] data = UtilAll.string2bytes(msgId.substring(16, 32)); // ...  } } 获取到偏移量之后，Admin 会对 Broker 服务器发送一个 VIEW_MESSAGE_BY_ID 的请求命令，Broker 服务器在收到请求后，会依据偏移量定位到 CommitLog 文件中的相应位置,然后取出消息，返回给 Admin 端:\npublic class DefaultMessageStore implements MessageStore { @Override public SelectMappedBufferResult selectOneMessageByOffset(long commitLogOffset) { SelectMappedBufferResult sbr = this.commitLog .getMessage(commitLogOffset, 4); // 1 TOTALSIZE  int size = sbr.getByteBuffer().getInt(); return this.commitLog.getMessage(commitLogOffset, size); } } 三、消息队列偏移量查询 根据队列偏移量查询是最简单的一种查询方式，Admin 会启动一个 PullConsumer ，然后利用用户传递给 Admin 的队列 ID、队列偏移量等信息，从服务器拉取一条消息过来:\npublic class QueryMsgByOffsetSubCommand implements SubCommand { @Override public void execute(CommandLine commandLine, Options options, RPCHook rpcHook) throws SubCommandException { // 根据参数构建 MessageQueue  MessageQueue mq = new MessageQueue(); mq.setTopic(topic); mq.setBrokerName(brokerName); mq.setQueueId(Integer.parseInt(queueId)); // 从 Broker 服务器拉取消息  PullResult pullResult = defaultMQPullConsumer.pull(mq, \u0026#34;*\u0026#34;, Long.parseLong(offset), 1); } } 四、消息索引服务 在继续讲解剩下两种查询方式之前，我们必须先介绍以下 Broker 端的消息索引服务。\n在之前提到过，每当一条消息发送过来之后，其会封装为一个 DispatchRequest 来下发给各个转发服务，而 CommitLogDispatcherBuildIndex 构建索引服务便是其中之一:\nclass CommitLogDispatcherBuildIndex implements CommitLogDispatcher { @Override public void dispatch(DispatchRequest request) { if (DefaultMessageStore.this.messageStoreConfig.isMessageIndexEnable()) { DefaultMessageStore.this.indexService.buildIndex(request); } } } (1) 索引文件结构 消息的索引信息是存放在磁盘上的，文件以时间戳命名的，默认存放在 $HOME/store/index 目录下。由下图来看，一个索引文件的结构被分成了三部分:\n 前 40 个字节存放固定的索引头信息，包含了存放在这个索引文件中的消息的最小/大存储时间、最小/大偏移量等状况 中间一段存储了 500 万个哈希槽位，每个槽内部存储的是索引文件的地址 (索引槽) 最后一段存储了 2000 万个索引内容信息，是实际的索引信息存储的地方。每一个槽位存储了这条消息的键哈希值、存储偏移量、存储时间戳与下一个索引槽地址  RocketMQ 在内存中还维护了一个索引文件列表，对于每一个索引文件，前一个文件的最大存储时间是下一个文件的最小存储时间，前一个文件的最大偏移量是下一个文件的最大偏移量。每一个索引文件都索引了在某个时间段内、某个偏移量段内的所有消息，当文件满了，就会用前一个文件的最大偏移量和最大存储时间作为起始值，创建下一个索引文件:\n(2) 添加消息 当有新的消息过来后，构建索引服务会取出这条消息的键，然后对字符串 “话题#键” 构建索引。构建索引的步骤如下:\n 找出哈希槽: 生成字符串哈希码，取余落到 500W 个槽位之一，并取出其中的值，默认为 0 找出索引槽: IndexHeader 维护了 indexCount，实际存储的索引槽就是直接依次顺延添加的 存储索引内容: 找到索引槽后，放入键哈希值、存储偏移量、存储时间戳与下一个索引槽地址。下一个索引槽地址就是第一步哈希槽中取出的值，0 代表这个槽位是第一次被索引，而不为 0 代表这个槽位之前的索引槽地址。由此，通过索引槽地址可以将相同哈希槽的消息串联起来，像单链表那样。 更新哈希槽: 更新原有哈希槽中存储的值  我们以实际例子来说明。假设我们需要依次为键的哈希值为 “{16,29,29,8,16,16}” 这几条消息构建索引，我们在这个地方忽略了索引信息中存储的存储时间和偏移量字段，只是存储键哈希和下一索引槽信息，那么:\n 放入 16: 将 “16|0” 存储在第 1 个索引槽中，并更新哈希槽为 16 的值为 1，即哈希槽为 16 的第一个索引块的地址为 1 放入 29: 将 “29|0” 存储在第 2 个索引槽中，并更新哈希槽为 29 的值为 2，即哈希槽为 29 的第一个索引块的地址为 2 放入 29: 取出哈希槽为 29 中的值 2，然后将 “29|2” 存储在第 3 个索引槽中，并更新哈希槽为 29 的值为 3，即哈希槽为 29 的第一个索引块的地址为 3。而在找到索引块为 3 的索引信息后，又能取出上一个索引块的地址 2，构成链表为： “[29]-\u0026gt;3-\u0026gt;2” 放入 8: 将 “8|0” 存储在第 4 个索引槽中，并更新哈希槽为 8 的值为 4，即哈希槽为 8 的第一个索引块的地址为 4 放入 16: 取出哈希槽为 16 中的值 1，然后将 “16|1” 存储在第 5 个索引槽中，并更新哈希槽为 16 的值为 5。构成链表为: “[16]-\u0026gt;5-\u0026gt;1” 放入 16: 取出哈希槽为 16 中的值 5，然后将 “16|5” 存储在第 6 个索引槽中，并更新哈希槽为 16 的值为 6。构成链表为: “[16]-\u0026gt;6-\u0026gt;5-\u0026gt;1”  整个过程如下图所示:\n(3) 查询消息 当需要根据键来查询消息的时候，其会按照倒序回溯整个索引文件列表，对于每一个在时间上能够匹配用户传入的 begin 和 end 时间戳参数的索引文件，会一一进行消息查询：\npublic class IndexService { public QueryOffsetResult queryOffset(String topic, String key, int maxNum, long begin, long end) { // 倒序  for (int i = this.indexFileList.size(); i \u0026gt; 0; i--) { // 位于时间段内  if (f.isTimeMatched(begin, end)) { // 消息查询  } } } } 而具体到每一个索引文件，其查询匹配消息的过程如下所示:\n 确定哈希槽: 根据键生成哈希值，定位到哈希槽 定位索引槽: 哈希槽中的值存储的就是链表的第一个索引槽地址 遍历索引槽: 沿着索引槽地址，依次取出下一个索引槽地址，即沿着链表遍历，直至遇见下一个索引槽地址为非法地址 0 停止 收集偏移量: 在遇到匹配的消息之后，会将相应的物理偏移量放到列表中，最后根据物理偏移量，从 CommitLog 文件中取出消息  public class DefaultMessageStore implements MessageStore { @Override public QueryMessageResult queryMessage(String topic, String key, int maxNum, long begin, long end) { for (int m = 0; m \u0026lt; queryOffsetResult.getPhyOffsets().size(); m++) { long offset = queryOffsetResult.getPhyOffsets().get(m); // 根据偏移量从 CommitLog 文件中取出消息  } } } 以查询哈希值 16 的消息为例，图示如下:\n五、唯一键查询消息 (1) 构建键 消息的唯一键是在客户端发送消息前构建的:\npublic class DefaultMQProducerImpl implements MQProducerInner { private SendResult sendKernelImpl(final Message msg, /** 其它参数 **/) throws XXXException { // ...  if (!(msg instanceof MessageBatch)) { MessageClientIDSetter.setUniqID(msg); } } } 创建唯一 ID 的算法:\npublic class MessageClientIDSetter { public static String createUniqID() { StringBuilder sb = new StringBuilder(LEN * 2); sb.append(FIX_STRING); sb.append(UtilAll.bytes2string(createUniqIDBuffer())); return sb.toString(); } } 唯一键是根据客户端的进程 ID、IP 地址、ClassLoader 哈希码、时间戳、计数器这几个值来生成的一个唯一的键，然后作为这条消息的附属属性发送到 Broker 服务器的:\npublic class MessageClientIDSetter { public static void setUniqID(final Message msg) { if (msg.getProperty(MessageConst.PROPERTY_UNIQ_CLIENT_MESSAGE_ID_KEYIDX) == null) { msg.putProperty(MessageConst.PROPERTY_UNIQ_CLIENT_MESSAGE_ID_KEYIDX, createUniqID()); } } } (2) 索引键 当服务器收到客户端发送过来的消息之后，索引服务便会取出客户端生成的 uniqKey 并为之建立索引，放入到索引文件中:\npublic class IndexService { public void buildIndex(DispatchRequest req) { // ...  if (req.getUniqKey() != null) { indexFile = putKey(indexFile, msg, buildKey(topic, req.getUniqKey())); } // ...  } } (3) 使用键查询 客户端在生成消息唯一键的时候，在 ByteBuffer 的第 11 位到第 14 位放置的是当前的时间与当月第一天的时间的毫秒差:\npublic class MessageClientIDSetter { private static byte[] createUniqIDBuffer() { long current = System.currentTimeMillis(); if (current \u0026gt;= nextStartTime) { setStartTime(current); } // 时间差 [当前时间 - 这个月 1 号的时间]  // putInt 占据的是第 11 位到第 14 位  buffer.putInt((int) (System.currentTimeMillis() - startTime)); } private synchronized static void setStartTime(long millis) { Calendar cal = Calendar.getInstance(); cal.setTimeInMillis(millis); cal.set(Calendar.DAY_OF_MONTH, 1); cal.set(Calendar.HOUR_OF_DAY, 0); cal.set(Calendar.MINUTE, 0); cal.set(Calendar.SECOND, 0); cal.set(Calendar.MILLISECOND, 0); // 开始时间设置为这个月的 1 号  startTime = cal.getTimeInMillis(); // ...  } } 我们知道消息索引服务的查询需要用户传入 begin 和 end 这连个时间值，以进行这段时间内的匹配。所以 RocketMQ 为了加速消息的查询，于是在 Admin 端对特定 ID 进行查询的时候，首先取出了这段时间差值，然后与当月时间进行相加得到 begin 时间值:\npublic class MessageClientIDSetter { public static Date getNearlyTimeFromID(String msgID) { ByteBuffer buf = ByteBuffer.allocate(8); byte[] bytes = UtilAll.string2bytes(msgID); buf.put((byte) 0); buf.put((byte) 0); buf.put((byte) 0); buf.put((byte) 0); // 取出第 11 位到 14 位  buf.put(bytes, 10, 4); buf.position(0); // 得到时间差值  long spanMS = buf.getLong(); Calendar cal = Calendar.getInstance(); long now = cal.getTimeInMillis(); cal.set(Calendar.DAY_OF_MONTH, 1); cal.set(Calendar.HOUR_OF_DAY, 0); cal.set(Calendar.MINUTE, 0); cal.set(Calendar.SECOND, 0); cal.set(Calendar.MILLISECOND, 0); long monStartTime = cal.getTimeInMillis(); if (monStartTime + spanMS \u0026gt;= now) { cal.add(Calendar.MONTH, -1); monStartTime = cal.getTimeInMillis(); } // 设置为这个月(或者上个月) + 时间差值  cal.setTimeInMillis(monStartTime + spanMS); return cal.getTime(); } } 由于发送消息的客户端和查询消息的 Admin 端可能不在一台服务器上，而且从函数的命名 getNearlyTimeFromID 与上述实现来看，Admin 端的时间戳得到的是一个近似起始值，它尽可能地加速用户的查询。而且太旧的消息(超过一个月的消息)是查询不到的。\n当 begin 时间戳确定以后，Admin 便会将其它必要的信息如话题、Key等信息封装到 QUERY_MESSAGE 的包中，然后向 Broker 服务器传递这个请求，来进行消息的查询。Broker 服务器在获取到这个查询消息的请求后，便会根据 Key 从索引文件中查询符合的消息，最终返回到 Admin 端。\n六、键查询消息 (1) 构建键 我们提到过，在发送消息的时候，可以填充一个 keys 的值，这个值将会作为消息的一个属性被发送到 Broker 服务器上:\npublic class Message implements Serializable { public void setKeys(String keys) { this.putProperty(MessageConst.PROPERTY_KEYS, keys); } } (2) 索引键 当服务器收到客户端发送过来的消息之后，索引服务便会取出这条消息的 keys 并将其用空格进行分割，分割后的每一个字符串都会作为一个单独的键，创建索引，放入到索引文件中:\npublic class IndexService { public void buildIndex(DispatchRequest req) { // ...  if (keys != null \u0026amp;\u0026amp; keys.length() \u0026gt; 0) { // 使用空格进行分割  String[] keyset = keys.split(MessageConst.KEY_SEPARATOR); for (int i = 0; i \u0026lt; keyset.length; i++) { String key = keyset[i]; if (key.length() \u0026gt; 0) { indexFile = putKey(indexFile, msg, buildKey(topic, key)); } } } } } 由此我们也可以得知，keys 键的设置通过使用空格分割字符串，一条消息可以指定多个键。\n(3) 使用键查询 keys 键查询的方式也是通过将参数封装为 QUERY_MESSAGE 请求包中去请求服务器返回相应的信息。由于键本身不能和时间戳相关联，因此 begin 值设置的是 0，这是和第五节的不同之处:\npublic class QueryMsgByKeySubCommand implements SubCommand { private void queryByKey(final DefaultMQAdminExt admin, final String topic, final String key) throws MQClientException, InterruptedException { // begin: 0  // end: Long.MAX_VALUE  QueryResult queryResult = admin.queryMessage(topic, key, 64, 0, Long.MAX_VALUE); } } 扫描下面二维码，在手机端阅读：\n"});index.add({'id':71,'href':'/docs/tutorial/unix-command/top/','title':"top",'content':"top 本文介绍 top 命令的常见例子！top 可以显示系统运行的进程和资源等情况的有用信息。\n基础展示 top 上述命令将会显示：\n 红色区域：系统的统计信息 蓝色区域：系统所有的进程列表信息  默认情况下，top 命令每隔 3 秒刷新一次。\n 红色区域\n 第一行展示的是：时间、电脑运行多久了、多少人登录着电脑、过去 1、5、15 分钟电脑的平均负载。 第二行展示的是，任务的总数量，以及各个状态的任务数量。 第三行展示的是 CPU 的一些信息。  CPU 信息的每一列的含义：\n us：用户态 CPU 占用处理器的总时间 sy：内核态 CPU 占用处理器的总时间 ni：使用手动设置的 nice 值执行进程所花费的时间。 id：CPU空闲时间的数量。 wa：CPU等待I/O完成所花费的时间。 hi：维护硬件中断所花费的时间。 si：维护软件中断所花费的时间。 st：由于运行虚拟机而损失的时间（“窃取时间”）。  第四行显示物理内存的总量（以kibibytes为单位），以及空闲、使用、缓冲或缓存的内存量。 第五行显示交换内存的总量（也以kibibytes为单位），以及空闲、使用和可用的内存量。后者包括预期可以从缓存中恢复的内存。\n 蓝色区域的，进程列表中的各个列的信息如下：\n PID：进程ID。 USER：进程的所有者。 PR：流程优先级。 NI：这个过程很有价值。 VIRT：进程使用的虚拟内存量。 RES：进程使用的常驻内存量。 SHR：进程使用的共享内存量。 S： 进程的状态。（有关此字段可以采用的值，请参见下面的列表）。 %CPU：自上次更新以来进程使用的CPU时间的份额。 %MEM：使用的物理内存份额。 TIME+：任务使用的总CPU时间（以百分之一秒为单位）。 COMMAND：命令名或命令行（名称+选项）。  内存值以kibibytes为单位显示。进程的状态可以是以下之一：\n D： 不间断睡眠 R： 跑步 S： 睡觉 T： 跟踪（停止） Z： 僵尸  按 Q 退出 top 命令。\n滚动区域 您可以按向上或向下箭头、Home、End和Page Up或Down键上下移动并访问所有进程。\n更改数字单位 让我们把显示单位改为合理的值。\n按大写 E 循环显示这些选项中用于显示内存值的单位：kibibytes、mebibytes、gibibytes、tebibytes、pebibytes和exbibytes。\n按小写 e 对进程列表中的值执行相同的操作：kibibytes、mebibytes、gibibytes、tebibytes和pebibytes。\n我们按 E 将红色区域的内存单位设置为gibibytes，按 e 将进程列表内存单位设置为mebibytes。\n更改统计区域的显示 如果您有多核CPU，请按 1 更改显示并查看每个CPU的个别统计信息。我们的电脑上有四个CPU。我们按1，看看他们每个 CPU 的使用情况。\n按 t 可以修改 CPU 的展示方式：\n按 m 可以修改内存的展示方式：\n高亮显示 您可以按 “z” 键为 top 添加颜色。\n根据列排序 默认情况下，进程列表按 %CPU 列排序。您可以按以下键更改排序列：\n P： %CPU 列 M： %MEM 列 N： PID 列 T： TIME+ 列  在下图中，进程列表按PID列排序。\n显示完整命令行 按 “c” 可以调整 COMMAND 列，在显示进程名和完整命令行之间进行切换。\n参考  How to Use the Linux top Command (and Understand Its Output)  扫描下面二维码，在手机端阅读：\n"});index.add({'id':72,'href':'/docs/programmer-interview/algorithm/best-time-to-buy-and-sell-stock-with-transaction-fee/','title':"Best Time to Buy and Sell Stock with Transaction Fee",'content':"Best Time to Buy and Sell Stock with Transaction Fee  每次交易都需要交易费用\n // 可以交易任意多次 // 只不过每一次都有小费 // // https://leetcode.com/problems/best-time-to-buy-and-sell-stock-with-transaction-fee/discuss/160964/java-Using-State-Machine-like-stock-III public class BestTimetoBuyandSellStockwithTransactionFee { public int maxProfit(int[] prices, int fee) { if (prices == null || prices.length \u0026lt;= 1) { return 0; } int s0 = 0; int s1 = s0 - prices[0]; // 买入  for (int i = 1; i \u0026lt; prices.length; i++) { // 这两种状态都能转移到 s0 状态:  //  // s0 -\u0026gt; s0  // s1 卖出 -\u0026gt; s0  s0 = Math.max(s0, s1 + prices[i] - fee); // s1 卖出又能重新买入: s1 -\u0026gt; s0  // 怎样能转移到 s1  s1 = Math.max(s1, s0 - prices[i]); // s0 转移到 s1  } return s0; } } "});index.add({'id':73,'href':'/docs/tutorial/unix-command/cat/','title':"cat",'content':"cat cat 命令的常见用法！\n查看文件内容 要使用 cat 显示文件的内容，只需传递要查看的一个或多个文件的名称。文件内容将打印到标准输出并在终端中可见。下面的示例假设文件foo.txt 文件只有一行“Hello World”。\ncat foo.txt Hello world 如果文件的内容很长，则全部内容将写入终端。在这种情况下，很难找到文件的某些部分。在寻找特定内容时，grep 可能是一个更好的选择。\n将一个文件的内容写入到另外一个文件 使用cat工具结合重定向，可以将文件内容写入新的文件。下面的示例假设文件foo.txt文件只有一行“Hello World”并将其写入bar.txt文件.\ncat foo.txt \u0026gt; bar.txt cat bar.txt Hello world 如果 bar.txt 文件不存在，那么 cat 工具会自动创建 bar.txt 文件。\n将一个文件的内容追加到另外一个文件 cat wine.txt \u0026gt;\u0026gt; beer.txt 多个文件合并为一个 cat *.txt \u0026gt; combined.txt 上述命令行，将当前目录以 .txt 结尾的文件，合并到 combined.txt 文件中。\ncat 输出显示行号 -n 参数可以显示文件的行号：\ncat -n /usr/share/dict/words 1 A 2 a 3 aa 4 aal 5 aalii 输出的每行行尾显示 $ 符号 cat -e test hello everyone, how do you do?$ $ Hey, am fine.$ How\u0026#39;s your training going on?$ $ 多个空行压缩为一个空行 cat -s blanks.txt -s 选项可以将多个相邻的空行压缩为一个空行，并不是消除所有空行，而是仅仅保留一行空行。比如：\nLine one Line two Line three 压缩为：\nLine one Line two Line three 参考  Linux and Unix cat command tutorial with examples  扫描下面二维码，在手机端阅读：\n"});index.add({'id':74,'href':'/docs/tutorial/devops/','title':"DevOps",'content':"DevOps 参考  《DevOps 实践指南》  "});index.add({'id':75,'href':'/docs/tutorial/git/git-stash/','title':"Git 保存当前进度",'content':"Git 保存当前进度 git stash 命令可以帮助我们保存和恢复日常的工作进度。\n应用场景 你正在 dev 分支上开发项目的某个新功能，开发到一半的时候，master 分支的代码（线上正在运行的代码）出现了一个 bug，需要紧急修复。你现在需要从 dev 分支切换到 master 分支修 BUG，而你现在在 dev 分支正在开发的代码也不可能开发到一半就要 push 上去，此时就可以先在 dev 分支把代码给 stash 起来，也就是暂存起来，然后再切换到 master 分支。等 master 分支修复好了后，再切回 dev 分支，执行 stash pop 把这部分代码给恢复出来即可。\n下面示例几个基础用法：\n保存当前工作进度 git stash 显示进度列表 git stash list stash 就是一个栈数据结构管理的，你可以保存多次工作进度，并且恢复的时候也可以选择恢复哪个。\n恢复进度 # 恢复最新保存的工作进度，并将工作进度从 stash 列表中清除 git stash pop # 恢复某个指定的 stash (git stash list 可以看到) git stash pop [\u0026lt;stash\u0026gt;] 命令 git stash apply [\u0026lt;stash\u0026gt;] 同 git stash pop，只是不会从 stash 列表中删除恢复的进度。\n删除一个存储的进度 git stash drop [\u0026lt;stash\u0026gt;] 删除所有存储的进度 git stash clear 扫描下面二维码，在手机端阅读：\n"});index.add({'id':76,'href':'/docs/rocketmq/rocketmq-timing-message-and-retry-message/','title':"RocketMQ 定时消息和重试消息",'content':"RocketMQ 定时消息和重试消息 讲述 RocketMQ 定时消息和重试消息\n一、定时消息概述 RocketMQ 支持 Producer 端发送定时消息，即该消息被发送之后，到一段时间之后才能被 Consumer 消费者端消费。但是当前开源版本的 RocketMQ 所支持的定时时间是有限的、不同级别的精度的时间，并不是任意无限制的定时时间。因此在每条消息上设置定时时间的 API 叫做 setDelayTimeLevel，而非 setDelayTime 这样的命名:\nMessage msg = new Message(\u0026#34;TopicTest\u0026#34; /* Topic */, \u0026#34;TagA\u0026#34; /* Tag */, (\u0026#34;Hello RocketMQ \u0026#34; + i).getBytes(RemotingHelper.DEFAULT_CHARSET) /* Message body */); msg.setDelayTimeLevel(i + 1); 默认 Broker 服务器端有 18 个定时级别:\npublic class MessageStoreConfig { private String messageDelayLevel = \u0026#34;1s 5s 10s 30s 1m 2m 3m 4m 5m 6m 7m 8m 9m 10m 20m 30m 1h 2h\u0026#34;; } 这 18 个定时级别在服务器端启动的时候，会被解析并放置到表 delayLevelTable 中。解析的过程就是上述字符串按照空格拆分开，然后根据时间单位的不同再进一步进行计算，得到最终的毫秒时间。级别就是根据这些毫秒时间的顺序而确定的，例如上述 1s 延迟就是级别 1， 5s 延迟就是级别 2，以此类推:\npublic class ScheduleMessageService extends ConfigManager { public boolean parseDelayLevel() { for (int i = 0; i \u0026lt; levelArray.length; i++) { // ...  int level = i + 1; long delayTimeMillis = tu * num; // 级别:延迟时间  this.delayLevelTable.put(level, delayTimeMillis); } } } 二、定时消息预存储 客户端在为某条消息设置上定时级别的时候，实际上级别这个字段会被作为附属属性放到消息中:\npublic class Message implements Serializable { public void setDelayTimeLevel(int level) { this.putProperty(MessageConst.PROPERTY_DELAY_TIME_LEVEL, String.valueOf(level)); } } 我们先前的文章提到过，发送到 Broker 服务器的消息会被存储到 CommitLog 消息文件中。那么在此处即使是定时消息也不例外，将定时消息存储下来是为了保证消息最大程度地不丢失。然而毕竟和普通消息不同，在遇到定时消息后，CommitLog 会将这条消息的话题和队列 ID 替换成专门用于定时的话题和相应的级别对应的队列 ID。真实的话题和队列 ID 会作为属性放置到这条消息中。\npublic class CommitLog { public PutMessageResult putMessage(final MessageExtBrokerInner msg) { // Delay Delivery  if (msg.getDelayTimeLevel() \u0026gt; 0) { topic = ScheduleMessageService.SCHEDULE_TOPIC; queueId = ScheduleMessageService.delayLevel2QueueId(msg.getDelayTimeLevel()); // Backup real topic, queueId  MessageAccessor.putProperty(msg, MessageConst.PROPERTY_REAL_TOPIC, msg.getTopic()); MessageAccessor.putProperty(msg, MessageConst.PROPERTY_REAL_QUEUE_ID, String.valueOf(msg.getQueueId())); msg.setPropertiesString(MessageDecoder.messageProperties2String(msg.getProperties())); // 替换 Topic 和 QueueID  msg.setTopic(topic); msg.setQueueId(queueId); } } } 随后，这条消息会被存储在 CommitLog 消息文件中。而我们知道后台重放消息服务 ReputMessageService 会一直监督 CommitLog 文件是否添加了新的消息。当有了新的消息后，重放消息服务会取出消息并封装为 DispatchRequest 请求，然后将其分发给不同的三个分发服务，建立消费队列文件服务就是这其中之一。而此处当取消息封装为 DispatchRequest 的时候，当遇到定时消息时，又多做了一些额外的事情。\n当遇见定时消息时，CommitLog 计算 tagsCode 标签码与普通消息不同。对于定时消息，tagsCode 值设置的是这条消息的投递时间，即建立消费队列文件的时候，文件中的 tagsCode 存储的是这条消息未来在什么时候被投递:\npublic class CommitLog { public DispatchRequest checkMessageAndReturnSize(java.nio.ByteBuffer byteBuffer, final boolean checkCRC, final boolean readBody) { // Timing message processing  { String t = propertiesMap.get(MessageConst.PROPERTY_DELAY_TIME_LEVEL); if (ScheduleMessageService.SCHEDULE_TOPIC.equals(topic) \u0026amp;\u0026amp; t != null) { int delayLevel = Integer.parseInt(t); if (delayLevel \u0026gt; 0) { tagsCode = this.defaultMessageStore.getScheduleMessageService() .computeDeliverTimestamp(delayLevel,storeTimestamp); } } } } } 如下是，发送了 10 条定时级别分别为 1-10 的消息以后，$HOME/store/consumequeue 文件下的消费队列文件的分布情况:\n不同的定时级别对应于不同的队列 ID，定时级别减 1 得到的就是队列 ID 的值。因此级别 1-10 对应的是 0-9 的队列 ID:\npublic class ScheduleMessageService extends ConfigManager { public static int delayLevel2QueueId(final int delayLevel) { return delayLevel - 1; } } 三、定时消息再存储 Broker 启动的时候，会开启一个调度消息服务，此服务会监控所有定时消息队列，每一个消息队列会创建一个专门的延时消息投递任务用以到达规定时间后投递此消息:\npublic class ScheduleMessageService extends ConfigManager { public void start() { for (Map.Entry\u0026lt;Integer, Long\u0026gt; entry : this.delayLevelTable.entrySet()) { Integer level = entry.getKey(); Long timeDelay = entry.getValue(); Long offset = this.offsetTable.get(level); if (timeDelay != null) { this.timer.schedule(new DeliverDelayedMessageTimerTask(level, offset), FIRST_DELAY_TIME); } } } } 每个消息队里的消息投递任务，会检查自己跟踪的消息队列，并从此消息队列所对应的定时级别的偏移量中检查是否有新的定时消息到来。其中定时级别的偏移量是维护在内存中的偏移量表 offsetTable 中。每隔 10 秒钟，这个表会被持久化到磁盘上的 delayOffset.json 文件中一次:\npublic class ScheduleMessageService extends ConfigManager { private final ConcurrentMap\u0026lt;Integer /* level */, Long/* offset */\u0026gt; offsetTable = new ConcurrentHashMap\u0026lt;Integer, Long\u0026gt;(32); public void start() { // 每隔 10 秒钟持久化一次  this.timer.scheduleAtFixedRate(new TimerTask() { @Override public void run() { ScheduleMessageService.this.persist(); } }, 10000, this.defaultMessageStore.getMessageStoreConfig().getFlushDelayOffsetInterval()); } } delayOffset.json 文件中存储的示例信息如下所示：\nDeliverDelayedMessageTimerTask 任务会从消费任务队列文件中取出最新的定时消息的 tagsCode ，并计算出的当前是否已经到了这条消息投递的时间。如果到了，即 countdown \u0026lt; 0，那么便会从 CommitLog 文件中取出消息，修正消息的话题和队列 ID 等信息，然后重新存储此条消息。如果还没有到，那么便会重新执行一个定时时间设置为 countdown 毫秒的定时任务。在完成之后，会更新当前的偏移量表，为下一次做准备:\nclass DeliverDelayedMessageTimerTask extends TimerTask { public void executeOnTimeup() { // ...  for (; i \u0026lt; bufferCQ.getSize(); i += ConsumeQueue.CQ_STORE_UNIT_SIZE) { // 是否到时间  long countdown = deliverTimestamp - now; if (countdown \u0026lt;= 0) { // 取出消息  MessageExt msgExt = ScheduleMessageService.this.defaultMessageStore.lookMessageByOffset(offsetPy, sizePy); // 修正消息，设置上正确的话题和队列 ID  MessageExtBrokerInner msgInner = this.messageTimeup(msgExt); // 重新存储消息  PutMessageResult putMessageResult = ScheduleMessageService.this.defaultMessageStore .putMessage(msgInner); } else { // countdown 后投递此消息  ScheduleMessageService.this .timer .schedule(new DeliverDelayedMessageTimerTask(this.delayLevel, nextOffset), countdown); // 更新偏移量  } } // end of for  // 更新偏移量  } } 四、消息重试概述 消息重试分为消息发送重试和消息接受重试，消息发送重试是指消息从 Producer 端发送到 Broker 服务器的失败以后的重试情况，消息接受重试是指 Consumer 在消费消息的时候出现异常或者失败的重试情况。\nProducer 端通过配置如下这两个两个 API 可以分别配置在同步发送和异步发送消息失败的时候的重试次数:\nDefaultMQProducer producer = new DefaultMQProducer(\u0026#34;please_rename_unique_group_name\u0026#34;); producer.setRetryTimesWhenSendAsyncFailed(3); producer.setRetryTimesWhenSendFailed(3); Consumer 端在消费的时候，如果接收消息的回调函数出现了以下几种情况:\n 抛出异常 返回 NULL 状态 返回 RECONSUME_LATER 状态 超时 15 分钟没有响应  那么 Consumer 便会将消费失败的消息重新调度直到成功消费:\nconsumer.registerMessageListener(new MessageListenerConcurrently() { @Override public ConsumeConcurrentlyStatus consumeMessage(List\u0026lt;MessageExt\u0026gt; msgs, ConsumeConcurrentlyContext context) { // 抛出异常  // 返回 NULL 或者 RECONSUME_LATER 状态  return ConsumeConcurrentlyStatus.RECONSUME_LATER; } }); 五、Producer 消息发送重试 发送失败的重试方式，主要表现在发送消息的时候，会最多尝试 getRetryTimesWhenSendFailed() 次发送，当成功发送以后，会直接返回发送结果给调用者。当发送失败以后，会继续进行下一次发送尝试，核心代码如下所示：\npublic class DefaultMQProducerImpl implements MQProducerInner { private SendResult sendDefaultImpl(Message msg, /** 其他参数 **/) throws MQClientException, RemotingException, MQBrokerException, InterruptedException { int timesTotal = communicationMode == CommunicationMode.SYNC ? 1 + this.defaultMQProducer.getRetryTimesWhenSendFailed() : 1; int times = 0; for (; times \u0026lt; timesTotal; times++) { // 尝试发送消息，发送成功 return，发送失败 continue  } } } 六、Consumer 消息接受重试 (1) 订阅重试话题 Consumer 在启动的时候，会执行一个函数 copySubscription() ，当用户注册的消息模型为集群模式的时候，会根据用户指定的组创建重试组话题并放入到注册信息中:\npublic class DefaultMQPushConsumerImpl implements MQConsumerInner { public synchronized void start() throws MQClientException { switch (this.serviceState) { case CREATE_JUST: // ...  this.copySubscription(); // ...  this.serviceState = ServiceState.RUNNING; break; } } private void copySubscription() throws MQClientException { switch (this.defaultMQPushConsumer.getMessageModel()) { case BROADCASTING: break; case CLUSTERING: // 重试话题组  final String retryTopic = MixAll.getRetryTopic(this.defaultMQPushConsumer.getConsumerGroup()); SubscriptionData subscriptionData = FilterAPI.buildSubscriptionData(this.defaultMQPushConsumer.getConsumerGroup(), retryTopic, SubscriptionData.SUB_ALL); this.rebalanceImpl.getSubscriptionInner().put(retryTopic, subscriptionData); break; default: break; } } } 假设用户指定的组为 “ORDER”，那么重试话题则为 “%RETRY%ORDER”，即前面加上了 “%RETRY%” 这个字符串。\nConsumer 在一开始启动的时候，就为用户自动注册了订阅组的重试话题。即用户不单单只接受这个组的话题的消息，也接受这个组的重试话题的消息。这样一来，就为下文用户如何重试接受消息奠定了基础。\n(2) 失败消息发往重试话题 当 Consumer 客户端在消费消息的时候，抛出了异常、返回了非正确消费的状态等错误的时候，这个时候 ConsumeMessageConcurrentlyService 会收集所有失败的消息，然后将每一条消息封装进 CONSUMER_SEND_MSG_BACK 的请求中，并将其发送到 Broker 服务器:\npublic class ConsumeMessageConcurrentlyService implements ConsumeMessageService { public void processConsumeResult(final ConsumeConcurrentlyStatus status, /** 其他参数 **/) { switch (this.defaultMQPushConsumer.getMessageModel()) { case BROADCASTING: // ...  break; case CLUSTERING: for (int i = ackIndex + 1; i \u0026lt; consumeRequest.getMsgs().size(); i++) { MessageExt msg = consumeRequest.getMsgs().get(i); // 重新将消息发往 Broker 服务器  boolean result = this.sendMessageBack(msg, context); } // ...  break; default: break; } } } 当消费失败的消息重新发送到服务器后，Broker 会为其指定新的话题重试话题，并根据当前这条消息的已有的重试次数来选择定时级别，即将这条消息变成定时消息投放到重试话题消息队列中。可见消息消费失败后并不是立即进行新的投递，而是有一定的延迟时间的。延迟时间随着重试次数的增加而增加，也即投递的时间的间隔也越来越长:\npublic class SendMessageProcessor extends AbstractSendMessageProcessor implements NettyRequestProcessor { private RemotingCommand consumerSendMsgBack(final ChannelHandlerContext ctx, final RemotingCommand request) throws RemotingCommandException { // 指定为重试话题  String newTopic = MixAll.getRetryTopic(requestHeader.getGroup()); int queueIdInt = Math.abs(this.random.nextInt() % 99999999) % subscriptionGroupConfig.getRetryQueueNums(); // 指定为延时信息，设定延时级别  if (0 == delayLevel) { delayLevel = 3 + msgExt.getReconsumeTimes(); } msgExt.setDelayTimeLevel(delayLevel); // 重试次数增加  msgInner.setReconsumeTimes(msgExt.getReconsumeTimes() + 1); // 重新存储  PutMessageResult putMessageResult = this.brokerController.getMessageStore().putMessage(msgInner); // ...  } } 当然，消息如果一直消费不成功，那也不会一直无限次的尝试重新投递的。当重试次数大于最大重试次数 (默认为 16 次) 的时候，该消息将会被送往死信话题队列，认定这条话题投递无门:\npublic class SendMessageProcessor extends AbstractSendMessageProcessor implements NettyRequestProcessor { private RemotingCommand consumerSendMsgBack(final ChannelHandlerContext ctx, final RemotingCommand request) throws RemotingCommandException { // 重试次数大于最大重试次数  if (msgExt.getReconsumeTimes() \u0026gt;= maxReconsumeTimes || delayLevel \u0026lt; 0) { // 死信队列话题  newTopic = MixAll.getDLQTopic(requestHeader.getGroup()); queueIdInt = Math.abs(this.random.nextInt() % 99999999) % DLQ_NUMS_PER_GROUP; } // ...  } } 上述客户端消费失败信息的流程图如下所示:\n扫描下面二维码，在手机端阅读：\n"});index.add({'id':77,'href':'/docs/books/','title':"书籍",'content':"书籍  书籍是人类进步的阶梯。\u0026ndash; 高尔基\n "});index.add({'id':78,'href':'/docs/books/in-depth_analysis_of_the_core_technology_of_apache_dubbo/','title':"深度剖析 Apache Dubbo 核心技术",'content':"深度剖析 Apache Dubbo 核心技术 SPI 扩展 Dubbo 支持扩展的核心接口上，都会通过类似 @SPI(\u0026quot;dubbo\u0026quot;) 这样的注解，来标识当前接口的默认实现。如果你想替换掉这个默认实现，那么需要两个步骤。第一，实现 Protocol 接口，然后在 META-INF/dubbo 目录下创建一个名字为 org.apache.dubbo.rpc.Protocol 的文本文件。这个 META-INF 目录如果使用的是 IDEA 开发，那么其应该放到 resources 目录下的顶层，这样打 jar 包的时候，其也会被复制到 jar 包的第一级目录。内容如下：\nmyProtocol = com.zk.MyProtocol 第二，需要在 XML 配置文件中，声明使用这个扩展实现：\n\u0026lt;dubbo:protocol name=\u0026#34;myProtocol\u0026#34;\u0026gt; 其实 JDK 本身也提供了 SPI 扩展，Dubbo 之所以没有使用默认提供的实现，是因为：\n JDK 标准的 SPI 一次性实例化扩展点的所有实现，如果有些没有使用到，那么会浪费资源。 扩展点加载失败的异常提示不是很好。 增强了 Ioc 和 AOP 的支持。  性能 Dubbo 会给每个服务提供者的实现类生产一个 Wrapper 类，这个 Wrapper 类里面最终调用服务提供者的接口实现类，Wrapper 类的存在是为了减少反射的调用。当服务提供方收到消费方发来的请求后，需要根据消费者传递过来的方法名和参数反射调用服务提供者的实现类，而反射本身是有性能开销的，Dubbo 把每个服务提供者的实现类通过 JavaAssist 包装为一个 Wrapper 类以减少反射调用开销。\n其实就是由反射改为了比较方法名称，然后调用，伪代码如下：\nGreetingServiceImpl impl = (GreetingServiceImpl) object; if (\u0026#34;sayHello\u0026#34;.equals(methodName) \u0026amp;\u0026amp; argClass.length == 1) { return impl.sayHello((String) argObject[0]); } if (\u0026#34;testGeneric\u0026#34;.equals(methodName) \u0026amp;\u0026amp; argClass.length == 1) { return impl.testGeneric((Pojo) arrObject[0]); } 容错 异常情况下的，代码逻辑应该怎么走？Dubbo 提供了如下几种容错方案：\n 失败重试：通常用于读操作或者具有幂等的写操作。需要注意的是，重试会带来更长延迟。 快速失败：抛出异常。 安全失败：忽略异常，场景：写入审计日志。 失败自动恢复：后台记录失败请求，并按照策略后期再重试，场景：消息通知。 并行调用：通常用于实时性要求较高的读操作，但需要浪费更多服务资源。 广播调用：通常用于通知所有提供者更新缓存或日志等本地资源信息。  负载均衡  随机策略 轮循策略 最少活跃调用数 一致性 Hash 策略  协议设计 服务消费端如何把服务请求信息序列化为二进制数据、服务提供方如何把消费端发送的二进制数据反序列化为可识别的POJO对象、Dubbo的应用层协议是怎么样的？\n看一下这个 \u0026ldquo;request flag and serialization id\u0026rdquo;：高四位标示请求类型：\n低四位标示序列化方式，其枚举值如下：\n再后面的一字节是只在响应报文里才设置（在请求报文里不设置），用来标示响应的结果码，具体定义如下：\n在此列出这个编码格式，是想要学习 Dubbo 是如果用较少的字节头，编码较多的信息的。还有编码的粒度，响应码这部分，并没有直接定义与业务紧密关联的状态码，比如 \u0026ldquo;磁盘存储失败\u0026rdquo; 等状态码，相反定义的是较为粗粒度的状态码，更为细粒度的可以放到 \u0026ldquo;body\u0026rdquo; 里面。\n"});index.add({'id':79,'href':'/docs/programmer-interview/algorithm/binary-search/','title':"Binary Search 二分搜索",'content':"Binary Search // https://leetcode.com/problems/binary-search/ // public class BinarySearch { public int search(int[] nums, int target) { if (nums == null || nums.length == 0) { return -1; } int lo = 0; int hi = nums.length - 1; while (lo \u0026lt;= hi) { int m = lo + ((hi - lo) \u0026gt;\u0026gt; 1); if (nums[m] == target) { return m; } else if (nums[m] \u0026gt; target) { hi = m - 1; } else { lo = m + 1; } } return -1; } } "});index.add({'id':80,'href':'/docs/tutorial/git/merge-multiple-commit/','title':"Git 多次提交合并成一次提交",'content':"Git 多次提交合并成一次提交 你在 dev 分支上开发某个功能，在本地执行了三次 commit，注意这三次 commit 都没有 push 到远程分支，都只是在本地存在。现在你想要在 push 之前，将你本地的这多个 commit 合并成一个 commit，请问应该怎么做？\n答案是：git rebase -i HEAD~N，N 代表你想把最近的几条 commitId 记录合并。具体操作步骤如下：\n查看提交记录 git log 查看提交记录：\n871adf OK, feature Z is fully implemented --- newer commit --┐ 0c3317 Whoops, not yet... | 87871a I'm ready! | 643d0e Code cleanup |-- Join these into one afb581 Fix this and that | 4e9baa Cool implementation | d94e78 Prepare the workbench for feature Z -------------------┘ 6394dc Feature Y --- older commit  假设 6394dc 提交已经 push 上去了 你现在想把 d94e78 ~ 871adf 这几个 commit 合并一下  即最终你再次执行 git log 想要看到的效果如下：\n84d1f8 Feature Z --- newer commit (result of rebase) 6394dc Feature Y --- older commit 从 d94e78 ~ 871adf 共有 7 个 commit，因此执行命令：\ngit rebase -i HEAD~7  -i 是 --interactive 参数的缩写表达，即交互的 rebase\n 现在只有 7 个 commit，数起来还简单一些。假设，我需要将 70 个 commit 合并，难不成我还要一个一个精确的数？答案是不需要。后面加上最后一次的 commitId 也可以，含义是从这个 commitId 之后的多个 commit 都要合并到一起，但是并不包含这个 commit：\ngit rebase -i 6394dc 合并 commit 记录 执行 git rebase -i HEAD~7 命令后，你将会进入到命令行编辑其中（比如 Vi 中），然后选择这些 commit 如何进行合并。\n 在这个地方特别需要注意，在编辑器中，现在看到的旧的提交位于第一行，新的提交位于最后一行，顺序和 git log 查看的顺序颠倒了。\n pick d94e78 Prepare the workbench for feature Z --- older commit pick 4e9baa Cool implementation pick afb581 Fix this and that pick 643d0e Code cleanup pick 87871a I'm ready! pick 0c3317 Whoops, not yet... pick 871adf OK, feature Z is fully implemented --- newer commit 然后下面其实也有注释：\n# Commands: # p, pick = use commit # r, reword = use commit, but edit the commit message # e, edit = use commit, but stop for amending # s, squash = use commit, but meld into previous commit # f, fixup = like \u0026#34;squash\u0026#34;, but discard this commit\u0026#39;s log message # x, exec = run command (the rest of the line) using shell 下面对 p 和 s 命令，简单解释：\n p：这条 commit 依然保留，不要被去掉，这条 commit 的信息也依然维持原样，最终的 git log 也依然能看到这条 commit s：将这条 commit 与前一次 commit  合并到一起  我们在编辑器中，使用 s 来将最近 6 次的 commit 合并到第一次 commit 上，修改如下：\npick d94e78 Prepare the workbench for feature Z --- older commit s 4e9baa Cool implementation s afb581 Fix this and that s 643d0e Code cleanup s 87871a I'm ready! s 0c3317 Whoops, not yet... s 871adf OK, feature Z is fully implemented --- newer commit 然后输入 :wq 保存编辑器的内容。\n创建一个新的 commit 上述当离开编辑器的时候，Git 会再次弹出一个编辑器让你输入此次合并 commit 的信息输入界面：\nPrepare the workbench for feature Z Cool implementation Fix this and that Code cleanup I'm ready! Whoops, not yet... OK, feature Z is fully implemented 你可以在这个地方修改信息，也可以直接使用 Git 给你生成好的信息，之后再次输入 :wq 保存即可。\n参考  Squash commits into one with Git Git Interactive Rebase, Squash, Amend and Other Ways of Rewriting History  扫描下面二维码，在手机端阅读：\n"});index.add({'id':81,'href':'/docs/rocketmq/rocketmq-master-slave-sync/','title':"RocketMQ 主备同步",'content':"RocketMQ 主备同步 介绍 RocketMQ 的主备同步机制\n一、简介 RocketMQ 通过 Master-Slave 主备机制，来实现整个系统的高可用，具体表现在:\n Master 磁盘坏掉，Slave 依然保存了一份 Master 宕机，不影响消费者继续消费  二、搭建环境 我们在一台机器上搭建一个 Master 一个 Slave 的环境:\n为了能够将 Master 和 Slave 搭建在同一台计算机上，我们除了需要将 Broker 的角色设置为 SLAVE ，还需要为其指定单独的 brokerId、 storePathRootDir、 storePathCommitLog。\n// SLAVE 角色 messageStoreConfig.setBrokerRole(BrokerRole.SLAVE); // 一个机器如果要启动多个 Broker，那么每个 Broker 的 store 根目录必须不同 messageStoreConfig.setStorePathRootDir(storePathRootDir); // 一个机器如果要启动多个 Broker，那么每个 Broker 的 storePathCommitLog 根目录必须不同 messageStoreConfig.setStorePathCommitLog(storePathCommitLog); // 设置 Slave 的 Master HA 地址 messageStoreConfig.setHaMasterAddress(\u0026#34;localhost:10912\u0026#34;); // SLAVE 角色的 brokerId 必须大于 0 brokerConfig.setBrokerId(1); 注意 Slave 和 Master 的 brokerName 必须一致，即它们必须处于同一个 BrokerData 数据结构里面。实际上在做了如上的修改之后， Slave 和 Master 依旧不能同时运行在同一台机器上，因为 Slave 本身也可以称为 Master，接受来自其他 Slave 的请求，因此当运行 Slave 的时候，需要将 HAService 里面的启动 AcceptSocketService 运行的相关方法注释掉。\n三、建立连接 当一个 Broker 在启动的时候，会调用 HAService 的 start() 方法:\npublic class HAService { public void start() throws Exception { this.acceptSocketService.beginAccept(); this.acceptSocketService.start(); this.groupTransferService.start(); this.haClient.start(); } } AcceptSocketService 服务的功能是 Master 等待接受来自其它客户端 Slave 的连接，当成功建立连接后，会将这条连接 HAConnection 放入到 connectionList 连接列表里面。而 HAClient 服务的功能是 Slave 主动发起同其它 Master 的连接。\n四、数据传输 当启动 HAService 之后，一旦 Master 发现和 Slave 不同步，那么Master 会自动开始同步消息到 Slave，无需其它的触发机制。\n(1) 消息异步传输 如果 Master Broker 的角色是 ASYNC_MASTER，那么消息等待从 Master 同步到 Slave 的方式是异步传输的方式。这意味当一条消息发送到 Master Broker 的时候，Master Broker 在存储完这条消息到本地之后，并不会等待消息同步到 Slave Broker 才返回。这种方式会缩短发送消息的响应时间。\n(2) 消息同步传输 如果 Master Broker 的角色是 SYNC_MASTER，那么消息等待从 Master 同步到 Slave 的方式是同步传输的方式。除此之外，进入同步方式还得满足另外两个条件：\n 消息体的 PROPERTY_WAIT_STORE_MSG_OK 属性值为 true，即这条消息允许等待 Slave 相比 Master 落下的同步进度不能超过 256MB  public class CommitLog { public void handleHA(AppendMessageResult result, PutMessageResult putMessageResult, MessageExt messageExt) { if (BrokerRole.SYNC_MASTER == this.defaultMessageStore.getMessageStoreConfig().getBrokerRole()) { HAService service = this.defaultMessageStore.getHaService(); // 消息是否允许等待同步  if (messageExt.isWaitStoreMsgOK()) { // Slave 是否没有落下 Master 太多  if (service.isSlaveOK(result.getWroteOffset() + result.getWroteBytes())) { // 等待同步完成  // ...  } // Slave problem  else { // Tell the producer, slave not available  putMessageResult.setPutMessageStatus(PutMessageStatus.SLAVE_NOT_AVAILABLE); } } } } } 其中 isSlaveOK 方法就是用来检测 Slave 和 Master 落下的同步进度是否太大的:\npublic class HAService { public boolean isSlaveOK(final long masterPutWhere) { boolean result = this.connectionCount.get() \u0026gt; 0; result = result \u0026amp;\u0026amp; ((masterPutWhere - this.push2SlaveMaxOffset.get()) \u0026lt; this.defaultMessageStore .getMessageStoreConfig() .getHaSlaveFallbehindMax()); // 默认 256 * 1024 * 1024 = 256 MB  return result; } } 如果上面两个条件不满足的话，那么 Master 便不会再等待消息同步到 Slave 之后再返回，能尽早返回便尽早返回了。\n消息等待是否同步到 Slave 是借助 CountDownLatch 来实现的。当消息需要等待的时候，便会构建一个 GroupCommitRequest ，每个请求在其内部都维护了一个 CountDownLatch ，然后通过调用 await(timeout) 方法来等待消息同步到 Slave 之后，或者超时之后自动返回。\npublic static class GroupCommitRequest { private final CountDownLatch countDownLatch = new CountDownLatch(1); public void wakeupCustomer(final boolean flushOK) { this.flushOK = flushOK; this.countDownLatch.countDown(); } public boolean waitForFlush(long timeout) { try { this.countDownLatch.await(timeout, TimeUnit.MILLISECONDS); return this.flushOK; } catch (InterruptedException e) { log.error(\u0026#34;Interrupted\u0026#34;, e); return false; } } } 我们再重点来看几个循环体和唤醒点:\n GroupTransferService 服务的是否处理请求的循环体和唤醒点:  class GroupTransferService extends ServiceThread { public synchronized void putRequest(final CommitLog.GroupCommitRequest request) { // ...  // 放入请求，唤醒  if (hasNotified.compareAndSet(false, true)) { waitPoint.countDown(); // notify  } } public void run() { // 循环体  while (!this.isStopped()) { try { // putRequest 会提前唤醒这句话  this.waitForRunning(10); this.doWaitTransfer(); } catch (Exception e) { log.warn(this.getServiceName() + \u0026#34; service has exception. \u0026#34;, e); } } } }  HAConnection 的是否进行消息传输的循环体和唤醒点：  class WriteSocketService extends ServiceThread { @Override public void run() { // 循环体  while (!this.isStopped()) { SelectMappedBufferResult selectResult = HAConnection.this.haService.getDefaultMessageStore().getCommitLogData(this.nextTransferFromWhere); if (selectResult != null) { // 传输（写入）消息  } else { // 等待 100 毫秒或者提前被唤醒  HAConnection.this.haService.getWaitNotifyObject().allWaitForRunning(100); } } } } public class CommitLog { public void handleHA(AppendMessageResult result, PutMessageResult putMessageResult, MessageExt messageExt) { GroupCommitRequest request = new GroupCommitRequest(result.getWroteOffset() + result.getWroteBytes()); service.putRequest(request); // 提前唤醒 WriteSocketService  service.getWaitNotifyObject().wakeupAll(); } }  Slave 汇报进度唤醒 GroupTransferService， 等待同步完成唤醒 GroupCommitRequest 的 CountDownLatch:  class ReadSocketService extends ServiceThread { private boolean processReadEvent() { // 唤醒 GroupTransferService  HAConnection.this.haService.notifyTransferSome(HAConnection.this.slaveAckOffset); } } class GroupTransferService extends ServiceThread { // 被唤醒  public void notifyTransferSome() { this.notifyTransferObject.wakeup(); } private void doWaitTransfer() { for (CommitLog.GroupCommitRequest req : this.requestsRead) { boolean transferOK = HAService.this.push2SlaveMaxOffset.get() \u0026gt;= req.getNextOffset(); // 5 次重试  for (int i = 0; !transferOK \u0026amp;\u0026amp; i \u0026lt; 5; i++) { // 等待被唤醒或者超时  this.notifyTransferObject.waitForRunning(1000); transferOK = HAService.this.push2SlaveMaxOffset.get() \u0026gt;= req.getNextOffset(); } // 唤醒 GroupCommitRequest 的 CountDownLatch  req.wakeupCustomer(transferOK); } } } public static class GroupCommitRequest { // 被唤醒  public void wakeupCustomer(final boolean flushOK) { this.flushOK = flushOK; this.countDownLatch.countDown(); } } 下图是上图一个完整的消息唤醒链:\n五、主备消费 当消费者在消费的时候，如果 Master 突然宕机，那么消费者会自动切换到 Slave 机器上继续进行消费。\n六、消费建议 RocketMQ 提供了自动从 Slave 读取老数据的功能。这个功能主要由 slaveReadEnable 这个参数控制。默认是关的（slaveReadEnable = false）。推荐把它打开，主从都要开。这个参数打开之后，在客户端消费数据时，会判断，当前读取消息的物理偏移量跟最新的位置的差值，是不是超过了内存容量的一个百分比（accessMessageInMemoryMaxRatio = 40 by default）。如果超过了，就会告诉客户端去备机上消费数据。如果采用异步主从，也就是 brokerRole 等于 ASYNC_AMSTER 的时候，你的备机 IO 打爆，其实影响不太大。但是如果你采用同步主从，那还是有影响。所以这个时候，最好挂两个备机。因为 RocketMQ 的主从同步复制，只要一个备机响应了确认写入就可以了，一台 IO 打爆，问题不大。参考自阿里中间件团队博客。\n七、异常处理 Q: Master(Slave) 读取来自 Slave(Master) 的消息异常 (IOException、 read() 返回 -1 等) 的时候怎么处理? A: 打印日志 + 关闭这条连接\nQ: Master(Slave) 长时间没有收到来自 Slave(Master) 的进度汇报怎么处理? A: 每次读取之后更新 lastReadTimestamp 或者 lastWriteTimestamp，一旦发现在 haHousekeepingInterval 间隔内 (默认 20秒) 这个时间戳都没有改变的话，关闭这条连接\nQ: Slave 检测到来自 Master 汇报的本次传输偏移量和本地的传输偏移量不同时怎么处理? A: 打印日志 + 关闭这条连接\nQ: Master 如何知道 Slave 是否真正的存储了刚才发送过去的消息? A: Slave 存储完毕之后，通过向 Master 汇报进度来完成。相当于 TCP 的 ACK 机制。\nQ: Master 宕掉 A: 无论 Maser 是主动关闭 Mater，还是 Master 因为异常而退出，Slave 都会每隔 5 秒重连一次 Master\n扫描下面二维码，在手机端阅读：\n"});index.add({'id':82,'href':'/docs/books/everyone-is-architect/','title':"人人都是架构师 (一)",'content':"人人都是架构师 - 分布式系统架构落地与瓶颈突破 分布式系统应对高并发、大流量的常用手段：\n 扩容 动静分离 缓存 服务降级 限流  限流 常见算法：\n 令牌桶，Nginx 限流模块用的是这个：限制的是流量的平均流入速率，允许一定程度上的突发流量。 漏桶：限制的是流出速率，并且这个速率还是保持不变的，不允许突发流量。  Nginx 限流 http { # 每个 IP 的 session 空间大小 limit_zone one $binary_remote_addr 20m; # 每个 IP 每秒允许发起的请求数 limit_req_zone $binary_remote_addr zone=req_one:20m rate=10r/s; # 每个 IP 能够发起的并发连接数 limit_conn one 10; # 缓存还没有来得及处理的请求 limit_req zone=req_one burst=100; } 消峰  活动分时段 答题验证  高并发读 \u0026ldquo;马某出轨王某\u0026rdquo;、\u0026ldquo;iPhone SE 2020 发布\u0026rdquo; 等这种热点新闻的 key 会始终落在同一个缓存节点上，分布式缓存一定会出现单点瓶颈，其资源连接容易瞬间耗尽。有如下两种方案解决这个问题：\n 基于 Redis 的集群多写多读方案。  多写如何保持一致性：将 Key 配置在 ZooKeeper，客户端监听 ZNode，一旦变化，全量更新本地持有的 Key   LocalCache 结合 Redis 集群的多级 Cache 方案。  LocalCache 拉取下来的商品数量有 5 个，但是实际上只有 4 个了，怎么解决？对于这种读场景，允许接受一定程度上的数据脏读，最终扣减库存的时候再提示商品已经售罄即可。    实时热点自动发现 交易系统产生的相关数据、上游系统中埋点上报的数据这两个，异步写入日志，对日志进行次数统计和热点分析\n高并发写 InnoDB 行锁 乐观锁扣减：\nSELECT stock, version FROM item WHERE item_id = 1; UPDATE ITEM SET version = version + 1, stock = stock - 1 WHERE item_id = 1 AND version = version; 引入条件 \u0026ldquo;实际库存数 \u0026gt;= 扣减库存数\u0026rdquo;：\nUPDATE item SET stock = stock - 1 WHERE item_id = 1 AND stock \u0026gt;= 1; 查询队列中等待拿锁的线程：\nSELECT * FROM information_schema.INNODB_TRX WHERE trx_state = \u0026#39;LOCK_WAIT\u0026#39;; Redis Redis 读写能力远胜任何类型的关心型数据库。使用 Redission 实现分布式锁，避免超卖：\nRedissionClient redission = null; try { redission = Redission.create(config); RLock lock = redission.getLock(\u0026#34;testLock\u0026#34;); // lock(long leaseTime, TimeUnit unit)  // 某个线程没有获取到锁，那么这个线程只能在队列中阻塞等待，与 InnoDB 如出一辙  lock.lock(20, TimeUnit.MILLISECONDS); lock.unlock(); // tryLock(long waitTime, long leaseTime, TimeUnit unit)  // 并发较大的情况下，建议使用这个  boolean result = lock.tryLock(10, 20, TimeUnit.MILLISECONDS); if (result) { lock.forceUnlock(); } } finally { if (null != redission) { redission.shutdown(); } } 扣除库存成功后的消息，通过消息队列写入到数据库中，由于才用了排队机制，并发写入数据库的流量可控，数据库负载压力始终保持在一个恒定的范围内。\n批处理 如何有效减少获取锁的次数，提升系统整体的 TPS？\n批量提交扣减商品库：先收集扣减请求，达到某个阈值，对请求进行合并，获取一次分布式锁。缺点：库存不足，这一批全部扣减失败。\n控制单机并发写  单机排队串行写 抢购限流  分布式 SequenceID 生成 Shark（一款开源的 MySQL 分库分表中间件）内部提供了生成 SequenceID 的 API （底层支持数据库和 ZooKeeper 作为申请 SequenceID 的存储系统）：\nCREATE TABLE shark_sequenceid( s_id INT NOT NULL AUTO_INCREMENT COMMENT \u0026#39;主键\u0026#39;, s_type INT NOT NULL COMMENT \u0026#39;类型\u0026#39;, s_useData BIGINT NOT NULL COMMENT \u0026#39;申请占位数量\u0026#39;, PRIMARY KEY(s_id) ) ENGINE = InnoDB DEFAULT CHARSET = utf8mb4 COLLATE utf8mb4_bin; 通过如下 API 获取：\n// (int idcNum, int type, long memData) SequenceIDManager.getSequenceId(100, 10, 5000); 第一个参数：IDC 机房编码，第二个参数：业务类别，第三个参数：向数据库申请的 ID 缓存数，返回一个长度为 19 位的 SequenceID。\nShark 只是负责封装 ID 的生成逻辑，真正保证唯一性和连续性的还是单点数据库。\n多维度复杂查询 Solr 的目的就是要替换 SQL 中的 like '%香水%' 这种模糊查询，因为数据库会采用全表扫描。\n"});index.add({'id':83,'href':'/docs/programmer-interview/','title':"程序员面试题",'content':"程序员面试题 "});index.add({'id':84,'href':'/docs/tutorial/sentinel/','title':"阿里巴巴 Sentinel",'content':"阿里巴巴 Sentinel "});index.add({'id':85,'href':'/docs/programmer-interview/algorithm/circular-array/','title':"Circular Array (循环数组)",'content':"Circular Array 循环数组 来自一亩三分地，微软面试官问的问题。过去任意 1 秒内来自同一 IP 的请求是否超过 100 次，可以用循环数组可以做。\n// // https://www.javaguides.net/2018/09/queue-implementation-using-circular-array-in-java.html // package com.zk.algorithm.array; /** * Queue Implementation using Circular Array * @author Ramesh Fadatare * */ public class CircularArray { // Array used to implement the queue.  private int[] queueRep; // 添加数据，存放在 (rear + 1) % size，size++  // 取出数据，(front + 1) % size，size--  private int size, front, rear; // Length of the array used to implement the queue.  private static final int CAPACITY = 16; //Default Queue size  // Initializes the queue to use an array of default length.  public CircularArray (){ queueRep = new int [CAPACITY]; size = 0; front = 0; rear = 0; } // Initializes the queue to use an array of given length.  public CircularArray (int cap){ queueRep = new int [ cap]; size = 0; front = 0; rear = 0; } // Inserts an element at the rear of the queue. This method runs in O(1) time.  public void enQueue (int data)throws NullPointerException, IllegalStateException{ if (size == CAPACITY) throw new IllegalStateException (\u0026#34;Queue is full: Overflow\u0026#34;); else { size++; queueRep[rear] = data; rear = (rear+1) % CAPACITY; } } // Removes the front element from the queue. This method runs in O(1) time.  public int deQueue () throws IllegalStateException{ // Effects: If queue is empty, throw IllegalStateException,  // else remove and return oldest element of this  if (size == 0) throw new IllegalStateException (\u0026#34;Queue is empty: Underflow\u0026#34;); else { size--; int data = queueRep [ (front % CAPACITY) ]; queueRep [front] = Integer.MIN_VALUE; front = (front+1) % CAPACITY; return data; } } // Checks whether the queue is empty. This method runs in O(1) time.  public boolean isEmpty(){ return (size == 0); } // Checks whether the queue is full. This method runs in O(1) time.  public boolean isFull(){ return (size == CAPACITY); } // Returns the number of elements in the queue. This method runs in O(1) time.  public int size() { return size; } // Returns a string representation of the queue as a list of elements, with  // the front element at the end: [ ... , prev, rear ]. This method runs in O(n)  // time, where n is the size of the queue.  public String toString(){ String result = \u0026#34;[\u0026#34;; for (int i = 0; i \u0026lt; size; i++){ result += Integer.toString(queueRep[ (front + i) % CAPACITY ]); if (i \u0026lt; size -1) { result += \u0026#34;, \u0026#34;; } } result += \u0026#34;]\u0026#34;; return result; } public static void main(String[] args) { CircularArray arrayQueue = new CircularArray(); arrayQueue.enQueue(10); arrayQueue.enQueue(20); arrayQueue.enQueue(30); arrayQueue.enQueue(40); arrayQueue.enQueue(50); arrayQueue.enQueue(60); arrayQueue.enQueue(70); arrayQueue.enQueue(80); arrayQueue.enQueue(90); arrayQueue.deQueue(); System.out.println(arrayQueue.toString()); } } "});index.add({'id':86,'href':'/docs/tutorial/git/git-branch/','title':"Git 分支",'content':"Git 分支 Git 的分支管理命令：git branch。\n示例 列举本地所有分支 git branch  当前分支会用 * 标识出来，也会用特别的颜色标识出来\n 列举本地和远程所有分支 git branch -a 创建分支 git branch \u0026lt;branchName\u0026gt; 删除分支 # 删除时，会检查此分支是否已经合并到其它分支，否则拒绝删除 git branch -d \u0026lt;branchName\u0026gt; # 不管有没有合并到其它分支，都强制删除分支 git branch -D \u0026lt;branchName\u0026gt; 重命名分支 # 如果版本库已经存在 newbranch，则拒绝重命名 git branch -m \u0026lt;oldbranch\u0026gt; \u0026lt;newbranch\u0026gt; # 如果版本库已经存在 newbranch，则强制重命名 git branch -M \u0026lt;oldbranch\u0026gt; \u0026lt;newbranch\u0026gt; 创建并切换分支 git checkout -b \u0026lt;new_branch\u0026gt; 扫描下面二维码在手机端阅读：\n"});index.add({'id':87,'href':'/docs/tutorial/zipkin/','title':"Zipkin 源码分析",'content':"Zipkin 源码分析 Zipkin是一款开源的分布式实时数据追踪系统（Distributed Tracking System），基于 Google Dapper的论文设计而来，由 Twitter 公司开发贡献。其主要功能是聚集来自各个异构系统的实时监控数据。\n架构图 四大组件 Collector Zipkin 收集上来的数据，交由 Collector 进行校验、存储、索引，以便后续查询。\nStorage 搜索 Web UI 官方提供的例子  brave-webmvc-example  "});index.add({'id':88,'href':'/docs/cloud-plus-bbs/','title':"云+社区技术沙龙",'content':"云+社区技术沙龙 云+社区沙龙 online，是腾讯云推出的一系列由技术专家、高级工程师、技术总监等在线直播的技术分享沙龙。本专栏整理收录了观看部分课程的心得体会。如需更多课程请访问腾讯云沙龙 。\n"});index.add({'id':89,'href':'/docs/books/the-art-of-readable-code/','title':"编写可读代码的艺术",'content':"编写可读代码的艺术 代码应当易于理解 Q: 可读性基本定理？\n 可读性基本原理：使别人理解它所需的时间最小化。\n Q: 代码总是越小越好？\n 减少代码行数是一个好目标，但是把理解代码所需的时间最小化是一个更好的目标。\n 表面层次的改进 把信息装到名字里 （1）选择专业的词\ndef getPage(url) 上述例子，get 词没有表达出很多信息。从本地缓存得到一个页面，还是从数据库中，或者从互联网中？如果从互联网中，应该使用更为专业的名字：fetchPage(url) 或 downloadPage(url)。\nclass BinaryTree { int size(); } 上述例子，size() 返回的是什么？树的高度，节点树，还是树在内存中所占的空间？size() 没有承载更多的信息，更专业的词汇是 height()、numNodes() 或 memoryBytes()。\n英语是一门丰富的语言，有很多词汇可以选择。下面是一些例子，这些单词更富有表现力，可能更适合你的语境：\n   单词 更多选择     send deliver、dispatch、announce、distribute、route   find search、extract、locate、recover   start launch、create、begin、open   make create、set up、build、generate、compose、add、new    （2）避免像 tmp 和 retval 这样泛泛的名字\n除非你有更好的理由！\n（3）用具体的名字代替抽象的名字\nsearchCanStart() 比 canListenOnPort() 更具体一些，这个名字直接描述了方法所做的事情。\n（4）为名字附带更多信息\n附带单位：\n   单词 更多选择     start(int delay) delay -\u0026gt; delay_secs   createCache(int size) size -\u0026gt; size_mb   throttleDownload(float limit) limit -\u0026gt; max_kbps   rotate(float angle) angle -\u0026gt; degrees_cw    附带其它重要属性：\n（5）名字应该有多长\n作用域大的名字采用更长的名字，不要用让人费解的一个或两个字母的名字来命名在几屏之间都可见的变量。对于只存在于几行之间的变量用短一点的名字更好。\n不会误解的名字 （1）例子：filter()\nresults = database.allObjects.filter(\u0026#34;year \u0026lt;= 2011\u0026#34;); 这里的 filter 是挑出还是减掉？\n（2）例子：clip(text, length)\n这里的 clip 是从尾部删除掉 length 的长度？还是裁掉最大长度为 length 的一段？\n（3）推荐用 min 和 max 来表示极限\n优化前 CART_TOO_BIG_LIMIT = 10; if shoppingCart.numItems() \u0026gt;= CART_TOO_BIG_LIMIT: error(\u0026#34;too many items in cart\u0026#34;)   优化后 static final MAX_ITEMS_IN_CART = 10; if shoppingCart.numItems() \u0026gt; MAX_ITEMS_IN_CART: error(\u0026#34;too many items in cart.\u0026#34;)    （4）推荐用 first 和 last 来表示包含的范围\nset.printKeys(first = \u0026#34;Bart\u0026#34;, last = \u0026#34;Maggie\u0026#34;) （5）推荐用 begin 和 end 来表示包含/排除范围\n（6）给布尔值命名\n 通常加上 is、has、can、should 这样的词，可以把布尔值变得更明确（存疑：JSON 序列化是否有影响？） 最好避免使用反义名字  （7）与使用者的期望相匹配\n如果 getMean() 做的是一个比较重的任务，并不是一个轻量级访问器，那么这样的命名换成 computeMean() 会更好一些。\n审美 （1）重新安排换行来保持一致\nNO  YES   （2）个人风格与一致性\n 一致的风格比 “正确” 的风格更为重要\n 该写什么样的注释 好的注释记录你在写代码时的重要想法。\n写出言简意赅的注释 （1）保持紧凑\nNO  YES   （2）具名函数参数的注释\nNO - 让人困惑  YES   简化循环和逻辑 把控制流变得易读 （1）条件语句中参数的顺序\n if (length \u0026gt;= 10) 和 if (10 \u0026lt;= length) 第一个更易读 whiler (bytes_received \u0026lt; bytes_expected) 和 while(bytes_expected \u0026gt; bytes_received) 第一个更易读  通用的规则是什么？怎么决定 a \u0026lt; b 好还是 b \u0026gt; a 好？\n上述指导原则与英语的语法一致。\n（2）if/else 语句块的顺序\n 首先处理正逻辑，而非负逻辑。 先处理掉简单的情况。 先处理有趣或者可疑的情况。  （3）?: 条件表达式\n下述代码应该是用 if/else 拆分开：\nreturn exponent \u0026gt;= 0 ? mantissa * (1 \u0026lt;\u0026lt; exponent) : mantissa / (1 \u0026lt;\u0026lt; -exponent);  默认情况下都用 if/else，三目运算发 ?: 只有在最简单的情况下使用。\n （4）避免 do/while 循环\n 我的经验是，do 语句是错误和困惑的来源……我倾向于把条件放在“前面我能看到的地方”。其结果是，我倾向于避免使用 do 语句。\u0026mdash; C++ 开创者 Bjarne Stroustrup《C++ 程序设计语言》\n （5）从函数中提前返回\n从函数中提前返回，常常很受欢迎。\npublic boolean contains(String str, String substr) { if (str == null || substr == null) { return false; } if (substr.equals(\u0026#34;\u0026#34;)) { return true; } // do other things ... } （6）最小化嵌套\n每个嵌套层次都在读者的 “思维栈” 上又增加了一个条件。\n 提早返回来减少嵌套 在循环中，提早返回的技术是：continue  拆分超长的表达式 （1）用作解释的变量\nNO if line.split(\u0026#39;:\u0026#39;)[0].strip() == \u0026#39;root\u0026#39;   YES username = line.split(\u0026#39;:\u0026#39;)[0].strip() if username == \u0026#39;root\u0026#39;    （2）总结变量\nNO if (request.user.id == document.owner_id) { // user 可疑编辑文档 } if (request.user.id != document.owner_id) { // 文档只可读 }   YES final boolean user_own_document = (request.user.id == document.owner_id); if (oser_own_document) { // user 可以编辑文档 } if (!oser_own_document) { // 文档只可读 }    变量与可读性  让你的变量对尽量少的代码行可见 操作一个变量的地方越多，越难确定它的当前值。  重新组织代码 抽取不相关的子问题  纯工具函数抽取到一起，从项目中拆分出的独立库越多越好 永远都不要安于使用不理想的接口，你总是可以创建你自己的包装函数来隐藏接口的粗陋细节 不要太过：引入很多小函数对可读性是不利的，因为读者要关注更多东西。   把一般项目和项目专有的代码分开，其结果是，大部分代码都是一般代码，其余的是让你的程序与众不同的核心部分。\n 一次只做一件事  列出所有任务，一些任务变为单独的函数或类，另外一些可以称为一个函数中的逻辑段落。  把想法变成代码  用自然语言描述程序，然后用这个描述来帮助你写出更自然的代码。  NO  易读无反义(即时有空语句体)   少写代码  最好读的代码就是没有代码\n  从项目中消除不必要的功能，不要过度设计 重新考虑需求，解决版本最简单的问题，只要能完成工作就行 经常性地通读标准库的整个 API，保持对它们的熟悉程度  精度代码 测试与可读性  测试应当具有可读性，以便其他程序员可以舒服地改变或增加测试 对使用者隐去不重要的细节，以便更重要的细节会更突出 选择一组最简单的输入，它能完整地使用被测代码  扫描下面二维码，在手机端阅读：\n"});index.add({'id':90,'href':'/docs/programmer-interview/algorithm/container-with-most-water/','title':"Container With Most Water",'content':"Container With Most Water // 两个柱子中间包含最多的水 // 可以看一下这道题的这个图 // 这个是两个柱子之间的所能容纳的水的矩形面积 // // https://leetcode.com/problems/container-with-most-water/ // // [1,8,6,2,5,4,8,3,7] // ↑ ↑ // 7 * 7 = 49 // public class ContainerWithMostWater { public int maxArea(int[] height) { int maxArea = Integer.MIN_VALUE; int lo = 0; int hi = height.length - 1; // O(n)  while (lo \u0026lt; hi) { maxArea = Math.max(maxArea, Math.min(height[lo], height[hi]) * (hi - lo)); // =======================================  // 此处这个地方，必须是小的一边移动  // 因为大的移动的话，面积一定变小 (宽度变小，而且高度不会超过小的)  // 而小的移动有可能变大  //  // 另外一种解释：  // 我们选择一个高的，以便容纳更多的水  // https://leetcode.com/problems/container-with-most-water/discuss/6100/Simple-and-clear-proofexplanation  // =======================================  if (height[lo] \u0026lt; height[hi]) { lo++; } else { hi--; } } return maxArea; } } "});index.add({'id':91,'href':'/docs/tutorial/git/git-merge-branch/','title':"Git 分支合并",'content':"Git 分支合并 某个功能在开发分支上开发完毕后，需要合并到 master 分支，合并分支有两种方式：\n git merge git rebase  分支现状展示  从 master 分支的 A 提交点，拉取了分支 user2/i18n user2/i18n 的功能开发总共有两个 commit：E 和 F master 在 A 提交点之后，又有 B、C 和 D 这三个提交被合入进来  Git merge 我们使用 git merge 来合并 user2/i18n 分支到 master 分支上：\n# 切换到 master 分支 git checkout master # 合并 user2/i18n 分支 git merge user2/i18n 合并后的分支示意图：\nGit rebase 我们使用 git rebase 来合并 user2/i18n 到 master 分支上：\ngit checkout user2/i18n git rebase master # 如果有冲突，则需要解决冲突 # 解决完冲突，使用 git add -u 将完成冲突解决的文件加入到暂存区 # git rebase --continue # 直接推送，用本地的 user2/i18n 分支更新远程的 master 分支即可 git push origin user2/i18n:master rebase 之后的分支示例：\nmerge 和 rebase 对比  rebase 相比 merge 少了一次 merge 产生的提交，减轻了代码审核的负担 rebase 产生的分支关系图，比 merge 产生的分支关系图更为简单，更有顺序性  扫描下面二维码，在手机端阅读：\n"});index.add({'id':92,'href':'/docs/tools/','title':"实用工具",'content':"阮一峰周刊提到的工具集 阮一峰《科技爱好者周刊》中列举的所有好用的工具集，持续收录，目前已经将前 28 期的所有实用的工具收录整理在下表中，方便小伙伴们使用。直接在本文 Ctrl(Command) + F 查找工具集的名字，即可快速搜索定位到你想找的工具。\n   类别 🍄 🍄     Resource 吴恩达《Machine Learning Yearning》 Google 面试自学手册    Android 开发工程师面试指南 《React in patterns》    《技术面试需掌握的基础知识整理》 各大互联网公司技术架构    收集开源书籍：love2.io Facebook 机器学习教程    AWK 编程语言 Python 100天从新手到大师    14000种鸟叫 网页设计常见错误    GO 高级教程 《Node.js 调试指南》    网站架构101 Google 数据集搜索    V8引擎官方网站    工具 火焰🔥图生成: flamebearer 合并多张图片    Tabler - Dashboard 浏览器自动化框架: Remote Browser    网页日历库 优化图片下载: img-2    开源图标库 PNG 图片压缩    AutoCAD 在线版 自动生成背景图片    各种 CSS 使用技巧 手绘风格组件库    HTML转PDF：ReLaXed 自动格式化 Python 代码    代理服务器：goproxy Terminal 显示 Dashboard    免费存储 JSON: jsonstore.io MAC 免费软件    生成 .gitignore 生成 localhost 证书    React 拖放库 开源代码片段管理服务    各种软件的 Cheatsheet 开源的在线图片编辑器    查找重复代码 命令行画出柱状图    设计原型产品 UI 开源短网址服务    命令行操作录制成SVG Crontab UI    APK安装在Ubuntu 任何网页转为 RSS    下载 Youtube 视频     "});index.add({'id':93,'href':'/docs/books/the-wisdom-of-trading-stocks/','title':"炒股的智慧",'content':"炒股的智慧  如果要我用一句话解释何以一般股民败多胜少，那就是：人性使然！说的全面些，就是这些永远不变的人性\u0026ndash;讨厌风险、急着发财、自以为是、赶潮跟风、因循守旧和耿于报复\u0026ndash;使股民难以逃避开股市的陷阱。说得简单些，就是好贪小便宜、吃不得小亏的心态使得一般股民几乎必然地成为了输家。\n 炒股的挑战 炒股与人性 炒股最重要的原则就是止损。但人性是好贪小便宜，不肯吃小亏，只有不断地因为贪了小便宜却失去大便宜，不肯吃小亏最终却吃了大亏，你才能最终学会不贪小便宜，不怕吃小亏。\n特殊的赌局 问问你自己喜欢做决定吗？喜欢独自为自己地决定负全部责任吗？对 99% 的人来说，答案是否定的。股市这一恒久的赌局却要求你每时每刻都要做理性的决定，并且为决定的结果负全部的责任！这就淘汰了一大部分股民，因为他们没有办法长期承受这样的心理能力。\n一般股民何以失败 人性讨厌风险 纽约有位叫做夏皮诺的心理医生，请了一批人来做两个实验：\n 实验一  选择：第一，75% 的机会得到 1000 美元，但有 25% 的机会什么都得不到；第二，确定得到 700 美元。结果 80% 的人选择了第二选择，大多数人宁愿少些，也要确定的利润。\n 股民好获小利，买进的股票升了一点，便迫不及待地脱手。这只股票或许有 75% 继续上升地机会，但为了避免 25% 什么都得不到的可能性，股民宁可少赚些。任何炒过股的读者都明白，要用较出场价更高地价位重新入场是多么困难。股价一天比一天高，你只能做旁观者。\n  实验二  选择：第一，75% 的机会付出 1000 美元，但有 25% 的机会什么都不付；第二，确定付出 700 美元。结果 75% 的人选择了第一选择。他们为了搏 25% 什么都不付的机会，从数学上讲多失去了 50 美元。\n 一旦买进的股票跌了，股民便死皮赖脸不肯止损，想象出各种各样的理由说服自己下跌只是暂时的。其真正的原因只不过为了搏那 25% 可能全身而退的机会！结果是小亏慢慢积累成大亏。\n 人的发财心太急 心一旦大了，行动上就开始缺少谨慎。首先我每次买股买得太多，其次止损止得太迟。我为此遭受了巨大的损失。\n人好自以为是 一天结束的时候，股票以某一价钱收盘。你有没有思考过它代表了什么？它代表了股市的参与者在今天收市的时候对该股票的认同。\n不要太固执己见，不要对自己的分析抱太大的信心。认真观察股市，不对时就认错。否则，你在这行生存的机会是不大的。\n人好跟风 人好报复 在股市中，买进的股票跌了，你就再多买一点，因为第二次买的价钱较上次为低，所以平均进价摊低了。从心理上看，你的心态和赌场亏钱时一样。一方面你亏不起，另一方面你在报复股市，报复股市让你亏钱。同时内心希望，只要赢一手，就能连本带利全回来。因为平均进价摊低了，股票的小反弹就能提供你全身而退的机会。\n这样的心态是极其有害的。股票跌的时候通常有它跌的理由，常常下跌的股票会越跌越低。这样被套牢，你就越陷越深，直到你心理无法承受的地步。一个致命的大亏损，常常就彻底淘汰了一位股民。\n人总是迟疑不决，心怀侥幸 每个炒股人都会经过这个过程。20元买好股票，定好18元止损，当股票跌到18元时，你有没有想想再等等？或许股票马上反弹！股票又跌到16元，你会不会拍自己的脑壳说：“真该按定好的规矩办！18元时就走人；现若股票反弹5毛钱我就一定说再见。”\n现股票跌到10元了，你准备怎么办？你会发毛吗？你会不会发狠：“老子这次拼了！现在就是不走，我倒要看看你最低会跌到什么地方？”\n当然，最后的结局很少例外，通常是股票学校又多了位交了学费毕不了业的炒股\n股票分析的基本知识 技术分析 升势：一浪比一浪高     朋友，你认为什么因素使投资者入市买股票？华尔街有过调查，使一般投资者入场买股票的原因最主要的就是因为股票在升！你明白吗？一般投资者入场买股票主要不是因为股票的成本收益比率低或红利高，而是因为股票在升！升！升！而投资人卖股票的最主要原因是因为股票在跌！在跌！\n双肩图：\n头肩图：\n 股市操纵可能改变每天的或短期的波动，但不可能改变大势。\n 成功的要素 几乎所有的行家，他们对炒股的首要建议便是尽量保住你的本金。要做到保本的办法只有两个：一是快速止损；二是别一次下注太多。\n什么是你对风险的承受力？最简单的办法就是问自己睡得好吗？\n专业炒手明白股票买卖不可能每次都正确，那么在错误的时候为何要付大的代价？但在在他们正确的时候，他们试图从中得到最大的利润。\n只要股票运动正常（是否正常的判定，请参考上一章节），便必须按兵不动。这是很难的一件事，你要克服对脱手获利的冲动。如果你确定股票运动正常，你的胜算很大，这时你应该在这只股票商适当加大下注的比重。\n在股市不断赚钱的秘诀：通过你自己的观察和研究，不断累技经验，将自己每次入场获胜的概率从 50% 提高到 60%，甚至 70%；而且每次进场不要下注太大，应只是本金的小部分。这样长期以来，你就能 ”久赌必赢“。\n股票走升势的正常运动  股票的危险信号   炒股的最基本信条是在任何时候，你手上持有股票的上升潜力必须大过下跌的可能，否则你就不应留在手里。看到危险信号，表示你的获胜概率此时已不超过 50%。\n何时买股票，何时卖股票 选买点最最重要点时选择止损点。在你进场之前，你必须很清楚若股票的运动与你的预期不合，你必须在何点止损离场。你在投资做生意，不要老是想你要赚多少钱，首先应该清除自己亏得起多少。这个止损点不应超出投资额的 20%。\n何时买股票 阻力线和支撑线：\n    你选择哪一只股票？\n突破阻力线之前的蓄劲期左是 3 个月，右是半年，应该买半年的：\n何时卖股票 选择卖点 大家应记住自己在做声音，就如同做服装生意一样，一有合理的利润，就可以卖出去。一个大走势，头和尾都是很难抓住的，炒手们应学习怎样抓中间的一截，能抓到波幅的 70% 就算是很好的成绩了。\n要决定何时卖股票，最简单的方法就是问自己：我愿此时买进这只股票吗？如果答案是否定的，你就可以考虑卖掉这只股票。\n总结：\n 注意危险信号 保本第一 亏小钱 遇有暴力，拿了再说。(两星期股票从 20 升到 40) 第一天转头（转头表示收市低于开市）的时候你就可以把股票卖掉。别期待好事情会没完没了。这样的暴升是股价短期到顶的信号，特别是最后两天，交易量猛增，公司并没有特别的好消息。 小心交易量猛增，股价却不升。这也是危险信号，它告诉你有人乘这个机会在出货。它通常是股票到顶的信号，起码短期内如此。 用移动止损来卖股票。止损点放在每个波浪的波谷，随着波浪往上翻，你将卖点由 A-\u0026gt;B-\u0026gt;C-\u0026gt;D-\u0026gt;E 往上移。这样就能保证你不会在升势时过早离场。同时这样做很简单，情绪上的波动很小。这是一般不能全时专职炒股人的最常用方法。它提供了一个原则，遵照这一原则，你不会情绪化地过早离场，导致一个 10000 元的赚钱机会只赚到 2000 元。   华尔街将炒股的诀窍归纳成两句话：截短亏损，让利润奔跑！英文叫 Cut loss short，let profit run！意思是一见股票情况不对，即刻止损，把它缩得越短越好！一旦有了利润，就必须让利润奔跑，从小利润跑成大利润。\n     华尔街的家训  止损！止损！止损！（炒股行的最高行为准则） 分散风险。（你有 10 次好运，第 11 次好运不见得会落在你头上） 避免买太多种股票 有疑问的时候，离场！ 忘掉你的入场价。（股票跌了，还留在手中干什么？这和你在什么价位进价有什么关系？） 别频繁交易。（频繁交易常常是因为枯燥无聊） 不要向下摊平。（第一次入场后，纸面上没有利润的话不要加码） 别让利润变成亏损。（你给股票 10% 左右的喘息空间，一只正常上升的股票，不会轻易跌 10% 的） 跟着股市走，别跟朋友走！ 该卖股票的时候，要当机立断，千万别迟疑！ 别把 “股价很低了” 当成买的理由，也别将 “股价很高了” 当成卖的理由！（别试着去接往下掉的刀子，它会把你的手扎的血淋淋的！） 定好计划，按既定方针办 别爱上任何股票 市场从来不会错，你自己的想法常常是错的   我赚到大钱的诀窍不在于我怎么思考，而在于我能安坐不动，坐着不动！明白吗？\u0026ndash; 杰西·利物莫\n 从有招迈向无招 抓住大机会  经济史是一部基于假象和谎言的连续剧，经济史的演绎从不基于真实的剧本，但它铺平了累积巨额财富的道路。做法就是认清其假象，投入其中，在假象被公众认识之前退出游戏。\u0026ndash; 索罗斯\n 和炒手们谈谈天 "});index.add({'id':94,'href':'/docs/programmer-interview/algorithm/countofsmallerafterself/','title':"Count Of Smaller After Self",'content':"Count Of Smaller After Self 题目 数组里面的每一个数字，排在这个数字后面的小于这个数字的有多少个数字\n解法 import java.util.ArrayList; import java.util.List; // Input: [5,2,6,1] // Output: [2,1,1,0] // // 统计小于自己的有多少个数字 public class CountOfSmallerAfterSelf { public List\u0026lt;Integer\u0026gt; countSmaller(int[] nums) { List\u0026lt;Integer\u0026gt; result = new ArrayList\u0026lt;\u0026gt;(); for (int i = 0; i \u0026lt; nums.length; i++) { int curr = nums[i]; int count = 0; for (int j = i + 1; j \u0026lt; nums.length; j++) { if (nums[j] \u0026lt; curr) { count++; } } result.add(count); } return result; } } "});index.add({'id':95,'href':'/docs/tutorial/git/git-fix-conflict/','title':"Git 解决冲突",'content':"Git 解决冲突 某个分支的代码想要合并到其它分支，可能会产生冲突，产生的原因就是这两个分支都对代码的同一个区域做了修改，Git 本身并不知道应该采用哪个修改最为合适，因此需要你来决定。\n解决冲突 如下所示是冲突代码的示例：\n A 和 B 之间的代码，是你本地的代码所做的改动 B 和 C 之间的代码，是远程代码所做的改动  你的工作是重新编辑 A 到 C 区域之间的内容，去掉 \u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt; 、=======、\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt; 符号，重新编辑 A 和 C 之间的代码，以让整个项目运行起来。\n编辑完之后，可以通过 git add 命令将冲突的文件假如到暂存区，然后再 git commit，就完成了冲突解决。\n打开图形界面工具解决冲突 使用图形化工具来帮助你解决冲突，不过需要事先安装工具。打开图形界面工具的命令如下：\ngit mergetool 打开之前，也可以使用 git config 进行简单的配置，比如使用 vimdiff 工具作为默认的冲突解决工具：\ngit config merge.tool vimdiff git config merge.conflictstyle diff3 git config mergetool.prompt false 放弃合并操作 你暂时不想解决冲突：\ngit reset 参考  How to resolve merge conflicts in Git  扫描下面二维码，在手机端阅读：\n"});index.add({'id':96,'href':'/docs/tutorial/git/git-tag/','title':"Git tag",'content':"Git tag 什么是 Tags Tag 是对某次 commit 的一个有意义的命名，比如某个重大的版本发布，某个重大的 BUG 修复等。如下展示了前端开发框架 React 在开发过程中标记的各个版本的 Tag 列表。\n显示版本库的 Tag 列表 git tag 创建 Tag # 在最新的提交是创建一个 Tag git tag myTag # 创建一个带有说明信息的 Tag git tag -m \u0026#34;My fir st annotated tag.\u0026#34; myTag2 删除 Tag git tag -d myTag 重命名 Tag 只能先删除旧的 Tag，然后创建一个新的\n将 Tag 推送到远程服务器 # 将 myTag 推送到远程服务器 git push origin myTag # 将本地所有 Tag 推送到远程服务器 git push origin refs/tags/* # 或 git push origin --tags 扫描下面二维码，在手机端阅读：\n"});index.add({'id':97,'href':'/docs/programmer-interview/algorithm/designcircularqueue/','title':"设计循环队列",'content':"Design Circular Queue 题目 设计循环队列\n解法 public class DesignCircularQueue { static class MyCircularQueue { private int[] queue; private int frontIndex; private int rearIndex; private int size; /** Initialize your data structure here. Set the size of the queue to be k. */ public MyCircularQueue(int k) { this.size = k + 1; this.queue = new int[k + 1]; } /** Insert an element into the circular queue. Return true if the operation is successful. */ public boolean enQueue(int value) { if (isFull()) { return false; } queue[rearIndex] = value; rearIndex = (rearIndex + 1) % size; return true; } /** Delete an element from the circular queue. Return true if the operation is successful. */ public boolean deQueue() { if (isEmpty()) { return false; } frontIndex = (frontIndex + 1) % size; return true; } /** Get the front item from the queue. */ public int Front() { if (isEmpty()) { return -1; } return queue[frontIndex]; } /** Get the last item from the queue. */ public int Rear() { if (isEmpty()) { return -1; } return rearIndex == 0 ? queue[size - 1] : queue[rearIndex - 1]; } /** Checks whether the circular queue is empty or not. */ public boolean isEmpty() { return frontIndex == rearIndex; } /** Checks whether the circular queue is full or not. */ public boolean isFull() { return (rearIndex + 1) % size == frontIndex; } } } "});index.add({'id':98,'href':'/docs/tutorial/git/git-add-and-rm/','title':"Git add 和 Git rm",'content':"Git add 和 Git rm  git add 用来从工作区向暂存区添加文件 git rm 用来从工作区向暂存区删除文件  git add 示例 git add [--all|-A] git add . git add -u Git 1.X 版本  假设 . 当前指向的目录是 .git 文件所在的目录\n Git 2.X 版本  假设 . 当前指向的目录是 .git 文件所在的目录\n git rm 示例 # 只从工作区删除文件 rm xxx.txt # 只从暂存区删除文件 git rm --cached # 从工作区和暂存区都删除这个文件 git rm xxx.txt # 递归强制删除 xxx_folder 中的所有文件 # -r: recursive # -f: override the up-to-date check git rm -rf xxx_folder 参考  Difference between “git add -A” and “git add .”  扫描下面二维码，在手机端阅读：\n"});index.add({'id':99,'href':'/docs/programmer-interview/algorithm/findfirstandlastpositionofelementinsortedarray/','title':"有序数组查找最小和最大元素的位置",'content':"有序数组查找最小和最大元素的位置 public class FindFirstandLastPositionofElementinSortedArray { public int[] searchRange(int[] nums, int target) { int minIndex = searchMinIndex(nums, target); if (minIndex == -1) { return new int[]{ -1, -1 }; } int maxIndex = searchMaxIndex(nums, target); return new int[] { minIndex, maxIndex }; } private int searchMaxIndex(int[] nums, int target) { int lo = 0; int hi = nums.length - 1; while (lo \u0026lt;= hi) { int m = lo + ((hi - lo) \u0026gt;\u0026gt; 1); if (nums[m] \u0026gt; target) { hi = m - 1; } else if (nums[m] \u0026lt; target) { lo = m + 1; } else { if (m == nums.length - 1 || nums[m + 1] \u0026gt; target) { return m; } lo = m + 1; } } return -1; } private int searchMinIndex(int[] nums, int target) { int lo = 0; int hi = nums.length - 1; while (lo \u0026lt;= hi) { int m = lo + ((hi - lo) \u0026gt;\u0026gt; 1); if (nums[m] \u0026gt; target) { hi = m - 1; } else if (nums[m] \u0026lt; target) { lo = m + 1; } else { if (m == 0 || nums[m - 1] \u0026lt; target) { return m; } hi = m - 1; } } return -1; } } "});index.add({'id':100,'href':'/docs/tutorial/git/git-push-and-pull/','title':"Git push 和 Git pull",'content':"Git push 和 Git pull git push 、git pull 用于向远程分支推送文件，以及从远程分支拉取文件等。\n远程版本库地址 .git/config 文件中记录了当前仓库远程版本库的地址：\nvi .git/config 直接修改这个地址保存后，当前版本库的远程版本库的地址也就变化了。Git 本身也提供了用来操纵版本库地址的命令：\n# 添加远程版本库地址 git remote add origin git@github.com:facebook/react.git # 更新远程版本库地址 git remote set-url origin git@github.com:facebook/react.git push 和 pull push 命令和 pull 命令的语法相似：\ngit push \u0026lt;remote_name\u0026gt; \u0026lt;branch_name\u0026gt; git pull \u0026lt;remote_name\u0026gt; \u0026lt;branch_name\u0026gt; 不带参数，执行命令 git push 的过程（git pull 同理）：\n 如果当前分支有 remote（如何知道是否有 remote？还是看 .git/config 文件，如下图所示，每个 branch 的 remote 都不是空的），那么 git push 相当于执行了 git push \u0026lt;remote\u0026gt; 如果没有设置，则相当于执行 git push origin  一般而言，你这个项目本身应该只有一个版本库地址，如下图所示，版本库的名称就叫做 origin，它的地址就是 url 后面的那一部分：\n一般情况下，在日常开发过程中，直接使用不带参数的 git push 和 git pull 命令就可以完成当前分支文件的推送和拉取操作。\ngit push -u 部分程序员在 git push 的时候，会加上 -u 这个参数，这个主要目的是为了能够使用不带参数的 git pull 命令，更方便地拉取分支代码。其相当于是下面两条命令的结合（master 也可以换成其它分支名字，此处仅仅是一个例子）：\ngit push -u origin master git push origin master ; git branch --set-upstream master origin/master 假如我们本地新建了一个分支，git push 不带 -u，你 git pull 的时候，git 会提示你不能直接这样用：\n$ git checkout -b test $ git push origin test $ git pull You asked me to pull without telling me which branch you want to merge with, and \u0026#39;branch.test.merge\u0026#39; in your configuration file does not tell me, either. Please specify which branch you want to use on the command line and try again (e.g. \u0026#39;git pull \u0026lt;repository\u0026gt; \u0026lt;refspec\u0026gt;\u0026#39;). See git-pull(1) for details. If you often merge with the same branch, you may want to use something like the following in your configuration file: [branch \u0026#34;test\u0026#34;] remote = \u0026lt;nickname\u0026gt; merge = \u0026lt;remote-ref\u0026gt; [remote \u0026#34;\u0026lt;nickname\u0026gt;\u0026#34;] url = \u0026lt;url\u0026gt; fetch = \u0026lt;refspec\u0026gt; See git-config(1) for details. 假设 git push 的时候，带上了 -u 这个参数：\n$ git push -u origin test Branch test set up to track remote branch test from origin. Everything up-to-date $ git pull Already up-to-date. fetch git fetch 也可以拉取远程分支的文件，它和 git pull 的不同之处在于，它不会自动执行 git merge。\ngit pull = git fetch + git merge\n参考  What is the difference between \u0026lsquo;git pull\u0026rsquo; and \u0026lsquo;git fetch\u0026rsquo;? What exactly does the “u” do? “git push -u origin master” vs “git push origin master”  扫描下面二维码，在手机端阅读：\n"});index.add({'id':101,'href':'/docs/programmer-interview/algorithm/findmedianfromdatastream/','title':"数据流寻找中位数",'content':"数据流寻找中位数 import java.util.Comparator; import java.util.PriorityQueue; // https://leetcode.com/problems/find-median-from-data-stream/ // 剑指 Offer 41 题 // public class FindMedianfromDataStream { // 堆顶是最小的  // 最小堆的堆顶是最大值  //  private PriorityQueue\u0026lt;Integer\u0026gt; minQueue = new PriorityQueue\u0026lt;\u0026gt;(); // 堆顶是最大的  // 最大堆的堆顶是最小的值  private PriorityQueue\u0026lt;Integer\u0026gt; maxQueue = new PriorityQueue\u0026lt;\u0026gt;(new Comparator\u0026lt;Integer\u0026gt;() { @Override public int compare(Integer o1, Integer o2) { return o2.compareTo(o1); } }); private boolean sameSize = true; public FindMedianfromDataStream() { } public void addNum(int num) { if (sameSize) { minQueue.offer(num); maxQueue.offer(minQueue.poll()); } else { maxQueue.offer(num); minQueue.offer(maxQueue.poll()); } sameSize = !sameSize; } public double findMedian() { if (sameSize) { return (minQueue.peek() + maxQueue.peek()) / 2.0; } return maxQueue.peek(); } } "});index.add({'id':102,'href':'/docs/tutorial/git/git-commit/','title':"Git commit",'content':"Git commit git commit 可以将暂存区的文件，commit 提交到本地仓库中。\ngit commit -m -m 代表 message 信息的意思。git commit 需要一个信息作为它的参数，这个信息是对此次 commit 的简短描述，消息应该放到双引号里面。\ngit commit -m \u0026#34;my brief description about commit\u0026#34;  如果没有携带 -m 参数，Git 也会弹出编辑器让你输入消息的。\n git commit -a -a 选项代表 all，即所有。该选项可以将本地工作区所有改动的/被删除的文件，直接 commit 到仓库中，而无需调用 git add/rm 命令手动添加或删除。\ngit commit -am \u0026#34;My message\u0026#34;  -a 并不会将新添加的文件 commit 到版本库中。\n git commit \u0026ndash;amend --amend 选项可以让你修改上一次提交的信息。\n# 第一次提交信息 git commit -m \u0026#34;my first message\u0026#34; # 你对 my first message 这个描述不满意 # 所以使用下面命令来修正成你想要的信息 git commit --amend -m \u0026#34;an updated commit message\u0026#34; 参考  Git Commit Command Explained  扫描下面二维码，在手机端阅读：\n"});index.add({'id':103,'href':'/docs/programmer-interview/algorithm/findminimuminrotatedsortedarray/','title':"旋转有序数组中寻找最小数字",'content':"旋转有序数组中寻找最小数字 // 没有重复元素 // 1 2 3 4 5 6 7 // // 5 6 7 1 2 3 4 // lo hi // public class FindMinimuminRotatedSortedArray { public int findMin(int[] nums) { int lo = 0; // always point to 前半部分  int hi = nums.length - 1; // always point to 后半部分  if (nums[lo] \u0026gt; nums[hi]) { while (lo \u0026lt; hi) { if (hi - lo == 1) { return nums[hi]; } int m = lo + ((hi - lo) \u0026gt;\u0026gt; 1); if (nums[m] \u0026lt; nums[0]) { // middle 位于后半部分  hi = m; } else if (nums[m] \u0026gt; nums[nums.length - 1]) { // middle 位于前半部分  // min 在后半部分  //  // ==================================  // 注意这个地方， lo = m，而不是 lo = m + 1  // m + 1 有可能越界，跑到后半部分  // ==================================  lo = m; } } } return nums[lo]; } } "});index.add({'id':104,'href':'/docs/programmer-interview/algorithm/findpeakelement/','title':"寻找峰值元素",'content':"寻找峰值元素 题目 你给出一个整数数组(size为n)，其具有以下特点：\n 相邻位置的数字是不同的 A[0] \u0026lt; A[1] 并且 A[n - 2] \u0026gt; A[n - 1]  假定P是峰值的位置则满足A[P] \u0026gt; A[P-1]且A[P] \u0026gt; A[P+1]，返回数组中任意一个峰值的位置。\n 数组保证至少存在一个峰 如果数组存在多个峰，返回其中任意一个就行 数组至少包含 3 个数   微软面试题\n 解法 // https://www.lintcode.com/problem/find-peak-element/description // // Microsoft // A[P] \u0026gt; A[P-1] \u0026amp;\u0026amp; A[P] \u0026gt; A[P+1] public class FindPeakElement { // 返回的是索引  //  // 数组太大的话，会超时  public int findPeak(int[] A) { // [x,x,x,x,x]  int lo = 1; int hi = A.length - 2; while (lo \u0026lt;= hi) { int mid = lo + ((hi - lo) \u0026gt;\u0026gt; 1); if (A[mid] \u0026gt; A[mid - 1] \u0026amp;\u0026amp; A[mid] \u0026gt; A[mid + 1]) { return mid; } else if (A[mid] \u0026lt;= A[mid + 1]) { lo = mid + 1; } else if (A[mid] \u0026lt;= A[mid - 1]) { hi = mid - 1; } } return -1; } } "});index.add({'id':105,'href':'/docs/programmer-interview/algorithm/findtheduplicatenumber/','title':"寻找重复数字",'content':"寻找重复数字 // Given an array nums containing n + 1 integers where each integer is between 1 and n (inclusive), // prove that at least one duplicate number must exist. // Assume that there is only one duplicate number, find the duplicate one. // // 1 到 n 的数字，某个数字重复，可能重复次数 \u0026gt; 1 // // Input: [3,1,3,4,2] // Output: 3 // // https://leetcode.com/problems/find-the-duplicate-number/ public class FindtheDuplicateNumber { // ==================================  // 数组不允许修改版本  //  // 剑指 Offer  // ==================================  public int findDuplicate(int[] nums) { int lo = 1; int hi = nums.length - 1; // 数组长 n + 1，但是最大可能值为 n  while (lo \u0026lt;= hi) { // 1 2 3 4 5 6 7 8  // ↑  int m = lo + ((hi - lo) \u0026gt;\u0026gt; 1); // 统计 nums 里面位于 1 和 4 中间的数字有多少个  int count = countRange(nums, lo /** 1 */, m/** 4 */); int expectedCount = m - lo + 1; if (expectedCount == 1 /**期望 1 个 */ \u0026amp;\u0026amp; count \u0026gt; 1) { return m; // m == lo, 返回哪个都可以  } if (count \u0026gt; expectedCount) { hi = m; } else { lo = m + 1; } } return -1; } private int countRange(int[] nums, int lo, int hi) { int count = 0; for (int i = 0; i \u0026lt; nums.length; i++) { if (nums[i] \u0026gt;= lo \u0026amp;\u0026amp; nums[i] \u0026lt;= hi) { count++; } } return count; } // ==================================  // 数组允许修改版本  // ==================================  public int findDuplicate0(int[] nums) { for (int i = 0; i \u0026lt; nums.length; i++) { int expectedNum = i + 1; while (nums[i] != expectedNum) { if (nums[i] == nums[nums[i] - 1]) { return nums[i]; } swap(nums, i, nums[i] - 1); } } return -1; } private void swap(int[] nums, int i, int j) { int t = nums[i]; nums[i] = nums[j]; nums[j] = t; } } "});index.add({'id':106,'href':'/docs/programmer-interview/algorithm/firstmissingpositive/','title':"第一个缺失的最小正数",'content':"第一个缺失的最小正数 import java.util.ArrayList; import java.util.Collections; import java.util.HashSet; import java.util.List; import java.util.Set; // https://leetcode.com/problems/first-missing-positive/ // Given an unsorted integer array, find the smallest missing positive integer. // // Input: [3,4,-1,1] // Output: 2 // // Input: [7,8,9,11,12] // Output: 1 // public class FirstMissingPositive { // ===============================  // 不使用辅助空间  //  // 最核心的是，遇见哪些数字可以不用管:  // - 负数  // - 大于 nums.length 的数  // ===============================  public int firstMissingPositive(int[] nums) { int i = 0; while (i \u0026lt; nums.length) { int expected = i + 1; if (nums[i] == expected || nums[i] \u0026lt;= 0 || nums[i] \u0026gt; nums.length) { i++; continue; } // 将 nums[i] 放到正确的位置  //  // 1 5 3 4 4  // ↑ (5 应该放到 5 - 1 的位置)  int rightPos = nums[i] - 1; if (nums[rightPos] != nums[i]) { // i 指针没有移动  swap(nums, i, rightPos); continue; } // 如果正确的位置上已经有一个了  // 那么我们试探下一个就行了  i++; } i = 0; while (i \u0026lt; nums.length \u0026amp;\u0026amp; nums[i] == i + 1) { i++; } return i + 1; } private void swap(int[] nums, int i, int j) { int t = nums[i]; nums[i] = nums[j]; nums[j] = t; } // ===============================  // 使用了辅助空间 O(n)  // ===============================  public int firstMissingPositive0(int[] nums) { Set\u0026lt;Integer\u0026gt; set = new HashSet\u0026lt;\u0026gt;(); List\u0026lt;Integer\u0026gt; list = new ArrayList\u0026lt;\u0026gt;(); for (int num: nums) { if (num \u0026gt; 0) { if (set.add(num)) { list.add(num); } } } Collections.sort(list); if (list.isEmpty() || list.get(0).intValue() != 1) { return 1; } for (int i = 0; i \u0026lt; list.size(); i++) { int expected = i + 1; if (list.get(i).intValue() != expected) { return list.get(i - 1).intValue() + 1; } } return list.get(list.size() - 1) + 1; } } "});index.add({'id':107,'href':'/docs/programmer-interview/algorithm/firstuniquenumberindatastream/','title':"数据流的第一个唯一数字",'content':"数据流的第一个唯一数字 import java.util.HashMap; import java.util.LinkedHashMap; import java.util.Map; // https://www.lintcode.com/problem/first-unique-number-in-data-stream/description // // 给一个连续的数据流,写一个函数返回终止数字到达时的第一个唯一数字（包括终止数字）, // 如果在终止数字前无唯一数字或者找不到这个终止数字, 返回 -1. public class FirstUniqueNumberinDataStream { public int firstUniqueNumber(int[] nums, int number) { boolean hasStopNumber = false; HashMap\u0026lt;Integer, Integer\u0026gt; map = new LinkedHashMap\u0026lt;\u0026gt;(); for (int i = 0; i \u0026lt; nums.length; i++) { int count= map.getOrDefault(nums[i], 0); map.put(nums[i], count + 1); if (nums[i] == number) { hasStopNumber = true; break; } } if (!hasStopNumber) { return -1; } for (Map.Entry\u0026lt;Integer, Integer\u0026gt; entry: map.entrySet()) { if (entry.getValue() == 1) { return entry.getKey().intValue(); } } return -1; } } "});index.add({'id':108,'href':'/docs/programmer-interview/algorithm/insertinterval/','title':"插入区间",'content':"插入区间 import java.util.ArrayList; import java.util.Collections; import java.util.Comparator; import java.util.List; import com.zk.algorithm.beans.Interval; // Input: intervals = [[1,2],[3,5],[6,7],[8,10],[12,16]], newInterval = [4,8] // Output: [[1,2],[3,10],[12,16]] // Explanation: Because the new interval [4,8] overlaps with [3,5],[6,7],[8,10]. public class InsertInterval { // 插入一个新的 interval  // 如果有交集，那么合并  public List\u0026lt;Interval\u0026gt; insert(List\u0026lt;Interval\u0026gt; intervals, Interval newInterval) { intervals.add(newInterval); Collections.sort(intervals, new Comparator\u0026lt;Interval\u0026gt;() { public int compare(Interval a, Interval b) { if (a.start \u0026lt; b.start) { return -1; } else if (a.start \u0026gt; b.start) { return 1; } return 0; } }); List\u0026lt;Interval\u0026gt; res = new ArrayList\u0026lt;\u0026gt;(); Interval prev = null; for (Interval item: intervals) { if (prev == null || item.start \u0026gt; prev.end) { res.add(item); prev = item; } else if (item.start \u0026lt;= prev.end) { // 这种情况是 OK 的  //  // |______________|  // |_______________|  //  // 但是如果是下面这种情况呢  //  // |______________|  // |___|  prev.end = Math.max(item.end, prev.end); } } return res; } } "});index.add({'id':109,'href':'/docs/programmer-interview/algorithm/intersectionoftwoarrays/','title':"数组交集",'content':"数组交集 方法一 // // Input: nums1 = [4,9,5], nums2 = [9,4,9,8,4] // Output: [9,4] // public class IntersectionofTwoArrays { public int[] intersection(int[] nums1, int[] nums2) { Set\u0026lt;Integer\u0026gt; set1 = toSet(nums1); Set\u0026lt;Integer\u0026gt; set2 = toSet(nums2); return findIntersection(set1, set2); } private int[] findIntersection(Set\u0026lt;Integer\u0026gt; set1, Set\u0026lt;Integer\u0026gt; set2) { List\u0026lt;Integer\u0026gt; list = new ArrayList\u0026lt;\u0026gt;(); for (int num: set2) { if (set1.contains(num)) { list.add(num); } } int[] res = new int[list.size()]; for (int i = 0; i \u0026lt; list.size(); i++) { res[i] = list.get(i); } return res; } private Set\u0026lt;Integer\u0026gt; toSet(int[] nums) { Set\u0026lt;Integer\u0026gt; set = new HashSet\u0026lt;\u0026gt;(); for (int num: nums) { set.add(num); } return set; } } 方法二 public class IntersectionofTwoArrays_Solution_1 { public int[] intersection(int[] nums1, int[] nums2) { Arrays.sort(nums1); Arrays.sort(nums2); List\u0026lt;Integer\u0026gt; list = new ArrayList\u0026lt;Integer\u0026gt;(); int i1 = 0, i2 = 0; while (i1 \u0026lt; nums1.length \u0026amp;\u0026amp; i2 \u0026lt; nums2.length) { if (nums1[i1] == nums2[i2]) { int num = nums1[i1]; list.add(num); while (i1 \u0026lt; nums1.length \u0026amp;\u0026amp; nums1[i1] == num) { i1++; } while (i2 \u0026lt; nums2.length \u0026amp;\u0026amp; nums2[i2] == num) { i2++; } } else if (nums1[i1] \u0026lt; nums2[i2]) { i1++; } else { i2++; } } return toIntArray(list); } private int[] toIntArray(List\u0026lt;Integer\u0026gt; list) { int[] arr = new int[list.size()]; for (int i = 0; i \u0026lt; list.size(); i++) { arr[i] = list.get(i); } return arr; } } "});index.add({'id':110,'href':'/docs/programmer-interview/algorithm/ksmallestnuminanarray/','title':"最小的K个数",'content':"最小的K个数 import java.util.ArrayList; // 牛客网 // https://www.nowcoder.com/practice/6a296eb82cf844ca8539b57c23e6e9bf // 最小的 k 个数 // public class KSmallestNumInAnArray { public ArrayList\u0026lt;Integer\u0026gt; GetLeastNumbers_Solution(int[] input, int k) { int lo = 0; int hi = input.length - 1; while (lo \u0026lt;= hi) { int kth = partition(input, lo, hi); if (kth == k - 1) { ArrayList\u0026lt;Integer\u0026gt; res = new ArrayList\u0026lt;\u0026gt;(); for (int i = 0; i \u0026lt; k; i++) { res.add(input[i]); } return res; } else if (kth \u0026lt; k - 1) { lo = kth + 1; } else { hi = kth - 1; } } return new ArrayList\u0026lt;Integer\u0026gt;(); } private int partition(int[] nums, int lo, int hi) { int left = lo - 1; int pivot = nums[hi]; for (int i = lo; i \u0026lt;= hi - 1; i++) { if (nums[i] \u0026lt;= pivot) { swap(nums, ++left, i); } } swap(nums, left + 1, hi); return left + 1; } private void swap(int[] nums, int i, int j) { int tmp = nums[i]; nums[i] = nums[j]; nums[j] = tmp; } } "});index.add({'id':111,'href':'/docs/programmer-interview/algorithm/kdiffpairsinanarray/','title':"绝对值差为K的数对数量",'content':"绝对值差为K的数对数量 描述 给定一个整数数组和一个整数k，您需要找到数组中唯一k-diff对的数量。这里k-diff对被定义为整数对(i, j)，其中i和j都是数组中的数字，它们的绝对差是k。\n 对(i,j)和(j,i)计为同一对。 数组的长度不超过10,000。 给定输入中的所有整数都属于以下范围：[ -1e7, 1e7]。  答案 import java.util.Arrays; // https://www.lintcode.com/problem/k-diff-pairs-in-an-array/description // Amazon // // 这个 pair 差的绝对值 == k public class KdiffPairsinanArray { // O(n^2)  public int findPairs(int[] nums, int k) { Arrays.sort(nums); int count = 0; for (int i = 0; i \u0026lt; nums.length - 1; i++) { if (i \u0026gt; 0 \u0026amp;\u0026amp; nums[i] == nums[i - 1]) { continue; } for (int j = i + 1; j \u0026lt; nums.length; j++) { if (j \u0026gt; i + 1 \u0026amp;\u0026amp; nums[j] == nums[j - 1]) { continue; } int diff = Math.abs(nums[j] - nums[i]); if (diff \u0026gt; k) { break; } else if (diff == k) { count++; } } } return count; } } "});index.add({'id':112,'href':'/docs/programmer-interview/algorithm/kthlargestelement/','title':"第 K 个最大的数字",'content':"第 K 个最大的数字 数组中的第 K 个最大数字 // 数组无序 public class KthLargestElementinanArray { public int findKthLargest(int[] nums, int k) { k = nums.length - k; // 1 2 3 4 5 6  // ↑(第 2 大)  // ↑(partition = 2 的时候，实际上指向的是这里)  int lo = 0; int hi = nums.length - 1; // ==========================  // while (lo \u0026lt; hi)  // nums = [1]，这种情况进入不了循环  //  // ==========================  while (lo \u0026lt;= hi) { int index = partition(nums, lo, hi); if (index == k) { return nums[index]; } else if (index \u0026lt; k) { lo = index + 1; } else { hi = index - 1; } } return -1; } private int partition(int[] nums, int lo, int high) { int i = lo - 1; int pivot = nums[high]; for (int j = lo; j \u0026lt;= high - 1; j++) { if (nums[j] \u0026lt;= pivot) { i++; swap(nums, i, j); } } swap(nums, i + 1, high); return i + 1; } private void swap(int[] array, int i, int j) { int temp = array[i]; array[i] = array[j]; array[j] = temp; } } 数据流中的第 K 个最大数字  堆  import java.util.Comparator; import java.util.PriorityQueue; // 1 2 3 4 5 6 7 8 9 10 // ↑ // 第 3 大 (维护 size() = k 的小项堆，大于 k 个就移除最小的) public class KthLargestElementinaStream { private PriorityQueue\u0026lt;Integer\u0026gt; queue = new PriorityQueue\u0026lt;Integer\u0026gt;(new Comparator\u0026lt;Integer\u0026gt;() { @Override public int compare(Integer o1, Integer o2) { return o1.compareTo(o2); } }); private int k; public KthLargestElementinaStream(int k, int[] nums) { this.k = k; for (int i = 0; i \u0026lt; nums.length; i++) { queue.offer(nums[i]); if (queue.size() \u0026gt; k) { queue.poll(); } } } public int add(int val) { queue.offer(val); if (queue.size() \u0026gt; this.k) { queue.poll(); } return queue.peek(); } } "});index.add({'id':113,'href':'/docs/programmer-interview/algorithm/kthsmallestelement/','title':"第 K 个最小的数字",'content':"第 K 个最小的数字 9 * 9 乘法表中的第 K 个最小数字 // http://exercise.acmcoder.com/online/online_judge_ques?ques_id=3819\u0026amp;konwledgeId=40 // https://leetcode.com/problems/kth-smallest-number-in-multiplication-table/ // // 百度乘法表 // 9 * 9 乘法表 // public class KthSmallestNumberinMultiplicationTable { public int findKthNumber(int m, int n, int k) { int lo = 1; int hi = m * n; while (lo \u0026lt;= hi) { int middle = lo + ((hi - lo) \u0026gt;\u0026gt; 1); int count = countLessOrEqualK(m, n, middle); if (count \u0026lt; k) { lo = middle + 1; } else { hi = middle - 1; } } return lo; } private int countLessOrEqualK(int m, int n, int k) { int c = 0; for (int i = 1; i \u0026lt;= m; i++) { // 1 2 3 4  // 2 4 6 8  // 3 6 9 12  //  // k = 5  // - k \u0026gt;= 第 1 行的 (1 2 3 4) 最后的 4，所以 c += n 个  // - k \u0026lt; 第 2 行的 (2 4 6 8) 最后的 8，所以 c += k / i 个  //  if (k \u0026gt;= n * i) { c += n; } else { c += k / i; } } return c; } } 行或列均有序的矩阵中的第 K 个最小数字 // matrix = [ // [ 1, 5, 9], // [10, 11, 13], // [12, 13, 15] // ], // k = 8,  // return 13. // // 每行、每列都是有序的 public class KthSmallestElementinaSortedMatrix { public int kthSmallest(int[][] matrix, int k) { int lo = matrix[0][0]; int hi = matrix[matrix.length - 1][matrix[0].length - 1]; while (lo \u0026lt;= hi) { int middle = lo + ((hi - lo) \u0026gt;\u0026gt; 1); //  // 小于或者等于 middle 的是 count 个  int count = countLessOrEqual(matrix, middle); if (count \u0026lt; k) { lo = middle + 1; } else if (count \u0026gt; k) { hi = middle - 1; } else if (count == k) { // 1 2 3 4 5 6 7 7 12  // ↑ (mid 是 12， 小于 mid 的是 12 个，尝试降低 mid 的值，然后再去寻找)  // (我们必须保证 mid 是在这个 matrix 里面)  //  // ↑ (我们最终要找的是 7，是位于 mid 左边的数字)  //  // 1 2 3 4 5 6 7 7 7 7 7 7 12  // ↑ ↑  // lo hi  //  // 当 lo 和 hi 相同的时候, 挺难理解的，不好证明，难道是夹逼定理 ?  // lo \u0026lt;= kth \u0026lt; mid \u0026lt;= hi ?  hi = middle - 1; } } return lo; // or hi 因为现在 lo == hi;  } private int countLessOrEqual(int[][] matrix, int target) { // 最后一行的第一个数  int row = matrix.length - 1; int col = 0; int count = 0; while (row \u0026gt;= 0 \u0026amp;\u0026amp; col \u0026lt; matrix[0].length) { if (matrix[row][col] \u0026gt; target) { row--; } else { count += (row + 1); col++; } } return count; } // ========================================  // 下面这种解法不能处理  //  // [1, 2]  // [1, 3]  //  // 寻找第 3 大的数字这种情况  // ========================================  public int kthSmallest0(int[][] matrix, int k) { int lo = matrix[0][0]; int hi = matrix[matrix.length - 1][matrix[0].length - 1]; while (lo \u0026lt;= hi) { int middle = lo + ((hi - lo) \u0026gt;\u0026gt; 1); //  // 小于或者等于 middle 的是 count 个  int count = countLessOrEqual(matrix, middle); if (count \u0026lt; k) { lo = middle + 1; } else if (count \u0026gt; k) { hi = middle - 1; } else if (count == k) { return lessOrEqualThanBinarySearch(matrix, middle); } } return lo; } private int lessOrEqualThanBinarySearch(int[][] matrix, int target) { int lo = 0; int hi = matrix.length - 1; int row = 0; while (lo \u0026lt;= hi) { int m = lo + ((hi - lo) \u0026gt;\u0026gt; 1); if (matrix[m][0] == target) { return target; } else if (matrix[m][0] \u0026gt; target) { hi = m - 1; } else { if (m == matrix.length - 1 || matrix[m + 1][0] \u0026gt; target) { row = m; break; } lo = m + 1; } } lo = 0; hi = matrix[row].length - 1; int col = 0; while (lo \u0026lt;= hi) { int m = lo + ((hi - lo) \u0026gt;\u0026gt; 1); if (matrix[row][m] == target) { return target; } else if (matrix[row][m] \u0026gt; target) { hi = m - 1; } else { if (m == matrix[row].length - 1 || matrix[row][m + 1] \u0026gt; target) { col = m; break; } lo = m + 1; } } return matrix[row][col]; } private int countLessOrEqual0(int[][] matrix, int target) { // 最后一行的第一个数  int row = matrix.length - 1; int col = 0; int count = 0; while (row \u0026gt;= 0 \u0026amp;\u0026amp; col \u0026lt; matrix[0].length) { if (matrix[row][col] \u0026gt; target) { row--; } else { count += (row + 1); col++; } } return count; } } "});index.add({'id':114,'href':'/docs/programmer-interview/algorithm/largestnumber/','title':"数组元素所能拼成的最大数字",'content':"数组元素所能拼成的最大数字 import java.util.ArrayList; import java.util.Collections; import java.util.Comparator; import java.util.List; public class LargestNumber { public String largestNumber(int[] nums) { List\u0026lt;String\u0026gt; numList = toList(nums); Collections.sort(numList, new Comparator\u0026lt;String\u0026gt;() { @Override public int compare(String a, String b) { return (b + a).compareTo(a + b); } }); final StringBuilder sb = new StringBuilder(); for (String str: numList) { sb.append(str); } String res = sb.toString(); if (allZero(res)) { return \u0026#34;0\u0026#34;; } return res; } private boolean allZero(String str) { for (char c: str.toCharArray()) { if (c != \u0026#39;0\u0026#39;) { return false; } } return true; } private List\u0026lt;String\u0026gt; toList(int[] nums) { List\u0026lt;String\u0026gt; list = new ArrayList\u0026lt;\u0026gt;(); for (int num: nums) { list.add(String.valueOf(num)); } return list; } } "});index.add({'id':115,'href':'/docs/programmer-interview/algorithm/largestrectangleinhistogram/','title':"柱状图中最大的矩形",'content':"柱状图中最大的矩形 描述 题目来源\n给定 n 个非负整数，用来表示柱状图中各个柱子的高度。每个柱子彼此相邻，且宽度为 1 。求在该柱状图中，能够勾勒出来的矩形的最大面积。\n题解 // https://leetcode.com/problems/largest-rectangle-in-histogram/ 直方图 // __ // __| | // | | | // | | | __ // __ | | |__| | // | |__| | | | | // |__|__|__|__|__|__| // public class LargestRectangleinHistogram { public int largestRectangleArea(int[] heights) { // =================================  // 左边最多延展到哪个索引  // =================================  // 左边比自己大的或相等的  //  // 单调栈找到第一个比自己大的或者小的数字  int[] left = new int[heights.length]; for (int i = 0; i \u0026lt; heights.length; i++) { int j = i; while (j - 1 \u0026gt;= 0 \u0026amp;\u0026amp; heights[j - 1] \u0026gt;= heights[i]) { j--; } left[i] = j; } // =================================  // 右边最多延展到哪个索引  // =================================  int[] right = new int[heights.length]; for (int i = heights.length - 1; i \u0026gt;= 0; i--) { int j = i; while (j + 1 \u0026lt; heights.length \u0026amp;\u0026amp; heights[i] \u0026lt;= heights[j + 1]) { j++; } right[i] = j; } int largest = 0; for (int i = 0; i \u0026lt; heights.length; i++) { largest = Math.max(heights[i] * (right[i] - left[i] + 1), largest); } return largest; } // 2, 1, 5, 6, 2, 3  public int largestRectangleArea0(int[] heights) { // =================================  // 左边最多延展到哪个索引  // =================================  // 左边比自己大的或相等的  //  // 单调栈找到第一个比自己大的或者小的数字  Stack\u0026lt;Integer\u0026gt; stack = new Stack\u0026lt;\u0026gt;(); // __ // __| | // | | | // | | | __ // __ | | |__| | // | |__| | | | | // |__|__|__|__|__|__| // 0 1 2 3 4 5 // ↑ // 假设当前指向的是这个 // 只要栈里面的比自身高，那么就一直 pop // 所以 2、3 都被 pop 出去了  int[] left = new int[heights.length]; for (int i = 0; i \u0026lt; heights.length; i++) { int j = i; while (!stack.isEmpty() \u0026amp;\u0026amp; heights[i] \u0026lt;= heights[stack.peek()]) { j = stack.pop(); } // 栈空了，说明左边的都大于等于自己  // 栈不空，说明栈里面的 peek() 是小于自己的，那么 peek() + 1 是大于等于自己的  left[i] = stack.isEmpty() ? 0 : stack.peek() + 1; stack.push(i); } // =================================  // 右边最多延展到哪个索引  // =================================  stack.clear(); // 2,1,5,6,2,3  // ↑  // 5, 5  // 5, 4  int[] right = new int[heights.length]; for (int i = heights.length - 1; i \u0026gt;= 0; i--) { int j = i; while (!stack.isEmpty() \u0026amp;\u0026amp; heights[i] \u0026lt;= heights[stack.peek()]) { j = stack.pop(); } // 栈空了，说明右边的都大于等于自己  // 栈不空，说明栈里面的 peek() 是小于自己的，那么 peek() - 1 是大于等于自己的  right[i] = stack.isEmpty() ? heights.length - 1 : stack.peek() - 1; stack.push(i); } int largest = 0; for (int i = 0; i \u0026lt; heights.length; i++) { largest = Math.max(heights[i] * (right[i] - left[i] + 1), largest); } return largest; } } "});index.add({'id':116,'href':'/docs/programmer-interview/algorithm/longestsequence/','title':"最长序列",'content':"最长序列 最长连续递增相差为 1 的序列 import java.util.Arrays; // [100, 4, 200, 1, 3, 2] // // 必须是连续的 1 2 3 4 差值为 1 public class LongestConsecutiveSequence { public int longestConsecutive(int[] nums) { if (nums.length == 0) { return 0; } Arrays.sort(nums); int longestStreak = 1; int currentStreak = 1; for (int i = 1; i \u0026lt; nums.length; i++) { if (nums[i] != nums[i - 1]) { if (nums[i] == nums[i - 1] + 1) { currentStreak += 1; } else { longestStreak = Math.max(longestStreak, currentStreak); currentStreak = 1; } } } return Math.max(longestStreak, currentStreak); } } 连续递增子序列 // Input: [1,3,5,4,7] // Output: 3 // // 连续递增子数组, [1,3,5] public class LongestContinuousIncreasingSubsequence { public int findLengthOfLCIS(int[] nums) { if (nums.length == 0) { return 0; } int[] maxLength = new int[nums.length]; maxLength[0] = 1; for (int i = 1; i \u0026lt; nums.length; i++) { maxLength[i] = nums[i] \u0026gt; nums[i - 1] ? maxLength[i - 1] + 1 : 1; } return findMax(maxLength); } private int findMax(int[] arr) { int max = arr[0]; for (int i = 1; i \u0026lt; arr.length; i++) { if (arr[i] \u0026gt; max) { max = arr[i]; } } return max; } } "});index.add({'id':117,'href':'/docs/programmer-interview/algorithm/majorityelement/','title':"找出过半数的元素",'content':"找出过半数的元素 // Given an array of size n, find the majority element. // The majority element is the element that appears more than ⌊ n/2 ⌋ times. // You may assume that the array is non-empty and the majority element always exist in the array. // public class MajorityElement { public int majorityElement(int[] nums) { int candidate = nums[0]; int count = 1; for (int i = 1; i \u0026lt; nums.length; i++) { // ================  // no candidate  // ================  if (count == 0) { candidate = nums[i]; count = 1; } else if (nums[i] == candidate) { count++; } else { count--; } } return candidate; } } "});index.add({'id':118,'href':'/docs/programmer-interview/algorithm/maxareaofisland/','title':"最大的岛屿",'content':"最大的岛屿 // 时间复杂度 O(row * col)，因为每个小方格访问一次 // public class MaxAreaofIsland { public int maxAreaOfIsland(int[][] grid) { int row = grid.length; int col = grid[0].length; boolean[][] visited = new boolean[row][col]; int max = 0; for (int r = 0; r \u0026lt; row; r++) { for (int c = 0; c \u0026lt; col; c++) { max = Math.max(maxArea(grid, visited, r, c), max); } } return max; } private int maxArea(int[][] grid, boolean[][] visited, int r, int c) { if (r \u0026lt; 0 || r \u0026gt;= grid.length || c \u0026lt; 0 || c \u0026gt;= grid[0].length || grid[r][c] == 0 || visited[r][c]) { return 0; } visited[r][c] = true; return 1 + maxArea(grid, visited, r - 1, c) + maxArea(grid, visited, r + 1, c) + maxArea(grid, visited, r, c - 1) + maxArea(grid, visited, r, c + 1) ; } } "});index.add({'id':119,'href':'/docs/programmer-interview/algorithm/maxpointsonaline/','title':"直线上最多的点数",'content':"直线上最多的点数 描述 题目 给定一个二维平面，平面上有 n 个点，求最多有多少个点在同一条直线上。\n输入: [[1,1],[3,2],[5,3],[4,1],[2,3],[1,4]]\n输出: 4\n解释:\n^\r|\r| o\r| o o\r| o\r| o o\r+-------------------\u0026gt;\r0 1 2 3 4 5 6\r题解 public class MaxPointsonaLine { public int maxPoints(Point[] points) { if (points.length \u0026lt;= 1) { return points.length; } int max = 0; for (int i = 0; i \u0026lt; points.length - 1; i++) { for (int j = i + 1; j \u0026lt; points.length; j++) { max = Math.max(maxPoint(points[i], points[j], points), max); } } return max; } private int maxPoint(Point p1, Point p2, Point[] points) { int max = 0; for (Point p: points) { if (_eq(p1, p) || _eq(p2, p) || isSameLine(p1, p2, p)) { max++; } } return max; } private boolean _eq(Point p1, Point p2) { return p1.x == p2.x \u0026amp;\u0026amp; p1.y == p2.y; } private boolean isSameLine(Point p1, Point p2, Point p) { // y2 - y1 y - y1  // ------- = ------  // x2 - x1 x - x1  //  if (p1.x == p2.x) { return p.x == p1.x; } if (p1.y == p2.y) { return p.y == p1.y; } if (p.x == p1.x || p.x == p2.x || p.y == p1.y || p.y == p2.y) { return false; } return (p2.y - p1.y) * (p.x - p1.x) == (p2.x - p1.x) * (p.y - p1.y); } } "});index.add({'id':120,'href':'/docs/programmer-interview/algorithm/maximalrectangle/','title':"最大的矩形",'content':"最大的矩形 描述 题目 给定一个仅包含 0 和 1 的二维二进制矩阵，找出只包含 1 的最大矩形，并返回其面积。\n输入:\r[\r[\u0026quot;1\u0026quot;,\u0026quot;0\u0026quot;,\u0026quot;1\u0026quot;,\u0026quot;0\u0026quot;,\u0026quot;0\u0026quot;],\r[\u0026quot;1\u0026quot;,\u0026quot;0\u0026quot;,\u0026quot;1\u0026quot;,\u0026quot;1\u0026quot;,\u0026quot;1\u0026quot;],\r[\u0026quot;1\u0026quot;,\u0026quot;1\u0026quot;,\u0026quot;1\u0026quot;,\u0026quot;1\u0026quot;,\u0026quot;1\u0026quot;],\r[\u0026quot;1\u0026quot;,\u0026quot;0\u0026quot;,\u0026quot;0\u0026quot;,\u0026quot;1\u0026quot;,\u0026quot;0\u0026quot;]\r]\r输出: 6\r答案 // Given a matrix: // [ // [1, 1, 0, 0, 1], // [0, 1, 0, 0, 1], // [0, 0, 1, 1, 1], // [0, 0, 1, 1, 1], // [0, 0, 0, 0, 1] // ] // return 6. public class MaximalRectangle { public int maximalRectangle(boolean[][] matrix) { if (matrix == null || matrix.length == 0) { return 0; } int[][] height = new int[matrix.length][matrix[0].length]; height[0][0] = matrix[0][0] ? 1 : 0; for (int i = 1; i \u0026lt; matrix[0].length; i++) { height[0][i] = matrix[0][i] ? 1 : 0; } for (int i = 1; i \u0026lt; matrix.length; i++) { height[i][0] = matrix[i][0] ? height[i - 1][0] + 1 : 0; } int max = largestRectangleArea(height[0]); for (int i = 1; i \u0026lt; matrix.length; i++) { for (int j = 1; j \u0026lt; matrix[0].length; j++) { height[i][j] = matrix[i][j] ? height[i - 1][j] + 1 : 0; } max = Math.max(largestRectangleArea(height[i]), max); } return max; } public int largestRectangleArea(int[] heights) { // =================================  // 左边最多延展到哪个索引  // =================================  int[] left = new int[heights.length]; for (int i = 0; i \u0026lt; heights.length; i++) { int j = i; while (j - 1 \u0026gt;= 0 \u0026amp;\u0026amp; heights[j - 1] \u0026gt;= heights[i]) { j--; } left[i] = j; } // =================================  // 右边最多延展到哪个索引  // =================================  int[] right = new int[heights.length]; for (int i = heights.length - 1; i \u0026gt;= 0; i--) { int j = i; while (j + 1 \u0026lt; heights.length \u0026amp;\u0026amp; heights[i] \u0026lt;= heights[j + 1]) { j++; } right[i] = j; } int largest = 0; for (int i = 0; i \u0026lt; heights.length; i++) { largest = Math.max(heights[i] * (right[i] - left[i] + 1), largest); } return largest; } } "});index.add({'id':121,'href':'/docs/programmer-interview/algorithm/maximumaveragesubarray/','title':"子数组的最大平均值",'content':"子数组的最大平均值 描述 原题 给定一个由 n 个整数组成的数组，找到给定长度 k 的连续子数组，该子数组具有最大平均值。你需要输出最大平均值。\n答案  前缀和  // https://www.lintcode.com/problem/maximum-average-subarray/description // 给定一个由 n 个整数组成的数组，找到给定长度 k 的连续子数组，该子数组具有最大平均值。你需要输出最大平均值。 // 注意这个长度 k 是固定的 // public class MaximumAverageSubarray { public double findMaxAverage(int[] nums, int k) { int[] prefixSum = prefixSum(nums); int maxSum = 0; for (int i = k; i \u0026lt; prefixSum.length; i++) { maxSum = Math.max(maxSum, prefixSum[i] - prefixSum[i - k]); } return maxSum * 1.0 / k; } private int[] prefixSum(int[] nums) { int[] prefixSum = new int[nums.length + 1]; for (int i = 1; i \u0026lt;= nums.length; i++) { prefixSum[i] = prefixSum[i - 1] + nums[i - 1]; } return prefixSum; } } "});index.add({'id':122,'href':'/docs/programmer-interview/algorithm/maximumproductsubarray/','title':"连续子数组最大乘积",'content':"连续子数组最大乘积 // 连续子数组最大乘积 public class MaximumProductSubarray { public int maxProduct(int[] nums) { int min = nums[0]; int max = nums[0]; int ans = nums[0]; for (int i = 1; i \u0026lt; nums.length; i++) { // ==============================  // max 值基于更新后的 min 值进行了计算  // ==============================  int A = nums[i] * min; int B = nums[i] * max; min = min(A, B, nums[i]); max = max(A, B, nums[i]); if (max \u0026gt; ans) { ans = max; } } return ans; } private int min(int...arr) { int m = arr[0]; for (int i = 1; i \u0026lt; arr.length; i++) { if (arr[i] \u0026lt; m) { m = arr[i]; } } return m; } private int max(int...arr) { int m = arr[0]; for (int i = 1; i \u0026lt; arr.length; i++) { if (arr[i] \u0026gt; m) { m = arr[i]; } } return m; } } "});index.add({'id':123,'href':'/docs/programmer-interview/algorithm/maximumsizesubarraysumequalsk/','title':"最大子数组之和为 K",'content':"最大子数组之和为 K 描述 给一个数组nums和目标值k，找到数组中最长的子数组，使其中的元素和为k。如果没有，则返回0。\n 数组之和保证在32位有符号整型数的范围内\n 题解  前缀和 + Map  import java.util.HashMap; import java.util.Map; // https://www.lintcode.com/problem/maximum-size-subarray-sum-equals-k/description // Facebook // // 微软面试题 // longest consecutive sequence of numbers that sum to K // https://www.1point3acres.com/bbs/thread-541121-1-1.html // // 给一个数组nums和目标值k，找到数组中最长的子数组，使其中的元素和为k。如果没有，则返回0。 // // ↓ ↓ (k = 17) // 2 [ 3 5 6 3 ] 8 public class MaximumSizeSubarraySumEqualsk { public int maxSubArrayLen(int[] nums, int k) { int[] prefixSum = prefixSum(nums); // 感觉就是跟 two sum 似的  // 借助 map 直接让复杂度降低了  Map\u0026lt;Integer, Integer\u0026gt; map = new HashMap\u0026lt;\u0026gt;(); // 左边的边界  map.put(0, 0); int ans = 0; for (int i = 1; i \u0026lt; prefixSum.length; i++) { int target = prefixSum[i] - k; if (map.containsKey(target)) { ans = Math.max(ans, i - map.get(target)); } if (!map.containsKey(prefixSum[i])) { map.put(prefixSum[i], i); } } return ans; } private int[] prefixSum(int[] nums) { int[] prefixs = new int[nums.length + 1]; for (int i = 0; i \u0026lt; nums.length; i++) { prefixs[i + 1] = prefixs[i] + nums[i]; } return prefixs; } } "});index.add({'id':124,'href':'/docs/programmer-interview/algorithm/maximumsubmatrix/','title':"最大子矩阵",'content':"最大子矩阵 描述 原题 给出一个大小为 n x n 的矩阵，里面元素为 正整数 和 负整数 ，找到具有最大和的子矩阵。\n输入:\rmatrix = [\r[1,3,-1],\r[2,3,-2],\r[-1,-2,-3]\r]\r输出: 9\r解释:\r具有最大和的子矩阵是:\r[\r[1,3],\r[2,3]\r]\r题解  二维数组的前缀和  // https://www.lintcode.com/problem/maximum-submatrix/description // // Given an n x n matrix of positive and negative integers, // find the submatrix with the largest possible sum. // public class MaximumSubmatrix { public int maxSubmatrix(int[][] matrix) { if (matrix == null || matrix.length == 0 || matrix[0].length == 0) { return 0; } int[][] prefixSum = prefixSum(matrix); int max = Integer.MIN_VALUE; for (int i = 1; i \u0026lt;= matrix.length; i++) { for (int j = i; j \u0026lt;= matrix.length; j++) { int currMax = sumColumn(i, j, 1, prefixSum); max = Math.max(currMax, max); for (int col = 1; col \u0026lt; matrix[0].length; col++) { if (currMax \u0026lt; 0) { currMax = sumColumn(i, j, col + 1, prefixSum); } else { currMax = currMax + sumColumn(i, j, col + 1, prefixSum); } max = Math.max(currMax, max); } } } return max; } private int sumColumn(int i, int j, int col, int[][] prefixSum) { return prefixSum[j][col] - prefixSum[i - 1][col] - (prefixSum[j][col - 1] - prefixSum[i - 1][col - 1]); } private int[][] prefixSum(int[][] matrix) { int[][] prefixSum = new int[matrix.length + 1][matrix[0].length + 1]; for (int i = 1; i \u0026lt;= matrix.length; i++) { for (int j = 1; j \u0026lt;= matrix[0].length; j++) { prefixSum[i][j] = prefixSum[i - 1][j] + prefixSum[i][j - 1] + matrix[i - 1][j - 1] - prefixSum[i - 1][j - 1]; } } return prefixSum; } } "});index.add({'id':125,'href':'/docs/programmer-interview/algorithm/maximumswap/','title':"最大的交换",'content':"最大的交换 描述 原题 给定一个非负整数, 你可以选择交换它的两个数位. 返回你能获得的最大的合法的数.\n 给定的数字在 [0, 10^8] 范围内\n 输入: 2736\r输出: 7236\r解释: 交换数字2和数字7.\r题解 // https://www.lintcode.com/problem/maximum-swap/description // // 给定一个非负整数, 你可以选择交换它的两个数位. 返回你能获得的最大的合法的数. // // 输入: 2736 // 输出: 7236 // 解释: 交换数字2和数字7. // // 给定的数字在 [0, 10^8] 范围内 public class MaximumSwap { public static void main(String...args) { MaximumSwap maximumSwap = new MaximumSwap(); System.out.println(maximumSwap.maximumSwap0(98368)); System.out.println(maximumSwap.maximumSwap0(1993)); } public int maximumSwap0(int num) { char[] arr = String.valueOf(num).toCharArray(); int[] max = new int[arr.length]; max[arr.length - 1] = arr.length - 1; for (int i = arr.length - 2; i \u0026gt;= 0; i--) { char prevNum = arr[max[i + 1]]; char singleNum = arr[i]; if (singleNum \u0026gt; prevNum) { max[i] = i; } else { max[i] = max[i + 1]; } } print(max); for (int i = 0; i \u0026lt; arr.length; i++) { // 索引不同  // 并且数字也要不同  if (i != max[i] \u0026amp;\u0026amp; arr[i] != arr[max[i]]) { swap0(arr, i, max[i]); return Integer.parseInt(new String(arr)); } } return num; } public static final void print(int[] arr) { StringBuilder sb = new StringBuilder(\u0026#34;[\u0026#34;); for (int i = 0; i \u0026lt; arr.length; i++) { sb.append(arr[i]); if (i != arr.length - 1) { sb.append(\u0026#39;,\u0026#39;); } } sb.append(\u0026#34;]\u0026#34;); System.out.println(sb.toString()); } private void swap0(char[] arr, int i, int j) { char t = arr[i]; arr[i] = arr[j]; arr[j] = t; } // 1 0000 0000  public int maximumSwap(int num) { char[] bucket = String.valueOf(num).toCharArray(); int[] intBucket = new int[bucket.length]; for (int i = 0; i \u0026lt; bucket.length; i++) { intBucket[i] = bucket[i] - \u0026#39;0\u0026#39;; } for (int i = 0; i \u0026lt; intBucket.length - 1; i++) { int candidateI = i; int candidateJ = i; // 5656626 =\u0026gt; 6656625  // =\u0026gt; 6556626  //  // 98386 =\u0026gt; 98836  for (int j = i + 1; j \u0026lt; intBucket.length; j++) { if (intBucket[j] \u0026gt;= intBucket[candidateJ]) { candidateJ = j; } } if (candidateI != candidateJ \u0026amp;\u0026amp; intBucket[candidateI] != intBucket[candidateJ]) { swap(intBucket, candidateI, candidateJ); return toInt(intBucket); } } return num; } private int toInt(int[] intBucket) { final StringBuilder sb = new StringBuilder(); for (int i = 0; i \u0026lt; intBucket.length; i++) { sb.append(intBucket[i]); } return Integer.parseInt(sb.toString()); } private void swap(int[] array, int i, int j) { int tmp = array[i]; array[i] = array[j]; array[j] = tmp; } } "});index.add({'id':126,'href':'/docs/programmer-interview/algorithm/medianoftwosortedarrays/','title':"两个有序数组合并后的中位数",'content':"两个有序数组合并后的中位数 题解 public class MedianofTwoSortedArrays { public double findMedianSortedArrays(int[] nums1, int[] nums2) { int n = nums1.length + nums2.length; if (n % 2 == 1) { return findKth(nums1, nums2, 0, nums1.length - 1, 0, nums2.length - 1, n / 2 + 1); } else { double a = findKth(nums1, nums2, 0, nums1.length - 1, 0, nums2.length - 1, n / 2); double b = findKth(nums1, nums2, 0, nums1.length - 1, 0, nums2.length - 1, n / 2 + 1); return (a + b) / 2.0; } } private double findKth(int[] nums1, int[] nums2, int l1, int h1, int l2, int h2, int k) { if (l1 \u0026gt; h1) { return nums2[l2 + k - 1]; } else if (l2 \u0026gt; h2) { return nums1[l1 + k - 1]; } int m1 = l1 + ((h1 - l1) \u0026gt;\u0026gt; 1); int m2 = l2 + ((h2 - l2) \u0026gt;\u0026gt; 1); if (nums1[m1] \u0026lt;= nums2[m2]) { if (k \u0026lt;= (m1 - l1) + (m2 - l2) + 1) { return findKth(nums1, nums2, l1, h1, l2, m2 - 1, k); } else { return findKth(nums1, nums2, m1 + 1, h1, l2, h2, k - (m1 - l1 + 1)); } } else { if (k \u0026lt;= (m1 - l1) + (m2 - l2) + 1) { return findKth(nums1, nums2, l1, m1 - 1, l2, h2, k); } else { return findKth(nums1, nums2, l1, h1, m2 + 1, h2, k - (m2 - l2 + 1)); } } } } 其他网友答案 (有注释) // O(log(m + n)) public class MedianofTwoSortedArrays_Reference { // using divide and conquer idea, each time find the mid of both arrays  public double findMedianSortedArrays(int A[], int m, int B[], int n) { /* A[0, 1, 2, ..., n-1, n] */ /* A[0, 1, 2, ..., m-1, m] */ int k = (m + n + 1) / 2; double v = (double) FindKth(A, 0, m - 1, B, 0, n - 1, k); if ((m + n) % 2 == 0) { int k2 = k + 1; double v2 = (double) FindKth(A, 0, m - 1, B, 0, n - 1, k2); v = (v + v2) / 2; } return v; } // find the kth element int the two sorted arrays  // let us say: A[aMid] \u0026lt;= B[bMid], x: mid len of a, y: mid len of b, then wen can know  //  // (1) there will be at least (x + 1 + y) elements before bMid  // (2) there will be at least (m - x - 1 + n - y) = m + n - (x + y +1) elements after aMid  // therefore  // if k \u0026lt;= x + y + 1, find the kth element in a and b, but unconsidering bMid and its suffix  // if k \u0026gt; x + y + 1, find the k - (x + 1) th element in a and b, but unconsidering aMid and its prefix  //  // A: [X, X, X, X, X, X, X, X, X, X, X]  // ↑ ↑  // aL aR  //  // B: [X, X, X, X, X, X, X, X, X, X, X]  // ↑ ↑  // bL bR  int FindKth(int A[], int aL, int aR, int B[], int bL, int bR, int k /** 第 k 个的意思 */) { if (aL \u0026gt; aR) return B[bL + k - 1]; if (bL \u0026gt; bR) return A[aL + k - 1]; int aMid = (aL + aR) / 2; int bMid = (bL + bR) / 2; // =====================  // 排在 B[bMid] 前面的元素，至少有 A 前半部分，B 前半部分，这两部分  // =====================  if (A[aMid] \u0026lt;= B[bMid]) { // ========================  // K 位于这两个前半部分，那么肯定可以砍掉 B 的最后半部分  // ========================  //  // 这个 1 代表的是 kth，而非 indexK，实际上可以这样写：  // k 的索引位于某个区间  //  // (kIndex = k - 1) \u0026lt;= (aMid - aL) + (bMid - bL)  if (k \u0026lt;= (aMid - aL) + (bMid - bL) + 1) return FindKth(A, aL, aR, B, bL, bMid - 1, k); else // ========================  // K 不位于这两个前半部分，肯定可以砍掉 A 的前半部分  // ========================  return FindKth(A, aMid + 1, aR, B, bL, bR, k - (aMid - aL) - 1); } else { // A[aMid] \u0026gt; B[bMid]  if (k \u0026lt;= (aMid - aL) + (bMid - bL) + 1) return FindKth(A, aL, aMid - 1, B, bL, bR, k); else return FindKth(A, aL, aR, B, bMid + 1, bR, k - (bMid - bL) - 1); } } } "});index.add({'id':127,'href':'/docs/programmer-interview/algorithm/mergeintervals/','title':"合并区间",'content':"合并区间 描述 原题 给出一个区间的集合，请合并所有重叠的区间。\n输入: [[1,3],[2,6],[8,10],[15,18]]\r输出: [[1,6],[8,10],[15,18]]\r解释: 区间 [1,3] 和 [2,6] 重叠, 将它们合并为 [1,6].\r题解 // Input: [[1,3],[2,6],[8,10],[15,18]] // Output: [[1,6],[8,10],[15,18]] // Explanation: Since intervals [1,3] and [2,6] overlaps, merge them into [1,6]. // // 56: https://leetcode.com/problems/merge-intervals/ public class MergeIntervals { public List\u0026lt;Interval\u0026gt; merge(List\u0026lt;Interval\u0026gt; intervals) { if (intervals == null || intervals.isEmpty()) { return Collections.emptyList(); } Collections.sort(intervals, new Comparator\u0026lt;Interval\u0026gt;() { @Override public int compare(Interval a, Interval b) { if (a.start \u0026lt; b.start) { return -1; } else if (a.start \u0026gt; b.start) { return 1; } else { if (a.end \u0026lt; b.end) { return -1; } else if (a.end \u0026gt; b.end) { return 1; } else { return 0; } } } }); List\u0026lt;Interval\u0026gt; res = new LinkedList\u0026lt;\u0026gt;(); Interval prev = null; for (Interval interval: intervals) { if (prev == null || interval.start \u0026gt; prev.end) { prev = interval; res.add(interval); } else { prev.end = Math.max(interval.end, prev.end); } } return res; } } "});index.add({'id':128,'href':'/docs/programmer-interview/algorithm/mergeksortedarrays/','title':"合并 K 个有序数组",'content':"合并 K 个有序数组 题解  优先级队列  import java.util.PriorityQueue; // https://www.lintcode.com/problem/merge-k-sorted-arrays/description // public class MergeKSortedArrays { public int[] mergekSortedArrays(int[][] arrays) { PriorityQueue\u0026lt;Integer\u0026gt; queue = new PriorityQueue\u0026lt;\u0026gt;(); int n = 0; for (int i = 0; i \u0026lt; arrays.length; i++) { for (int j = 0; j \u0026lt; arrays[i].length; j++) { n++; queue.offer(arrays[i][j]); } } int[] sortedArr = new int[n]; int index = 0; while (!queue.isEmpty()) { sortedArr[index++] = queue.poll(); } return sortedArr; } } "});index.add({'id':129,'href':'/docs/programmer-interview/algorithm/minimumsizesubarraysum/','title':"长度最小的子数组",'content':"长度最小的子数组 描述 题目 给定一个含有 n 个正整数的数组和一个正整数 s ，找出该数组中满足其和 ≥ s 的长度最小的 连续 子数组，并返回其长度。如果不存在符合条件的子数组，返回 0。\n输入：s = 7, nums = [2,3,1,2,4,3]\r输出：2\r解释：子数组 [4,3] 是该条件下的长度最小的子数组。\r题解 // Given an array of n positive integers and a positive integer s, // find the minimal length of a contiguous subarray of which the sum ≥ s. If there isn\u0026#39;t one, return 0 instead. // // Input: s = 7, nums = [2,3,1,2,4,3] // Output: 2 // Explanation: the subarray [4,3] has the minimal length under the problem constraint. // // 必须得连续 // // 时间复杂度 O(n^2) public class MinimumSizeSubarraySum { public int minSubArrayLen(int s, int[] nums) { int[] prefixSum = prefixSum(nums); int min = nums.length + 1; for (int i = 0; i \u0026lt; nums.length; i++) { for (int j = i + 1; j \u0026lt;= nums.length; j++) { if (prefixSum[j] - prefixSum[i] \u0026gt;= s) { min = Math.min(j - i, min); } } } return min == (nums.length + 1) ? 0 : min; } private int[] prefixSum(int[] nums) { int[] prefixSum = new int[nums.length + 1]; for (int i = 0; i \u0026lt; nums.length; i++) { prefixSum[i + 1] = prefixSum[i] + nums[i]; } return prefixSum; } } "});index.add({'id':130,'href':'/docs/programmer-interview/algorithm/movingaveragefromdatastream/','title':"数据流滑动窗口平均值",'content':"数据流滑动窗口平均值 描述 原题 给出一串整数流和窗口大小，计算滑动窗口中所有整数的平均值。\n题解 import java.util.LinkedList; import java.util.Queue; // https://www.lintcode.com/problem/moving-average-from-data-stream/description // 给出一串整数流和窗口大小，计算滑动窗口中所有整数的平均值。 // // MovingAverage m = new MovingAverage(3); // m.next(1) = 1 // 返回 1.00000 // m.next(10) = (1 + 10) / 2 // 返回 5.50000 // m.next(3) = (1 + 10 + 3) / 3 // 返回 4.66667 // m.next(5) = (10 + 3 + 5) / 3 // 返回 6.00000 // public class MovingAveragefromDataStream { private final int size; private final Queue\u0026lt;Integer\u0026gt; queue = new LinkedList\u0026lt;\u0026gt;(); private double sum; /* * @param size: An integer */ public MovingAveragefromDataStream(int size) { this.size = size; } /* * @param val: An integer * @return: */ public double next(int val) { if (this.size == 0) { return 0; } sum += val; queue.add(val); if (queue.size() \u0026gt; this.size) { Integer removed = queue.remove(); sum -= removed.intValue(); } return sum / queue.size(); } } "});index.add({'id':131,'href':'/docs/programmer-interview/algorithm/nextgreaterelementii/','title':"下一个更大元素 II",'content':"下一个更大元素 II 描述 原题 给定一个循环数组（最后一个元素的下一个元素是数组的第一个元素），输出每个元素的下一个更大元素。数字 x 的下一个更大的元素是按数组遍历顺序，这个数字之后的第一个比它更大的数，这意味着你应该循环地搜索它的下一个更大的数。如果不存在，则输出 -1。\n输入: [1,2,1]\r输出: [2,-1,2]\r解释: 第一个 1 的下一个更大的数是 2；\r数字 2 找不到下一个更大的数； 第二个 1 的下一个最大的数需要循环搜索，结果也是 2。\r题解 // 循环数组 // Input: [1,2,1] // Output: [2,-1,2] public class NextGreaterElementII { // O(n^2)  public int[] nextGreaterElements(int[] nums) { int[] greater = new int[nums.length]; for (int i = 0; i \u0026lt; nums.length; i++) { greater[i] = findNextGreat(nums, i); } return greater; } private int findNextGreat(int[] nums, int i) { int great = nums[i]; int j = i + 1; while (j \u0026lt; nums.length) { if (nums[j] \u0026gt; great) { return nums[j]; } j++; } j = 0; while (j \u0026lt; i) { if (nums[j] \u0026gt; great) { return nums[j]; } j++; } return -1; } } 另外一种解法  单调递增栈  import java.util.Arrays; import java.util.Stack; public class NextGreaterElementII_Solution_1 { public int[] nextGreaterElements(int[] nums) { if (nums == null || nums.length == 0) return new int[0]; Stack\u0026lt;Integer\u0026gt; stack = new Stack\u0026lt;\u0026gt;(); // store the index  int n = nums.length; int[] res = new int[n]; Arrays.fill(res, -1); // =========================  // stack j  // ↓ ↓  // xxxxxxxxx yyyyyyyy  // =========================  for (int i = 0; i \u0026lt; 2 * n; i++) { int j = i % n; // ====================================================================  // 单调递增栈  //  // 只要栈里面的存储的比它小，那么栈里面的那个数的 next great element 就是这个 nums[j]  // ====================================================================  while (!stack.isEmpty() \u0026amp;\u0026amp; nums[j] \u0026gt; nums[stack.peek()]) { int index = stack.pop(); if (res[index] != -1) continue; res[index] = nums[j]; } stack.push(j); } return res; } } "});index.add({'id':132,'href':'/docs/programmer-interview/algorithm/nextpermutation/','title':"下一个排列",'content':"下一个排列 描述 原题 实现获取下一个排列的函数，算法需要将给定数字序列重新排列成字典序中下一个更大的排列。\n如果不存在下一个更大的排列，则将数字重新排列成最小的排列（即升序排列）。\n必须原地修改，只允许使用额外常数空间。\n以下是一些例子，输入位于左侧列，其相应输出位于右侧列。\n1,2,3 → 1,3,2\r3,2,1 → 1,2,3\r1,1,5 → 1,5,1\r题解 public class NextPermutation { // 1 5 8 4 7 6 5 3 1  // ↑  // ↑(5 \u0026gt; 4 最后一个大于它的)  // 1 5 8 5 7 6 4 3 1 (交换)  // ↑(reverse)↑  // 1 5 8 5 1 3 4 6 7  //  // 找到第一个不符合从右到左升序对的数字 i = 4  // 找到第一个刚刚大于 nums[i] 的数字 j = 5  // swap(i, j)  // reverse(i + 1)  //  // ↓ (第一个不符合的数字 3，如果相等，比如多个 3 还要再往前找)  // 7 3 6 4 2  // ↑ (第一个刚刚大于 3 的数字 4)  //  // 7 4 6 3 2 (交换)  //  // 7 4 2 3 6 (4 后面的数字也交换)  public void nextPermutation(int[] nums) { int i = nums.length - 1; while (i \u0026gt; 0) { // ===========================  // 这个地方是 \u0026gt;=  // [1,1,2,2,5,2]  // ↑  // i  // ===========================  if (nums[i - 1] \u0026gt;= nums[i]) { i--; } else { break; } } // 指向前一个  i--; if (i \u0026gt;= 0) { int j = i; // ===========================  // 这个地方是 \u0026gt; 必须大于，不能等于  // [1,1,2,2,5,2]  // ↑ ↑  // i j  //  // 如果允许等于的话，那么 2 最终 j 还会指向 2  // reverse(i, j) 没什么用  // ===========================  while (j + 1 \u0026lt; nums.length \u0026amp;\u0026amp; nums[j + 1] \u0026gt; nums[i]) { j++; } swap(nums, i, j); } reverse(nums, i + 1, nums.length - 1); } private void reverse(int[] nums, int i, int j) { while (i \u0026lt; j) { swap(nums, i, j); i++; j--; } } private void swap(int[] nums, int i, int j) { int t = nums[i]; nums[i] = nums[j]; nums[j] = t; } } "});index.add({'id':133,'href':'/docs/programmer-interview/algorithm/numberofairplanesinthesky/','title':"数飞机",'content':"数飞机 描述 原题 给出飞机的起飞和降落时间的列表，用序列 interval 表示. 请计算出天上同时最多有多少架飞机？\n 如果多架飞机降落和起飞在同一时刻，我们认为降落有优先权。\n 输入: [(1, 10), (2, 3), (5, 8), (4, 7)]\r输出: 3\r解释: 第一架飞机在1时刻起飞, 10时刻降落.\r第二架飞机在2时刻起飞, 3时刻降落.\r第三架飞机在5时刻起飞, 8时刻降落.\r第四架飞机在4时刻起飞, 7时刻降落.\r在5时刻到6时刻之间, 天空中有三架飞机.\r题解 import java.util.ArrayList; import java.util.Collections; import java.util.Comparator; import java.util.List; import com.zk.algorithm.beans.Interval; // https://www.lintcode.com/problem/number-of-airplanes-in-the-sky/description // Amazon // // Input: [(1, 10), (2, 3), (5, 8), (4, 7)] // Output: 3 // Explanation: // The first airplane takes off at 1 and lands at 10. // The second ariplane takes off at 2 and lands at 3. // The third ariplane takes off at 5 and lands at 8. // The forth ariplane takes off at 4 and lands at 7. // During 5 to 6, there are three airplanes in the sky. // Example 2:  // Input: [(1, 2), (2, 3), (3, 4)] // Output: 1 // Explanation: Landing happen before taking off. // // 天空同时有几个飞机 // // 降落优先于起飞 public class NumberofAirplanesintheSky { public int countOfAirplanes(List\u0026lt;Interval\u0026gt; airplanes) { List\u0026lt;int[]\u0026gt; times = new ArrayList\u0026lt;\u0026gt;(airplanes.size() * 2); for (Interval interval: airplanes) { times.add(new int[]{ interval.start, 0 }); times.add(new int[]{ interval.end, 1 }); } Collections.sort(times, new Comparator\u0026lt;int[]\u0026gt;() { @Override public int compare(int[] a, int[] b) { if (a[0] \u0026lt; b[0]) { return -1; } else if (a[0] \u0026gt; b[0]) { return 1; } else { // 降落优先于起飞  // 降落排在前面  //  if (a[1] \u0026lt; b[1]) { return 1; } else if (a[1] \u0026gt; b[1]) { return -1; } return 0; } } }); int max = 0; int count = 0; for (int[] t: times) { if (t[1] == 0) { // 起飞  count++; } else { // 降落  count--; } max = Math.max(max, count); } return max; } } "});index.add({'id':134,'href':'/docs/programmer-interview/algorithm/partitionequalsubsetsum/','title':"分割等和子集",'content':"分割等和子集 描述 原题 给定一个只包含正整数的非空数组。是否可以将这个数组分割成两个子集，使得两个子集的元素和相等。\n注意:\n 每个数组中的元素不会超过 100 数组的大小不会超过 200  输入: [1, 5, 11, 5]\r输出: true\r解释: 数组可以分割成 [1, 5, 5] 和 [11].\r题解 import java.util.Arrays; // https://leetcode.com/problems/partition-equal-subset-sum/ // // 0 1 背包问题 // 从 nums.length 个数中找出若干个数，使其和 == sum /2 // // 416. Two subset public class PartitionEqualSubsetSum { public boolean canPartition(int[] nums) { int sum = 0; for (int num : nums) { sum += num; } if ((sum \u0026amp; 1) == 1) { return false; } // ======================  // sum 变为一半  // ======================  sum /= 2; int n = nums.length; // dp[i][j]  boolean[][] dp = new boolean[n + 1][sum + 1]; for (int i = 0; i \u0026lt; dp.length; i++) { Arrays.fill(dp[i], false); } // ======================  // 0 个物品，选取值等于 0 的  // ======================  dp[0][0] = true; // ======================  // 1 个物品、2 个物品、3 个物品...，选取值等于 0 的，全部为 true，我们不选就行了  // ======================  for (int i = 1; i \u0026lt; n + 1; i++) { dp[i][0] = true; } // ======================  // 0 个物品选取，值等于 j 的，我们全部选择也不够  // ======================  for (int j = 1; j \u0026lt; sum + 1; j++) { dp[0][j] = false; } for (int i = 1; i \u0026lt; n + 1; i++) { for (int j = 1; j \u0026lt; sum + 1; j++) { // 如果 i - 1 个物品已经选择够 j 了，那么 i 个物品当然也可以选择够  if (dp[i - 1][j]) { dp[i][j] = dp[i - 1][j]; } else if (j \u0026gt;= nums[i - 1]) { // 选上 nums[i - 1]，也就是说最后一个，因为 i - 1 代表最后一个，i: 0 ~ n - 1  // 然后看之前的是否是 true 或者 false  dp[i][j] = dp[i - 1][j - nums[i - 1]]; } } } return dp[n][sum]; } } "});index.add({'id':135,'href':'/docs/programmer-interview/algorithm/productofarrayexceptself/','title':"数组除了自身的乘积",'content':" 描述 原题 给定 n 个整数的数组 nums，其中 n \u0026gt; 1，返回一个数组输出，使得 output[i] 等于 nums 的所有除了nums[i] 的元素的乘积。\n输入: [1,2,3,4]\r输出: [24,12,8,6]\r解释:\r2*3*4=24\r1*3*4=12\r1*2*4=8\r1*2*3=6\r题解 // 给定n个整数的数组nums，其中n\u0026gt; 1，返回一个数组输出，使得output [i]等于nums的所有除了nums [i]的元素的乘积。 // 在没有除和O(n)时间内解决 // https://www.lintcode.com/problem/product-of-array-except-self/description // 输入: [1,2,3,4] // 输出: [24,12,8,6] // 解释: // 2*3*4=24 // 1*3*4=12 // 1*2*4=8 // 1*2*3=6 // // 输入: [2,3,8] // 输出: [24,16,6] // 解释: // 3*8=24 // 2*8=16 // 2*3=6 public class ProductofArrayExceptSelf { public int[] productExceptSelf(int[] nums) { //  // 2, 3, 8  //  // 2, 6, 1  // 1, 24, 8  //  // 24, 16, 6  int[] leftProduct = new int[nums.length]; leftProduct[0] = nums[0]; leftProduct[nums.length - 1] = 1; for (int i = 1; i \u0026lt; nums.length - 1; i++) { leftProduct[i] = leftProduct[i - 1] * nums[i]; } // 2  // 0 1  // 1 * 2  int[] rightProduct = new int[nums.length]; rightProduct[nums.length - 1] = nums[nums.length - 1]; rightProduct[0] = 1; for (int i = nums.length - 2; i \u0026gt;= 1; i--) { rightProduct[i] = rightProduct[i + 1] * nums[i]; } int[] res = new int[nums.length]; for (int i = 0; i \u0026lt; nums.length; i++) { res[i] = (i \u0026gt;= 1 ? leftProduct[i - 1] : 1) * (i \u0026lt; nums.length - 1 ? rightProduct[i + 1] : 1); } return res; } } "});index.add({'id':136,'href':'/docs/programmer-interview/algorithm/queuereconstructionbyheight/','title':"根据身高重建队列",'content':"根据身高重建队列 原题 假设有打乱顺序的一群人站成一个队列。 每个人由一个整数对(h, k)表示，其中h是这个人的身高，k是排在这个人前面且身高大于或等于h的人数。 编写一个算法来重建这个队列。\n注意：\n 总人数少于1100人。  示例\n输入:\r[[7,0], [4,4], [7,1], [5,0], [6,1], [5,2]]\r输出:\r[[5,0], [7,0], [5,2], [6,1], [4,4], [7,1]]\r题解 import java.util.ArrayList; import java.util.Arrays; import java.util.Comparator; import java.util.List; // https://leetcode.com/problems/queue-reconstruction-by-height/ public class QueueReconstructionbyHeight { // [[7,0], [7,1], [6,1], [5,2], [5,0], [4,4]]  //  // [[7,0]]  // [[7,0], [7,1]]  // [[7,0], [6,1], [7,1]]  // [[7,0], [6,1], [5,2], [7,1]]  // [[5,0], [7,0], [6,1], [5,2], [7,1]]  // [[5,0], [7,0], [6,1], [5,2], [4,4], [7,1]]  public int[][] reconstructQueue(int[][] people) { // 个高的排在最前面，个矮的排在后面  Arrays.sort(people, new Comparator\u0026lt;int[]\u0026gt;() { @Override public int compare(int[] a, int[] b) { if (a[0] \u0026lt; b[0]) { return 1; } else if (a[0] \u0026gt; b[0]) { return -1; } if (a[1] \u0026lt; b[1]) { return -1; } else if (a[1] \u0026gt; b[1]) { return 1; } return 0; } }); List\u0026lt;int[]\u0026gt; list = new ArrayList\u0026lt;\u0026gt;(people.length); for (int i = 0; i \u0026lt; people.length; i++) { // 个头矮的去前面寻找自己的位置，这样不会对每个人前面有几个人高于自己的这个 k 产生影响  // 所以必须是个头矮的去寻找位置  list.add(people[i][1], people[i]); } return list.toArray(people); } } "});index.add({'id':137,'href':'/docs/programmer-interview/algorithm/ratelimiter/','title':"限流器",'content':"限流器  基于 Token Bucket 的限流算法 基于 Redis 的限流算法  public class RateLimiter { public static long now() { return System.currentTimeMillis(); } // ==================  // - Token Bucket  // - Redis  // ==================  // =========================  // Token Bucket 算法  // 每过 RATE / PER 时间，就加  // =========================  public static class TokenBucketRateLimiter { private long lastCheck = now(); private static final int RATE = 5; // 5 requests  private static final int PER = 8; // 8 seconds  private int allowance = RATE; public boolean overhead(String key) { long current = now(); long timePassed = current - lastCheck; lastCheck = timePassed; // ======================  // 过去的这段时间内可以增加多少个 allowance  // ======================  allowance += timePassed * (RATE / PER); if (allowance \u0026gt; RATE) { allowance = RATE; } // ======================  // 是否能够减去 1.0 个  // ======================  if (allowance \u0026lt; 1.0) { return true; } else { allowance -= 1.0; return false; } } } // =========================  // Redis RateLimiter 算法  // 系统要限定用户的某个行为在指定的时间里只能允许发生 N 次  //  // 每一个行为到来时，都维护一次时间窗口。  // 将时间窗口外的记录全部清理掉，只保留窗口内的记录。  // zset 集合中只有 score 值非常重要，value 值没有特别的意义，  // 只需要保证它是唯一的就可以了  //  // 因为这几个连续的 Redis 操作都是针对同一个 key 的，  // 使用 pipeline 可以显著提升 Redis 存取效率。  // 但这种方案也有缺点，因为它要记录时间窗口内所有的行为记录，  // 如果这个量很大，比如限定 60s 内操作不得超过 100w 次这样的参数，  // 它是不适合做这样的限流的，因为会消耗大量的存储空间。  // =========================  public static class RedisRateLimiter { private static final int MAX_COUNT = 5; // 5 requests  private static final int PERIOD = 60; // 60 s  private Jedis jedis = new Jedis(); public boolean overhead(String key) { long nowTs = now(); Pipeline pipe = jedis.pipelined(); pipe.multi(); pipe.zadd(key, nowTs, \u0026#34;\u0026#34; + nowTs); pipe.zremrangeByScore(key, 0, nowTs - PERIOD * 1000); Response\u0026lt;Long\u0026gt; count = pipe.zcard(key); pipe.expire(key, PERIOD + 1); // 防止这个 key 一直存在  pipe.exec(); pipe.close(); return count.get() \u0026lt;= MAX_COUNT; } } static class Jedis { Pipeline pipelined() { return null; } } static class Pipeline { void exec() {} void close() {} void multi() {} void zadd(String key, long time, String value) {} void zremrangeByScore(String key, long begin, long end) {}; void expire(String key, long timeout) {} Response\u0026lt;Long\u0026gt; zcard(String key) { return new Response\u0026lt;Long\u0026gt;(); } } static class Response\u0026lt;T\u0026gt; { int get() { return 0; } } } "});index.add({'id':138,'href':'/docs/programmer-interview/algorithm/removeduplicatesfromsortedarray/','title':"删除排序数组中的重复项",'content':"删除排序数组中的重复项 描述 原题 给定一个排序数组，你需要在 原地 删除重复出现的元素，使得每个元素只出现一次，返回移除后数组的新长度。\n不要使用额外的数组空间，你必须在 原地 修改输入数组 并在使用 O(1) 额外空间的条件下完成。\n 示例 1:\n给定数组 nums = [1,1,2], 函数应该返回新的长度 2, 并且原数组 nums 的前两个元素被修改为 1, 2。 你不需要考虑数组中超出新长度后面的元素。\r题解 // 排序数组 // 移除重复数字 public class RemoveDuplicatesfromSortedArray { public int removeDuplicates(int[] nums) { // [1,1,1,1,2,2,3,4,5,5]  //  int noDuplicated = 0; for (int i = 1; i \u0026lt; nums.length; i++) { if (nums[i] == nums[i - 1]) { continue; } else { nums[++noDuplicated] = nums[i]; } } return nums.length == 0 ? 0 : noDuplicated + 1; } } "});index.add({'id':139,'href':'/docs/programmer-interview/algorithm/removeelement/','title':"移除元素",'content':"移除元素 描述 原题 给你一个数组 nums 和一个值 val，你需要 原地 移除所有数值等于 val 的元素，并返回移除后数组的新长度。\n不要使用额外的数组空间，你必须仅使用 O(1) 额外空间并 原地 修改输入数组。\n元素的顺序可以改变。你不需要考虑数组中超出新长度后面的元素。 示例 1:\n给定 nums = [3,2,2,3], val = 3,\r函数应该返回新的长度 2, 并且 nums 中的前两个元素均为 2。\r你不需要考虑数组中超出新长度后面的元素。\r题解 public class RemoveElement { // [1,1,1,2,2]  public int removeElement(int[] nums, int val) { int valid = -1; for (int i = 0; i \u0026lt; nums.length; i++) { if (nums[i] != val) { nums[++valid] = nums[i]; } } return nums.length == 0 ? 0 : valid + 1; } } "});index.add({'id':140,'href':'/docs/programmer-interview/algorithm/reversepairs/','title':"逆序对",'content':"逆序对 描述 数组的逆序对个数\n题解 // https://www.lintcode.com/problem/reverse-pairs/description // // Input: A = [2, 4, 1, 3, 5] // Output: 3 // Explanation: // (2, 1), (4, 1), (4, 3) are reverse pairs // // 逆序对个数 public class ReversePairs { public long reversePairs(int[] A) { return mergeSort(A, 0, A.length - 1); } private long mergeSort(int[] A, int lo, int hi) { int sum = 0; if (lo \u0026lt; hi) { int mid = lo + ((hi - lo) \u0026gt;\u0026gt; 1); // =====================  // 注意：这个地方是都加了一遍  // =====================  sum += mergeSort(A, lo, mid); sum += mergeSort(A, mid + 1, hi); sum += merge(A, lo, mid, hi); } return sum; } private int merge(int[] A, int lo, int mid, int hi) { int[] temp = new int[hi - lo + 1]; int tempIndex = 0; int loIndex = lo; int hiIndex = mid + 1; int count = 0; while (loIndex \u0026lt;= mid \u0026amp;\u0026amp; hiIndex \u0026lt;= hi) { // left | right  // 3 5 6 | 2  //  // 3 比 2 大的话，那么 3 5 6 都比 2 大  if (A[loIndex] \u0026gt; A[hiIndex]) { count += mid - loIndex + 1; temp[tempIndex++] = A[hiIndex++]; } else { temp[tempIndex++] = A[loIndex++]; } } while (loIndex \u0026lt;= mid) { temp[tempIndex++] = A[loIndex++]; } while (hiIndex \u0026lt;= hi) { temp[tempIndex++] = A[hiIndex++]; } tempIndex = 0; while (tempIndex \u0026lt; temp.length) { A[lo + tempIndex] = temp[tempIndex]; tempIndex++; } return count; } } "});index.add({'id':141,'href':'/docs/programmer-interview/algorithm/rotateimage/','title':"旋转图像",'content':"旋转图像 描述 原题 给定一个 n × n 的二维矩阵表示一个图像。\n将图像顺时针旋转 90 度。\n说明：\n你必须在原地旋转图像，这意味着你需要直接修改输入的二维矩阵。请不要使用另一个矩阵来旋转图像。\n题解 // Given input matrix = // [ // [1,2,3], // [4,5,6], // [7,8,9] // ],  // rotate the input matrix in-place such that it becomes: // [ // [7,4,1], // [8,5,2], // [9,6,3] // ] public class RotateImage { public void rotate(int[][] matrix) { int n = matrix.length; for (int i = 0; i \u0026lt; n / 2; i++) { // ↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓  // ↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓  //  // 【j 走到哪里停】? (无需走到9，这个时候就已经完了. j \u0026lt; (n - 1) - i，小于号，而非小于等于)  //  // ↓ ↓  // 7, 8, 9  // 12, 13, 14  // 17, 18, 19  for (int j = i; j \u0026lt; n - 1 - i; j++) { // ----------------------------------------\u0026gt;  // | (i,j)  // | X  // | X (n-1-j, i)  // |  // |  // |  // |  // |  // | X (j,n-1-i)  // | X  // | (n-1-i, n-1-j)  // |  // |  // |  // |  // V  //  // (i,j)  // |  // (j,n-1-i)  // |  // (n-1-i,n-1-j)  // |  // (n-1-j,i)  //  int tmp = matrix[i][j]; matrix[i][j] = matrix[n - 1 - j][i]; matrix[n - 1 - j][i] = matrix[n - 1 - i][n - 1 - j]; matrix[n - 1 - i][n - 1 - j] = matrix[j][n - 1 - i]; matrix[j][n - 1 - i] = tmp; } } } } "});index.add({'id':142,'href':'/docs/programmer-interview/algorithm/searcha2dmatrix/','title':"二维数组中的查找",'content':"二维数组中的查找 描述  剑指offer  在一个 n * m 的二维数组中，每一行都按照从左到右递增的顺序排序，每一列都按照从上到下递增的顺序排序。请完成一个函数，输入这样的一个二维数组和一个整数，判断数组中是否含有该整数。\n题解 // 这个算法适用于行有序、列有序的情况 public class Searcha2DMatrix { public boolean searchMatrix(int[][] matrix, int target) { if (matrix.length == 0) { return false; } int m = matrix.length; int n = matrix[0].length; // 第一行最后一个数字  //  int r = 0; int c = n - 1; while (r \u0026lt; m \u0026amp;\u0026amp; c \u0026gt;= 0) { int val = matrix[r][c]; if (target \u0026gt; val) { r++; } else if (target \u0026lt; val) { c--; } else { return true; } } return false; } } "});index.add({'id':143,'href':'/docs/programmer-interview/algorithm/searchforarange/','title':"搜索区间",'content':"搜索区间 描述 原题 给定一个包含 n 个整数的排序数组，找出给定目标值 target 的起始和结束位置。\n如果目标值不在数组中，则返回 [-1, -1]\n题解 // LintCode // https://www.lintcode.com/problem/search-for-a-range/leaderboard // public class SearchforaRange { public int[] searchRange(int[] A, int target) { if (A == null || A.length == 0) { return new int[]{ -1, -1 }; } int start = searchStartIndex(A, target); int end = searchEndIndex(A, target); return new int[]{ start, end }; } // target 开始的地方  private int searchStartIndex(int[] A, int target) { int lo = 0; int hi = A.length - 1; while (lo \u0026lt;= hi) { int mid = lo + ((hi - lo) \u0026gt;\u0026gt; 1); if (A[mid] \u0026gt; target) { hi = mid - 1; } else if (A[mid] \u0026lt; target) { lo = mid + 1; } else { // ↓ (mid)  // 4 4 4 5 6 7  //  // ↓ (mid)  // 3 4 4 5 6 7  if (mid == 0 || mid - 1 \u0026gt;= 0 \u0026amp;\u0026amp; A[mid - 1] \u0026lt; target) { return mid; } else { hi = mid - 1; } } } return -1; } private int searchEndIndex(int[] A, int target) { int lo = 0; int hi = A.length - 1; while (lo \u0026lt;= hi) { int mid = lo + ((hi - lo) \u0026gt;\u0026gt; 1); if (A[mid] \u0026gt; target) { hi = mid - 1; } else if (A[mid] \u0026lt; target) { lo = mid + 1; } else { if (mid == A.length - 1 || mid + 1 \u0026lt;= A.length - 1 \u0026amp;\u0026amp; A[mid + 1] \u0026gt; target) { return mid; } else { lo = mid + 1; } } } return -1; } } "});index.add({'id':144,'href':'/docs/programmer-interview/algorithm/searchinrotatedsortedarray/','title':"搜索旋转排序数组",'content':"搜索旋转排序数组 Search in Rotated Sorted Array 和 Search in Rotated Sorted Array II\n数组无重复数字 // 么有重复数字 public class SearchinRotatedSortedArray { // https://leetcode.com/problems/search-in-rotated-sorted-array/discuss/14472/Java-AC-Solution-using-once-binary-search  // 使用一次二分搜索  //  // 核心思想: 确定 m 位于哪一边，然后确定 target 是不是位于有序的一边  //  public int search(int[] nums, int target) { int lo = 0; int hi = nums.length - 1; while (lo \u0026lt;= hi) { int m = lo + ((hi - lo) \u0026gt;\u0026gt; 1); if (nums[m] == target) { return m; } // 6 7 1 2 3 4 5  // ↑ ↑ ↑ ↑ ↑  //  // 1 2 3 4 5 6 7  // ↑ ↑ ↑ ↑ ↑ ↑ ↑  //  // 右侧有序  // target 是不是位于有序右侧空间  if (nums[m] \u0026lt;= nums[hi]) { if (target \u0026gt; nums[m] \u0026amp;\u0026amp; target \u0026lt;= nums[hi]) { lo = m + 1; } else { hi = m - 1; } } else { // 6 7 1 2 3 4 5  // ↑ ↑  //  // target 是否位于左侧有序空间内  if (target \u0026gt;= nums[lo] \u0026amp;\u0026amp; target \u0026lt; nums[m]) { hi = m - 1; } else { lo = m + 1; } } } return -1; } // ================================  // 下面这个方案先查找 min 值  // ================================  public int search0(int[] nums, int target) { // ================================  // 忘记这一步骤了  // ================================  if (nums.length == 0) { return -1; } int minIndex = searchMin(nums); int index = -1; if ((index = binarySearch(nums, minIndex, nums.length - 1, target)) != -1) { return index; } return binarySearch(nums, 0, minIndex - 1, target); } private int searchMin(int[] nums) { int lo = 0; // always point to 前半部分  int hi = nums.length - 1; // always point to 后半部分  if (nums[lo] \u0026gt; nums[hi]) { while (lo \u0026lt; hi) { if (hi - lo == 1) { return hi; } int m = lo + ((hi - lo) \u0026gt;\u0026gt; 1); if (nums[m] \u0026lt; nums[0]) { // middle 位于后半部分  hi = m; } else if (nums[m] \u0026gt; nums[nums.length - 1]) { // middle 位于前半部分  // min 在后半部分  //  // ==================================  // 注意这个地方， lo = m，而不是 lo = m + 1  // m + 1 有可能越界，跑到后半部分  // ==================================  lo = m; } } } return 0; } private int binarySearch(int[] nums, int lo, int hi, int target) { while (lo \u0026lt;= hi) { int m = lo + ((hi - lo) \u0026gt;\u0026gt; 1); if (nums[m] == target) { return m; } else if (nums[m] \u0026gt; target) { hi = m - 1; } else { lo = m + 1; } } return -1; } } 有重复数字 // (i.e., [0,0,1,2,2,5,6] might become [2,5,6,0,0,1,2]). // 包含重复元素 // public class SearchinRotatedSortedArray2 { // https://leetcode.com/problems/search-in-rotated-sorted-array-ii/discuss/28202/Neat-JAVA-solution-using-binary-search  // 使用一次二分搜索  //  // 核心思想: 确定 m 位于哪一边，然后确定 target 是不是位于有序的一边  //  public boolean search(int[] nums, int target) { int lo = 0; int hi = nums.length - 1; while (lo \u0026lt;= hi) { int m = lo + ((hi - lo) \u0026gt;\u0026gt; 1); if (nums[m] == target) { return true; } // 0 0 0 1 1 1  // 1 1 0 0 0 1  //  // 0 1 1 2 2  // 2 0 1 2 2  if (nums[m] == nums[hi] \u0026amp;\u0026amp; nums[lo] == nums[hi]) { // 我们的指针无法确定哪一边是有序的  // 移动 lo++ 或者 hi-- 都可以帮助减少一个重复的元素  // 所以最坏情况是 O(n)  hi--; continue; } // 6 7 1 2 3 4 5  // ↑ ↑ ↑ ↑ ↑  //  // 1 2 3 4 5 6 7  // ↑ ↑ ↑ ↑ ↑ ↑ ↑  //  // 右侧有序  // target 是不是位于有序右侧空间  if (nums[m] \u0026lt;= nums[hi]) { if (target \u0026gt; nums[m] \u0026amp;\u0026amp; target \u0026lt;= nums[hi]) { lo = m + 1; } else { hi = m - 1; } } else { // 6 7 1 2 3 4 5  // ↑ ↑  //  // target 是否位于左侧有序空间内  if (target \u0026gt;= nums[lo] \u0026amp;\u0026amp; target \u0026lt; nums[m]) { hi = m - 1; } else { lo = m + 1; } } } return false; } public boolean search0(int[] nums, int target) { if (nums.length == 0) { return false; } // ==========================  // 1. we find the array\u0026#39;s rotate pivot  //  // 4 5 6 0 0 0 1 2 3  // ↑  // minIndex  // ==========================  int minIndex = searchMin(nums); // ==========================  // 2. search the second half by using binary search  //  // 4 5 6 0 0 0 1 2 3  // ↑ ↑  // ==========================  if (binarySearch(nums, minIndex, nums.length - 1, target) != -1) { return true; } // ==========================  // 2. search the first half by using binary search  //  // 4 5 6 0 0 0 1 2 3  // ↑ ↑  // ==========================  return binarySearch(nums, 0, minIndex - 1, target) != -1; } private int searchMin(int[] nums) { int lo = 0; // always point to the first half  int hi = nums.length - 1; // always point to the second half  // ==========================  // 1 2 3 4 5 6 7  // ↑ ↑  // ==========================  if (nums[lo] \u0026gt;= nums[hi]) { while (lo \u0026lt; hi) { // ==========================  // 4 5 6 1 2 3  // ↑ ↑  // lo hi  // ==========================  if (hi - lo == 1) { return hi; } int m = lo + ((hi - lo) \u0026gt;\u0026gt; 1); // ==========================  // we has no way to know the min located in which half  // ==========================  if (nums[m] == nums[lo] \u0026amp;\u0026amp; nums[m] == nums[hi]) { return findMin(nums, lo, hi); } else if (nums[m] \u0026lt; nums[lo]) { hi = m; } else if (nums[m] \u0026gt; nums[hi]) { lo = m; } } } return 0; } private int findMin(int[] nums, int lo, int hi) { int min = hi; // ==========================  // 1 3 1 1 1  // ↑  // minIndex (we need return this)  // ==========================  for (int i = hi - 1; i \u0026gt;= lo; i--) { if (nums[i] \u0026lt;= nums[min]) { min = i; } else { break; } } return min; } private int binarySearch(int[] nums, int lo, int hi, int target) { while (lo \u0026lt;= hi) { int m = lo + ((hi - lo) \u0026gt;\u0026gt; 1); if (nums[m] == target) { return m; } else if (nums[m] \u0026gt; target) { hi = m - 1; } else { lo = m + 1; } } return -1; } } "});index.add({'id':145,'href':'/docs/programmer-interview/algorithm/slidingwindowmaximum/','title':"滑动窗口最大值",'content':"滑动窗口最大值 描述 原题 给定一个数组 nums，有一个大小为 k 的滑动窗口从数组的最左侧移动到数组的最右侧。你只可以看到在滑动窗口内的 k 个数字。滑动窗口每次只向右移动一位。\n返回滑动窗口中的最大值。\n输入: nums = [1,3,-1,-3,5,3,6,7], 和 k = 3\r输出: [3,3,5,5,6,7] 解释: 滑动窗口的位置 最大值\r--------------- -----\r[1 3 -1] -3 5 3 6 7 3\r1 [3 -1 -3] 5 3 6 7 3\r1 3 [-1 -3 5] 3 6 7 5\r1 3 -1 [-3 5 3] 6 7 5\r1 3 -1 -3 [5 3 6] 7 6\r1 3 -1 -3 5 [3 6 7] 7\r题解 import java.util.Deque; import java.util.LinkedList; // 滑动窗口最大值 // k always valid // public class SlidingWindowMaximum { public int[] maxSlidingWindow(int[] nums, int k) { if (nums.length == 0) { return new int[]{}; } // [1,3,-1,-3,5,3,6,7]  // ↑(1)  // ↑(3)  // ↑(3)  // ↑(3)  // ↑(5)  //  // Queue 是一个 FIFO 队列，并不是一个 Deque  // Queue 中存放的是索引  //  // ==============================  // Deque 中维护的是索引值  //  // [1,2,3]  // ↑  // 最大元素  //  // - 如果超出范围了，那么移除 head 元素  // - 如果大于等于末尾元素，那么移除 last 元素  // ==============================  Deque\u0026lt;Integer\u0026gt; queue = new LinkedList\u0026lt;\u0026gt;(); int[] result = new int[nums.length - k + 1]; int index = 0; for (int i = 0; i \u0026lt; nums.length; i++) { // 超出范围了，从 head 移除元素  while (outOfRange(queue, i, k)) { queue.poll(); } // 比队列中最后一个元素大，那么移除最后一个元素  while (biggerThanLastElementInQueue(queue, nums, nums[i])) { queue.pollLast(); } queue.offer(i); if (i + 1 \u0026gt;= k) { result[index++] = nums[queue.peek()]; } } return result; } private boolean outOfRange(Deque\u0026lt;Integer\u0026gt; queue, int i, int k) { return !queue.isEmpty() \u0026amp;\u0026amp; (i - queue.peek() \u0026gt;= k); } private boolean biggerThanLastElementInQueue(Deque\u0026lt;Integer\u0026gt; queue, int[] nums, int curr) { return !queue.isEmpty() \u0026amp;\u0026amp; curr \u0026gt;= nums[queue.peekLast()]; } } "});index.add({'id':146,'href':'/docs/programmer-interview/algorithm/slidingwindowmedian/','title':"滑动窗口中位数",'content':"滑动窗口中位数 描述 原题 中位数是有序序列最中间的那个数。如果序列的大小是偶数，则没有最中间的数；此时中位数是最中间的两个数的平均数。\n例如：\n [2,3,4]，中位数是 3 [2,3]，中位数是 (2 + 3) / 2 = 2.5  给你一个数组 nums，有一个大小为 k 的窗口从最左端滑动到最右端。窗口中有 k 个数，每次窗口向右移动 1 位。你的任务是找出每次窗口移动后得到的新窗口中元素的中位数，并输出由它们组成的数组。\n示例：\n给出 nums = [1,3,-1,-3,5,3,6,7]，以及 k = 3。\n窗口位置 中位数\r--------------- -----\r[1 3 -1] -3 5 3 6 7 1\r1 [3 -1 -3] 5 3 6 7 -1\r1 3 [-1 -3 5] 3 6 7 -1\r1 3 -1 [-3 5 3] 6 7 3\r1 3 -1 -3 [5 3 6] 7 5\r1 3 -1 -3 5 [3 6 7] 6\r因此，返回该滑动窗口的中位数数组 [1,-1,-1,3,5,6]。\n题解 暂未找到一个好记易理解的方法\n"});index.add({'id':147,'href':'/docs/programmer-interview/algorithm/sortcolors/','title':"颜色分类",'content':"颜色分类 描述 原题 给定一个包含红色、白色和蓝色，一共 n 个元素的数组，原地对它们进行排序，使得相同颜色的元素相邻，并按照红色、白色、蓝色顺序排列。\n此题中，我们使用整数 0、 1 和 2 分别表示红色、白色和蓝色。\n题解 public class SortColors { // 0,0,1,1,2,2  //  // 2 0 1 0 1 1 2  public void sortColors(int[] nums) { // 000001111122222  // ↑ ↑  // l r  //  int left = 0; int right = nums.length - 1; int i = 0; while (i \u0026lt;= right) { if (nums[i] == 0) { // =========================  // 遇到 0 就换到左边  //  // 0 0 0 0 1 1 1 1 0 2  // ↑ ↑  // left i  //  // =========================  swap(nums, left++, i++); } else if (nums[i] == 1) { i++; } else { // =========================  // right 指向的是第一个非 2 的位置  //  // 遇到 2 就换到右边，但是换过来的不一定是 1 还是 0，所以 i 不能动  //  // 1 1 1 1 1 2 2 0  // ↑ ↑  // i right  //  // =========================  swap(nums, i, right--); } } } private void swap(int[] nums, int i, int j) { int tmp = nums[i]; nums[i] = nums[j]; nums[j] = tmp; } } "});index.add({'id':148,'href':'/docs/programmer-interview/algorithm/spiralmatrix/','title':"螺旋矩阵",'content':"螺旋矩阵 Spiral Matrix 和 Spiral Matrix II\n返回螺旋顺序 给定一个包含 m x n 个元素的矩阵（m 行, n 列），请按照顺时针螺旋顺序，返回矩阵中的所有元素。\nimport java.util.ArrayList; import java.util.Collections; import java.util.List; public class SpiralMatrix { public List\u0026lt;Integer\u0026gt; spiralOrder(int[][] matrix) { if (matrix == null || matrix.length == 0) { return Collections.emptyList(); } List\u0026lt;Integer\u0026gt; res = new ArrayList\u0026lt;\u0026gt;(); int left = 0; int right = matrix[0].length - 1; int top = 0; int bottom = matrix.length - 1; while (true) { for (int c = left; c \u0026lt;= right; c++) { res.add(matrix[top][c]); } // top 不能超过 bottom  if (++top \u0026gt; bottom) { break; } for (int r = top; r \u0026lt;= bottom; r++) { res.add(matrix[r][right]); } // right 不能低于 left  if (--right \u0026lt; left) { break; } for (int c = right; c \u0026gt;= left; c--) { res.add(matrix[bottom][c]); } // bottom 不能低于 top  if (--bottom \u0026lt; top) { break; } for (int r = bottom; r \u0026gt;= top; r--) { res.add(matrix[r][left]); } // left 不能大于 right  if (++left \u0026gt; right) { break; } } return res; } } 生成螺旋矩阵 给定一个正整数 n，生成一个包含 1 到 n^2 所有元素，且元素按顺时针顺序螺旋排列的正方形矩阵。\n// 给定一个数n, 生成一个包含1~n^2 的螺旋矩阵 // (螺旋由外向内顺时针旋转, 可参照样例) // // 输入: 3 // 输出: // [ // [ 1, 2, 3 ], // [ 8, 9, 4 ], // [ 7, 6, 5 ] // ] public class SpiralMatrixII { public int[][] generateMatrix(int n) { int[][] array = new int[n][n]; int top = 0; int bottom = n - 1; int left = 0; int right = n - 1; int count = 1; while (true) { for (int i = left; i \u0026lt;= right; i++) { array[top][i] = count++; } if (++top \u0026gt; bottom) { break; } for (int i = top; i \u0026lt;= bottom; i++) { array[i][right] = count++; } if (--right \u0026lt; left) { break; } for (int i = right; i \u0026gt;= left; i--) { array[bottom][i] = count++; } if (--bottom \u0026lt; top) { break; } for (int i = bottom; i \u0026gt;= top; i--) { array[i][left] = count++; } if (++left \u0026gt; right) { break; } } return array; } } "});index.add({'id':149,'href':'/docs/programmer-interview/algorithm/splitarraylargestsum/','title':"分割数组的最大值",'content':"分割数组的最大值 描述 原题 给定一个非负整数数组和一个整数 m，你需要将这个数组分成 m 个非空的连续子数组。设计一个算法使得这 m 个子数组各自和的最大值最小。\n注意: 数组长度 n 满足以下条件:\n 1 ≤ n ≤ 1000 1 ≤ m ≤ min(50, n)  输入:\rnums = [7,2,5,10,8]\rm = 2\r输出:\r18\r解释:\r一共有四种方法将nums分割为2个子数组。\r其中最好的方式是将其分为[7,2,5] 和 [10,8]，\r因为此时这两个子数组各自的和的最大值为18，在所有情况中最小。\r题解 // 数组包含非负整数，以及一个 整数 m // 将数组分成 m 个连续的 subarray // 写一个算法，来使得所有的这些 subarrays 的最大和最小 // // [7,2,5,10,8] // // https://leetcode.com/problems/split-array-largest-sum/discuss/89817/Clear-Explanation%3A-8ms-Binary-Search-Java public class SplitArrayLargestSum { // [.......]  //  // max: 所有数相加  // min: Math.max(array) 最大的那个数  //  // 做一个二分搜索  public int splitArray(int[] nums, int m) { long sum = 0; int max = 0; for (int num: nums) { max = Math.max(max, num); sum += num; } // ============================  // 答案最少是这个最大的那个数，或者是所有数之和  // ============================  return (int) binary(nums, m, sum, max /** 最低的最大值是 max */); } private long binary(int[] nums, int m /** m 份 */, long high /** 最大值 */, long low /** 最小值 */) { long mid = 0; while (low \u0026lt; high) { mid = (high + low) / 2; // 每一份切成比 mid 刚刚小的值，切成 m 份可以做到  if (valid(nums, m, mid)) { high = mid; } else { // 切割不成，需要大于 m 份，证明 mid 选择小了  low = mid + 1; } } return high; } // 尽可能地去切分  // 每一份都切分为刚好比 max 小，如果可以做到，那么证明我们的最大值 max 小了，  // 因为每一份尽可能的去切分，依然可以做到，所以切成 m 份是不可能的  //  // 做不到，那么证明 mid 选大了  private boolean valid(int[] nums, int m /** m 份 */, long max /** 最大值 */) { int cur = 0; int count = 1; for (int num: nums) { cur += num; if (cur \u0026gt; max) { cur = num; count++; /** 大于 max 的子数组份数 \u0026gt; m 组 */ if (count \u0026gt; m) { return false; } } } return true; } } "});index.add({'id':150,'href':'/docs/programmer-interview/algorithm/sqrt/','title':"X 的平方根",'content':"X 的平方根 描述 原题 实现 int sqrt(int x) 函数。\n计算并返回 x 的平方根，其中 x 是非负整数。\n由于返回类型是整数，结果只保留整数的部分，小数部分将被舍去。\n题解 public class Sqrt { public int mySqrt(int x) { // 注意边界条件  if (x == 0) { return 0; } int lo = 1; int hi = x / 2; int ans = lo; while (lo \u0026lt;= hi) { int mid = lo + ((hi - lo) \u0026gt;\u0026gt; 1); // 注意这里  // 防止溢出  if (mid \u0026gt; x / mid) { hi = mid - 1; } else if (mid \u0026lt;= x / mid) { ans = mid; lo = mid + 1; } } return ans; } } "});index.add({'id':151,'href':'/docs/programmer-interview/algorithm/subarrayproductlessthank/','title':"乘积小于K的子数组",'content':"乘积小于K的子数组 描述 原题 给定一个正整数数组 nums。\n找出该数组内乘积小于 k 的连续的子数组的个数。\n示例 1:\n输入: nums = [10,5,2,6], k = 100\r输出: 8\r解释: 8个乘积小于100的子数组分别为: [10], [5], [2], [6], [10,5], [5,2], [2,6], [5,2,6]。\r需要注意的是 [10,5,2] 并不是乘积小于100的子数组。\r题解 // Input: nums = [10, 5, 2, 6], k = 100 // Output: 8 // Explanation: The 8 subarrays that have product less than 100 are: [10], [5], [2], [6], [10, 5], [5, 2], [2, 6], [5, 2, 6]. // Note that [10, 5, 2] is not included as the product of 100 is not strictly less than k. // // 0 \u0026lt; nums[i] \u0026lt; 1000 只包含正数 // // ============================== // 滑动窗口 // // 子数组乘积小于 k // [X, X, X, X, X, X, X, X] // ↑ ↑ // ============================== public class SubarrayProductLessThanK { public int numSubarrayProductLessThanK(int[] nums, int k) { if (k \u0026lt;= 1) { // 数组最小元素是 1，而且 less than 必须严格小于，因此 k = 0 的时候，直接返回 0 就行了  return 0; } int ans = 0; int left = 0; int product = 1; for (int right = 0; right \u0026lt; nums.length; right++) { product *= nums[right]; while (product \u0026gt;= k) { if (left \u0026gt;= nums.length) { return ans; } product /= nums[left++]; } // 1 2 3 4  // ↑  // left  // ↑  // right  //  // 多一个 right，那么就多 right - left + 1 个候选数组  ans += (right - left + 1); } return ans; } } "});index.add({'id':152,'href':'/docs/programmer-interview/algorithm/subarraysumequalsk/','title':"和为K的子数组",'content':"和为K的子数组 描述 给定一个整数数组和一个整数 k，你需要找到该数组中和为 k 的连续的子数组的个数。\n示例 1 :\n输入:nums = [1,1,1], k = 2\r输出: 2 , [1,1] 与 [1,1] 为两种不同的情况。\r题解 // Given an array of integers and an integer k, you need to find the total number of continuous subarrays whose sum equals to k. // // 和为 k 的连续子数组，有多少组 public class SubarraySumEqualsK { public int subarraySum(int[] nums, int k) { int[] preSum = calcPreSum(nums); int count = 0; for (int i = 0; i \u0026lt; preSum.length - 1; i++) { for (int j = i + 1; j \u0026lt; preSum.length; j++) { // =======================  // [___|_________|___]  // ↑ k ↑  // i j  // =======================  if (preSum[j] - preSum[i] == k) { count++; } } } return count; } // 计算前缀子数组  // 非降序列  private int[] calcPreSum(int[] nums) { int[] preSum = new int[nums.length + 1]; for (int i = 1; i \u0026lt; preSum.length; i++) { preSum[i] = nums[i - 1] + preSum[i - 1]; } return preSum; } } "});index.add({'id':153,'href':'/docs/programmer-interview/algorithm/subarrayswithkdifferentintegers/','title':"K 个不同整数的子数组",'content':"K 个不同整数的子数组 描述 给定一个正整数数组 A，如果 A 的某个子数组中不同整数的个数恰好为 K，则称 A 的这个连续、不一定独立的子数组为好子数组。\n（例如，[1,2,3,1,2] 中有 3 个不同的整数：1，2，以及 3。）\n返回 A 中好子数组的数目。\n示例 1：\n输入：A = [1,2,1,2,3], K = 2\r输出：7\r解释：恰好由 2 个不同整数组成的子数组：[1,2], [2,1], [1,2], [2,3], [1,2,1], [2,1,2], [1,2,1,2].\r题解 import java.util.HashMap; import java.util.Map; // Input: A = [1,2,1,2,3], K = 2 // Output: 7 // Explanation: Subarrays formed with exactly 2 different integers: [1,2], [2,1], [1,2], [2,3], [1,2,1], [2,1,2], [1,2,1,2]. // // 子数组里面有 k 个不同的数字 // // 解法参考了 // https://leetcode.com/problems/subarrays-with-k-different-integers/discuss/235235/C%2B%2BJava-with-picture-prefixed-sliding-window // public class SubarrayswithKDifferentIntegers { public int subarraysWithKDistinct(int[] A, int K) { int ans = 0; int left = 0; Map\u0026lt;Integer /** 数字 */, Integer /** 这个数字出现的次数 */\u0026gt; map = new HashMap\u0026lt;\u0026gt;(); //  // 前 prefix 个数，代表的就是有多少个重复的，也出现在当前这个窗口中  //  // 以下面这个为例，前 prefix = 2 个数也出现在后面的 [1, 2, 3] 窗口中  //  // [1, 2, 1, 2, 3]  // l r  //  // 这个 l 和 r 维护的区间刚好是 k 个，添加上前面 prefix 个也是可以的  int prefix = 0; // ===================  // 始终维护的是一个最紧凑的窗口，刚刚好能放下 k 个不同的数字  // ===================  for (int right = 0; right \u0026lt; A.length; right++) { map.put(A[right], map.getOrDefault(A[right], 0) + 1); // ===================  // 始终维护的是一个最紧凑的窗口，刚刚好能放下 k 个不同的数字  //  // [X, X, X, X, X, X, X]  // ↑ ↑  // 移动  // ===================  int size = map.size(); if (size \u0026gt; K) { map.remove(A[left++]); prefix = 0; } // [1, 2, 1, 2, 3]  // ↑ ↑  //  // left  // ↓  // [1, 2, 1, 2, 3]  //  // left  // ↓  // [1, 2, 1, 2, 3]  //  // [1, 2, 1, 2, 3]  //  // prefix = 2  while (map.get(A[left]) \u0026gt; 1) { map.put(A[left], map.get(A[left]) - 1); prefix++; left++; } if (map.size() == K) { ans += prefix + 1; } } return ans; } } "});index.add({'id':154,'href':'/docs/programmer-interview/algorithm/sum/','title':"2、3、4个数之和",'content':"2、3、4个数之和 从 nums 数组中找到数字相加的结果符合要求的几个数字。\n两数之和 import java.util.HashMap; import java.util.Map; // 返回索引 // // O(N) public class TwoSum { public int[] twoSum(int[] nums, int target) { Map\u0026lt;Integer, Integer\u0026gt; map = new HashMap\u0026lt;\u0026gt;(); for (int i = 0; i \u0026lt; nums.length; i++) { if (map.containsKey(target - nums[i])) { return new int[]{ map.get(target - nums[i]), i }; } map.put(nums[i], i); } return new int[]{}; } } 三个数之和 import java.util.List; import java.util.LinkedList; import java.util.ArrayList; import java.util.Arrays; public class ThreeSum { // ========================  // 方法一: 排序 + 二分搜索 O(n^2)  // ========================  public List\u0026lt;List\u0026lt;Integer\u0026gt;\u0026gt; threeSum(int[] num) { Arrays.sort(num); List\u0026lt;List\u0026lt;Integer\u0026gt;\u0026gt; res = new LinkedList\u0026lt;\u0026gt;(); for (int i = 0; i \u0026lt; num.length-2; i++) { if (i == 0 || (i \u0026gt; 0 \u0026amp;\u0026amp; num[i] != num[i-1])) { int lo = i + 1, hi = num.length - 1, sum = 0 - num[i]; while (lo \u0026lt; hi) { if (num[lo] + num[hi] == sum) { res.add(Arrays.asList(num[i], num[lo], num[hi])); while (lo \u0026lt; hi \u0026amp;\u0026amp; num[lo] == num[lo+1]) lo++; while (lo \u0026lt; hi \u0026amp;\u0026amp; num[hi] == num[hi-1]) hi--; lo++; hi--; } else if (num[lo] + num[hi] \u0026lt; sum) { lo++; } else { hi--; } } } } return res; } // ========================  // 方法二: 排序 + 二分搜索 O(n^2 * logn)  // ========================  public List\u0026lt;List\u0026lt;Integer\u0026gt;\u0026gt; threeSum0(int[] nums) { Arrays.sort(nums); List\u0026lt;List\u0026lt;Integer\u0026gt;\u0026gt; res = new ArrayList\u0026lt;\u0026gt;(); for (int i = 0; i \u0026lt; nums.length - 2; i++) { if (i \u0026gt; 0 \u0026amp;\u0026amp; nums[i] == nums[i - 1]) { continue; } List\u0026lt;int[]\u0026gt; twoSumList = twoSum(nums, i + 1, nums.length - 1, 0 - nums[i]); if (!twoSumList.isEmpty()) { for (int[] twoSumArray: twoSumList) { res.add(new ArrayList\u0026lt;\u0026gt;(Arrays.asList( nums[i], twoSumArray[0], twoSumArray[1] ))); } } } return res; } private List\u0026lt;int[]\u0026gt; twoSum(int[] nums, int lo, int hi, int target) { List\u0026lt;int[]\u0026gt; list = new ArrayList\u0026lt;\u0026gt;(); for (int i = lo; i \u0026lt;= hi - 1; i++) { if (i \u0026gt; lo \u0026amp;\u0026amp; nums[i] == nums[i - 1]) { continue; } // target = a + b  int a = nums[i]; int bIndex = binarySearch(nums, i + 1, hi, target - a); if (bIndex != -1) { list.add(new int[]{ a, nums[bIndex] }); } } return list; } // 二分搜索  // =============================  // 用 HashSet 可以将查询复杂度降低到 O(1)  // =============================  private int binarySearch(int[] nums, int lo, int hi, int target) { while (lo \u0026lt;= hi) { int m = lo + ((hi - lo) \u0026gt;\u0026gt; 1); if (nums[m] == target) { return m; } else if (nums[m] \u0026gt; target) { hi = m - 1; } else { lo = m + 1; } } return -1; } } 最接近 target 的三个数之和 import java.util.Arrays; // 3 个数字和最接近 target public class Sum3Closest { public int threeSumClosest(int[] nums, int target) { // O(nlogn)  Arrays.sort(nums); int min = nums[0] + nums[1] + nums[nums.length - 1]; // O(n^2)  for (int i = 0; i \u0026lt; nums.length - 2; i++) { int lo = i + 1; int hi = nums.length - 1; // =============================  // 这个地方不能是等于号  // =============================  while (lo \u0026lt; hi) { int sum = nums[i] + nums[lo] + nums[hi]; if (sum == target) { return sum; } else if (sum \u0026gt; target) { hi--; } else { lo++; } if (Math.abs(sum - target) \u0026lt; Math.abs(min - target)) { min = sum; } } } return min; } } 四个数之和 import java.util.ArrayList; import java.util.Arrays; import java.util.List; public class Sum4 { public List\u0026lt;List\u0026lt;Integer\u0026gt;\u0026gt; fourSum(int[] nums, int target) { List\u0026lt;List\u0026lt;Integer\u0026gt;\u0026gt; res = new ArrayList\u0026lt;\u0026gt;(); Arrays.sort(nums); for (int i = 0; i \u0026lt; nums.length - 3; i++) { if (i \u0026gt; 0 \u0026amp;\u0026amp; nums[i] == nums[i - 1]) { continue; } for (int j = i + 1; j \u0026lt; nums.length - 2; j++) { if (j \u0026gt; (i + 1) \u0026amp;\u0026amp; nums[j] == nums[j - 1]) { continue; } for (int k = j + 1; k \u0026lt; nums.length - 1; k++) { if (k \u0026gt; (j + 1) \u0026amp;\u0026amp; nums[k] == nums[k - 1]) { continue; } int index = binarySearch(nums, k + 1, nums.length - 1, target - nums[i] - nums[j] - nums[k]); if (index != -1) { res.add(new ArrayList(Arrays.asList( nums[i], nums[j], nums[k], nums[index] ))); } } } } return res; } // =============================  // 用 HashSet 可以将查询复杂度降低到 O(1)  // =============================  private int binarySearch(int[] nums, int lo, int hi, int target) { while (lo \u0026lt;= hi) { int m = lo + ((hi - lo) \u0026gt;\u0026gt; 1); if (nums[m] == target) { return m; } else if (nums[m] \u0026gt; target) { hi = m - 1; } else { lo = m + 1; } } return -1; } } 四个数之和第二种解法 import java.util.HashMap; import java.util.Map; // A、B、C、D 是 4 个数组 // // 计算多少对 A[i] + B[j] + C[k] + D[l] = 0 public class Sum4_2 { public int fourSumCount(int[] A, int[] B, int[] C, int[] D) { int[] E = sumAAndB(A, B); Map\u0026lt;Integer, Integer\u0026gt; map = toMap(E); int count = 0; for (int i = 0; i \u0026lt; C.length; i++) { for (int j = 0; j \u0026lt; D.length; j++) { int target = -(C[i] + D[j]); if (map.containsKey(target)) { // 我们得到的就是有几个  //  count += map.get(target); } } } return count; } private Map\u0026lt;Integer, Integer\u0026gt; toMap(int[] A) { Map\u0026lt;Integer, Integer\u0026gt; map = new HashMap\u0026lt;\u0026gt;(); for (int num: A) { if (map.containsKey(num)) { map.put(num, map.get(num) + 1); } else { map.put(num, 1); } } return map; } private int[] sumAAndB(int[] A, int[] B) { int[] E = new int[A.length * B.length]; for (int i = 0; i \u0026lt; A.length; i++) { for (int j = 0; j \u0026lt; B.length; j++) { E[i * A.length + j] = A[i] + B[j]; } } return E; } } "});index.add({'id':155,'href':'/docs/programmer-interview/algorithm/sumofsubarrayminimums/','title':"子数组的最小值之和",'content':"子数组的最小值之和 描述 原题 给定一个整数数组 A，找到 min(B) 的总和，其中 B 的范围为 A 的每个（连续）子数组。\n由于答案可能很大，因此返回答案模 10^9 + 7。\n示例：\n输入：[3,1,2,4]\r输出：17\r解释：\r子数组为 [3]，[1]，[2]，[4]，[3,1]，[1,2]，[2,4]，[3,1,2]，[1,2,4]，[3,1,2,4]。 最小值为 3，1，2，4，1，1，2，1，1，1，和为 17。\r题解 import java.util.Stack; // // 连续子数组里面的最小值 min 相加的和 // [3,1,2,4]: // // [3][1][2][4][3,1][1,2][2,4][3,1,2][1,2,4][3,1,2,4] // public class SumofSubarrayMinimums { public int sumSubarrayMins(int[] A) { Stack\u0026lt;Integer\u0026gt; stack = new Stack\u0026lt;Integer\u0026gt;(); // ==========================================  // 最左侧，第一个比 A[i] 小的值  // ==========================================  int[] leftMin = new int[A.length]; for (int i = 0; i \u0026lt; A.length; i++) { // ↓  // 这两个地方至少要有一个添加一个等于号, 否则就会遗漏  while (!stack.isEmpty() \u0026amp;\u0026amp; A[i] \u0026lt;= A[stack.peek()]) { stack.pop(); } leftMin[i] = stack.isEmpty() ? -1 : stack.peek(); stack.push(i); } // ==========================================  // 最右侧，第一个比 A[i] 小的值  // ==========================================  int[] rightMin = new int[A.length]; stack.clear(); for (int i = A.length - 1; i \u0026gt;= 0; i--) { // ↓  // 这两个地方至少要有一个添加一个等于号  while (!stack.isEmpty() \u0026amp;\u0026amp; A[i] \u0026lt; A[stack.peek()]) { stack.pop(); } rightMin[i] = stack.isEmpty() ? A.length : stack.peek(); stack.push(i); } long sum = 0; for (int i = 0; i \u0026lt; A.length; i++) { // =======================  // 这两段区间内的 subarray 有多少个 A[i] (min)  // =======================  sum += (A[i] * (i - leftMin[i]) * (rightMin[i] - i)); } return (int)(sum % (1e9 + 7)); } } "});index.add({'id':156,'href':'/docs/programmer-interview/algorithm/thirdmaximumnumber/','title':"第三大的数",'content':"第三大的数 描述 给定一个非空数组，返回此数组中第三大的数。如果不存在，则返回数组中最大的数。要求算法时间复杂度必须是 O(n)。\n示例 1:\n输入: [3, 2, 1]\r输出: 1\r解释: 第三大的数是 1.\r题解 // 返回第三大，如果不存在，返回最大的 // // Input: [3, 2, 1] // Output: 1 // Explanation: The third maximum is 1. // // Input: [2, 2, 3, 1] // Output: 1 // Explanation: Note that the third maximum here means the third maximum distinct number. // Both numbers with value 2 are both considered as second maximum. // // https://leetcode.com/problems/third-maximum-number/ public class ThirdMaximumNumber { public int thirdMax(int[] nums) { Integer maximumA = null; Integer maximumB = null; Integer maximumC = null; for (int num: nums) { if (maximumA == null || num == maximumA.intValue()) { maximumA = num; continue; } else if (num \u0026gt; maximumA.intValue()) { // A: 3, num: 5  maximumC = maximumB; maximumB = maximumA; maximumA = num; } else if (num \u0026lt; maximumA.intValue()) { if (maximumB == null || num == maximumB.intValue()) { maximumB = num; continue; } else if (num \u0026gt; maximumB) { maximumC = maximumB; maximumB = num; } else { if (maximumC == null || num == maximumC.intValue()) { maximumC = num; continue; } else { maximumC = Math.max(num, maximumC); } } } } return maximumC == null ? maximumA.intValue() : maximumC.intValue(); } } "});index.add({'id':157,'href':'/docs/programmer-interview/algorithm/topklargestnumbers/','title':"前K大数",'content':"前K大数 描述 原题 在一个数组中找到前K大的数\n题解 // https://www.lintcode.com/problem/top-k-largest-numbers/description // // Input: [3, 10, 1000, -99, 4, 100] and k = 3 // Output: [1000, 100, 10] import java.util.*; public class TopkLargestNumbers { public int[] topk(int[] nums, int k) { PriorityQueue\u0026lt;Integer\u0026gt; queue = new PriorityQueue\u0026lt;\u0026gt;(new Comparator\u0026lt;Integer\u0026gt;() { @Override public int compare(Integer o1, Integer o2) { return o1.compareTo(o2); } }); for (int num: nums) { queue.offer(num); if (queue.size() \u0026gt; k) { queue.poll(); } } // addFirst();  // addLast();  // removeFirst();  // removeLast();  int[] res = new int[queue.size()]; for (int i = queue.size() - 1; i \u0026gt;= 0; i--) { res[i] = queue.poll().intValue(); } // Error: int[] res = new int[list.size()];  //  // Integer[] res = new Integer[list.size()];  // list.toArray(res);  return res; } } "});index.add({'id':158,'href':'/docs/programmer-interview/algorithm/validmountainarray/','title':"有效的山脉数组",'content':"有效的山脉数组 原题 给定一个整数数组 A，如果它是有效的山脉数组就返回 true，否则返回 false。\n让我们回顾一下，如果 A 满足下述条件，那么它是一个山脉数组：\n A.length \u0026gt;= 3 在 0 \u0026lt; i \u0026lt; A.length - 1 条件下，存在 i 使得：  A[0] \u0026lt; A[1] \u0026lt; ... A[i-1] \u0026lt; A[i] A[i] \u0026gt; A[i+1] \u0026gt; ... \u0026gt; A[A.length - 1]    题解 // https://leetcode.com/problems/valid-mountain-array/ // // (1) A.length \u0026gt;= 3 // (2) There exists some i with 0 \u0026lt; i \u0026lt; A.length - 1 such that: // A[0] \u0026lt; A[1] \u0026lt; ... A[i-1] \u0026lt; A[i] // A[i] \u0026gt; A[i+1] \u0026gt; ... \u0026gt; A[B.length - 1] // public class ValidMountainArray { public boolean validMountainArray(int[] A) { if (A == null || A.length \u0026lt; 3) { return false; } int stopIndex = -1; for (int i = 1; i \u0026lt; A.length; i++) { if (A[i - 1] \u0026lt; A[i]) { continue; } else { stopIndex = i - 1; break; } } if (stopIndex == 0 /** 5 (stop) 1 2 3 4 */ || stopIndex == -1 /** 1 2 3 4 5, never stop */) { return false; } for (int i = stopIndex; i \u0026lt; A.length - 1; i++) { if (A[i] \u0026gt; A[i + 1]) { continue; } else { return false; } } return true; } } "});index.add({'id':159,'href':'/docs/programmer-interview/algorithm/validsudoku/','title':"有效的数独",'content':"有效的数独 描述 原题 判断一个 9x9 的数独是否有效。只需要根据以下规则，验证已经填入的数字是否有效即可。\n 数字 1-9 在每一行只能出现一次。 数字 1-9 在每一列只能出现一次。 数字 1-9 在每一个以粗实线分隔的 3x3 宫内只能出现一次。  题解 import java.util.HashMap; import java.util.HashSet; import java.util.Map; import java.util.Set; // https://leetcode.com/problems/valid-sudoku/ // // public class ValidSudoku { public boolean isValidSudoku(char[][] board) { int m = board.length; int n = board[0].length; Map\u0026lt;Integer, Set\u0026lt;Integer\u0026gt;\u0026gt; rowMap = new HashMap\u0026lt;\u0026gt;(); Map\u0026lt;Integer, Set\u0026lt;Integer\u0026gt;\u0026gt; colMap = new HashMap\u0026lt;\u0026gt;(); // 1 2 3  // 4 5 6  // 7 8 9  Map\u0026lt;Integer, Set\u0026lt;Integer\u0026gt;\u0026gt; smallBoxMap = new HashMap\u0026lt;\u0026gt;(); for (int i = 0; i \u0026lt; m; i++) { for (int j = 0; j \u0026lt; n; j++) { char c = board[i][j]; if (c == \u0026#39;.\u0026#39;) { continue; } int num = c - \u0026#39;0\u0026#39;; Set\u0026lt;Integer\u0026gt; rowSet = getOrCreate(rowMap, i + 1); if (!rowSet.add(num)) { return false; } Set\u0026lt;Integer\u0026gt; colSet = getOrCreate(colMap, j + 1); if (!colSet.add(num)) { return false; } int boxPos = 3 * (i / 3) + ((j / 3) % 3 + 1); Set\u0026lt;Integer\u0026gt; smallBoxSet = getOrCreate(smallBoxMap, boxPos); if (!smallBoxSet.add(num)) { return false; } } } return true; } private Set\u0026lt;Integer\u0026gt; getOrCreate(Map\u0026lt;Integer, Set\u0026lt;Integer\u0026gt;\u0026gt; map, int key) { if (map.containsKey(key)) { return map.get(key); } Set\u0026lt;Integer\u0026gt; set = new HashSet\u0026lt;\u0026gt;(); map.put(key, set); return set; } } "});index.add({'id':160,'href':'/docs/programmer-interview/algorithm/validtrianglenumber/','title':"有效三角形的个数",'content':"有效三角形的个数 描述 原题 给定一个包含非负整数的数组，你的任务是统计其中可以组成三角形三条边的三元组个数。\n示例 1:\n输入: [2,2,3,4]\r输出: 3\r解释:\r有效的组合是: 2,3,4 (使用第一个 2)\r2,3,4 (使用第二个 2)\r2,2,3\r题解 import java.util.Arrays; // 给定一个包含非负整数的数组，你的任务是计算从数组中选出的可以制作三角形的三元组数目，如果我们把它们作为三角形的边长。 // 非负 // // https://www.lintcode.com/problem/valid-triangle-number/description // public class ValidTriangleNumber { // ERROR: O(n ^ 2)，错误解法  public int triangleNumber(int[] nums) { // a + b \u0026gt; c  // c \u0026lt; a + b  //  // 1 2 3 4  Arrays.sort(nums); int count = 0; // 2 2 3 4  // ↑  // 2, 2, 4  // 2, 3, 4  // 2, 3, 4  // 2, 2, 3  for (int i = 0; i \u0026lt; nums.length - 2; i++) { int lo = i + 1; int hi = nums.length - 1; // 0 1 2 3 4 5 6 7  // ↑ ↑  // ↑ ↑  while (lo \u0026lt; hi) { // 最短两边 \u0026gt; 最长一边  // 2 2 3 4  // ↑ (2 + 2 不大于 4, 这个时候增加 lo 和减少 hi 都可能成立，所以无法确定)  // ======================  // ERROR  // ======================  if (nums[lo] + nums[i] \u0026gt; nums[hi]) { count += (hi - lo); lo++; } else { hi--; } } } return count; } // O(n ^ 2) 正确解法  public int triangleNumber0(int[] nums) { // a + b \u0026gt; c  // c \u0026lt; a + b  //  // 1 2 3 4  Arrays.sort(nums); int count = 0; // nums[i] 代表的就是最长一边  for (int i = nums.length - 1; i \u0026gt;= 2; i--) { int lo = 0; int hi = i - 1; // 0 1 2 3 4 5 6 7  // ↑ ↑  // ↑ ↑  while (lo \u0026lt; hi) { // 最短两边 \u0026gt; 最长一边  if (nums[lo] + nums[hi] \u0026gt; nums[i]) { count += (hi - lo); hi--; } else { lo++; } } } return count; } // O(n ^ 3)  public int triangleNumber1(int[] nums) { // a + b \u0026gt; c  // c \u0026lt; a + b  //  // 1 2 3 4  Arrays.sort(nums); int count = 0; for (int i = 0; i \u0026lt; nums.length - 2; i++) { for (int j = i + 1; j \u0026lt; nums.length - 1; j++) { for (int k = j + 1; k \u0026lt; nums.length; k++) { if (nums[i] + nums[j] \u0026gt; nums[k]) { count++; } } } } return count; } } "});index.add({'id':161,'href':'/docs/programmer-interview/algorithm/combinationsum/','title':"组合总和",'content':"组合总和 下属题目，所有数字均是正整数\nCombination Sum 原题 一个数组，从这个数组中找出所有相加等于 target 的元素的组合，数组中的每一个数字可以被多次重复选取。\n 数组无重复数字。\n import java.util.ArrayList; import java.util.List; // Input: candidates = [2,3,5], target = 8, // A solution set is: // [ // [2,2,2,2], // [2,3,3], // [3,5] // ] // // candidates 里面没有重复数字 // 每一个 candidate 可以重复使用多次 // // 时间复杂度可以转为，见这个帖子分析 // https://leetcode.com/problems/combination-sum/discuss/16634/if-asked-to-discuss-the-time-complexity-of-your-solution-what-would-you-say // // 每个元素有 ceil(target / element) 个 // 展开后的数组个数为 n\u0026#39; = ceil(target / element) * n // 最后时间复杂度为 O(k * 2 ^ n\u0026#39;) // public class CombinationSum { public List\u0026lt;List\u0026lt;Integer\u0026gt;\u0026gt; combinationSum(int[] candidates, int target) { List\u0026lt;List\u0026lt;Integer\u0026gt;\u0026gt; res = new ArrayList\u0026lt;\u0026gt;(); helper(candidates, res, new ArrayList\u0026lt;Integer\u0026gt;(), 0, 0, target); return res; } private void helper(int[] candidates, List\u0026lt;List\u0026lt;Integer\u0026gt;\u0026gt; res, List\u0026lt;Integer\u0026gt; cur, int curSum, int index, int target) { if (curSum \u0026gt; target) { return; } if (curSum == target) { res.add(new ArrayList\u0026lt;\u0026gt;(cur)); return; } for (int i = index; i \u0026lt; candidates.length; i++) { cur.add(candidates[i]); // 之所以不是 i + 1 的原因是因为这道题的数字: 可重复使用  helper(candidates, res, cur, curSum + candidates[i], i, target); cur.remove(cur.size() - 1); } } } Combination Sum 2 原题 这次增加了限制条件：\n 数组可能包含重复数字 数组中的每个数字只能被选取一次，不能多次重复使用  import java.util.ArrayList; import java.util.Arrays; import java.util.List; // Input: candidates = [10,1,2,7,6,1,5], target = 8, // A solution set is: // [ // [1, 7], // [1, 2, 5], // [2, 6], // [1, 1, 6] // ] // // candidates 可能有重复数字 // 所有数字只让用 1 次 // // 时间复杂度: // 假设一个 solution 平均需要 k 个数字才能解决，那么 // 时间复杂度为 O(k * 2 ^ n)，我们需要 O(k) 时间来拷贝结果，总共 2^n 次方的选择方式 // // 我们从 n 个数选择 1 个，有多少组 // 我们从 n 个数选择 2 个，有多少组 // 我们从 n 个数选择 3 个，有多少组 // // C(n, 0) + C(n, 1) + C(n, 2) + ... + C(n, n) = 2 ^ n 一共这么多可能的解决方案 // // 0, 0, 0, 0, 0, 0, 0, 0 public class CombinationSum2 { public List\u0026lt;List\u0026lt;Integer\u0026gt;\u0026gt; combinationSum2(int[] candidates, int target) { List\u0026lt;List\u0026lt;Integer\u0026gt;\u0026gt; res = new ArrayList\u0026lt;\u0026gt;(); Arrays.sort(candidates); helper(candidates, res, new ArrayList\u0026lt;Integer\u0026gt;(), 0, 0, target); return res; } private void helper(int[] candidates, List\u0026lt;List\u0026lt;Integer\u0026gt;\u0026gt; res, List\u0026lt;Integer\u0026gt; cur, int curSum, int index, int target) { if (curSum \u0026gt; target) { return; } // 第一种情况:  //  // 这种情况会多跳过，相当于多层递归之间有交叉的部分  //  // if (index - 1 \u0026gt;= 0 \u0026amp;\u0026amp; candidates[index - 1] == candidates[index]) {  // return;  // }  // ============================  // 结束判断优先于越界判断  // ============================  if (curSum == target) { res.add(new ArrayList\u0026lt;\u0026gt;(cur)); return; } // ============================  // 越界判断低于结束判断  // ============================  if (index \u0026gt;= candidates.length) { return; } for (int i = index; i \u0026lt; candidates.length; i++) { // 以这个为例  // 1 1 6 7  //  // index = 0, i = 0 A  // index = 1, i = 1 B [如果使用了第一种情况，那么相当与 B 轮和 A 轮连在一起了，B 轮的 1 == A 轮的 1，所以 return 了]  // index = 2, i = 2  // index = 3, i = 3  // index = 2, i = 3  // index = 1, i = 2  // index = 3, i = 3  // index = 1, i = 3  //  // ↓ ↓  // index = 0, i = 1 [1, 1, 6, 7] 跳过了，两个 1 使用了 1 个。也就是说这是单就这一轮的限制，这是平级的限制，没有 A 轮和 B 轮之间的交叉限制  // index = 2, i = 2  // index = 3, i = 3  // index = 2, i = 3  //  // index = 0, i = 2  // index = 3, i = 3  //  // index = 0, i = 3  if (i \u0026gt; index \u0026amp;\u0026amp; candidates[i] == candidates[i - 1]) { continue; } cur.add(candidates[i]); helper(candidates, res, cur, curSum + candidates[i], i + 1, target); cur.remove(cur.size() - 1); } } } Combination Sum 3 找出所有相加之和为 n 的 k 个数的组合。组合中只允许含有 1 - 9 的正整数，并且每种组合中不存在重复的数字。\n 这次还限定了可使用元素的个数  import java.util.ArrayList; import java.util.List; // Input: k = 3, n = 9 // Output: [[1,2,6], [1,3,5], [2,3,4]] // // 3 个数相加等于 9 // // 时间复杂度 C(n, k) * O(k) public class CombinationSum3 { public List\u0026lt;List\u0026lt;Integer\u0026gt;\u0026gt; combinationSum3(int k, int n) { int[] array = buildArray(9); List\u0026lt;List\u0026lt;Integer\u0026gt;\u0026gt; res = new ArrayList\u0026lt;List\u0026lt;Integer\u0026gt;\u0026gt;(); helper(res, array, new ArrayList\u0026lt;\u0026gt;(), k, n, 0, 0); return res; } private void helper(List\u0026lt;List\u0026lt;Integer\u0026gt;\u0026gt; res, int[] nums, List\u0026lt;Integer\u0026gt; cur, int k, int sum, int curSum, int begin) { if (cur.size() == k \u0026amp;\u0026amp; curSum == sum) { res.add(new ArrayList\u0026lt;\u0026gt;(cur)); return; } if (cur.size() \u0026gt; k || curSum \u0026gt; sum) { return; } for (int i = begin; i \u0026lt; nums.length; i++) { cur.add(nums[i]); helper(res, nums, cur, k, sum, nums[i] + curSum, i + 1); cur.remove(cur.size() - 1); } } private int[] buildArray(int n) { int[] array = new int[n]; for (int i = 1; i \u0026lt;= n; i++) { array[i - 1] = i; } return array; } } "});index.add({'id':162,'href':'/docs/programmer-interview/algorithm/combinations/','title':"组合",'content':"组合 描述 原题 给定两个整数 n 和 k，返回 1 \u0026hellip; n 中所有可能的 k 个数的组合。\n示例:\n输入: n = 4, k = 2\r输出:\r[\r[2,4],\r[3,4],\r[2,3],\r[1,2],\r[1,3],\r[1,4],\r]\r题解 import java.util.ArrayList; import java.util.List; // Input: n = 4, k = 2 // Output: // [ // [2,4], // [3,4], // [2,3], // [1,2], // [1,3], // [1,4], // ] // // 时间复杂度看起来像是 C(n, k)，从 n 个数里面选择 k 个 // 所以总的时间复杂度为 C(n, k) * O(k) public class Combinations { public List\u0026lt;List\u0026lt;Integer\u0026gt;\u0026gt; combine(int n, int k) { List\u0026lt;List\u0026lt;Integer\u0026gt;\u0026gt; res = new ArrayList\u0026lt;\u0026gt;(); int[] array = buildArray(n); helper(res, new ArrayList\u0026lt;Integer\u0026gt;(), array, k, 0); return res; } private void helper(List\u0026lt;List\u0026lt;Integer\u0026gt;\u0026gt; res, List\u0026lt;Integer\u0026gt; cur, int[] array, int k, int begin) { // Base Case  // 得到之后，需要花费 O(K) 来拷贝结果到 res 里面  //  if (cur.size() == k) { res.add(new ArrayList\u0026lt;\u0026gt;(cur)); return; } for (int i = begin; i \u0026lt; array.length; i++) { cur.add(array[i]); helper(res, cur, array, k, i + 1); cur.remove(cur.size() - 1); } } private int[] buildArray(int n) { int[] array = new int[n]; for (int i = 1; i \u0026lt;= n; i++) { array[i - 1] = i; } return array; } } "});index.add({'id':163,'href':'/docs/programmer-interview/algorithm/differentwaystoaddparentheses/','title':"为运算表达式设计优先级",'content':"为运算表达式设计优先级 描述 原题 给定一个含有数字和运算符的字符串，为表达式添加括号，改变其运算优先级以求出不同的结果。你需要给出所有可能的组合的结果。有效的运算符号包含 +, - 以及 * 。\n输入: \u0026quot;2-1-1\u0026quot;\r输出: [0, 2]\r解释: ((2-1)-1) = 0 (2-(1-1)) = 2\r 头条面试题\n 题解 import java.util.LinkedList; import java.util.List; // 头条面试题 // // https://leetcode.com/problems/different-ways-to-add-parentheses/ // Input: \u0026#34;2*3-4*5\u0026#34; // Output: [-34, -14, -10, -10, 10] // Explanation: // (2*(3-(4*5))) = -34 // ((2*3)-(4*5)) = -14 // ((2*(3-4))*5) = -10 // (2*((3-4)*5)) = -10 // (((2*3)-4)*5) = 10 // // 只有 +、- 和 * // // 有几种不同的结果 public class DifferentWaysToAddParentheses { public List\u0026lt;Integer\u0026gt; diffWaysToCompute(String input) { List\u0026lt;Integer\u0026gt; ret = new LinkedList\u0026lt;Integer\u0026gt;(); for (int i = 0; i \u0026lt; input.length(); i++) { if (input.charAt(i) == \u0026#39;-\u0026#39; || input.charAt(i) == \u0026#39;*\u0026#39; || input.charAt(i) == \u0026#39;+\u0026#39; ) { String part1 = input.substring(0, i); String part2 = input.substring(i + 1); List\u0026lt;Integer\u0026gt; part1Ret = diffWaysToCompute(part1); List\u0026lt;Integer\u0026gt; part2Ret = diffWaysToCompute(part2); for (Integer p1:part1Ret) { for (Integer p2:part2Ret) { int c = 0; switch (input.charAt(i)) { case \u0026#39;+\u0026#39;: c = p1 + p2; break; case \u0026#39;-\u0026#39;: c = p1 - p2; break; case \u0026#39;*\u0026#39;: c = p1 * p2; break; } ret.add(c); } } } } if (ret.size() == 0) { // input 是一个单一数字  ret.add(Integer.valueOf(input)); } return ret; } } "});index.add({'id':164,'href':'/docs/programmer-interview/algorithm/game24/','title':"快算 24",'content':"快算 24 描述 原题 你有 4 张写有 1 到 9 数字的牌。你需要判断是否能通过 *，/，+，-，(，) 的运算得到 24。\n题解 import java.util.ArrayList; // Input: [4, 1, 8, 7] // Output: True // Explanation: (8-4) * (7-1) = 24 // // https://leetcode.com/articles/24-game/ public class Game24 { public boolean judgePoint24(int[] nums) { ArrayList A = new ArrayList\u0026lt;Double\u0026gt;(); for (int v: nums) { A.add((double) v); } return solve(A); } private boolean solve(ArrayList\u0026lt;Double\u0026gt; nums) { if (nums.size() == 0) return false; if (nums.size() == 1) return Math.abs(nums.get(0) - 24) \u0026lt; 1e-6; // ================================  // 挑选两个数  // ================================  for (int i = 0; i \u0026lt; nums.size(); i++) { for (int j = 0; j \u0026lt; nums.size(); j++) { if (i != j) { // ====================================  // 任意取出两个数 nums[i] 和 nums[j]  //  // 把剩余的那没有用到的数字放到 nums2 里面  // ====================================  ArrayList\u0026lt;Double\u0026gt; nums2 = new ArrayList\u0026lt;Double\u0026gt;(); for (int k = 0; k \u0026lt; nums.size(); k++) if (k != i \u0026amp;\u0026amp; k != j) { nums2.add(nums.get(k)); } // 运算符号 4 种  // 对取出来的 nums[i] 和 nums[j] 进行不同的四则运算  // 将所得结果重新放入到 nums2 里面  // 然后递归 nums2 这个新的数组  //  for (int k = 0; k \u0026lt; 4; k++) { if (k \u0026lt; 2 \u0026amp;\u0026amp; j \u0026gt; i) continue; if (k == 0) nums2.add(nums.get(i) + nums.get(j)); if (k == 1) nums2.add(nums.get(i) * nums.get(j)); if (k == 2) nums2.add(nums.get(i) - nums.get(j)); if (k == 3) { if (nums.get(j) != 0) { nums2.add(nums.get(i) / nums.get(j)); } else { continue; } } if (solve(nums2)) return true; nums2.remove(nums2.size() - 1); } } } } return false; } } "});index.add({'id':165,'href':'/docs/programmer-interview/algorithm/generateparentheses/','title':"生成括号对",'content':"生成括号对 描述 原题 数字 n 代表生成括号的对数，请你设计一个函数，用于能够生成所有可能的并且 有效的 括号组合。\n输入：n = 3\r输出：[\r\u0026quot;((()))\u0026quot;,\r\u0026quot;(()())\u0026quot;,\r\u0026quot;(())()\u0026quot;,\r\u0026quot;()(())\u0026quot;,\r\u0026quot;()()()\u0026quot;\r]\r题解 import java.util.LinkedList; import java.util.List; // 时间复杂度，总的括号对个数是 Catalan number 个 // O(C(2n, n) / (n + 1)) // public class GenerateParentheses { public List\u0026lt;String\u0026gt; generateParenthesis(int n) { List\u0026lt;String\u0026gt; res = new LinkedList\u0026lt;\u0026gt;(); helper(res, \u0026#34;\u0026#34;, 0, 0, n); return res; } private void helper(List\u0026lt;String\u0026gt; res, String cur, int open, int close, int n) { if (open == n \u0026amp;\u0026amp; close == n) { res.add(cur); return; } if (open \u0026lt; n) { helper(res, cur + \u0026#34;(\u0026#34;, open + 1, close, n); } if (close \u0026lt; open) { helper(res, cur + \u0026#34;)\u0026#34;, open, close + 1, n); } } } "});index.add({'id':166,'href':'/docs/programmer-interview/algorithm/lettercasepermutation/','title':"字母大小写全排列",'content':"字母大小写全排列 描述 给定一个字符串S，通过将字符串S中的每个字母转变大小写，我们可以获得一个新的字符串。返回所有可能得到的字符串集合。\n题解 import java.util.ArrayList; import java.util.List; // Examples: // Input: S = \u0026#34;a1b2\u0026#34; // Output: [\u0026#34;a1b2\u0026#34;, \u0026#34;a1B2\u0026#34;, \u0026#34;A1b2\u0026#34;, \u0026#34;A1B2\u0026#34;]  // Input: S = \u0026#34;3z4\u0026#34; // Output: [\u0026#34;3z4\u0026#34;, \u0026#34;3Z4\u0026#34;]  // Input: S = \u0026#34;12345\u0026#34; // Output: [\u0026#34;12345\u0026#34;] // // 假设字符串中包含 k 个需要转的字符 // 那么总共有 2 ^ k 个状态，base case 需要拷贝，那么就是 O(n) // 所以复杂度为 O(n * 2^k) public class LetterCasePermutation { public List\u0026lt;String\u0026gt; letterCasePermutation(String S) { List\u0026lt;String\u0026gt; res = new ArrayList\u0026lt;\u0026gt;(); helper(res, S.toCharArray(), 0); return res; } private void helper(List\u0026lt;String\u0026gt; res, char[] array, int index) { if (index == array.length) { res.add(new String(array)); return; } // 这个地方不用 for 循环了  //  // a 1 b 2  // ↑  // ↑  // ↑  // ↑  // a 1 b 2  // ↑  // a 1 b 2  // ↑  // a 1 b 2  // ↑  if ((array[index] \u0026gt;= \u0026#39;a\u0026#39; \u0026amp;\u0026amp; array[index] \u0026lt;= \u0026#39;z\u0026#39;) || (array[index] \u0026gt;= \u0026#39;A\u0026#39; \u0026amp;\u0026amp; array[index] \u0026lt;= \u0026#39;Z\u0026#39;)) { array[index] = toUpperCase(array[index]); helper(res, array, index + 1); array[index] = toLowerCase(array[index]); helper(res, array, index + 1); } else { helper(res, array, index + 1); } } private char toLowerCase(char c) { return c \u0026gt;= \u0026#39;A\u0026#39; \u0026amp;\u0026amp; c \u0026lt;= \u0026#39;Z\u0026#39; ? (char)(c + 32) : c; } private char toUpperCase(char c) { return c \u0026gt;= \u0026#39;a\u0026#39; \u0026amp;\u0026amp; c \u0026lt;= \u0026#39;z\u0026#39; ? (char)(c - 32) : c; } } "});index.add({'id':167,'href':'/docs/programmer-interview/algorithm/lettercombinationsofaphonenumber/','title':"电话号码的字母组合",'content':"电话号码的字母组合 描述 给定一个仅包含数字 2-9 的字符串，返回所有它能表示的字母组合。\n给出数字到字母的映射如下（与电话按键相同）。注意 1 不对应任何字母。\n题解 import java.util.HashMap; import java.util.LinkedList; import java.util.List; import java.util.Map; // 时间复杂度为 O(3 ^ N * 4 ^ M) 次方个 // // 每一个数有 3 种选法的有 N 个 // 每一个数有 4 种选法的有 M 个 // public class LetterCombinationsofaPhoneNumber { static Map\u0026lt;Character, String\u0026gt; map = new HashMap\u0026lt;\u0026gt;(); static { map.put(\u0026#39;2\u0026#39;, \u0026#34;abc\u0026#34;); map.put(\u0026#39;3\u0026#39;, \u0026#34;def\u0026#34;); map.put(\u0026#39;4\u0026#39;, \u0026#34;ghi\u0026#34;); map.put(\u0026#39;5\u0026#39;, \u0026#34;jkl\u0026#34;); map.put(\u0026#39;6\u0026#39;, \u0026#34;mno\u0026#34;); map.put(\u0026#39;7\u0026#39;, \u0026#34;pqrs\u0026#34;); map.put(\u0026#39;8\u0026#39;, \u0026#34;tuv\u0026#34;); map.put(\u0026#39;9\u0026#39;, \u0026#34;wxyz\u0026#34;); } public List\u0026lt;String\u0026gt; letterCombinations(String digits) { List\u0026lt;String\u0026gt; res = new LinkedList\u0026lt;\u0026gt;(); if (digits == null || digits.length() == 0) { return res; } helper(res, digits, 0, \u0026#34;\u0026#34;); return res; } private void helper(List\u0026lt;String\u0026gt; res, String digits, int index, String cur) { if (index == digits.length()) { res.add(cur); } else { String chs = map.get(digits.charAt(index)); for (char c: chs.toCharArray()) { helper(res, digits, index + 1, cur + c); } } } } "});index.add({'id':168,'href':'/docs/programmer-interview/algorithm/nqueues/','title':"N 皇后",'content':"N 皇后 描述 原题 n 皇后问题研究的是如何将 n 个皇后放置在 n×n 的棋盘上，并且使皇后彼此之间不能相互攻击。\n题解 import java.util.ArrayList; import java.util.Arrays; import java.util.LinkedList; import java.util.List; public class NQueues { public List\u0026lt;List\u0026lt;String\u0026gt;\u0026gt; solveNQueens(int n) { char[][] grid = new char[n][n]; for (int i = 0; i \u0026lt; n; i++) { Arrays.fill(grid[i], \u0026#39;.\u0026#39;); } List\u0026lt;List\u0026lt;String\u0026gt;\u0026gt; res = new ArrayList\u0026lt;List\u0026lt;String\u0026gt;\u0026gt;(); helper(res, grid, 0, n); return res; } // 方法是对于固定的列 colIndex，依次试探第 0 1 2 ... n 行，然后看是否 OK，如果 OK，试探 colIndex + 1 列  // colIndex == n 的时候，就可以返回了  private void helper(List\u0026lt;List\u0026lt;String\u0026gt;\u0026gt; res, char[][] grid, int colIndex /** 对于固定的列 */, int n) { if (colIndex == n) { res.add(construct(grid)); return; } for (int r = 0; r \u0026lt; n; r++) { // 对于第 r 行，试探着放第 0、1、2、...、n 列，然后看是否 valid，  // valid 则用 \u0026#39;Q\u0026#39; 替代，然后继续放  if (isValid(grid, r, colIndex, n)) { grid[r][colIndex] = \u0026#39;Q\u0026#39;; helper(res, grid, colIndex + 1, n); grid[r][colIndex] = \u0026#39;.\u0026#39;; } } } private boolean isValid(char[][] grid, int r, int c, int n) { for (int i = 0; i \u0026lt; n; i++) { // 行  if (grid[r][i] == \u0026#39;Q\u0026#39;) { return false; } // 列  if (grid[i][c] == \u0026#39;Q\u0026#39;) { return false; } } return isDiagonalValid(grid, r, c, n); // 斜坡  } private boolean isDiagonalValid(char[][] grid, int r, int c, int n) { for (int i = r + 1, j = c + 1; i \u0026lt; n \u0026amp;\u0026amp; j \u0026lt; n; i++, j++) { if (grid[i][j] == \u0026#39;Q\u0026#39;) { return false; } } for (int i = r - 1, j = c - 1; i \u0026gt;= 0 \u0026amp;\u0026amp; j \u0026gt;= 0; i--, j--) { if (grid[i][j] == \u0026#39;Q\u0026#39;) { return false; } } for (int i = r + 1, j = c - 1; i \u0026lt; n \u0026amp;\u0026amp; j \u0026gt;= 0; i++, j--) { if (grid[i][j] == \u0026#39;Q\u0026#39;) { return false; } } for (int i = r - 1, j = c + 1; i \u0026gt;= 0 \u0026amp;\u0026amp; j \u0026lt; n; i--, j++) { if (grid[i][j] == \u0026#39;Q\u0026#39;) { return false; } } return true; } private List\u0026lt;String\u0026gt; construct(char[][] board) { List\u0026lt;String\u0026gt; res = new LinkedList\u0026lt;String\u0026gt;(); for(int i = 0; i \u0026lt; board.length; i++) { String s = new String(board[i]); res.add(s); } return res; } } "});index.add({'id':169,'href':'/docs/tutorial/git/git-ignore/','title':"Git .gitignore 文件",'content':"Git .gitignore 文件 Git 可以使用 .gitignore 文件来对工作区的某个目录、某个文件等设置忽略，忽略后这些文件的状态变化，将不会被记录在 git 中，也不会被 push 到远程服务器上。\n如果想要忽略项目里面的某些文件夹，比如 build/、target/、node_modules/ 等文件夹，不 push 到服务器上，就需要在相应的目录中添加一个 .gitignore 文件，并在里面将这些文件夹的名字给加上。\n.gitignore 的作用范围 作用范围：.gitignore 文件所处的目录及其子目录。\n如何查看哪些文件被忽略了 git status --ignored # 或 git check-ignore -v example.jpg .gitignore 文件语法  # 开始的行代表注释 *：代表任意多个字符，?：代表一个字符，[abc] 代表可选字符范围等 **：匹配任意数量的目录 名称以 / 开头：只忽略此目录下的文件，对于子目录中的文件不忽略 名称以 / 结尾：忽略整个目录，同名文件不忽略；否则同名文件和目录都被忽略 名称以 ! 开头：代表不忽略这个文件  示例 # 任何目录下面的 .DS_Store 文件都会被忽略 .DS_Store # 忽略整个目录 node_modules/ logs/ # 忽略所有以 log 结尾的文件，但是 example.log 不被忽略 *.log !example.log # 忽略 abc 文件夹下面的以 log 结尾的文件，注意：子目录不会被忽略 abc/*.log # 忽略 abc 文件夹以及所有子目录下面的以 log 结尾的文件 abc/**/*.log 快速生成一份 .gitingore 忽略文件 如果你不知道应该忽略哪些文件，那么请访问 gitignore.io 网站，通过输入你的框架名称、IDE 名称、开发语言等来生成一份 .gitignore 文件。\n参考  How to Use a .gitignore File  扫描下面二维码，在手机端阅读：\n"});index.add({'id':170,'href':'/categories/','title':"Categories",'content':""});index.add({'id':171,'href':'/tags/','title':"Tags",'content':""});index.add({'id':172,'href':'/tags/war/','title':"War",'content':""});index.add({'id':173,'href':'/posts/','title':"博客",'content':""});index.add({'id':174,'href':'/categories/%E7%BC%96%E7%A8%8B/','title':"编程",'content':""});index.add({'id':175,'href':'/','title':"首页",'content':"赵坤的个人网站 本博客将致力于整理、分析 Java、前端 等开发者生态圈的开源项目的教程、源码等，我会参阅大量书籍，一一对这些基础知识点抽丝剥茧，并匹配大量图表，为大家呈现出它们最本质的面目。\n通过阅读和分析开源项目等，可以增长自己的工程实践能力，可以让自己从代码中汲取养分，也可以学习到他人的设计权衡之道，其对于自己成长的重要性不言而喻！\n欢迎大家关注【我是前端喵】公众号，这里有最新、最全、更新最及时的前端文章收录：\n"});index.add({'id':176,'href':'/tags/jsp/','title':"JSP",'content':""});index.add({'id':177,'href':'/tags/mq/','title':"MQ",'content':""});index.add({'id':178,'href':'/tags/spring/','title':"Spring",'content':""});index.add({'id':179,'href':'/tags/jax-ws/','title':"JAX-WS",'content':""});index.add({'id':180,'href':'/tags/oracle/','title':"Oracle",'content':""});index.add({'id':181,'href':'/tags/ant/','title':"Ant",'content':""});index.add({'id':182,'href':'/tags/struts/','title':"Struts",'content':""});index.add({'id':183,'href':'/tags/%E7%BC%93%E5%AD%98/','title':"缓存",'content':""});index.add({'id':184,'href':'/tags/nginx/','title':"Nginx",'content':""});index.add({'id':185,'href':'/tags/%E4%BF%A1%E6%81%AF/','title':"信息",'content':""});index.add({'id':186,'href':'/categories/%E7%A7%91%E6%8A%80/','title':"科技",'content':""});index.add({'id':187,'href':'/tags/%E7%B3%BB%E7%BB%9F%E4%B8%80%E8%87%B4%E6%80%A7/','title':"系统一致性",'content':""});index.add({'id':188,'href':'/tags/java/','title':"Java",'content':""});index.add({'id':189,'href':'/docs/','title':"Docs",'content':""});})();