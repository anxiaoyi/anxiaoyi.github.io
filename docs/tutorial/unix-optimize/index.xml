<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>UNIX 性能优化 on 赵坤的个人网站</title>
    <link>https://kunzhao.org/docs/tutorial/unix-optimize/</link>
    <description>Recent content in UNIX 性能优化 on 赵坤的个人网站</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-cn</language><atom:link href="https://kunzhao.org/docs/tutorial/unix-optimize/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>平均负载</title>
      <link>https://kunzhao.org/docs/tutorial/unix-optimize/avg-load/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/tutorial/unix-optimize/avg-load/</guid>
      <description>平均负载  作者：赵坤
 uptime 命令 了解负载情况：
$ uptime 22:39:37 up 2:47, 1 user, load average: 1.44, 1.12, 0.79 含义：
# 当前时间 22:39:37 # 系统运行多久了 up 2:47 # 当前有几个用户登录 1 user # 过去 1 分钟、5 分钟、15 分钟的平均负载 load average: 1.44, 1.12, 0.79 平均负载的含义  平均负载是指单位时间内，系统处于可运行状态和不可中断状态的平均进程数，也就是平均活跃进程数。它不仅包括了正在使用 CPU 的进程，还包括等待 CPU 和等待 I/O 的进程。
  可运行状态的进程，是指正在使用 CPU 或者正在等待 CPU 的进程，也就是我们常用 ps 命令看到的，处于 R 状态（Running 或 Runnable）的进程。 不可中断状态的进程则是正处于内核态关键流程中的进程，并且这些流程是不可打断的，比如最常见的是等待硬件设备的 I/O 响应，也就是我们在 ps 命令中看到的 D 状态（Uninterruptible Sleep，也称为 Disk Sleep）的进程。  $ ps -efl F S UID PID PPID C PRI NI ADDR SZ WCHAN STIME TTY TIME CMD 4 S root 1 0 0 80 0 - 42420 - 19:51 ?</description>
    </item>
    
    <item>
      <title>CPU 上下文切换</title>
      <link>https://kunzhao.org/docs/tutorial/unix-optimize/context-switch/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/tutorial/unix-optimize/context-switch/</guid>
      <description>CPU 上下文切换  作者：赵坤
 CPU 上下文  CPU 上下文是 CPU 在运行任何任务前，必须的依赖环境。在每个任务运行前，CPU 需要知道任务从哪里加载、又从哪里开始运行，所以这些环境通常包括 CPU 寄存器和程序计数器等。
 查看系统上下文切换情况 可以使用 vmstat 查询：
# 每隔 5 秒查询一次 $ vmstat 5 procs -----------memory---------- ---swap-- -----io---- -system-- ------cpu----- r b swpd free buff cache si so bi bo in cs us sy id wa st 0 0 256 170532 136656 3361432 0 0 38 53 189 557 6 2 92 0 0 0 0 256 170060 136668 3362284 0 0 0 62 441 785 2 1 97 0 0 0 0 256 170320 136676 3362360 0 0 0 13 706 1002 3 1 97 0 0  cs：每秒上下文切换的次数</description>
    </item>
    
    <item>
      <title>CPU 飙升或 load 飙升</title>
      <link>https://kunzhao.org/docs/tutorial/unix-optimize/high-cpu-and-load/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/tutorial/unix-optimize/high-cpu-and-load/</guid>
      <description>CPU 飙升或 load 飙升 CPU 使用率飙升怎么办 ? 通过 top、ps、pidstat 等工具，你能够轻松找到 CPU 使用率较高（比如 100% ）的进程。接下来，你可能又想知道，占用 CPU 的到底是代码里的哪个函数呢？找到它，你才能更高效、更针对性地进行优化。
哪种工具适合在第一时间分析进程的 CPU 问题呢？我的推荐是 perf。perf 是 Linux 2.6.31 以后内置的性能分析工具。它以性能事件采样为基础，不仅可以分析系统的各种事件和内核性能，还可以用来分析指定应用程序的性能问题。
# -g开启调用关系分析，-p指定php-fpm的进程号21515 $ perf top -g -p 21515  用户 CPU 和 Nice CPU 高，说明用户态进程占用了较多的 CPU，所以应该着重排查进程的性能问题。 系统 CPU 高，说明内核态占用了较多的 CPU，所以应该着重排查内核线程或者系统调用的性能问题。  CPU 毛刺  参考  某服务所在机器统计显示，其 CPU 使用率在高峰时段出现毛刺。
 查看 CPU 1 分钟平均负载，发现 1 分钟平均负载有高有低，波动明显。说明机器上有些进程使用 CPU 波动很大。 登录机器排查进程，使用top指令。因为 CPU 会明显上升，重点怀疑使用 CPU 总时间高的进程，在打开 top 后，使用shift +t可以按照 CPU TIME 进行排序。 perf top -p 45558 gcore pid 可以保留堆栈信息，明确看到负载的位置  Java 高 CPU 传统的方案：</description>
    </item>
    
    <item>
      <title>内存管理</title>
      <link>https://kunzhao.org/docs/tutorial/unix-optimize/memory/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/tutorial/unix-optimize/memory/</guid>
      <description>内存 内存分配 虚拟内存空间的管理，每个进程看到的是独立的、互不干扰的虚拟地址空间。
首先给出 32 位系统虚拟内存空间分布图。从程序的视角看，有 2^32 = 4G 的内存可以供自己使用。当然最顶部的空间是给内核使用的，下面的才是用户可以使用的。
 只读段，即 Text Segment，存放二进制可执行代码 数据段，即 Data Segment，存放静态常量 数据段上面其实还有 BSS Segment，存放未初始化的静态常量 内核代码也是 ELF 格式的，也有上述这 3 个段  在 C 语言中，内存分配采用 malloc() 函数进行分配。底层实现：
 申请的内存小于 128K，使用 brk() 函数完成，也就是从上图中的堆中分配的内存 申请的内存大于 128K，使用 mmap() 内存映射函数完成，也就是从上图中的文件映射中分配的内存  内存回收 应用程序应通过 free() 或 unmap() 来释放内存。
当然，系统也会监管进程的内存，当发现系统内存不足时，会采取措施：
 使用 LRU 算法回收缓存 回收不常访问的内存，写到 Swap 区（位于硬盘上） 杀死进程  虚拟内存 分段机制 分段机制下的虚拟地址由两部分组成，段选择子和段内偏移量。段选择子就保存在咱们前面讲过的段寄存器里面。段选择子里面最重要的是段号，用作段表的索引。段表里面保存的是这个段的基地址、段的界限和特权等级等。虚拟地址中的段内偏移量应该位于 0 和段界限之间。如果段内偏移量是合法的，就将段基地址加上段内偏移量得到物理内存地址。
分段对内存区域的映射以程序为单位，内存不足，换入换出到磁盘的是整个程序，粒度比较大，产生大量磁盘 IO，而根据程序的局部性原理，程序运行时，某个时间段，一般只是频繁用到很小的一部分数据。那么可以利用更小粒度的内存分割和映射方法，这就是分页。
分页 (Paging) 对于物理内存，操作系统把它分成一块一块大小相同的页，这样更方便管理，例如有的内存页面长时间不用了，可以暂时写到硬盘上，称为换出。一旦需要的时候，再加载进来，叫做换入。这样可以扩大可用物理内存的大小，提高物理内存的利用率。
这个换入和换出都是以页为单位的。页面的大小一般为 4KB。为了能够定位和访问每个页，需要有个页表，保存每个页的起始地址，再加上在页内的偏移量，组成线性地址，就能对于内存中的每个位置进行访问了。
虚拟地址分为两部分，页号和页内偏移。页号作为页表的索引，页表包含物理页每页所在物理内存的基地址。这个基地址与页内偏移的组合就形成了物理内存地址。</description>
    </item>
    
    <item>
      <title>Linux tail 命令源码解析</title>
      <link>https://kunzhao.org/docs/tutorial/unix-optimize/tail/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/tutorial/unix-optimize/tail/</guid>
      <description>Linux tail 命令源码解析 基础用法 tail 命令是在 Linux 系统上经常使用的一个命令，其能快速查看文件尾部的内容。它的基本用法如下所示。
(1) -n 查看末尾指定行数的内容，n 代表的是 number 的意思：
$ tail -n 15 word-list.txt (2) -c 查看末尾指定字节数的内容：
$ tail -c 93 list-2.txt (3) -f 实时打印日志。某个文件的末尾有新的追加行的时候，立即在控制台上显示出来，经常用这个命令查看某个文件的实时输出的日志，方便跟踪问题：
tail -f nginx.log tail 还有一些其他用法，可以通过执行 man tail 来查看。
读取倒数 n 行源码 tail 命令从文件尾部来显示文件内容，那么它是如何做到从尾部动态或者静态的去显示文件呢，它使用中有哪些需要注意的地方呢？接下来就带大家分析一下 tail 命令的源码。
在 tail 源码顶部，即定义了一个常量，表示如果没有指定查看的长度 (tail abc.txt)，那么就默认显示这个文件后 10 行的内容：
/* Number of items to tail. */ #define DEFAULT_N_LINES 10 首先是打开文件：
fd = open (f-&amp;gt;name, O_RDONLY | O_BINARY); 然后调用 tail 函数，tail 函数内部会根据参数的不同，选择 tail_lines 还是 tail_bytes 来调用。再次我们选择 tail_lines 函数来解释。</description>
    </item>
    
    <item>
      <title>磁盘 I/O</title>
      <link>https://kunzhao.org/docs/tutorial/unix-optimize/io/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/tutorial/unix-optimize/io/</guid>
      <description>磁盘 I/O  作者：赵坤
 虚拟文件系统 I/O 调度 为了减小不同块设备的差异带来的影响，Linux 通过一个统一的通用块层，来管理各种不同的块设备。通用块层，其实是处在文件系统和磁盘驱动中间的一个块设备抽象层。它会给文件系统和应用程序发来的 I/O 请求排队，并通过重新排序、请求合并等方式，提高磁盘读写的效率。
Linux 内核支持四种 I/O 调度算法，分别是 NONE、NOOP、CFQ 以及 DeadLine。
 NONE，不使用 I/O 调度算法 NOOP，先入先出 CFQ（Completely Fair Scheduler），为每个进程维护了一个 I/O 调度队列，并按照时间片来均匀分布每个进程的 I/O 请求 DeadLine，分别为读、写请求创建了不同的 I/O 队列，可以提高机械磁盘的吞吐量，并确保达到最终期限（deadline）的请求被优先处理  每块磁盘 I/O 性能 $ iostat -d -x 1 Linux 5.4.0-42-generic (zk) 2020年09月02日 _x86_64_	(4 CPU) Device r/s rkB/s rrqm/s %rrqm r_await rareq-sz w/s wkB/s wrqm/s %wrqm w_await wareq-sz d/s dkB/s drqm/s %drqm d_await dareq-sz aqu-sz %util loop0 0.</description>
    </item>
    
    <item>
      <title>Linux 零拷贝</title>
      <link>https://kunzhao.org/docs/tutorial/unix-optimize/zero-copy/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/tutorial/unix-optimize/zero-copy/</guid>
      <description>Linux 零拷贝 为什么需要零拷贝  传统 read，write I/O 接口，数据拷贝的好处：通过中间缓存的机制，**减少磁盘 I/O **的操作 拷贝的坏处：大量数据的拷贝，用户态和内核态的频繁切换，会消耗大量的 CPU 资源，严重影响数据传输的性能  什么是零拷贝 零拷贝就是这个问题的一个解决方案，通过尽量避免拷贝操作来缓解 CPU 的压力。Linux 下常见的零拷贝技术可以分为两大类：一是针对特定场景，去掉不必要的拷贝；二是去优化整个拷贝的过程。由此看来，零拷贝并没有真正做到“0”拷贝，它更多是一种思想，很多的零拷贝技术都是基于这个思想去做的优化。
零拷贝的几种方法 原始数据拷贝操作 在介绍之前，先看看 Linux 原始的数据拷贝操作是怎样的。如下图，假如一个应用需要从某个磁盘文件中读取内容通过网络发出去，像这样：
while((n = read(diskfd, buf, BUF_SIZE)) &amp;gt; 0) write(sockfd, buf , n); 那么整个过程就需要经历：
 1）read 将数据从磁盘文件通过 DMA 等方式拷贝到内核开辟的缓冲区； 2）数据从内核缓冲区复制到用户态缓冲区； 3）write 将数据从用户态缓冲区复制到内核协议栈开辟的 socket 缓冲区； 4）数据从 socket 缓冲区通过 DMA 拷贝到网卡上发出去。  可见，整个过程发生了至少四次数据拷贝，其中两次是 DMA 与硬件通讯来完成，CPU 不直接参与，去掉这两次，仍然有两次 CPU 数据拷贝操作。
方法一：用户态直接 I/O 这种方法可以使应用程序或者运行在用户态下的库函数直接访问硬件设备，数据直接跨过内核进行传输，内核在整个数据传输过程除了会进行必要的虚拟存储配置工作之外，不参与其他任何工作，这种方式能够直接绕过内核，极大提高了性能。
缺陷：
 1）这种方法只能适用于那些不需要内核缓冲区处理的应用程序，这些应用程序通常在进程地址空间有自己的数据缓存机制，称为自缓存应用程序，如数据库管理系统就是一个代表。 2）这种方法直接操作磁盘 I/O，由于 CPU 和磁盘 I/O 之间的执行时间差距，会造成资源的浪费，解决这个问题需要和异步 I/O 结合使用。  方法二：mmap 这种方法，使用 mmap 来代替 read，可以减少一次拷贝操作，如下：</description>
    </item>
    
    <item>
      <title>同步/异步与阻塞/非阻塞</title>
      <link>https://kunzhao.org/docs/tutorial/unix-optimize/async_block/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/tutorial/unix-optimize/async_block/</guid>
      <description>同步/异步与阻塞/非阻塞  两组概念不在同一个纬度
 同步/异步 同步：操作者主动完成了这件事情，需要自己完成的操作都是同步操作。
异步：调用指令发出，操作马上返回，处理完成后，再通过通知的手段来告诉操作者结果，不是调用者自己完成的。
阻塞/非阻塞 阻塞：从头到尾只做这一件事情，不能做其他事情：
非阻塞：无需等待在这里，反复过来检查：
总结  POSIX defines these two terms as follows: A synchronous I/O operation causes therequesting process to be blocked until that I/O operation completes. An asynchronous I/O operation does not cause the requesting process to be blocked. Using these definitions, the first four I/O modes - blocking, nonblocking, I/O multiplexing, and signal-driven I/O - are all synchronous because the actual I/O operation (recvfrom) blocks the process.</description>
    </item>
    
    <item>
      <title>性能优化命令</title>
      <link>https://kunzhao.org/docs/tutorial/unix-optimize/tools/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/tutorial/unix-optimize/tools/</guid>
      <description>性能优化常用命令 CPU 负载    命令 解释     uptime 0.63, 0.83, 0.88   grep &#39;model name&#39; /proc/cpuinfo \| wc -l 查看有几个CPU，以便对比uptime是否超过负载   mpstat -P ALL 5 监控所有CPU，后面数字5表示间隔5秒后输出一组数据   pidstat -u 5 1 间隔5秒后输出一组数据   stress --cpu 1 --timeout 600 模拟 CPU 密集型进程，pidstat的%usr升高   stress -i 1 --timeout 600 模拟 I/O 压力，即不停地执行 sync，pidstat的iowait升高   stress -c 8 --timeout 600 模拟大量进程，pidstat的%wait升高     平均负载 uptime 是指单位时间内，系统处于可运行状态和不可中断状态的平均进程数，也就是平均活跃进程数。通过 ps 命令可以看到进程的状态。</description>
    </item>
    
    <item>
      <title>线程和进程</title>
      <link>https://kunzhao.org/docs/tutorial/unix-optimize/thread_process/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/tutorial/unix-optimize/thread_process/</guid>
      <description>线程和进程 执行二进制文件 Linux 下二进制文件格式一般是 ELF(Executable and Linkable Format) 格式。
执行二进制文件的过程，简而言之就是先 load_elf_binary 加载二进制文件，然后 start_thread 。
其中 load_elf_binary 加载二进制文件中，很重要的一步就是建立内存映射：
 设置内存映射区 mmap_base 设置 vm_area_struct，栈底、栈顶 将 ELF 文件中的代码映射到内存 设置 vm_area_struct 将依赖的 so 文件映射到内存的内存映射区域  最后行程下面的内存映射图：
线程 线程通信方式  POSIX 信号量 互斥锁 (互斥量)：独占方式访问关键代码段。 条件变量：某个共享数据达到某个值的时候，唤醒等待这个共享数据的线程。  线程的数据 生命周期 另外一副 Java 线程的状态转换图：
另外一副更为详细的：
何时可以响应中断  线程在运行态是不响应中断的。
    状态 中断效果 描述     NEW 无    RUNNABLE 设置中断标志位 用户自己判断是否中断，以及如何处理   BLOCKED 设置中断标志位 用户自己判断是否中断，以及如何处理   WAITING 抛InterruptedException异常，并清空中断标志位    TIMED_WAITING 抛InterruptedException异常，并清空中断标志位    TERMINATED 无     自发性上下文切换 自发性上下文切换指线程由 Java 程序调用导致切出，在多线程编程中，执行调用以下方法或关键字，常常就会引发自发性上下文切换。sleep()、wait()、yield()、join()、park()、synchronized、lock。</description>
    </item>
    
    <item>
      <title>CPU</title>
      <link>https://kunzhao.org/docs/tutorial/unix-optimize/cpu/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/tutorial/unix-optimize/cpu/</guid>
      <description>CPU 美团相同配置的容器性能有差异 美团们不断收到业务反馈，同样配置的容器性能存在不小的差异，主要表现为部分容器请求延迟很高，经过我们测试和深入分析发现：这些容器存在跨 Numa Node 访问 CPU，在我们将容器的 CPU 使用限制在同一个 Numa Node 后问题消失。所以，对于一些延迟敏感型的业务，我们要保证应用性能表现的一致性和稳定性，需要做到在调度侧感知 Numa Node 的使用情况。
NUMA SMP（Symmetric multiprocessing），即对称多处理器。有一个显著的缺点，就是总线会成为瓶颈，因为数据都要走它。
NUMA（Non-uniform memory access），非一致内存访问。在这种模式下，内存不是一整块。每个 CPU 都有自己的本地内存，CPU 访问本地内存不用过总线，因而速度要快很多，每个 CPU 和内存在一起，称为一个 NUMA 节点。但是，在本地内存不足的情况下，每个 CPU 都可以去另外的 NUMA 节点申请内存，这个时候访问延时就会比较长。
这样，内存被分成了多个节点，每个节点再被分成一个一个的页面。由于页需要全局唯一定位，页还是需要有全局唯一的页号的。但是由于物理内存不是连起来的了，页号也就不再连续了。于是内存模型就变成了非连续内存模型，管理起来就复杂一些。
美团数据库业务独占 CPU 我们以 MySQL 平台为例，数据库业务对于稳定性、性能和可靠性要求非常高，业务自己又主要以物理机为主，所以成本压力非常大。
针对 CPU 资源分配，采用独占 CPU 集合的方式，避免 Pod 之间发生争抢。</description>
    </item>
    
    <item>
      <title>Linux 性能分析</title>
      <link>https://kunzhao.org/docs/tutorial/unix-optimize/analyze/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/tutorial/unix-optimize/analyze/</guid>
      <description>Linux 性能分析 CPU 性能 内存性能分析 磁盘和文件 I/O 问题 工具 strace strace 可以分析系统调用情况：
$ strace -p 12280 strace: Process 12280 attached select(0, NULL, NULL, NULL, {tv_sec=0, tv_usec=567708}) = 0 (Timeout) stat(&amp;#34;/usr/local/lib/python3.7/importlib/_bootstrap.py&amp;#34;, {st_mode=S_IFREG|0644, st_size=39278, ...}) = 0 stat(&amp;#34;/usr/local/lib/python3.7/importlib/_bootstrap.py&amp;#34;, {st_mode=S_IFREG|0644, st_size=39278, ...}) = 0 filetop filetop 它是 bcc 软件包的一部分，基于 Linux 内核的 eBPF（extended Berkeley Packet Filters）机制，主要跟踪内核中文件的读写情况，并输出线程 ID（TID）、读写大小、读写类型以及文件名称。
# -C 选项表示输出新内容时不清空屏幕  $ ./filetop -C filetop 只给出了文件名称，却没有文件路径，还得继续找啊。我再介绍一个好用的工具，opensnoop 。它同属于 bcc 软件包，可以动态跟踪内核中的 open 系统调用。这样，我们就可以找出这些 txt 文件的路径。
$ opensnoop 12280 python 6 0 /tmp/9046db9e-fe25-11e8-b13f-0242ac110002/650.</description>
    </item>
    
  </channel>
</rss>
