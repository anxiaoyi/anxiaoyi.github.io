<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>书籍 on 赵坤的个人网站</title>
    <link>https://kunzhao.org/docs/books/</link>
    <description>Recent content in 书籍 on 赵坤的个人网站</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-cn</language><atom:link href="https://kunzhao.org/docs/books/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>数学之美</title>
      <link>https://kunzhao.org/docs/books/beauty_of_mathematics/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/books/beauty_of_mathematics/</guid>
      <description>数学之美 2000多年前，古埃及人在罗塞塔石碑上，用三种文字记录了托勒密五世登基的诏书，这帮助后人破解了古埃及的象形文字，让我们了解了5000年前古埃及的历史。可见信息冗余是信息安全的保障，这对于信息编码具有重要指导意义。
犹太人为了避免抄错《圣经》，发明了一种校验码的方法，他们把每一个希伯来字母对应于一个数字，这样每行文字加起来便得到一个特殊的数字，这样的数字变成为了这一行的校验码。
隐含马尔可夫链成功应用在机器翻译、拼写纠错、手写体识别、图像处理、基因序列分析、股票预测和投资等方面。
如何准确的识别出一个快递地址，写一个分析器去分析这些描述恐怕是不行的，因为地址是比较复杂的上下文有关的文法。答案是使用有限状态机。当用户输入的地址不太标准或有错别字的时候，有限状态机会束手无措，因为有限状态机是严格匹配的，所以科学家提出了基于概率的有限状态机。
2002 年，Google 想要做一个全新的中、日、韩搜索算法，吴军写的算法比较简单，但是占用内存比较多，Google 服务器数量还没有那么多。辛格提出，用一个拟合函数替换很耗内存的语言模型，无需增加任何服务器，但是搜索质量会降到 80%。辛格指出，这样可以提早两个月将这个新算法提供给中国的用户，用户体验会有质的提高。辛格做事情的哲学，先帮助用户解决 80% 的问题，再慢慢解决剩下的 20% 的问题，是在工业界成功的秘诀之一。
新闻分类的关键在于计算出两篇新闻的相似度，每篇新闻变成一个向量，最后余弦定理可以计算出来相似度。但两两计算的迭代次数太多，如何一次性就把所有新闻的相关性计算出来呢？答案是矩阵运算中的奇异值分解。
如何判断两个集合是否相同？一种答案是双层 for 循环一一比较，复杂度 O(N^2)；稍好一点的办法是对集合进行排序，然后顺序比较，时间复杂度 O(NlogN)；还可以将一个集合的元素放到散列表里面，另外一个与之一一对比，时间复杂度 O(N)，但是额外使用了 O(N) 的空间，不完美；最完美的是计算这两个集合的指纹，对一个集合中的元素分别计算指纹，然后一一相加。
如何判断两个集合基本相同？答案是 Simhash。判断两个网页是否重复，也没有必要完全从头比到尾，只需要每个网页挑选出几个词 (IDF 最大的几个词)，构成特征词，然后计算信息指纹即可。判断一篇文章是否抄袭另外一篇文章，每篇文章切成小的片段，挑选特征词，并计算指纹。YouTuBe 如何从上百万视频中找出一个视频是否另外一个视频的盗版？其核心在于关键帧的提取和特征的提取。关键帧对于视频的重要性，就如同主题词对于新闻的重要性一样。
最大熵原理指出，对一个随机事件的概率分布进行预测时，我们的预测应当满足全部已知的条件，而对未知的情况不要做任何主观假设，这种情况下，概率分布最均匀，预测的风险最小。例如拼音输入法，Wang-Xiao-Bo 转换为王晓波和王小波，唯一确定用户需要的是哪一个，非常难。</description>
    </item>
    
    <item>
      <title>上帝掷骰子吗</title>
      <link>https://kunzhao.org/docs/books/history_of_quantum_physics/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/books/history_of_quantum_physics/</guid>
      <description>上帝掷骰子吗-量子物理史话 1887年德国，赫兹在实验室证实了电磁波的存在，也证实了光其实是电磁波的一种，两者具有共同的波的特性，古老的光学终于可以被完全包容于新兴的电磁学里面。1901年，赫兹死后的第 7 年，无线电报已经可以穿越大西洋，实现两地的实时通讯了。
赫兹铜环接收器的缺口之间不停地爆发着电火花，明白无误地昭示着电磁波的存在。但偶然间，赫兹又发现了一个奇怪的现象：当有光照射到这个缺口上的时候，似乎火花就出现得更容易一些。
 量子就是能量的最小单位，就是能量里的一美分。一切能量的传输，都只能以这个量为单位来进行，它可以传输一个量子，两个量子，任意整数个量子，但却不能传输1 又1/2 个量子，那个状态是不允许的，就像你不能用现钱支付1 又1/2 美分一样。这个值，现在已经成为了自然科学中最为 重要的常数之一，以它的发现者命名，称为“普朗克常数”，用 h 来表示。
在后来十几年的时间里，普朗克一直认为量子的假设并不是一个物理真实，而纯粹是一个为了方便而引入的假设而已。他不断地告诫人们，在引用普朗克常数 h 的时候，要尽量小心谨慎，不到万不得已千万不要胡思乱想。</description>
    </item>
    
    <item>
      <title>代码整洁之道</title>
      <link>https://kunzhao.org/docs/books/clean_code/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/books/clean_code/</guid>
      <description>代码整洁之道 勒布朗法则：Later equals never.
随着混乱的增加，团队生产力也持续下降，趋近于零。生产力下降的时候，管理层只能增加更多的人手，期望提高生产力。
什么是整洁代码  我喜欢优雅和高效的代码。代码逻辑应当直截了当，叫缺陷难以隐藏；尽量减少依赖关系，使之便于维护；依据某种分层战略完善错误处理代码；性能调至最优，省得引诱别人做没规矩的优化，搞出一堆混乱来。整洁的代码只做好一件事。&amp;mdash; Bjarne Stroustrup，C++ 语言发明者
  整洁的代码应可由作者之外的开发者阅读和增补。它应有单元测试和验收测试。它使用有意义的命名。它只提供一种而非多种做一件事的途径。它只有尽量少的依赖关系，且要明确地定义和提供清晰、尽量少的 API。代码应通过其表面表达含义，因为不同的语言导致并非所有必需信息均可通过代码自身清晰表达。&amp;mdash; Dave Thomas, OTI 公司创始人
  整洁的代码总是看起来像是某位特别在意它的人写的。几乎没有改进的余地，代码作者什么都想到了。&amp;mdash; 《修改代码的艺术》作者
 有意义的命名 对于变量，如果其需要注释来补充，那就不算是名副其实。比如你需要定义一个变量，这个变量存储的是消逝的时间，其单位是天，那么下面是一些比较好的命名：
int elapsedTimeInDays; int daysSinceCreation; int daysSinceModification; int fileAgeInDays; 别用 accountList 来指一组账号，除非它真的是 List 类型，List 一词对于程序员有特殊意义，所以用 accountGroup 或 bunchOfAcounts，甚至用 accounts 都会好一些。
别说废话，废话都是冗余。假如你有一个 Product 类，如果还有一个 ProductInfo 或 ProductData 类，它们虽然名称不同，意思却无区别。Info 和 Data 就像 a、an 和 the 一样，是意义含混的废话。下面三个函数的命名，我们怎么知道应该调用哪个呢？
getActiveAccount(); getActiveAccounts(); getActiveAccountInfo(); 使用常量，WORK_DAYS_PER_WEEK 比数字 5 要好找的多。
 对于类名，其应该是名词或名词短语，如 Customer、WikiPage、Account 和 AddressParser，避免使用 Manager、Processor、Data 或 Info 这样的类名。类名不应当是动词。</description>
    </item>
    
    <item>
      <title>企业 IT 架构转型之道</title>
      <link>https://kunzhao.org/docs/books/the_transformation_of_enterprise_it_architecture/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/books/the_transformation_of_enterprise_it_architecture/</guid>
      <description>企业 IT 架构转型之道 共享服务体系搭建 SOA 的主要特性：
 面向服务的分布式计算。 服务间松散耦合。 支持服务的组装。 服务注册和自动发现。 以服务契约方式定义服务交互方式。  基于 “中心化” 的 ESB 服务调用方式  “去中心化” 服务架构调用方式   数据拆分实现数据库能力线性扩展 数据库的读写分离 读写分离基本原理是让主数据库处理事务性增、改、删（INSERT、UPDATE、DELETE）操作，而从数据库专门负责处理查询（SELECT）操作，在数据库的后台会把事务性操作导致的主数据库中的数据变更同步到集群中的从数据库。
数据库分库分表 采用分库分表的方式将业务数据拆分后，如果每一条SQL语句中都能带有分库分表键，SQL语句的执行效率最高：
但不是所有的业务场景在进行数据库访问时每次都能带分库分表键的。比如在买家中心的界面中，要显示买家test1过去三个月的订单列表信息。此时就出现了我们所说的全表扫描，一条SQL语句同时被推送到后端所有数据库中运行。如果是高并发情况下同时请求的话，为了数据库整体的扩展能力，则要考虑下面描述的异构索引手段来避免这样的情况发生。对于在内存中要进行大数据量聚合操作和计算的SQL请求，如果这类SQL的不是大量并发或频繁调用的话，平台本身的性能影响也不会太大，如果这类SQL请求有并发或频繁访问的要求，则要考虑采用其他的平台来满足这一类场景的要求，比如Hadoop这类做大数据量离线分析的产品，如果应用对请求的实时性要求比较高，则可采用如内存数据库或HBase这类平台。
所谓“异构索引表”，就是采用异步机制将原表内的每一次创建或更新，都换另一个维度保存一份完整的数据表或索引表。本质上这是互联网公司很多时候都采用的一个解决思路：“拿空间换时间”。也就是应用在创建或更新一条按照订单ID为分库分表键的订单数据时，也会再保存一份按照买家ID为分库分表键的订单索引数据。
基于订单索引表实现买家订单列表查看流程示意：
实现对数据的异步索引创建有多种实现方式，其中一种就是从数据库层采用 binlog 数据复制的方式实现。
采用数据异构索引的方式在实战中基本能解决和避免90%以上的跨join或全表扫描的情况，是在分布式数据场景下，提升数据库服务性能和处理吞吐能力的最有效技术手段。但在某些场景下，比如淘宝商品的搜索和高级搜索，因为商品搜索几乎是访问淘宝用户都会进行的操作，所以调用非常频繁，如果采用SQL语句的方式在商品数据库进行全表扫描的操作，则必然对数据库的整体性能和数据库连接资源带来巨大的压力。面对此类场景，我们不建议采用数据库的方式提供这样的搜索服务，而是采用专业的搜索引擎平台来行使这样的职能，如Lucene、Solr、ElasticSearch 等。
异步化与缓存原则 业务流程异步化 以淘宝的交易订单为例，目前淘宝的订单创建流程需要调用超过200个服务，就算所有服务的调用时间都控制在20ms内返回结果，整个订单创建的时间也会超过4s：
以异步化方式将上述交易创建过程中，对于有严格先后调用关系的服务保持顺序执行，对于能够同步执行的所有服务均采用异步化方式处理。阿里巴巴内部使用消息中间件的方式实现了业务异步化，提高了服务的并发处理，从而大大减少整个业务请求处理所花的时间。
数据库事务异步化 扣款是一个要求事务一致性的典型场景，稍微数据不一致带来的后果都可能是成百上千（可能在某些借款项目中达到上百万的金额）的金额差异。所以在传统的实现方式中，整个扣款的逻辑代码都是在一个大的事务中，通过数据库的事务特性来实现这样一个稍显复杂的业务一致性。
数据库事务的异步化：通俗来说，就是将大事务拆分成小事务，降低数据库的资源被长时间事务锁占用而造成的数据库瓶颈，就能大大提升平台的处理吞吐量和事务操作的响应时间。
在实际的改造方案中，同样基于消息服务提供的异步机制，将整个还款流程进行异步化的处理：
事务与柔性事务 不管是业务流程异步化，还是数据库事务异步化，其实都面临一个如何保证业务事务一致性的问题。面对这个问题目前并没有完美的解决方案，本节会介绍淘宝是如何对订单创建场景实现业务一致的实践，以及近一两年来我们在分布式事务上所作出的创新尝试，供各技术同行在解决此类问题时借鉴和参考。
关于数据库事务，核心是体现数据库ACID（原子性、一致性、隔离性和持久性）属性，即作为一个事务中包含的所有逻辑处理操作在作用到数据库上时，只有这个事务中所有的操作都成功，对数据库的修改才会永久更新到数据库中，任何一个操作失败，对于数据库之前的修改都会失效。在分布式领域，基于CAP理论和在其基础上延伸出的BASE理论，有人提出了“柔性事务”的概念。
（1）CAP理论
一个分布式系统最多只能同时满足一致性（Consistency）、可用性（Availability）和分区容错性（Partition tolerance）这三项中的两项。“一致性”指更新操作成功并返回客户端完成后，所有节点在同一时间的数据完全一致。“可用性”指用户在访问数据时可以得到及时的响应。“分区容错性”指分布式系统在遇到某节点或网络分区故障的时候，仍然能够对外提供满足一致性和可用性的服务。
CAP定理并不意味着所有系统的设计都必须抛弃三个要素之中的一个。CAP三者可以在一定程度上衡量，并不是非黑即白的，例如可用性从0%到100%有不同等级。
（2）BASE理论
BASE理论是对CAP理论的延伸，核心思想是即使无法做到强一致性（Strong Consistency, CAP的一致性就是强一致性），但应用可以采用适合的方式达到最终一致性（EventualConsitency）。BASE是指基本可用（Basically Available）、柔性状态（Soft State）、最终一致性（Eventual Consistency）。
  “基本可用”是指分布式系统在出现故障的时候，允许损失部分可用性，即保证核心可用。电商大促时，为了应对访问量激增，部分用户可能会被引导到降级页面，服务层也可能只提供降级服务。这就是损失部分可用性的体现。
  “柔性状态”是指允许系统存在中间状态，而该中间状态不会影响系统整体可用性。分布式存储中一般一份数据至少会有三个副本，允许不同节点间副本同步的延时就是柔性状态的体现。MySQLReplication的异步复制也是一种柔性状态体现。
  “最终一致性”是指系统中的所有数据副本经过一定时间后，最终能够达到一致的状态。弱一致性和强一致性相反，最终一致性是弱一致性的一种特殊情况。
  对于如何实现高可用，我们认为：</description>
    </item>
    
    <item>
      <title>Redis 5 设计与源码分析</title>
      <link>https://kunzhao.org/docs/books/redis_5_source_code/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/books/redis_5_source_code/</guid>
      <description>Redis 5 设计与源码分析 Redis 5.0 新特性  新增Streams数据类型，这是 Redis 5.0 最重要的改进之一。可以把Streams当作消息队列。 新的模块API、定时器、集群及字典。 RDB中持久化存储LFU和LRU的信息。 将集群管理功能完全用C语言集成到redis-cli中，Redis 3.x 和 Redis4.x 的集群管理是通过Ruby脚本实现的。 有序集合新增命令ZPOPMIN/ZPOPMAX。 改进HyperLogLog的实现。 新增Client Unblock和Client ID。 新增LOLWUT命令。 Redis主从复制中的从不再称为Slave，改称Replicas。 Redis 5.0引入动态哈希，以平衡CPU的使用率和相应性能，可以通过配置文件进行配置。Redis 5.0默认使用动态哈希。 Redis核心代码进行了部分重构和优化。  简单动态字符串 （1） 长度小于 32 的短字符串
struct __attribute__ ((__packed__))sdshdr5 { unsigned char flags; // 低 3 位存储类型，高 5 位存储长度  char buf[]; // 柔性数组 } 结构如下：
（2） 长度大于 31 的字符串
此处仅展示一个示例：
struct __attribute__ ((__packed__))sdshdr8 { uint8_t len; // 已使用长度  uint8_t alloc; // 已分配的字节总长度  unsigned char flags; // 低 3 位存储类型  char buf[]; // 柔性数组 } SDS 读操作的复杂度多为O(1)，直接读取成员变量；涉及修改的写操作，则可能会触发扩容。</description>
    </item>
    
    <item>
      <title>深度剖析 Apache Dubbo 核心技术</title>
      <link>https://kunzhao.org/docs/books/in-depth_analysis_of_the_core_technology_of_apache_dubbo/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/books/in-depth_analysis_of_the_core_technology_of_apache_dubbo/</guid>
      <description>深度剖析 Apache Dubbo 核心技术 SPI 扩展 Dubbo 支持扩展的核心接口上，都会通过类似 @SPI(&amp;quot;dubbo&amp;quot;) 这样的注解，来标识当前接口的默认实现。如果你想替换掉这个默认实现，那么需要两个步骤。第一，实现 Protocol 接口，然后在 META-INF/dubbo 目录下创建一个名字为 org.apache.dubbo.rpc.Protocol 的文本文件。这个 META-INF 目录如果使用的是 IDEA 开发，那么其应该放到 resources 目录下的顶层，这样打 jar 包的时候，其也会被复制到 jar 包的第一级目录。内容如下：
myProtocol = com.zk.MyProtocol 第二，需要在 XML 配置文件中，声明使用这个扩展实现：
&amp;lt;dubbo:protocol name=&amp;#34;myProtocol&amp;#34;&amp;gt; 其实 JDK 本身也提供了 SPI 扩展，Dubbo 之所以没有使用默认提供的实现，是因为：
 JDK 标准的 SPI 一次性实例化扩展点的所有实现，如果有些没有使用到，那么会浪费资源。 扩展点加载失败的异常提示不是很好。 增强了 Ioc 和 AOP 的支持。  性能 Dubbo 会给每个服务提供者的实现类生产一个 Wrapper 类，这个 Wrapper 类里面最终调用服务提供者的接口实现类，Wrapper 类的存在是为了减少反射的调用。当服务提供方收到消费方发来的请求后，需要根据消费者传递过来的方法名和参数反射调用服务提供者的实现类，而反射本身是有性能开销的，Dubbo 把每个服务提供者的实现类通过 JavaAssist 包装为一个 Wrapper 类以减少反射调用开销。
其实就是由反射改为了比较方法名称，然后调用，伪代码如下：
GreetingServiceImpl impl = (GreetingServiceImpl) object; if (&amp;#34;sayHello&amp;#34;.</description>
    </item>
    
    <item>
      <title>人人都是架构师 (一)</title>
      <link>https://kunzhao.org/docs/books/everyone-is-architect/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/books/everyone-is-architect/</guid>
      <description>人人都是架构师 - 分布式系统架构落地与瓶颈突破 分布式系统应对高并发、大流量的常用手段：
 扩容 动静分离 缓存 服务降级 限流  限流 常见算法：
 令牌桶，Nginx 限流模块用的是这个：限制的是流量的平均流入速率，允许一定程度上的突发流量。 漏桶：限制的是流出速率，并且这个速率还是保持不变的，不允许突发流量。  Nginx 限流 http { # 每个 IP 的 session 空间大小 limit_zone one $binary_remote_addr 20m; # 每个 IP 每秒允许发起的请求数 limit_req_zone $binary_remote_addr zone=req_one:20m rate=10r/s; # 每个 IP 能够发起的并发连接数 limit_conn one 10; # 缓存还没有来得及处理的请求 limit_req zone=req_one burst=100; } 消峰  活动分时段 答题验证  高并发读 &amp;ldquo;马某出轨王某&amp;rdquo;、&amp;ldquo;iPhone SE 2020 发布&amp;rdquo; 等这种热点新闻的 key 会始终落在同一个缓存节点上，分布式缓存一定会出现单点瓶颈，其资源连接容易瞬间耗尽。有如下两种方案解决这个问题：
 基于 Redis 的集群多写多读方案。  多写如何保持一致性：将 Key 配置在 ZooKeeper，客户端监听 ZNode，一旦变化，全量更新本地持有的 Key   LocalCache 结合 Redis 集群的多级 Cache 方案。  LocalCache 拉取下来的商品数量有 5 个，但是实际上只有 4 个了，怎么解决？对于这种读场景，允许接受一定程度上的数据脏读，最终扣减库存的时候再提示商品已经售罄即可。    实时热点自动发现 交易系统产生的相关数据、上游系统中埋点上报的数据这两个，异步写入日志，对日志进行次数统计和热点分析</description>
    </item>
    
    <item>
      <title>编写可读代码的艺术</title>
      <link>https://kunzhao.org/docs/books/the-art-of-readable-code/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/books/the-art-of-readable-code/</guid>
      <description>编写可读代码的艺术 代码应当易于理解 Q: 可读性基本定理？
 可读性基本原理：使别人理解它所需的时间最小化。
 Q: 代码总是越小越好？
 减少代码行数是一个好目标，但是把理解代码所需的时间最小化是一个更好的目标。
 表面层次的改进 把信息装到名字里 （1）选择专业的词
def getPage(url) 上述例子，get 词没有表达出很多信息。从本地缓存得到一个页面，还是从数据库中，或者从互联网中？如果从互联网中，应该使用更为专业的名字：fetchPage(url) 或 downloadPage(url)。
class BinaryTree { int size(); } 上述例子，size() 返回的是什么？树的高度，节点树，还是树在内存中所占的空间？size() 没有承载更多的信息，更专业的词汇是 height()、numNodes() 或 memoryBytes()。
英语是一门丰富的语言，有很多词汇可以选择。下面是一些例子，这些单词更富有表现力，可能更适合你的语境：
   单词 更多选择     send deliver、dispatch、announce、distribute、route   find search、extract、locate、recover   start launch、create、begin、open   make create、set up、build、generate、compose、add、new    （2）避免像 tmp 和 retval 这样泛泛的名字
除非你有更好的理由！
（3）用具体的名字代替抽象的名字
searchCanStart() 比 canListenOnPort() 更具体一些，这个名字直接描述了方法所做的事情。</description>
    </item>
    
    <item>
      <title>炒股的智慧</title>
      <link>https://kunzhao.org/docs/books/the-wisdom-of-trading-stocks/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/books/the-wisdom-of-trading-stocks/</guid>
      <description>炒股的智慧  如果要我用一句话解释何以一般股民败多胜少，那就是：人性使然！说的全面些，就是这些永远不变的人性&amp;ndash;讨厌风险、急着发财、自以为是、赶潮跟风、因循守旧和耿于报复&amp;ndash;使股民难以逃避开股市的陷阱。说得简单些，就是好贪小便宜、吃不得小亏的心态使得一般股民几乎必然地成为了输家。
 炒股的挑战 炒股与人性 炒股最重要的原则就是止损。但人性是好贪小便宜，不肯吃小亏，只有不断地因为贪了小便宜却失去大便宜，不肯吃小亏最终却吃了大亏，你才能最终学会不贪小便宜，不怕吃小亏。
特殊的赌局 问问你自己喜欢做决定吗？喜欢独自为自己地决定负全部责任吗？对 99% 的人来说，答案是否定的。股市这一恒久的赌局却要求你每时每刻都要做理性的决定，并且为决定的结果负全部的责任！这就淘汰了一大部分股民，因为他们没有办法长期承受这样的心理能力。
一般股民何以失败 人性讨厌风险 纽约有位叫做夏皮诺的心理医生，请了一批人来做两个实验：
 实验一  选择：第一，75% 的机会得到 1000 美元，但有 25% 的机会什么都得不到；第二，确定得到 700 美元。结果 80% 的人选择了第二选择，大多数人宁愿少些，也要确定的利润。
 股民好获小利，买进的股票升了一点，便迫不及待地脱手。这只股票或许有 75% 继续上升地机会，但为了避免 25% 什么都得不到的可能性，股民宁可少赚些。任何炒过股的读者都明白，要用较出场价更高地价位重新入场是多么困难。股价一天比一天高，你只能做旁观者。
  实验二  选择：第一，75% 的机会付出 1000 美元，但有 25% 的机会什么都不付；第二，确定付出 700 美元。结果 75% 的人选择了第一选择。他们为了搏 25% 什么都不付的机会，从数学上讲多失去了 50 美元。
 一旦买进的股票跌了，股民便死皮赖脸不肯止损，想象出各种各样的理由说服自己下跌只是暂时的。其真正的原因只不过为了搏那 25% 可能全身而退的机会！结果是小亏慢慢积累成大亏。
 人的发财心太急 心一旦大了，行动上就开始缺少谨慎。首先我每次买股买得太多，其次止损止得太迟。我为此遭受了巨大的损失。
人好自以为是 一天结束的时候，股票以某一价钱收盘。你有没有思考过它代表了什么？它代表了股市的参与者在今天收市的时候对该股票的认同。
不要太固执己见，不要对自己的分析抱太大的信心。认真观察股市，不对时就认错。否则，你在这行生存的机会是不大的。
人好跟风 人好报复 在股市中，买进的股票跌了，你就再多买一点，因为第二次买的价钱较上次为低，所以平均进价摊低了。从心理上看，你的心态和赌场亏钱时一样。一方面你亏不起，另一方面你在报复股市，报复股市让你亏钱。同时内心希望，只要赢一手，就能连本带利全回来。因为平均进价摊低了，股票的小反弹就能提供你全身而退的机会。
这样的心态是极其有害的。股票跌的时候通常有它跌的理由，常常下跌的股票会越跌越低。这样被套牢，你就越陷越深，直到你心理无法承受的地步。一个致命的大亏损，常常就彻底淘汰了一位股民。
人总是迟疑不决，心怀侥幸 每个炒股人都会经过这个过程。20元买好股票，定好18元止损，当股票跌到18元时，你有没有想想再等等？或许股票马上反弹！股票又跌到16元，你会不会拍自己的脑壳说：“真该按定好的规矩办！18元时就走人；现若股票反弹5毛钱我就一定说再见。”
现股票跌到10元了，你准备怎么办？你会发毛吗？你会不会发狠：“老子这次拼了！现在就是不走，我倒要看看你最低会跌到什么地方？”
当然，最后的结局很少例外，通常是股票学校又多了位交了学费毕不了业的炒股
股票分析的基本知识 技术分析 升势：一浪比一浪高     朋友，你认为什么因素使投资者入市买股票？华尔街有过调查，使一般投资者入场买股票的原因最主要的就是因为股票在升！你明白吗？一般投资者入场买股票主要不是因为股票的成本收益比率低或红利高，而是因为股票在升！升！升！而投资人卖股票的最主要原因是因为股票在跌！在跌！</description>
    </item>
    
    <item>
      <title>设计数据密集型应用程序 - 可靠 &amp; 可扩展 &amp; 可维护</title>
      <link>https://kunzhao.org/docs/books/ddia-chapter1/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/books/ddia-chapter1/</guid>
      <description>设计数据密集型应用程序 - 可靠 &amp;amp; 可扩展 &amp;amp; 可维护  笔记来自于 《Designing Data-Intensive Applications》 的第一章
 何为数据密集型应用程序 很多应用程序都需要用到如下和数据打交道的系统:
 数据库 缓存 搜索数据 &amp;amp; 索引 流处理 批量处理  设计这样的应用程序需要考虑很多因素，在此重点关注:
 可靠性: 系统持续工作 可扩展: 能维持系统负载 (Load) 的增长 可维护: 多人维护  Twitter 的负载  2012 年 Tweet 平均产生的速率: 4.6k/s，峰值速率可以达到 12k/s. 用户浏览首页的这个 API 请求平均: 300k/s.  Twitter 主要的挑战在于，每个用户可以关注很多人，每个人可以被很多人关注。实现这种系统通常有两种方式:
(1) 用户发布 Tweet 直接写入到大的 Tweet 表中即可。而用户浏览首页，需要首先查找用户关注的所有人，找到这些人发布的所有 Tweet，然后(按照时间)合并这些 Tweet:
SELECT tweets.*, users.* FROM tweets JOIN users ON tweets.sender_id = users.</description>
    </item>
    
    <item>
      <title>设计数据密集型应用程序 - 数据模型 &amp; 查询语言</title>
      <link>https://kunzhao.org/docs/books/ddia-chapter2/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/books/ddia-chapter2/</guid>
      <description>设计数据密集型应用程序 - 数据模型 &amp;amp; 查询语言  笔记来自于 《Designing Data-Intensive Applications》 的第二章
 LinkedIn 的简历 简历是一种 self-contained 文档，采用 JSON 的表达方式应该会更为合适。
JSON 示例如下:
{ &amp;#34;user_id&amp;#34;: 251, &amp;#34;first_name&amp;#34;: &amp;#34;Bill&amp;#34;, &amp;#34;last_name&amp;#34;: &amp;#34;Gates&amp;#34;, &amp;#34;summary&amp;#34;: &amp;#34;Co-chair of the Bill &amp;amp; Melinda Gates... Active blogger.&amp;#34;, &amp;#34;region_id&amp;#34;: &amp;#34;us:91&amp;#34;, &amp;#34;industry_id&amp;#34;: 131, &amp;#34;photo_url&amp;#34;: &amp;#34;/p/7/000/253/05b/308dd6e.jpg&amp;#34;, &amp;#34;positions&amp;#34;: [ {&amp;#34;job_title&amp;#34;: &amp;#34;Co-chair&amp;#34;, &amp;#34;organization&amp;#34;: &amp;#34;Bill &amp;amp; Melinda Gates Foundation&amp;#34;}, {&amp;#34;job_title&amp;#34;: &amp;#34;Co-founder, Chairman&amp;#34;, &amp;#34;organization&amp;#34;: &amp;#34;Microsoft&amp;#34;} ], &amp;#34;education&amp;#34;: [ {&amp;#34;school_name&amp;#34;: &amp;#34;Harvard University&amp;#34;, &amp;#34;start&amp;#34;: 1973, &amp;#34;end&amp;#34;: 1975}, {&amp;#34;school_name&amp;#34;: &amp;#34;Lakeside School, Seattle&amp;#34;, &amp;#34;start&amp;#34;: null, &amp;#34;end&amp;#34;: null} ], &amp;#34;contact_info&amp;#34;: { &amp;#34;blog&amp;#34;: &amp;#34;http://thegatesnotes.</description>
    </item>
    
    <item>
      <title>设计数据密集型应用程序 - 存储和读取</title>
      <link>https://kunzhao.org/docs/books/ddia-chapter3/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/books/ddia-chapter3/</guid>
      <description>设计数据密集型应用程序 - 存储和读取  笔记来自于 《Designing Data-Intensive Applications》 的第三章
 精心选取的索引可以提升查询的速度，但是也会影响写入的速度。很多数据库系统内部会采用一种 append-only log file 文件，来记录更新了什么数据。
Hash 索引 使用 in-memory hash map 对只进行追加写入的文件进行索引:
如上述讨论，我们只对文件追加，但是如何防止文件大到超出磁盘空间呢？一种可行的办法是，将 log 文件切分为 segments (当一个 segment 文件达到某个大小的时候，就关闭它，然后开始往新的 segment 文件中写入)，我们可以在这些 compaction 中进行 compaction (去除对 key 的重复的历史更新，只保留最近一次的更新即可)。
事实上，在执行 compaction (可以让 segment 文件不至于太大) 的时候，我们还可以同时 merge segments 到新的 segment 文件中，可以使用一个后台线程来执行这些操作。在执行操作的同时，我们依然可以使用旧的 segment 文件继续对外提供 read 和 write 服务。当 merge 完毕后，我们再切换到新的 segment 文件上，然后将旧的 segment 文件删除即可。
现在每一个 segment 文件都拥有了自己的 in-memory hash table，存储了 key 到文件偏移量的映射关系。根据 key 查找值的过程，我们首先检查最近的 segment 的 hash map，如果 key 不在里面，我们就查找第二个 segment，以此类推。merge 操作本身会保证 segment 文件不至于太多，所以我们也无须查看太多的 hash map。当然在实际实现中，还是有很多问题需要考虑:</description>
    </item>
    
    <item>
      <title>设计数据密集型应用程序 - 编码与演化</title>
      <link>https://kunzhao.org/docs/books/ddia-chapter4/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/books/ddia-chapter4/</guid>
      <description>设计数据密集型应用程序 - 编码与演化  笔记来自于 《Designing Data-Intensive Applications》 的第四章
 </description>
    </item>
    
    <item>
      <title>设计数据密集型应用程序 - Replication</title>
      <link>https://kunzhao.org/docs/books/ddia-chapter5/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://kunzhao.org/docs/books/ddia-chapter5/</guid>
      <description>设计数据密集型应用程序 - Replication Replication 就是将相同数据的拷贝防止在多个通过网络连接在一起的机器上。
为什么需要 Replication  让数据在地理位置上更靠近用户 部分数据坏掉的时候，系统依然能持续工作 可伸缩，增加机器即可增加吞吐量  如果你需要 replication 的数据不发生变化，那么 replication 的过程是及其简单的，你只需拷贝到其它各个机器上，然后你的任务就完成了。然而 replication 最难的地方也就在这个地方，如何处理变化的数据？接下来就介绍三种常见的处理 replication 中数据变化的算法: single-leader、multi-leader、leaderless。
Leaders 和 Followers 每一个存储一份数据库拷贝的节点称之为: replica。每一个 replica 都需要处理写数据的操作，久而久之，每一个节点之间存储的数据也就不再一致了。解决这种问题最常见的办法就是: leader-based replication (active/passive 或 master-slave replication)，它的工作原理如下:
 其中某个 replica 被指定为 leader (master 或 primary)，客户端想要写数据，那么必须将它们的写数据的请求发送给 leader，然后 leader 随后写入到自己的本地磁盘中。 其余的 replica 称之为 follower (read replicas, slaves, secondaries, hot standbys)，当 leader 写入数据到本地磁盘的时候，同时将数据改变的部分作为 replication log 或者 change stream 发送给它的 followers。每一个 follower 根据收到的 log 按照和 leader 处理不同写操作之间的相同的顺序，来更新它自己本地的数据。 当一个客户端想要读取数据的时候，它可以发送读请求给 leader 或者任意一个 follower。但是写请求的话只能发送给 leader。  这种模式的 replication 内置在许多数据库中，例如: PostgreSQL、MySQL、Oracle Data Guard、SQL Server 的 AlwaysOn Availability Groups，甚至在许多非关系型数据库中也有它的身影，例如: MongoDB、RethinkDB、Espresso，这种模式也局限于数据库，像消息中间件 Kafka 和 RabbitMQ 高可用的队列都依赖它，一些网络文件系统和 replicated block devices 例如 DRBD 也是同样的道理。</description>
    </item>
    
  </channel>
</rss>
