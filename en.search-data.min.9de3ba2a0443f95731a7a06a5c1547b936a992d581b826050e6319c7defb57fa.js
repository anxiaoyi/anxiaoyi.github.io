'use strict';(function(){const indexCfg={cache:true};indexCfg.doc={id:'id',field:['title','content'],store:['title','href'],};const index=FlexSearch.create('balance',indexCfg);window.bookSearchIndex=index;index.add({'id':0,'href':'/posts/maintaining-cache-consistency/','title':"如何维持缓存的一致性？",'content':"Phil Karlton 曾经说过，“计算机科学中只有两件困难的事情：缓存失效和命名问题。” 这句话还有其他很好的举例。我个人最喜欢 Jeff Atwood 的一句话：“计算机科学中有两件困难的事情：缓存失效、命名和一个错误就关闭。”显然，缓存是困难的。就像分布式系统中的几乎所有东西一样，它甚至可能一眼就看不清。我将介绍分布式系统中几种常见的缓存方法，这些方法应该涵盖您将使用的绝大多数缓存系统。具体来说，我将关注如何维护缓存一致性。\n缓存 \u0026amp; 缓存一致性 在讨论不同的缓存方式之前，我们需要非常精确地说明缓存和缓存一致性的含义，特别是因为一致性是一个严重超载的术语。\n这里我们将缓存定义为：\n 一个单独的系统，它存储一个视图，这个视图是底层完整数据存储的一部分。\n 注意，这是一个非常笼统和轻松的定义。它包括通常被认为是缓存的内容，它存储与（通常是持久的）数据存储相同的值。它甚至包括一些人们通常不认为是缓存的东西。例如，数据库的非聚集二级索引。在我们的定义中，它也可以是一个缓存，保持缓存的一致性很重要。\n这里我们称缓存为一致的：\n 如果 k 存在于缓存中，则键 k 的值最终应与基础数据存储相同。\n 有了这个定义，如果缓存不存储任何内容，它总是一致的。但那根本没什么意思，因为它完全没用。\n为什么使用缓存 通常部署缓存是为了提高读写性能。这里的性能可以是延迟、吞吐量、资源利用率等，并且通常是相关的。保护数据库通常也是构建缓存的一个非常重要的动机。但你可以说这也是它正在解决的一个性能问题。\n不同类型的缓存 Look-aside / demand-fill 缓存 对于 look aside 缓存，客户端将在查询数据存储之前首先查询缓存。如果命中，它将返回缓存中的值。如果是未命中，它将从数据存储返回值。它没有说明缓存应该如何填充。它只是指定如何查询它。但通常情况下，是 demand-fill (按需填充)。Demand-fill 意味着在未命中的情况下，客户端不仅使用数据存储中的值，而且还将该值放入缓存中。通常，如果您看到一个look-aside 缓存，它也是一个 demand-fill 缓存。但这不一定。例如，你可以让缓存和数据存储订阅同一个日志（如Kafka）并独立实现。这是一个非常合理的设置。在本例中，缓存是一个 look-aside 缓存，而不是 demand-fill。而且缓存甚至可以拥有比持久数据存储更新鲜的数据。\n很简单，对吧？不过，简单的 Look aside/demand fill 缓存可能会有永久的不一致性！由于 look aside 缓存的简单性，这常常被人们忽略。根本上是因为当客户端将一些值放入缓存时，该值可能已经过时。具体来说\n- client gets a MISS (客户端未命中) - client reads DB get value `A` (客户端从数据库读取值：A) - someone updates the DB to value `B` and invalidates the cache entry (某人刷新了数据库，值变为了 B) - client puts value `A` into cache (客户端将 A 放入了缓存) 从那时起，客户端将继续从缓存中获取A，而不是B，后者是最新的值。取决于您的用例，这可能是正常的，也可能不是。它还取决于缓存条目是否有 TTL。但在使用 look aside/demand fill 缓存之前，您应该知道这一点。\n这个问题可以解决。Memcache使用 lease 来解决这个问题。因为从根本上讲，客户端在缓存上执行read-modify-write操作，而不使用原语来保证操作的安全性。在此设置中，read 从缓存中读取。modify 从数据库中读取。write 就是写回缓存。执行read-modify-write的一个简单解决方案是保留某种 “ticket” 来表示 read 时的缓存的状态，并比较 write 时的“ticket”。这就是 Memcache 解决问题的有效方法。Memcache 将其称为 lease，您可以将其作为简单的计数器，在每次缓存改变时都会碰到它。因此，在 read 时，它从 Memcache 主机获取 lease，在 write 时，客户端将 lease 一起传递。如果主机上的 lease 已更改，Memcache 将无法写入。现在回到前面的例子：\n- client gets a MISS with lease `L0` (客户端未命中，租约: L0) - client reads DB get value `A` (客户端从数据库读取值: A) - someone updates the DB to value `B` and invalidates the cache entry, which sets lease to `L1` (某人更新了数据库，最新值：B，租约：L1) - client puts value `A` into cache and fails due to lease mismatch (客户端放入 A 值到缓存失败，因为租约不匹配) 事情维持了一致：）\nWrite-through / read-through 缓存 Write-through 缓存方式意味着变异，客户端直接写入缓存。缓存负责同步写入到数据库中。它没有提到如何读取值的问题。客户端可以执行 look-aside 读或 read-through。\nRead-through 缓存意味着读取，客户端直接从缓存中读取。如果是未命中，cache 负责填充数据存储中的数据并回复客户端的查询。它没有提到写作。客户端可以 demand-fill 写入缓存或 write-through。\n现在你得到一张表格 (TAO: Facebook’s Distributed Data Store for the Social Graph)：\n同时有 write-through 和 look-aside 缓存并不常见。既然您已经构建了一个位于客户端和数据存储中间的服务，知道如何与数据存储对话，那么为什么不同时为读写操作这样做呢。也就是说，在有限的缓存大小下，根据查询模式的不同，write-through 和 look-aside 缓存可能是命中率的最佳选择。例如，如果大多数读操作在写操作之后立即执行，那么 write-through 和 look-aside 缓存可能提供最佳命中率。Read-through 和 demand-fill 的结合没有意义。\n现在让我们来看看 write-through 和 read-through 缓存的一致性。对于单个问题，只要正确获取 write 的 update lock 和 read 的 fill-lock，就可以序列化对同一个 key 的读写操作，并且不难看出缓存的一致性将得到维护。如果存在多个缓存副本，这将成为一个分布式系统问题，可能存在一些潜在的解决方案。保持缓存的多个副本一致的最直接的解决方案是拥有一个突变/事件日志，并基于该日志更新缓存。此日志用于单点序列化。它可以是 Kafka 甚至 MySQL binlog。只要突变是以易于重放这些事件的方式进行了全局的排序，就可以保持最终的缓存一致性。注意，这背后的推理与分布式系统中的同步相同。\nWrite-back / memory-only 缓存 还有一类缓存会遭受数据丢失的影响。例如，Write-back 缓存会在写入持久数据存储之前确认写入，如果在两者之间崩溃，则很明显会遭受数据丢失。这种类型的缓存有自己的使用场景，通常用于非常高的吞吐量和qps。但不一定太在意持久性和一致性。关闭持久性的 Redis 就属于这一类。\n译文来源  Different ways of caching and maintaining cache consistency  扫描下面二维码在手机端阅读：\n"});index.add({'id':1,'href':'/posts/help-the-world-by-healing-your-nginx-configuration/','title':"如何改进 NGINX 配置文件节省带宽？",'content':"2014年，Admiral William H. McRaven 在得克萨斯大学发表了著名的演讲，他说，如果你想改变世界，就从整理床铺开始。有时候小事情会有很大的影响——不管是在早上整理床铺，还是对网站的HTTP服务器配置做一些更改。\n这是不是有点言过其实了？2020年的头几个月，我们对世界上正常和合理的事物的所有定义都付之东流。由于COVID-19大流行，地球上几乎一半的人口被锁在家里，互联网已经成为他们唯一的交流、娱乐、购买食物、工作和教育方式。每周互联网的网络流量和服务器负载都比以往任何时候都要高。根据BroadbandNow在3月25日发表的一份报告，“在我们分析的200个城市中，有88个（44%）在过去一周内，相比之前的十周，经历了某种程度的网络退化”。\n为了保护网络链接，Netflix 和 YouTube 等主要媒体平台正在限制其传输质量，为人们工作、与家人交流或在学校上虚拟课程提供更多带宽。但这仍然不够，因为网络质量逐渐恶化，许多服务器变得过载。\n你可以通过优化你的网站来提供帮助 如果您拥有一个网站并可以管理其HTTP服务器配置，则可以提供帮助。一些小的更改可以减少用户生成的网络带宽和服务器上的负载。这是一个双赢的局面：如果你的网站目前负载很重，你可以减少它，使你能够为更多的用户服务，并可能降低你的成本。如果不是在高负载下，更快的加载可以改善用户的体验（有时会对你在谷歌搜索结果中的位置产生积极影响）。\n如果你有一个每月拥有数百万用户的应用程序，或者一个有烤菜谱的小博客，那就没什么关系了——每千字节的网络流量，你就消除了那些迫切需要在线检查医疗检测结果或创建包裹标签以向亲属发送重要信息的人的空闲容量。\n在这个博客中，我们提供了一些简单但强大的更改，您可以对您的 NGINX 配置。作为一个真实世界的例子，我们使用了 Rogalove 的朋友的电子商务网站，Rogalove 是一家位于波兰的生态化妆品制造商。该网站是一个相当标准的 woomerce 安装，运行 NGINX 1.15.9 作为其web服务器。为了便于我们的计算，我们假设网站每天有100个独立用户，30%的用户是经常访问的，每个用户在会话期间平均访问4个页面。\n这些技巧是您可以立即采取的简单步骤，以提高性能和减少网络带宽。如果要处理大量流量，可能需要实现更复杂的更改以产生重大影响，例如调整操作系统和 NGINX、提供正确的硬件容量，以及（最重要的）启用和调整缓存。查看以下博客文章了解详细信息：\n 调整 NGINX 的性能 性能调整-提示和技巧 10倍应用程序性能的10个技巧 在裸机服务器上部署 NGINX Plus 的大小调整指南 NGINX 和 NGINX Plus 缓存指南 NGINX 微缓存的优点  为HTML、CSS和JavaScript文件启用Gzip压缩 如您所知，用于在现代网站上构建页面的HTML、CSS和JavaScript文件可能非常庞大。在大多数情况下，web服务器可以动态压缩这些和其他文本文件，以节省网络带宽。\n查看web服务器是否正在压缩文件的一种方法是使用浏览器的开发工具。对于许多浏览器，可以使用F12键访问工具，相关信息位于“网络”选项卡上。下面是一个例子：\n正如您在左下角看到的，没有压缩：文本文件的大小为1.15 MB，并且传输了这么多数据。\n默认情况下，NGINX 中禁用压缩，但根据安装或Linux发行版的不同，可以在默认的 nginx.conf 文件中启用某些设置。在这里，我们在 NGINX 配置文件中启用 gzip 压缩：\ngzip on; gzip_types application/xml application/json text/css text/javascript application/javascript; gzip_vary on; gzip_comp_level 6; gzip_min_length 500; 正如您在下面的屏幕截图中看到的，通过压缩，数据传输仅下降到260kb，降幅约为80%！对于页面上的每个新用户，您可以节省大约917KB的数据传输。对于我们的 Woocomerce 安装，每天62MB，每月1860MB。\n设置缓存头 当浏览器检索网页的文件时，它会将副本保存在本地磁盘缓存中，这样当您再次访问该网页时，它就不必从服务器重新提取该文件。每个浏览器都使用自己的逻辑来决定何时使用文件的本地副本，以及在服务器上发生更改时何时再次获取该文件。但是作为网站所有者，您可以在发送的HTTP响应中设置缓存控制和过期头，以使浏览器的缓存行为更加高效。从长远来看，不必要的HTTP请求要少得多。\n一个好的开始，您可以为字体和图像设置一个很长的缓存过期时间，这些字体和图像可能不会经常更改（即使更改，它们通常也会得到一个新的文件名）。在下面的示例中，我们指示客户端浏览器将字体和图像保存在本地缓存中一个月：\nlocation ~* \\.(?:jpg|jpeg|gif|png|ico|woff2)$ { expires 1M; add_header Cache-Control \u0026#34;public\u0026#34;; } 启用 HTTP/2 协议支持 HTTP/2 是下一代网页服务协议，旨在提高网络和主机服务器的利用率。根据Google文档，它可以更快地加载页面：\n 由此产生的协议对网络更友好，因为与HTTP/1.x相比，使用的TCP连接更少。这意味着与其他流和存活时间更久的连接的竞争更少，进而导致可用网络容量的更好利用。\n NGINX 1.9.5 及更高版本（以及 NGINX Plus R7 及更高版本）支持 HTTP/2 协议，您只需启用它😀. 为此，请在 NGINX 配置文件的 listen 指令中包含 http2 参数：\nlisten 443 ssl http2; 注意，在大多数情况下，还需要启用 TLS 以使用HTTP/2。\n您可以使用 HTTP2.Pro 服务验证您的（或任何）站点是否支持HTTP/2：\n优化日志记录 给自己准备一杯你最喜欢的饮料，舒舒服服地坐着，想想：你最后一次查看访问日志文件是什么时候？上周，上个月，从来没有？即使您将它用于站点的日常监视，您可能只关注错误（400 和 500 状态代码，等等），而不是成功的请求。\n通过减少或消除不必要的日志记录，可以节省服务器上的磁盘存储、CPU和I/O操作。这不仅使您的服务器更快—如果您部署在云环境中，释放的I/O吞吐量和CPU周期可以更好地服务驻留在同一物理机上的另一个虚拟机或应用程序。\n有几种不同的方法可以减少和优化日志记录。在这里我们强调三点。\n方法1:禁用页面资源请求的日志记录\n如果不需要记录检索普通页面资源（如图像、JavaScript文件和CSS文件）的请求，这是一个快速而简单的解决方案。您只需创建一个与这些文件类型匹配的新位置块，并禁用其中的日志记录。（您也可以将此访问日志指令添加到上面设置缓存控制头的位置块中。）\nlocation ~* \\.(?:jpg|jpeg|gif|png|ico|woff2|js|css)$ { access_log off; } 方法2:禁用成功请求的日志记录\n这是一个更强大的方法，因为它放弃了带有2xx或3xx响应代码的查询，只记录错误。它比方法1稍微复杂一些，因为它取决于NGINX日志的配置方式。在我们的例子中，我们使用包含在Ubuntu服务器发行版中的标准nginx.conf文件，因此不管虚拟主机是什么，所有请求都会记录到/var/log/nginx/access.log.\n使用官方NGINX文档中的一个示例，我们打开条件日志记录。创建一个变量$loggable，对于带有2xx和3xx响应代码的请求，将其设置为0，否则设置为1。然后在access_log指令中将此变量作为条件引用。\n下面是位于 /etc/nginx/nginx.conf 文件中的 http 上下文的的原始指令：\naccess_log /var/log/nginx/access.log; 添加一个映射块并从 access_log 指令中引用它：\nmap $status $loggable { ~^[23] 0; default 1; } access_log /var/log/nginx/access.log combined if=$loggable; 注意，尽管 combined 是默认的日志格式，但是在包含 if 参数时需要显式地指定它。\n方法3：使用缓冲以减少I/O操作\n即使要记录所有请求，也可以通过打开访问日志缓冲来减少I/O操作。使用此指令，NGINX 将暂时不将日志数据写入磁盘，直到512KB缓冲区被填满或自上次刷新以来已过1分钟（以先发生者为准）。\naccess_log /var/log/nginx/access.log combined buffer=512k flush=1m; 限制特定URL的带宽 如果您的服务器提供了较大的文件（或较小但非常流行的文件，如表单或报表），则设置客户端下载这些文件的最大速度可能会很有用。如果您的站点已经处于高网络负载，限制下载速度会留下更多带宽，以保持应用程序的关键部分响应。这是硬件制造商使用的一个非常流行的解决方案-虽然有成千上万的其他人同时下载，您仍然可以获得您的下载，只是您可能需要等待更长的时间才能为打印机下载3GB驱动程序。😉\n使用 limit_rate 指令来限制特定URL的带宽。在这里，我们将每个文件在/download 下的传输速率限制为每秒50kb。\nlocation /download/ { limit_rate 50k; } 您可能还希望只对较大的文件进行速率限制，可以使用 limit-rate-after 指令执行此操作。在本例中，每个文件（从任何目录）的前500kb传输没有速度限制，之后的所有文件都限制在50kb/s。这样可以加快网站关键部分的传输速度，同时减慢其他部分的传输速度。\nlocation / { limit_rate_after 500k; limit_rate 50k; } 请注意，速率限制适用于浏览器和 NGINX 之间的各个HTTP连接，因此不要阻止用户使用下载管理器绕过速率限制。\n最后，还可以限制到服务器的并发连接数或请求速率。有关详细信息，请参阅我们的文档。\n总结 我们希望这五个技巧有助于优化您的网站的性能。速度和带宽增益因网站而异。即使优化 NGINX 配置似乎并没有显著地释放带宽或提高速度，数千个网站单独调整 NGINX 配置的总体影响也会增加。我们的全球网络使用效率更高，这意味着在需要时提供最关键的服务。\n如果您在您的网站上对 NGINX 有任何问题，我们将提供帮助！在COVID-19大流行期间，NGINX 员工和社区正在监视 Stackoverflow 网站上的 Nginx 板块，并尽快响应问题和请求。\n如果您在流行病前线的组织工作，并且有高级需求，那么您可以获得最多5个免费的NGINX Plus许可证以及更高级别的F5 DNS负载平衡器云服务。有关详细信息，请参阅受COVID-19影响的网站的免费资源。\n还可以查看上述链接，了解其他简单的方法，使用NGINX和F5的免费资源来提高网站性能。\n译文来源  Help the World by Healing Your NGINX Configuration "});index.add({'id':2,'href':'/docs/programmer-interview/algorithm/best-time-to-buy-and-sell-stock/','title':"Best Time to Buy and Sell Stock",'content':"Best Time to Buy and Sell Stock 题目 LeetCode 地址：Best Time to Buy and Sell Stock\n有一个数组，第 i 个元素的值代表第 i 天的股票价格，如果你最多只能进行一次交易（某天买入一支股票，然后过几天卖掉），请问你能收获的最大利润是多少？\n分析 这道题有两个简单做法：状态机和动态规划。\n使用状态机的做法的好处是，这种思路可以延续到其它几个买卖股票的问题上。关键是要想清楚，某一天有几种状态，在这道题是三种：\n 状态 s0: 不买也不卖，无操作。s0 的值只能有一个来源，就是和昨天保持一致，不买也不卖 状态 s1: 买入了股票。s1 的值有两个来源：1. 与昨天一致，即已经买入了，且只能买一次，所以不能再买了，s1 = s1；2. 买入今天的股票，花了 price[i] 钱，s1 = s0 - price[i] 状态 s2: 卖出了股票。s2 的值有两个来源：1. 之前已经卖出了，所以维持卖出状态，不能再次卖了，s2 = s1；2. 卖出之前买入的股票，挣 price[i] 钱，s2 = s1 + price[i]  所以，我们可以得到如下状态转移关系：\n s0 = s0 s1 = s1 s1 = s0 - price[i] s2 = s2 s2 = s1 + price[i]  在这整个过程中，我们都要保证每一天的 s0、s1、s2 都是 max 状态，s2 是最终卖完后的收益，所以返回这个结果就行。\n 动态规划的想法：\n我们不要考虑每一天的价格，只需要考虑今天与昨天的价格之差：diff[i]。最终的收益是从这个 diff 数组中取出连续的一段，这一段累加起来的和最大。\n对于股票这道题而言，如果累加起来的最大值为负数，那么我们还不如全程不买卖股票，这样收益至少不是负值，也就是0。所以当 currMax 的值变为负数的时候，我们就废弃掉之前的结果，从此刻开始进行新的累加。\n答案 // MaximumSubarray public class BestTimetoBuyandSellStock { // 状态机 State Machine 做法  public int maxProfit(int[] prices) { if (prices == null || prices.length \u0026lt;= 1) { return 0; } //  // Buy Sell  // s0 ----\u0026gt; s1 ------\u0026gt; s2 (end)  // ↑__| ↑___|  //  int s0 = 0; // 初始状态  int s1 = -prices[0]; // 买入这支股票，花费 prices[i] 钱  int s2 = 0; // 一开始也是 0  for (int i = 1; i \u0026lt; prices.length; i++) { // ====================  // s0: 自始至终从未有过买卖  // ====================  s0 = s0; /** 维持自身 */ // ====================  // s1: 买入某支股票。我们只能买一次，然后一直维持。而每一次买都让我们花费了 prices[i] 元  // ====================  s1 = Math.max(s1 /** 维持自身 */, s0 - prices[i] /** 花费 prices[i] 买入这支股票 */); // ====================  // s2: 卖出某支股票。我们只能卖一次，然后一直维持。而每一次卖都让我们盈利 s1 + prices[i] 元  // ====================  s2 = Math.max(s2 /** 维持自身 */, s1 + prices[i] /** 卖掉这支股票，赚取 prices[i] */); } return s2; } public int maxProfit0(int[] prices) { if (prices == null || prices.length == 0) { return 0; } int max = 0; int currMax = 0; // 股票每天都在降低的话，那么最大利润为 0  // 也就是说这个地方每一次都可以不买  //  // 但是 MaximumSubarray 这道题，每次都必须选择一个，所以这个 MaximumSubarray 可以是负数  for (int i = 1; i \u0026lt; prices.length; i++) { currMax = Math.max(currMax + (prices[i] - prices[i - 1]) /** 当前累加的总收益 */, 0); max = Math.max(currMax, max); /** 在这个中间过程中，记录最大的值 */ } return max; } } 扫描下面二维码，在手机上阅读这篇文章：\n"});index.add({'id':3,'href':'/docs/cloud-plus-bbs/bilibili-high-availability/','title':"B站高可用架构实践",'content':"B站高可用架构实践 流量洪峰下要做好高服务质量的架构是一件具备挑战的事情，从Google SRE的系统方法论以及实际业务的应对过程中出发，分享一些体系化的可用性设计。对我们了解系统的全貌上下游的联防有更进一步的了解。\n负载均衡 BFE 就是指边缘节点，BFE 选择下游 IDC 的逻辑权衡：\n 离 BFE 节点比较近的 基于带宽的调度策略 某个 IDC 的流量已经过载，选择另外一个 IDC  当流量走到某个 IDC 时，这个流量应该如何进行负载均衡？\n问题：RPC 定时发送的 ping-pong，也即 healthcheck，占用资源也非常多。服务 A 需要与账号服务维持长连接发送 ping-pong，服务 B 也需要维持长连接发送 ping-pong。这个服务越底层，一般依赖和引用这个服务的资源就越多，一旦有任何抖动，那么产生的这个故障面是很大的。那么应该如何解决？\n解决：以前是一个 client 跟所有的 backend 建立连接，做负载均衡。现在引入一个新的算法，子集选择算法，一个 client 跟一小部分的 backend 建立连接。图片中示例的算法，是从《Site Reliability Engineering》这本书里看的。\n如何规避单集群抖动带来的问题？多集群。\n如上述图片所示，如果采用的是 JSQ 负载均衡算法，那么对于 LBA 它一定是选择 Server Y 这个节点。但如果站在全局的视角来看，就肯定不会选择 Server Y 了，因此这个算法缺乏一个全局的视角。\n如果微服务采用的是 Java 语言开发，当它处于 GC 或者 FullGC 的时候，这个时候发一个请求过去，那么它的 latency 肯定会变得非常高，可能会产生过载。\n新启动的节点，JVM 会做 JIT，每次新启动都会抖动一波，那么就需要考虑如何对这个节点做预热？\n如上图所示，采用 \u0026ldquo;the choice-of-2\u0026rdquo; 算法后，各个机器的 CPU 负载趋向于收敛，即各个机器的 CPU 负载都差不多。Client 如何拿到后台的 Backend 的各项负载？是采用 Middleware 从 Rpc 的 Response 里面获取的，有很多 RPC 也支持获取元数据信息等。\n还有就是 JVM 在启动的时候做 JIT，以前的预热做法：手动触发预热代码，然后再引入流量，再进行服务发现注册等，不是非常通用。通过改进负载均衡算法，引入惩罚值的方式，慢慢放入流量进行预热。\n限流 用 QPS 限制的陷阱：\n 不同的参数，请求的数据量是不同的，对一个进程的一个吞吐是有影响的。 业务是经常迭代的，配一个静态的阈值，这个非常困难。能否按照每一个服务用多少个 CPU 来做限流？  每一个 API 都是有重要性的：非常重要、次重要，这样配置限流、做过载保护的时候，可以使用不同的阈值。\n每个服务都要配一个限流，是非常烦人的，需要压测，是不是可以自适应去限流？\n每个 Client 如何知道自己这一次需要申请多少 Quota ？基于历史数据窗口的 QPS。\n节点与节点之间是有差异的，分配算法不够好，会导致某些节点产生饥饿。那么可以采用最大最小公平算法，尽可能地比较公平地去分配资源，来解决这个问题。\n当量再大一点的时候，如果 Backend 一直忙着拒绝请求，比如发送 503，那么它还是会挂掉。这种情况就要考虑从 Client 去截流。此处，又提到了 Google 《Site Reliability Engineering》这本书里面的一个算法，即 Client 是按照一定概率去截流。那么这个概率怎么计算？一个是总请求量：requests，一个是成功的请求量：accepts。如果服务报错率比较高，意味着 accepts 不怎么增长，requests 一直增长，最终这个公式求极限，它会等于 1，所以它的丢弃概率是非常高的。基于这么一个简单的公式，不需要依赖什么 ZooKeeper，什么协调器之类的，就可以得到一个概率丢弃一些请求。它尽可能的在服务不挂掉的情况下，放更多的流量进去，而不是像 Netflix 一样全部拒掉。\n连锁故障通常都是某一个节点过载了挂掉，流量又会去剩下的 n - 1 个节点，又扛不住，又挂掉，所以最终一个一个挨着雪崩。所以过载保护的目的是为了自保。\nB 站参考了阿里的 Sentinel 框架、Netflix 的一些文章等，最终采用的是类似于 TCP BBR 探测的思路和算法。简单说：当 CPU 达到 80% 的时候，这个时候我们认为流量过载，如果此时吞吐量比如 100，用它作为阈值，瞬时值的请求比如是 110，那就可以丢掉 10 个流量。这样就可以实现一个限流算法。\nCPU 抖来抖去，使用 CPU 滑动均值（绿色线）可以跳动的没有这么厉害。这个 CPU 针对不同接口的优先级，例如低优先级 80% 触发，高优先级 90% 触发，可以定为一个阈值。\n那么吞吐如何计算？利特尔法则。当前的 QPS * 延迟 = 吞吐，可以用过去的一个窗口作为指标。一旦丢弃流量，CPU 立马下来，算法抖动非常厉害。图二右侧黄色线表示抖动非常高，绿色线表示放行的流量也是抖动非常高，所以又加了冷却时间，比如持续几秒钟，再重新判断。\n重试  BFE: 动态 CDN SLB: LVS + Nginx 实现，四七层负载均衡 BFF: 业务逻辑组装、编排  问题：每一层都重试，这一层 3 次，那一层 3 次，会指数级的放大。解决：只在失败这一层重试，如果重试之后失败，请返回一个全局约定好的错误码，比如说：过载，无需重试，发现这个错误码，通通放行，避免级联重试。\n重试都应该无脑的重试三次吗？API 级别的重试需要考虑集群的过载情况。是不是可以约定一个重试比例呢？比如只允许 10% 的流量进行重试，Client 端做统计，当发现有 10% 都是重试，那么剩下的都拒绝掉。这样最多产生 1.1 倍的放大，重试 3 次，极端情况下，会产生 3 倍放大。还有在重试的时候，尽量引入随机、指数递增的一个重试周期，大家不要都重试 1 秒钟，有可能会堆砌一个重试的波峰。\n重试的统计图和记录 QPS 的图分开。问题诊断的时候，可以知道它是来自流量重试导致的问题放大。\n某个服务不可用的时候，用户总是会猛点，那么这个时候，需要去限制它的频次，一个短周期内不允许发重复请求。这种策略，有可能会根据不同的过载情况经常调这种策略，那么可以挂载到每一个 API 里面。\n超时 大部分的故障都是因为超时控制不合理导致的。\n 某个高延迟服务可能会导致 Client 堆积，Client 线程会阻塞，上游流量不断进来，下游的消费速度跟不上上游的流入速度，进程会堆积越来越多请求，可能会 OOM。 超时的策略本质是就是为了丢弃或者消耗掉请求。 下游 2 秒返回，上游配置了 1 秒，上游超时已经返回给用户，下游还在执行，浪费资源。  某个服务需要在 1 秒返回，内部可能需要访问 Redis，需要访问 RPC，需要访问数据库，时间加起来就超过 1 秒，那么访问完每一层，应该计算供下一层使用的超时时间还剩多少可用。在 go 语言里，可能会使用 Context，每一个网络请求开始的阶段，都要根据配置文件配置的超时时间，和当前剩余多少，取一个最小值，最终整个超时时间不会超过 1 秒。\n通过 RPC 的元数据传递，类似 HTTP 的 request header，带给其它服务。例如在图中，就是把 700ms 这个配额传递给 Service B。\n下游服务作为服务提供者，在他的 RPC.IDL 文件中把自己的超时要配上，那么用 IDL 文件的时候，就知道是 200 ms，不用去问。\n应对连锁故障 优雅降级：一开始千人千面，后来只返回热门的\n参考 QA  Q: 请问负载均衡依据的 metric 是什么？ A: 服务端主要用 CPU，客户端用的是健康度，指连接的成功率，延迟也很重要，每个 Client 往不同的 Backend 发了多少个请求，四个指标归一，写一个线性方程，进行打分。    Q: BFE 到 SLB 走公网还是专线？ A: 既有公网，又有专线。    Q: Client 几千量级，每 10 秒 ping-pong 一下，会不会造成蛮高的 CPU？ A: 如果 Backend 很多的话，那么这个的确会造成。    Q: 多集群切换是否有阻塞的点？ A: 一个 Client 连接到各个集群，subset 算法，每个集群都有 Cache    Q: 负载均衡的探针是怎么做的？ A: 惩罚值，比如 5 秒，慢慢放流量    Q: Quota-Server 限流有开源实现吗？ A: 目前看到的都是针对单节点的。    Q: 客户端统计是否有点太多？ A: 可以做到 Sidecar、Service Mesh 里面    Q: 超时传递是不是太严格？ A: 有些情况下即便超时也要运行，可以通过 RPC Context 管控    Q: 每个 RPC 都获取 CPU 会不会很昂贵？ A: 后台开启线程定时计算 CPU 平滑均值    Q: 线上压测和测试环境压测 CPU 不一致 A: RPC 路由加影子库    Q: CC 攻击 A: 边缘节点或者核心机房都有防止 CC 攻击的一些手段，只要不是分布式搞你，都能找到流量特征进行管控  "});index.add({'id':4,'href':'/docs/rocketmq/rocketmq-send-message-flow/','title':"RocketMQ 消息发送流程",'content':"RocketMQ 消息发送流程 本文讲述 RocketMQ 发送一条普通消息的流程。\n一、服务器启动 我们可以参考官方文档来启动服务:\n 启动 Name 服务器:  sh bin/mqnamesrv  启动 Broker 服务器:  sh bin/mqbroker -n localhost:9876 二、构建消息体 一条消息体最少需要指定两个值:\n 所属话题 消息内容  如下就是创建了一条话题为 “Test”，消息体为 “Hello World” 的消息:\nMessage msg = new Message( \u0026#34;Test\u0026#34;, \u0026#34;Hello World\u0026#34;.getBytes() ); 三、启动 Producer 准备发送消息 如果我们想要发送消息呢，我们还需要再启动一个 DefaultProducer (生产者) 类来发消息:\nDefaultMQProducer producer = new DefaultMQProducer(); producer.start(); 现在我们所启动的服务如下所示:\n四、Name 服务器的均等性 注意我们上述开启的是单个服务，也即一个 Broker 和一个 Name 服务器，但是实际上使用消息队列的时候，我们可能需要搭建的是一个集群，如下所示:\n在 RocketMQ 的设计中，客户端需要首先询问 Name 服务器才能确定一个合适的 Broker 以进行消息的发送:\n然而这么多 Name 服务器，客户端是如何选择一个合适的 Name 服务器呢?\n首先，我们要意识到很重要的一点，Name 服务器全部都是处于相同状态的，保存的都是相同的信息。在 Broker 启动的时候，其会将自己在本地存储的话题配置文件 (默认位于 $HOME/store/config/topics.json 目录) 中的所有话题加载到内存中去，然后会将这些所有的话题全部同步到所有的 Name 服务器中。与此同时，Broker 也会启动一个定时任务，默认每隔 30 秒来执行一次话题全同步:\n五、选择 Name 服务器 由于 Name 服务器每台机器存储的数据都是一致的。因此我们客户端任意选择一台服务器进行沟通即可。\n其中客户端一开始选择 Name 服务器的源码如下所示:\npublic class NettyRemotingClient extends NettyRemotingAbstract implements RemotingClient { private final AtomicInteger namesrvIndex = new AtomicInteger(initValueIndex()); private static int initValueIndex() { Random r = new Random(); return Math.abs(r.nextInt() % 999) % 999; } private Channel getAndCreateNameserverChannel() throws InterruptedException { // ...  for (int i = 0; i \u0026lt; addrList.size(); i++) { int index = this.namesrvIndex.incrementAndGet(); index = Math.abs(index); index = index % addrList.size(); String newAddr = addrList.get(index); this.namesrvAddrChoosed.set(newAddr); Channel channelNew = this.createChannel(newAddr); if (channelNew != null) return channelNew; } // ...  } } 以后，如果 namesrvAddrChoosed 选择的服务器如果一直处于连接状态，那么客户端就会一直与这台服务器进行沟通。否则的话，如上源代码所示，就会自动轮寻下一台可用服务器。\n六、寻找话题路由信息 当客户端发送消息的时候，其首先会尝试寻找话题路由信息。即这条消息应该被发送到哪个地方去。\n客户端在内存中维护了一份和话题相关的路由信息表 topicPublishInfoTable，当发送消息的时候，会首先尝试从此表中获取信息。如果此表不存在这条话题的话，那么便会从 Name 服务器获取路由消息。\npublic class DefaultMQProducerImpl implements MQProducerInner { private TopicPublishInfo tryToFindTopicPublishInfo(final String topic) { TopicPublishInfo topicPublishInfo = this.topicPublishInfoTable.get(topic); if (null == topicPublishInfo || !topicPublishInfo.ok()) { this.topicPublishInfoTable.putIfAbsent(topic, new TopicPublishInfo()); this.mQClientFactory.updateTopicRouteInfoFromNameServer(topic); topicPublishInfo = this.topicPublishInfoTable.get(topic); } // ...  } } 当尝试从 Name 服务器获取路由信息的时候，其可能会返回两种情况:\n(1) 新建话题 这个话题是新创建的，Name 服务器不存在和此话题相关的信息：\n(2) 已存话题 话题之前创建过，Name 服务器存在此话题信息：\n服务器返回的话题路由信息包括以下内容:\n“broker-1”、”broker-2” 分别为两个 Broker 服务器的名称，相同名称下可以有主从 Broker，因此每个 Broker 又都有 brokerId 。默认情况下，BrokerId 如果为 MixAll.MASTER_ID （值为 0） 的话，那么认为这个 Broker 为 MASTER 主机，其余的位于相同名称下的 Broker 为这台 MASTER 主机的 SLAVE 主机。\npublic class MQClientInstance { public String findBrokerAddressInPublish(final String brokerName) { HashMap\u0026lt;Long/* brokerId */, String/* address */\u0026gt; map = this.brokerAddrTable.get(brokerName); if (map != null \u0026amp;\u0026amp; !map.isEmpty()) { return map.get(MixAll.MASTER_ID); } return null; } } 每个 Broker 上面可以绑定多个可写消息队列和多个可读消息队列，客户端根据返回的所有 Broker 地址列表和每个 Broker 的可写消息队列列表会在内存中构建一份所有的消息队列列表。之后客户端每次发送消息，都会在消息队列列表上轮循选择队列 (我们假设返回了两个 Broker，每个 Broker 均有 4 个可写消息队列):\npublic class TopicPublishInfo { public MessageQueue selectOneMessageQueue() { int index = this.sendWhichQueue.getAndIncrement(); int pos = Math.abs(index) % this.messageQueueList.size(); if (pos \u0026lt; 0) pos = 0; return this.messageQueueList.get(pos); } } 七、给 Broker 发送消息 在确定了 Master Broker 地址和这个 Broker 的消息队列以后，客户端才开始真正地发送消息给这个 Broker，也是从这里客户端才开始与 Broker 进行交互:\n这里我们暂且先忽略消息体格式的具体编/解码过程，因为我们并不想一开始就卷入这些繁枝细节中，现在先从大体上了解一下整个消息的发送流程，后续会写专门的文章来说明。\n八、Broker 检查话题信息 刚才说到，如果话题信息在 Name 服务器不存在的话，那么会使用默认话题信息进行消息的发送。然而一旦这条消息到来之后，Broker 端还并没有这个话题。所以 Broker 需要检查话题的存在性:\npublic abstract class AbstractSendMessageProcessor implements NettyRequestProcessor { protected RemotingCommand msgCheck(final ChannelHandlerContext ctx, final SendMessageRequestHeader requestHeader, final RemotingCommand response) { // ...  TopicConfig topicConfig = this.brokerController .getTopicConfigManager() .selectTopicConfig(requestHeader.getTopic()); if (null == topicConfig) { // ...  topicConfig = this.brokerController .getTopicConfigManager() .createTopicInSendMessageMethod( ... ); } } } 如果话题不存在的话，那么便会创建一个话题信息存储到本地，并将所有话题再进行一次同步给所有的 Name 服务器:\npublic class TopicConfigManager extends ConfigManager { public TopicConfig createTopicInSendMessageMethod(final String topic, /** params **/) { // ...  topicConfig = new TopicConfig(topic); this.topicConfigTable.put(topic, topicConfig); this.persist(); // ...  this.brokerController.registerBrokerAll(false, true); return topicConfig; } } 话题检查的整体流程如下所示:\n九、消息存储 当 Broker 对消息的一些字段做过一番必要的检查之后，便会存储到磁盘中去:\n十、整体流程 发送消息的整体流程:\n"});index.add({'id':5,'href':'/docs/programmer-interview/front-end/vue/','title':"VUE 面试题",'content':"VUE 面试题 整理 VUE 相关的常见面试题\n介绍一下 VUE 介绍一下 VUEX VUE 2.X 和 3.0 的区别 （1）数据监听方式变化\nVUE 2.X 使用 ES5 的 Object.defineProperty() 的 get() 和 set(newValue) 实现，VUE 3.0 基于 Proxy 监听实现，同时更为强大：\n 可以检测属性的新增和删除 可以检测数组索引的变化和 length 的变化 支持 Map、Set、WeakMap 和 WeakSet   优点：速度加倍，内存占用减半。\n （2）体积更小\n支持 Tree Shaking，内置组件、内置指令按需引入。\n（3）速度更快\n参考：vue3.0和vue2.x的区别、Vue 3.0 和 Vue 2.0的对比以及Vue 2.0精讲以及Vue全家桶精讲\nVUE 的生命周期 VUE 数据双向绑定原理 VUE 采用发布者-订阅者模式的方式来实现双向绑定。\n（1）视图更新数据：\ninput 标签监听 input 事件即可。\n（2）数据更新视图：\nObject.defineProperty() 监听数据变化，通过消息订阅器发布消息，订阅者收到消息执行相应的操纵 DOM 的函数，从而更新视图。\nVUE 的路由机制  hash 和 history 区别  v-if 和 v-show 的区别  v-show：无论值是 true 还是 false，元素都会存在于 HTML 代码中。 v-if：只有值为 true 的时候，元素才会存在于 HTML 代码中。  VUE 组件通信方式  引申：如果有多层的父子组件，用什么通信  VUE 的 v-for 中的 key 的作用 一句话回答：为了高效的更新虚拟 DOM。\nnextTick 原理与应用场景 Vue 在修改数据后，视图不会立刻更新，而是等同一事件循环中的所有数据变化完成之后，再统一进行视图更新。\n//改变数据 vm.message = \u0026#39;changed\u0026#39; //想要立即使用更新后的DOM。这样不行，因为设置message后DOM还没有更新 console.log(vm.$el.textContent) // 并不会得到\u0026#39;changed\u0026#39;  //这样可以，nextTick里面的代码会在DOM更新后执行 Vue.nextTick(function(){ console.log(vm.$el.textContent) //可以得到\u0026#39;changed\u0026#39; }) 应用场景：需要在 DOM 视图更新之后，基于新的 DOM 视图进行操作。\n参考：Vue.nextTick 的原理和用途\nVUE 的虚拟 DOM  VUE 是如何实现 VDOM 的 vue中keep-alive缓存的真实结点还是虚拟结点 vue改变组件的key值, 原来的组件会被销毁么 为什么要用虚拟结点 diff 原理  vue 从 data 改变到页面渲染的过程 参考  诚意满满的前端面试总结（回馈牛客）  "});index.add({'id':6,'href':'/docs/programmer-interview/front-end/','title':"前端",'content':"前端面试题 "});index.add({'id':7,'href':'/docs/tutorial/front-end-optimization-guide/','title':"前端优化指南",'content':"前端优化指南  图片优化 HTML 优化 CSS 优化  "});index.add({'id':8,'href':'/docs/tutorial/front-end-optimization-guide/image-optimization/','title':"图片优化",'content':"图片优化 图片在网页数据的传输中占据了非常大的流量，如何优化图片，对于前端页面加载的性能极其重要。本文讲述了比较常见的几种优化图片的技巧。\n图片格式介绍 （1）JPEG\nJPEG 是 Joint Photographic Experts Group 的缩写，不支持透明度，常用于网站的 Banner 图。JPEG 使用的是一种有损图像质量的压缩算法，压缩的越狠，图片的质量损失也就越大，图片的尺寸也就越小。根据你网站所能忍受的图片质量，来相应的选择压缩比：\n（2）PNG\n支持透明度，支持无损压缩，一般图片的尺寸都比较大。\n（3）GIF\n适合放动画图片。\n（4）WebP\n🔥Google 2010 年提出的新的图像压缩格式算法，在 2013 年又推出 Animated WebP，即支持动画的 Webp。优点：更优的图像数据压缩算法、拥有肉眼识别无差异的图像质量、具备了无损和有损的压缩模式、Alpha 透明以及动画的特性。\nPNG、JPG、WebP 压缩对比：\nGIF 和 WebP 对比：\n不同网络环境，加载不同尺寸图片 如下是京东网站首页占据 C 位的宣传图：\n它的 URL 地址如下，你任意改变这张图片的 URL 里面的宽、高，放到浏览器里面重新进行请求，就可以得到相应大小的图片：\n响应式图片 不同平台设备加载不同大小、甚至不同内容的图片！\nCSS 媒体查询 @media all and (max-width: 600px) { img { width: 300px; } } @media all and (min-width: 600px) and (max-width: 1200px) { img { width: 900px; } } srcset、sizes、picture 和 source （1）srcset 属性\nimg 标签的 srcset 属性定义了我们允许浏览器选择的图像集，以及每个图像的大小：\n\u0026lt;img srcset=\u0026#34;images/team-photo.jpg 1x, images/team-photo-retina.jpg 2x, images/team-photo-full.jpg 2048w, images/team-photo-default.jpg\u0026#34; src=\u0026#34;team-photo.jpg\u0026#34;\u0026gt; 上述代码，srcset 属性给出了四个图像的 URL。1x 或 2x 这个 x 代表 pixel density descriptor，代表当当前设备的像素密度是标准像素密度的 1 倍或 2 倍时，去加载对应的图片，这个值可以是浮点数。2048w 的 w 代表 width descriptor，也就是图片的以像素为单位的宽度，当浏览器的渲染器需要去渲染宽度为 2048 像素的图片的时候，就会使用这张图片，这个值必须是正整数。\n最后一个图像 URL images/team-photo-default.jpg 没有带 x 或者 w，这表示这张图片是一张候选图片，当 srcset 其它图片都没有匹配上的时候，那么就会使用这种图片。当然，候选图片是可选的，如果不提供，就会选择使用 src 图片作为默认图片。\n（2）sizes 属性\nsrcset 提供了一个图片的候选集，但是选择哪个图片是浏览器决定的，我们无法灵活控制。如果想要自己根据屏幕的大小，来告诉渲染器去渲染多大尺寸的图片，可以引入 sizes 属性。\n\u0026lt;img src=\u0026#34;/files/16870/new-york-skyline-wide.jpg\u0026#34; srcset=\u0026#34;/files/16870/new-york-skyline-wide.jpg 3724w, /files/16869/new-york-skyline-4by3.jpg 1961w, /files/16871/new-york-skyline-tall.jpg 1060w\u0026#34; sizes=\u0026#34;((min-width: 50em) and (max-width: 60em)) 50em, ((min-width: 30em) and (max-width: 50em)) 30em, (max-width: 30em) 20em\u0026#34;\u0026gt; sizes 的格式：媒体查询条件 目标值。\n上述的 sizes 属性表示，当屏幕宽度位于 50em ~ 60em 的时候，渲染所需图片宽度为 50em，当屏幕宽度位于 30em ~ 50em 的时候，渲染所需图片宽度为 30em，当屏幕宽度小于 30em，渲染所需图片宽度为 20em。当渲染器所需渲染的图片宽度确定的时候，再去 srcset 中去匹配最接近该宽度的图片 URL 即可。\n目标值的单位可以是：\n 相对字体大小的单位：em 或 ex 绝对单位：px 或 cm Viewport(窗口) 百分比单位：vw  （3）picture 和 source\nsrcset 和 sizes 可以让网站根据屏幕大小来加载**内容相同的（虽然也可以不同，但不应该这样用）**不同大小的图片，如果还想根据不同的屏幕，显示不同内容的图片，例如电脑上显示如下比较宽的图：\n而手机上为了突出人物，显示比较瘦的图：\n可以使用 \u0026lt;picture\u0026gt; 和 \u0026lt;source\u0026gt; 标签来解决这个问题：\n\u0026lt;picture\u0026gt; \u0026lt;source media=\u0026#34;(max-width: 799px)\u0026#34; srcset=\u0026#34;elva-480w-close-portrait.jpg\u0026#34;\u0026gt; \u0026lt;source media=\u0026#34;(min-width: 800px)\u0026#34; srcset=\u0026#34;elva-800w.jpg\u0026#34;\u0026gt; \u0026lt;img src=\u0026#34;elva-800w.jpg\u0026#34; alt=\u0026#34;Chris standing up holding his daughter Elva\u0026#34;\u0026gt; \u0026lt;/picture\u0026gt; 上述代码的 \u0026lt;img\u0026gt; 标签是必须提供，否则不会显示任何图片，当 \u0026lt;source\u0026gt; 的媒体查询条件都不满足的时候，\u0026lt;img\u0026gt; 将会显示 src 所指向的 URL 图片。\n除此之外，\u0026lt;picture\u0026gt; 标签还可以根据浏览器所能渲染的图片格式来选择不同的图片：\n\u0026lt;picture\u0026gt; \u0026lt;source type=\u0026#34;image/svg+xml\u0026#34; srcset=\u0026#34;pyramid.svg\u0026#34;\u0026gt; \u0026lt;source type=\u0026#34;image/webp\u0026#34; srcset=\u0026#34;pyramid.webp\u0026#34;\u0026gt; \u0026lt;img src=\u0026#34;pyramid.png\u0026#34; alt=\u0026#34;regular pyramid built from four equilateral triangles\u0026#34;\u0026gt; \u0026lt;/picture\u0026gt; 当浏览器按照 \u0026lt;source\u0026gt; 出现的顺序，依次探测是否满足条件，如果满足，就加载相应图片。\n懒加载 有很多库可以实现懒加载图片，例如 lazysizes。对于每一张图片，需要确定在其原图内容还未被浏览器渲染出来之前，这张图应该显示什么占位符，目前有两个库可以生成图像的占位符。当然，如果对于所有图片，都像是用一个统一的图片作为占位符，也未尝不可。\nLQIP LQIP 就是 Low Quality Image Placeholders (低质量图像占位符) 的缩写。\nSQIP 上述 LQIP 是基于像素的解决方案，而 SQIP 是 SVG-based LQIP (基于 SVG 的低质量图像占位符) 的缩写，其实基于 SVG 的，在任何设备上都看起来很清晰。\n下图展示的是一个效果图：\n换一种方式来表达图片 Data URL 对于一些较小的图片，可以将内容直接内嵌在 URL 中，常见格式如下：\ndata:[\u0026lt;mediatype\u0026gt;][;base64],\u0026lt;data\u0026gt; mediatype 标识图片的格式，例如 image/jpeg 等。\nImage sprites (雪碧图) 对于 HTTP 1.X 协议，雪碧图（即多张小图片合成一张大图）的加载方式，是很多网站都会采用的技巧，这种方式的缺点是，如果某个应用图标需要更新，那么整张大图都需要替换。\n然而对于 HTTP 2.0 协议的到来，加载多张小图是比较推荐的做法，因为多张图片本身的下载都会复用同一个连接。\n参考  HTMLImageElement.srcset Responsive images Essential Image Optimization  扫描下面二维码，在手机端阅读：\n"});index.add({'id':9,'href':'/docs/books/beauty_of_mathematics/','title':"数学之美",'content':"数学之美 2000多年前，古埃及人在罗塞塔石碑上，用三种文字记录了托勒密五世登基的诏书，这帮助后人破解了古埃及的象形文字，让我们了解了5000年前古埃及的历史。可见信息冗余是信息安全的保障，这对于信息编码具有重要指导意义。\n犹太人为了避免抄错《圣经》，发明了一种校验码的方法，他们把每一个希伯来字母对应于一个数字，这样每行文字加起来便得到一个特殊的数字，这样的数字变成为了这一行的校验码。\n隐含马尔可夫链成功应用在机器翻译、拼写纠错、手写体识别、图像处理、基因序列分析、股票预测和投资等方面。\n如何准确的识别出一个快递地址，写一个分析器去分析这些描述恐怕是不行的，因为地址是比较复杂的上下文有关的文法。答案是使用有限状态机。当用户输入的地址不太标准或有错别字的时候，有限状态机会束手无措，因为有限状态机是严格匹配的，所以科学家提出了基于概率的有限状态机。\n2002 年，Google 想要做一个全新的中、日、韩搜索算法，吴军写的算法比较简单，但是占用内存比较多，Google 服务器数量还没有那么多。辛格提出，用一个拟合函数替换很耗内存的语言模型，无需增加任何服务器，但是搜索质量会降到 80%。辛格指出，这样可以提早两个月将这个新算法提供给中国的用户，用户体验会有质的提高。辛格做事情的哲学，先帮助用户解决 80% 的问题，再慢慢解决剩下的 20% 的问题，是在工业界成功的秘诀之一。\n新闻分类的关键在于计算出两篇新闻的相似度，每篇新闻变成一个向量，最后余弦定理可以计算出来相似度。但两两计算的迭代次数太多，如何一次性就把所有新闻的相关性计算出来呢？答案是矩阵运算中的奇异值分解。\n如何判断两个集合是否相同？一种答案是双层 for 循环一一比较，复杂度 O(N^2)；稍好一点的办法是对集合进行排序，然后顺序比较，时间复杂度 O(NlogN)；还可以将一个集合的元素放到散列表里面，另外一个与之一一对比，时间复杂度 O(N)，但是额外使用了 O(N) 的空间，不完美；最完美的是计算这两个集合的指纹，对一个集合中的元素分别计算指纹，然后一一相加。\n如何判断两个集合基本相同？答案是 Simhash。判断两个网页是否重复，也没有必要完全从头比到尾，只需要每个网页挑选出几个词 (IDF 最大的几个词)，构成特征词，然后计算信息指纹即可。判断一篇文章是否抄袭另外一篇文章，每篇文章切成小的片段，挑选特征词，并计算指纹。YouTuBe 如何从上百万视频中找出一个视频是否另外一个视频的盗版？其核心在于关键帧的提取和特征的提取。关键帧对于视频的重要性，就如同主题词对于新闻的重要性一样。\n最大熵原理指出，对一个随机事件的概率分布进行预测时，我们的预测应当满足全部已知的条件，而对未知的情况不要做任何主观假设，这种情况下，概率分布最均匀，预测的风险最小。例如拼音输入法，Wang-Xiao-Bo 转换为王晓波和王小波，唯一确定用户需要的是哪一个，非常难。\n"});index.add({'id':10,'href':'/docs/javascript/understand-this-keyword/','title':"理解 This 关键字",'content':"理解 This 关键字 JavaScript 中的 this 所指向的对象，取决于上下文以及函数被调用的方式，本文列举了几种常见的情况，帮助大家理解。\n一、全局上下文 当直接在一个全局的上下文中，使用 this 指针的时候，this 指针会指向到全局对象上。例如在浏览器的调试工具栏中直接打印 this 指针，其指向的是 Window 对象：\n在 node 中打印 this 指针，其指向的是 node 提供的全局对象，其中包含了进程信息等：\n二、Function 上下文 在 Function 上下文中，this 的值取决于 function 是如何被调用的。\n(1) Function 调用 当 this 指针定义在一个 function 中，那么此 this 仍然会指向全局对象：\nfunction foo() { console.log(this) } foo(); // Window {parent: Window, postMessage: ƒ, blur: ƒ, focus: ƒ, close: ƒ, …} (2) 严格模式下的 Function 调用 如果在严格模式下定义的 function 的话，this 指针的值将会是 undefined：\nfunction foo() { \u0026#39;use strict\u0026#39;; console.log(this) } foo(); // undefined (3) Method 调用 Method 调用指的是，function 作为一个对象的属性而存在。当 this 指针被定义在一个对象内的时候，那么其将会指向紧紧包裹自己的这个对象。\nvar obj = { name: \u0026#39;outerObj\u0026#39;, innerObj: { name: \u0026#39;innerObj\u0026#39;, foo: function() { console.log(this.name) } } }; console.log(obj.innerObj.foo()) // innerObj (4) 构造器调用 当 function 被用于构造器的时候，那么定义在构造器内部的 this 指针将会指向此构造器新 new 出来的实例对象。\nfunction Person(name) { this.name = name console.log(this) } console.log(new Person(\u0026#34;Tom\u0026#34;)) // Person {name: \u0026#34;Tom\u0026#34;} (5) call()、apply()、bind() 调用 这三个函数最大的特点就是，你可以通过参数为他们指定 this 指针所需要指向的对象：\nfunction add(inc1, inc2) { var value = this.a + inc1 + inc2; console.log(this) return value; } var o = { a : 4 }; console.log(add.call(o, 5, 6)) // {a: 4} console.log(add.apply(o, [5, 6])) // {a: 4}  var g = add.bind(o, 5, 6) console.log(g()) // {a: 4} (6) ES6 箭头函数调用 当你使用 ES6 箭头函数的时候，this 指针返回的总是箭头函数定义所在位置的上一级的函数作用域的 this 对象，是箭头函数被 function() { } 包裹的作用域中的 this 对象。如下面示例，this 指向的是 log() 函数内部的 this 指针的值：\nclass Student { log() { // 这个地方的 this 的值  setTimeout(() =\u0026gt; console.log(this === student), 100) } } const student = new Student() student.log() // true 但是如果上一级并不是位于函数作用域中，而是位于 Object 对象嵌套层级中，则需要继续向上找函数作用域，因为 Object 嵌套层级不构成单独的作用域。如下所示 this 指针指向的是 Window 对象，而非 o 对象：\nvar o = { b: () =\u0026gt; { console.log(\u0026#39;this is\u0026#39;, this); // this is Window  } } o.b(); 三、参考  How does the “this” keyword work? Gentle Explanation of \u0026ldquo;this\u0026rdquo; in JavaScript MDN this 箭头函数this的指向问题  "});index.add({'id':11,'href':'/docs/programmer-interview/algorithm/','title':"算法",'content':"算法面试题 本专栏的面试题来自于牛客网、一亩三分地、LeetCode、LintCode等网站，覆盖了一线互联网如BAT、TMD、微软、亚马逊等巨头，在校招或者社招的时候最容易出的算法面试题。\n"});index.add({'id':12,'href':'/docs/tutorial/','title':"🔥教程",'content':"教程  前端优化指南  "});index.add({'id':13,'href':'/posts/half-life-of-information/','title':"信息的半衰期",'content':"今天，我想与您讨论一下信息能存活多久的问题，这个问题又会如何影响我们工作的方式。\n信息衰减 你可能不止一遍地听闻我们生活在一个“信息时代”，信息无所不在，无论是个人还是公司，掌握了信息就能让你事半功倍。而与此同时，随着信息被源源不断的生产出来，其又会很快变为过时信息，对人们能够起到的帮助越来越少。\n对于公司而言，有许多因素都会加速信息衰减的速度：员工离职、文档过时、1对1的知识分享等。而采用远程办公进行协作的团队，他们更为担心这个问题，员工可能不在一个时区，彼此之间也不能进行面对面的鼓励，知识分享也存在一些额外地物理限制。\n所以，我们应该如何避免或减缓知识衰减的速度呢？\n信息的半衰期 在核物理学中，放射性物质的半衰期是指它将衰变减少到一半所需的时间。同样，知识、信息或事实的半衰期是指知识的一半变得不相关或过时所需的时间。\n让我举几个例子来解释这一点。一家公司的新闻稿或投资者最新消息通常会有几个星期的半衰期。另一方面，你公司的 WIKI 或作业指导书的半衰期约为 0.5 - 1 年。\n信息的类型 这篇文章将知识分为三种不同的形式：\n 无意识知识：员工主动使用但可能没有意识到的知识（例如，使用工具或特定工作流的特定方式） 有意识的知识：员工知道的方法、过程、标准操作程序等 记录的知识：以可访问和有形形式捕获的所有信息  你可能已经猜到记录的知识半衰期最高，而无意识的知识半衰期最低。\n有效的知识转移与提高知识半衰期 因此，我们的目标应该是促进知识的流动或转移，主要是从无意识到有记录。实际上，这将增加知识的半衰期，并确保贵公司的信息长期保持相关和更新。\n下面是一些可以立即实现的功能：\n 默认为异步  即时消息或聊天的半衰期通常较短，约为5-10分钟，而长格式消息的半衰期至少为几个小时。另外，当您默认使用异步长格式对话时，您反过来会鼓励更周到的响应，并减少来回的次数。\n 跨团队共享知识  这是扩大公司记录知识的第一步。单个团队通常拥有大量的数据和洞察，如果在公司内部共享这些数据和洞察，可以帮助建立坚实的知识库。\n 开始建立学习型组织  更进一步，你应该致力于在你的组织中建立一种学习的文化。HBR的这篇文章很好地解释了什么是学习型组织，以及它如何促进员工的持续学习。\n 使用协作工作管理工具  像Slack这样的即时消息工具是很好的，并且是您的技术栈的重要组成部分。但是，您还应该投资于协作工作管理工具，如Notion或Slite，以存储、维护、优先排序和共享知识。\n译文来源  Knowledge Decays and Half-life of Information "});index.add({'id':14,'href':'/docs/programmer-interview/algorithm/best-time-to-buy-and-sell-stock-2/','title':"Best Time to Buy and Sell Stock Ⅱ",'content':"Best Time to Buy and Sell Stock Ⅱ 题目 LeetCode 地址：Best Time to Buy and Sell Stock Ⅱ\n有一个数组，第 i 个元素的值代表第 i 天的股票价格，如果你可以进行无限次交易（某天买入一支股票，然后过几天卖掉），请问你能收获的最大利润是多少？\n分析 这道题就一个想法，只要今天 price[i] 比昨天 price[i - 1] 的价格涨了，就可以算作是有效的利润，累加到最后的结果中。\n答案 // 假设有一个数组，它的第i个元素是一个给定的股票在第i天的价格。 // 设计一个算法来找到最大的利润。你可以完成尽可能多的交易(多次买卖股票)。 // 然而,你不能同时参与多个交易(你必须在再次购买前出售股票)。 // // https://www.lintcode.com/problem/best-time-to-buy-and-sell-stock-ii/description public class BestTimetoBuyandSellStockII { public int maxProfit(int[] prices) { int max = 0; for (int i = 1; i \u0026lt; prices.length; i++) { int diff = prices[i] - prices[i - 1]; if (diff \u0026gt; 0) { max += diff; } } return max; } } 扫描下面二维码，在手机上阅读这篇文章：\n"});index.add({'id':15,'href':'/docs/tutorial/front-end-optimization-guide/html-optimization/','title':"HTML 优化",'content':"HTML 优化 本文通过一些案例讲述了常见的优化 HTML 的几种小技巧：减少 DOM 树、精简 HTML 文件大小等。\n优化 DOM 节点树 去除页面除首屏外的对于用户不可见的信息区块，可以让页面的 DOM 节点数更少，DOM 树结构更简单，然后再使用懒加载异步化请求，去动态加载这些不可见的信息区块。\n在《大型网站性能优化实战》这本书中，作者为了优化搜索页面的渲染瓶颈问题，将首屏以下的 33 各搜索结果对应的 HTML 代码放到 \u0026lt;textarea\u0026gt; 节点中，当该区域处于可见状态时，再从 TextArea 中取出 HTML 代码，恢复到 DOM 树中进行渲染。这样一来，页面首次渲染的 DOM 树所包含的节点数大幅度减少，从而有效提高了首次渲染速度。\n多个空格合并为一个空格 通过将多个空格合并为一个空格，可以减少 HTML 的大小，从而缩短传输 HTML 文件所需的时间。通常在编写 HTML 文件的时候，总是倾向于格式化它，以方便我们人类阅读，所以这个文件中填充了许多空格，但这些空格对于浏览器来说是用不到的。在替换空格的时候，需要保留 \u0026lt;pre\u0026gt;、\u0026lt;textarea\u0026gt;、\u0026lt;script\u0026gt;、\u0026lt;style\u0026gt; 中的空格。\n不过，如果你的网页中使用了 white-space: pre 这个 CSS 属性就要小心了，这个属性可以避免让多个空格压缩为一个，在实际开发网站的时候，其实也很少用到这个属性。如果确实需要，那么就放弃把 HTML 的多个空格合并为一个空格吧。\n\u0026lt;html\u0026gt; \u0026lt;head\u0026gt; \u0026lt;title\u0026gt;Hello, world! \u0026lt;/title\u0026gt; \u0026lt;script\u0026gt; var x = \u0026#39;Hello, world!\u0026#39;;\u0026lt;/script\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; Hello, World! \u0026lt;pre\u0026gt; Hello, World! \u0026lt;/pre\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; 转为：\n\u0026lt;html\u0026gt; \u0026lt;head\u0026gt; \u0026lt;title\u0026gt;Hello, world!\u0026lt;/title\u0026gt; \u0026lt;script\u0026gt; var x = \u0026#39;Hello, world!\u0026#39;;\u0026lt;/script\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; Hello, World! \u0026lt;pre\u0026gt; Hello, World! \u0026lt;/pre\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; 精简属性 \u0026lt;button\u0026gt; 按钮的 disabled 属性：\n\u0026lt;button name=\u0026#34;ok\u0026#34; disabled=\u0026#34;disabled\u0026#34;\u0026gt; 可以写为\n\u0026lt;button name=\u0026#34;ok\u0026#34; disabled\u0026gt; 而 \u0026lt;form\u0026gt; 表单：\n\u0026lt;form method=\u0026#34;get\u0026#34;\u0026gt; 可以写为：\n\u0026lt;form\u0026gt; 即许多 HTML 节点的属性都有默认值，如果指定的属性值等于默认属性的值，那么就可以移除掉。\n移除注释 如下的 HTML 片段带有注释，去除注释，可以减少 HTML 文件的体积：\n\u0026lt;i class=\u0026#34;service_ico\u0026#34;\u0026gt; \u0026lt;!--常态 icon --\u0026gt; \u0026lt;img class=\u0026#34;service_ico_img\u0026#34; src=\u0026#34;service_ico_img.png\u0026#34;/\u0026gt; \u0026lt;!--hover 态 icon --\u0026gt; \u0026lt;img class=\u0026#34;service_ico_img_hover\u0026#34; src=\u0026#34;service_ico_img_hover.png\u0026#34;/\u0026gt; \u0026lt;/i\u0026gt; 移除引号 \u0026lt;html\u0026gt; \u0026lt;head\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;img src=\u0026#34;BikeCrashIcn.png\u0026#34; align=\u0026#39;left\u0026#39; alt=\u0026#34;\u0026#34; border=\u0026#34;0\u0026#34; width=\u0026#39;70\u0026#39; height=\u0026#39;30\u0026#39; \u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; 转变为\n\u0026lt;html\u0026gt; \u0026lt;head\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;img src=BikeCrashIcn.png align=left alt=\u0026#34;\u0026#34; border=0 width=70 height=30 \u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; 一方面去除了无关的引用，另外一方面也有利于 Gzip 算法的压缩。\n精简 URL 链接 如果 URL 的协议头与当前页面的协议头一致，那么可以删除协议头；在表达 URL 路径的时候，如果 HOST 与本网页一致，那么此 URL 也没必要使用绝对 URL 路径，使用相对 URL 路径即可。\n\u0026lt;html\u0026gt; \u0026lt;head\u0026gt; \u0026lt;base href=\u0026#34;http://www.example.com/\u0026#34;\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;a href=\u0026#34;http://www.example.com/bar\u0026#34;\u0026gt;Link with long URL\u0026lt;/a \u0026gt; \u0026lt;img src=\u0026#34;http://www.othersite.example.org/image.jpg\u0026#34;\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; 转变为：\n\u0026lt;html\u0026gt; \u0026lt;head\u0026gt; \u0026lt;base href=\u0026#34;http://www.example.com/\u0026#34;\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;a href=\u0026#34;bar\u0026#34;\u0026gt;Link with long URL\u0026lt;/a \u0026gt; \u0026lt;img src=\u0026#34;//www.othersite.example.org/image.jpg\u0026#34;\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; 参考  OptimizeHtml 《大型网站性能优化实战》  扫描下面二维码，在手机端阅读本文：\n"});index.add({'id':16,'href':'/docs/javascript/javascript-array/','title':"JavaScript 数组",'content':"JavaScript 数组 使用 JavaScript 在编程的时候，我们有很大一部分时间都是在与数组打交道，因此对数组常见的方法做到灵活的运用至关重要。本文整理了和 JavaScript 数组相关的，日常经常需要的功能和使用技巧，供大家参阅。\n从数组中移除指定元素 查阅 JavaScript 的数组 API，发现其并没有提供一个像 remove(obj) 或 removeAll(obj) 此类的方法，供我们方便的删除对象，因此我们需要通过使用其它的 API 来达到我们移出元素的目的。\n(1) 使用 splice 方法 splice 方法可以从指定索引处，向数组中添加元素或者删除元素，其会直接在原数组上改变，因此通过此方法可以达到我们的目的。但是在移除元素之前，我们必须首先通过 indexOf 方法找到我们的元素在数组中处于的索引位置。\nconst array = [2, 5, 9]; const index = array.indexOf(5); if (index \u0026gt; -1) { array.splice(index, 1); // 1 代表删除 1 个元素 } console.log(array) 当然，如果你不想使用 indexOf 的话，也可以直接从后向前遍历整个数组，对每个符合要求的元素都使用 splice 方法：\nconst array = [2, 5, 9]; for (var i = array.length; i--; ) { if (array[i] === 5) { array.splice(i, 1) } } console.log(array) 之所以需要从后向前移除，是因为在移除过程中，数组的 length 和 index 索引都是会改变的。\n(2) 使用 filter 方法 在 ES6 中，你可以使用 filter 函数遍历数组，对不符合元素值的对象进行过滤。filter 方法会返回一个新的数组，并不会直接在原数组上进行操作。\nlet value = 3; let array = [1, 2, 3, 4, 5, 3]; console.log(array.filter(item =\u0026gt; item !== value)) 如何遍历数组元素 JavaScript 数组提供了非常多的方法，这些方法都可以用来遍历数组：\n(1) 使用 forEach 方法 var a = [\u0026#34;a\u0026#34;, \u0026#34;b\u0026#34;, \u0026#34;c\u0026#34;]; a.forEach(function(entry) { console.log(entry) }) (2) 使用 for 遍历 var a = [\u0026#34;a\u0026#34;, \u0026#34;b\u0026#34;, \u0026#34;c\u0026#34;]; for (var index = 0; index \u0026lt; a.length; ++index) { console.log(a[index]) } (3) 使用 for 反向遍历 for (var i = array.length; i--; ) { // ... } 上述反向遍历的原理是：i-- 是属于测试条件的一部分，在每一次开始执行方法体之前，i 的值已经提前执行了 -- 这个操作了。当最后一次迭代，发现 i 等于 0 的时候，这个循环自然会停下来。\n(4) 使用 for-of 遍历 ES6 添加了迭代器的概念，当你使用 for-of 遍历的时候，其实已经隐形的在使用迭代器了：\nvar a = [\u0026#34;a\u0026#34;, \u0026#34;b\u0026#34;, \u0026#34;c\u0026#34;]; for (const val of a) { console.log(val); } (5) 不要使用 for-in 遍历 你或许听到过一些其它人的观点告诉你，使用 for-in 同样可以做到遍历数组。但是 for-in 是为了遍历对象用的，它并不保证按照数组的索引顺序来一一地遍历元素。所以在遍历数组的时候不推荐使用这种做法。\nfor (key in obj) { if (obj.hasOwnProperty(key)) { // ...  } } 如何清空数组 (1) 直接赋值一个空数组 如果你确实不在使用这个数组的话，也能保证其它地方没有引用这个数组，那么完全可以通过为其赋上一个新的空数组，从而置位空。\narr = [] (2) 将长度置为 0 arr.length = 0 (3) 使用 splice 方法 arr.splice(0, arr.length) (4) 使用 pop 方法 一一将元素 pop 出去，可能是最慢的一个方法了。\nwhile (arr.length) { arr.pop(); } 从头部插入元素 (1) 使用 unshift 方法  unshift 方法从头部插入一个元素到数组中 shift 方法从头部删除一个元素 push 方法从尾部插入一个元素到数组中 pop 方法从尾部删除一个元素  JavaScript 提供的从头部删除元素的方法名叫做 unshift，而不是叫做 insertAtHead 之类的，的确是在用到的时候不太容易想到这个名称。之所以这样命名，是因为 JavaScript 的数组的命名方式参考了 C 语言的栈的命名方式:\n array_unshift() array_shift() array_push() array_pop()  (2) 使用 concat 方法 concat() 方法可以用来连接两个数组：\nvar arr = [1, 2, 3, 4, 5, 6, 7]; console.log([0].concat(arr)); (3) 使用 Spread 操作符 在 ES6 中，可以使用 Spread 操作符 \u0026hellip; 来新增元素：\nvar arr = [23, 45, 12, 67]; arr = [34, ...arr]; 提前 break 数组循环 (1) 使用 Exception 对于 forEach 而言，使用 break 是不管用的，需要抛出异常强制终止循环，最好的建议是如果你需要 break 循环，在这种情况下就不要使用 forEach 来循环数组了：\nvar BreakException = {}; try { [1, 2, 3].forEach(function(el) { console.log(el); if (el === 2) throw BreakException; }); } catch (e) { if (e !== BreakException) throw e; } (2) 使用 for-of for (const [index, el] of arr.entries()) { if ( index === 5 ) break; } (3) 使用普通的循环 var array = [1, 2, 3]; for (var i = 0; i \u0026lt; array.length; i++) { if (array[i] === 1){ break; } } 数组去重 (1) 使用 filter 方法 var myArray = [\u0026#39;a\u0026#39;, 1, \u0026#39;a\u0026#39;, 2, \u0026#39;1\u0026#39;]; var unique = myArray.filter((value, index, arr) =\u0026gt; arr.indexOf(value) === index); (2) 使用 Set 构造器 var myArray = [\u0026#39;a\u0026#39;, 1, \u0026#39;a\u0026#39;, 2, \u0026#39;1\u0026#39;]; // unique = Array.from(new Set(myArray)) let unique = [...new Set(myArray)]; 参考  How do I remove a particular element from an array in JavaScript For-each over an array in JavaScript How do I empty an array in JavaScript How can I add new array elements at the beginning of an array in Javascript? Short circuit Array.forEach like calling break Get all unique values in a JavaScript array  "});index.add({'id':17,'href':'/docs/rocketmq/rocketmq-message-store-flow/','title':"RocketMQ 消息存储流程",'content':"RocketMQ 消息存储流程 本文讲述 RocketMQ 存储一条消息的流程。\n一、存储位置 当有一条消息过来之后，Broker 首先需要做的是确定这条消息应该存储在哪个文件里面。在 RocketMQ 中，这个用来存储消息的文件被称之为 MappedFile。这个文件默认创建的大小为 1GB。\n一个文件为 1GB 大小，也即 1024 * 1024 * 1024 = 1073741824 字节，这每个文件的命名是按照总的字节偏移量来命名的。例如第一个文件偏移量为 0，那么它的名字为 00000000000000000000；当当前这 1G 文件被存储满了之后，就会创建下一个文件，下一个文件的偏移量则为 1GB，那么它的名字为 00000000001073741824，以此类推。\n默认情况下这些消息文件位于 $HOME/store/commitlog 目录下，如下图所示:\n二、文件创建 当 Broker 启动的时候，其会将位于存储目录下的所有消息文件加载到一个列表中:\n当有新的消息到来的时候，其会默认选择列表中的最后一个文件来进行消息的保存:\npublic class MappedFileQueue { public MappedFile getLastMappedFile() { MappedFile mappedFileLast = null; while (!this.mappedFiles.isEmpty()) { try { mappedFileLast = this.mappedFiles.get(this.mappedFiles.size() - 1); break; } catch (IndexOutOfBoundsException e) { //continue;  } catch (Exception e) { log.error(\u0026#34;getLastMappedFile has exception.\u0026#34;, e); break; } } return mappedFileLast; } } 当然如果这个 Broker 之前从未接受过消息的话，那么这个列表肯定是空的。这样一旦有新的消息需要存储的时候，其就得需要立即创建一个 MappedFile 文件来存储消息。\nRocketMQ 提供了一个专门用来实例化 MappedFile 文件的服务类 AllocateMappedFileService。在内存中，也同时维护了一张请求表 requestTable 和一个优先级请求队列 requestQueue 。当需要创建文件的时候，Broker 会创建一个 AllocateRequest 对象，其包含了文件的路径、大小等信息。然后先将其放入 requestTable 表中，再将其放入优先级请求队列 requestQueue 中:\npublic class AllocateMappedFileService extends ServiceThread { public MappedFile putRequestAndReturnMappedFile(String nextFilePath, String nextNextFilePath, int fileSize) { // ...  AllocateRequest nextReq = new AllocateRequest(nextFilePath, fileSize); boolean nextPutOK = this.requestTable.putIfAbsent(nextFilePath, nextReq) == null; if (nextPutOK) { // ...  boolean offerOK = this.requestQueue.offer(nextReq); } } } 服务类会一直等待优先级队列是否有新的请求到来，如果有，便会从队列中取出请求，然后创建对应的 MappedFile，并将请求表 requestTable 中 AllocateRequest 对象的字段 mappedFile 设置上值。最后将 AllocateRequest 对象上的 CountDownLatch 的计数器减 1 ，以标明此分配申请的 MappedFile 已经创建完毕了:\npublic class AllocateMappedFileService extends ServiceThread { public void run() { // 一直运行  while (!this.isStopped() \u0026amp;\u0026amp; this.mmapOperation()) { } } private boolean mmapOperation() { req = this.requestQueue.take(); if (req.getMappedFile() == null) { MappedFile mappedFile; // ...  mappedFile = new MappedFile(req.getFilePath(), req.getFileSize()); // 设置上值  req.setMappedFile(mappedFile); } // ...  // 计数器减 1  req.getCountDownLatch().countDown(); // ...  return true; } } 其上述整体流程如下所示:\n等待 MappedFile 创建完毕之后，其便会从请求表 requestTable 中取出并删除表中记录:\npublic class AllocateMappedFileService extends ServiceThread { public MappedFile putRequestAndReturnMappedFile(String nextFilePath, String nextNextFilePath, int fileSize) { // ...  AllocateRequest result = this.requestTable.get(nextFilePath); if (result != null) { // 等待 MappedFile 的创建完成  boolean waitOK = result.getCountDownLatch().await(waitTimeOut, TimeUnit.MILLISECONDS); if (!waitOK) { return null; } else { // 从请求表中删除  this.requestTable.remove(nextFilePath); return result.getMappedFile(); } } } } 然后再将其放到列表中去:\npublic class MappedFileQueue { public MappedFile getLastMappedFile(final long startOffset, boolean needCreate) { MappedFile mappedFile = null; if (this.allocateMappedFileService != null) { // 创建 MappedFile  mappedFile = this.allocateMappedFileService .putRequestAndReturnMappedFile(nextFilePath, nextNextFilePath, this.mappedFileSize); } if (mappedFile != null) { // ...  // 添加至列表中  this.mappedFiles.add(mappedFile); } return mappedFile; } } 至此，MappedFile 已经创建完毕，也即可以进行下一步的操作了。\n三、文件初始化 在 MappedFile 的构造函数中，其使用了 FileChannel 类提供的 map 函数来将磁盘上的这个文件映射到进程地址空间中。然后当通过 MappedByteBuffer 来读入或者写入文件的时候，磁盘上也会有相应的改动。采用这种方式，通常比传统的基于文件 IO 流的方式读取效率高。\npublic class MappedFile extends ReferenceResource { public MappedFile(final String fileName, final int fileSize) throws IOException { init(fileName, fileSize); } private void init(final String fileName, final int fileSize) throws IOException { // ...  this.fileChannel = new RandomAccessFile(this.file, \u0026#34;rw\u0026#34;).getChannel(); this.mappedByteBuffer = this.fileChannel.map(MapMode.READ_WRITE, 0, fileSize); // ...  } } 四、消息文件加载 前面提到过，Broker 在启动的时候，会加载磁盘上的文件到一个 mappedFiles 列表中。但是加载完毕后，其还会对这份列表中的消息文件进行验证 (恢复)，确保没有错误。\n验证的基本想法是通过一一读取列表中的每一个文件，然后再一一读取每个文件中的每个消息，在读取的过程中，其会更新整体的消息写入的偏移量，如下图中的红色箭头 (我们假设最终读取的消息的总偏移量为 905):\n当确定消息整体的偏移量之后，Broker 便会确定每一个单独的 MappedFile 文件的各自的偏移量，每一个文件的偏移量是通过取余算法确定的:\npublic class MappedFileQueue { public void truncateDirtyFiles(long offset) { for (MappedFile file : this.mappedFiles) { long fileTailOffset = file.getFileFromOffset() + this.mappedFileSize; if (fileTailOffset \u0026gt; offset) { if (offset \u0026gt;= file.getFileFromOffset()) { // 确定每个文件的各自偏移量  file.setWrotePosition((int) (offset % this.mappedFileSize)); file.setCommittedPosition((int) (offset % this.mappedFileSize)); file.setFlushedPosition((int) (offset % this.mappedFileSize)); } else { // ...  } } } // ...  } } 在确定每个消息文件各自的写入位置的同时，其还会删除起始偏移量大于当前总偏移量的消息文件，这些文件可以视作脏文件，或者也可以说这些文件里面一条消息也没有。这也是上述文件 1073741824 被打上红叉的原因:\npublic void truncateDirtyFiles(long offset) { List\u0026lt;MappedFile\u0026gt; willRemoveFiles = new ArrayList\u0026lt;MappedFile\u0026gt;(); for (MappedFile file : this.mappedFiles) { long fileTailOffset = file.getFileFromOffset() + this.mappedFileSize; if (fileTailOffset \u0026gt; offset) { if (offset \u0026gt;= file.getFileFromOffset()) { // ...  } else { // 总偏移量 \u0026lt; 文件起始偏移量  // 加入到待删除列表中  file.destroy(1000); willRemoveFiles.add(file); } } } this.deleteExpiredFile(willRemoveFiles); } 五、写入消息 一旦我们获取到 MappedFile 文件之后，我们便可以往这个文件里面写入消息了。写入消息可能会遇见如下两种情况，一种是这条消息可以完全追加到这个文件中，另外一种是这条消息完全不能或者只有一小部分只能存放到这个文件中，其余的需要放到新的文件中。我们对于这两种情况分别讨论:\n(1) 文件可以完全存储消息 MappedFile 类维护了一个用以标识当前写位置的指针 wrotePosition，以及一个用来映射文件到进程地址空间的 mappedByteBuffer:\npublic class MappedFile extends ReferenceResource { protected final AtomicInteger wrotePosition = new AtomicInteger(0); private MappedByteBuffer mappedByteBuffer; } 由这两个数据结构我们可以看出来，单个文件的消息写入过程其实是非常简单的。首先获取到这个文件的写入位置，然后将消息内容追加到 byteBuffer 中，然后再更新写入位置。\npublic class MappedFile extends ReferenceResource { public AppendMessageResult appendMessagesInner(final MessageExt messageExt, final AppendMessageCallback cb) { // ...  int currentPos = this.wrotePosition.get(); if (currentPos \u0026lt; this.fileSize) { ByteBuffer byteBuffer = writeBuffer != null ? writeBuffer.slice() : this.mappedByteBuffer.slice(); // 更新 byteBuffer 位置  byteBuffer.position(currentPos); // 写入消息内容  // ...  // 更新 wrotePosition 指针的位置  this.wrotePosition.addAndGet(result.getWroteBytes()); return result; } } } 示例流程如下所示:\n(2) 文件不可以完全存储消息 在写入消息之前，如果判断出文件已经满了的情况下，其会直接尝试创建一个新的 MappedFile:\npublic class CommitLog { public PutMessageResult putMessage(final MessageExtBrokerInner msg) { // 文件为空 || 文件已经满了  if (null == mappedFile || mappedFile.isFull()) { mappedFile = this.mappedFileQueue.getLastMappedFile(0); } // ...  result = mappedFile.appendMessage(msg, this.appendMessageCallback); } } 如果文件未满，那么在写入之前会先计算出消息体长度 msgLen，然后判断这个文件剩下的空间是否有能力容纳这条消息。在这个地方我们还需要介绍下每条消息的存储方式。\n每条消息的存储是按照一个 4 字节的长度来做界限的，这个长度本身就是整个消息体的长度，当读完这整条消息体的长度之后，下一次再取出来的一个 4 字节的数字，便又是下一条消息的长度:\n围绕着一条消息，还会存储许多其它内容，我们在这里只需要了解前两位是 4 字节的长度和 4 字节的 MAGICCODE 即可:\nMAGICCODE 的可选值有:\n CommitLog.MESSAGE_MAGIC_CODE CommitLog.BLANK_MAGIC_CODE  当这个文件有能力容纳这条消息体的情况下，其便会存储 MESSAGE_MAGIC_CODE 值；当这个文件没有能力容纳这条消息体的情况下，其便会存储 BLANK_MAGIC_CODE 值。所以这个 MAGICCODE 是用来界定这是空消息还是一条正常的消息。\n当判定这个文件不足以容纳整个消息的时候，其将消息体长度设置为这个文件剩余的最大空间长度，将 MAGICCODE 设定为这是一个空消息文件 (需要去下一个文件去读)。由此我们可以看出消息体长度 和 MAGICCODE 是判别一条消息格式的最基本要求，这也是 END_FILE_MIN_BLANK_LENGTH 的值为 8 的原因:\n// CommitLog.java class DefaultAppendMessageCallback implements AppendMessageCallback { // File at the end of the minimum fixed length empty  private static final int END_FILE_MIN_BLANK_LENGTH = 4 + 4; public AppendMessageResult doAppend(final long fileFromOffset, final ByteBuffer byteBuffer, final int maxBlank, final MessageExtBrokerInner msgInner) { // ...  if ((msgLen + END_FILE_MIN_BLANK_LENGTH) \u0026gt; maxBlank) { // ...  // 1 TOTALSIZE  this.msgStoreItemMemory.putInt(maxBlank); // 2 MAGICCODE  this.msgStoreItemMemory.putInt(CommitLog.BLANK_MAGIC_CODE); // 3 The remaining space may be any value  byteBuffer.put(this.msgStoreItemMemory.array(), 0, maxBlank); return new AppendMessageResult(AppendMessageStatus.END_OF_FILE, /** other params **/ ); } } } 由上述方法我们看出在这种情况下返回的结果是 END_OF_FILE。当检测到这种返回结果的时候，CommitLog 接着又会申请创建新的 MappedFile 并尝试写入消息。追加方法同 (1) 相同，不再赘述:\n 注: 在消息文件加载的过程中，其也是通过判断 MAGICCODE 的类型，来判断是否继续读取下一个 MappedFile 来计算整体消息偏移量的。\n 六、消息刷盘策略 当消息体追加到 MappedFile 以后，这条消息实际上还只是存储在内存中，因此还需要将内存中的内容刷到磁盘上才算真正的存储下来，才能确保消息不丢失。一般而言，刷盘有两种策略: 异步刷盘和同步刷盘。\n(1) 异步刷盘 当配置为异步刷盘策略的时候，Broker 会运行一个服务 FlushRealTimeService 用来刷新缓冲区的消息内容到磁盘，这个服务使用一个独立的线程来做刷盘这件事情，默认情况下每隔 500ms 来检查一次是否需要刷盘:\nclass FlushRealTimeService extends FlushCommitLogService { public void run() { // 不停运行  while (!this.isStopped()) { // interval 默认值是 500ms  if (flushCommitLogTimed) { Thread.sleep(interval); } else { this.waitForRunning(interval); } // 刷盘  CommitLog.this.mappedFileQueue.flush(flushPhysicQueueLeastPages); } } } 在追加消息完毕之后，通过唤醒这个服务立即检查以下是否需要刷盘:\npublic class CommitLog { public void handleDiskFlush(AppendMessageResult result, PutMessageResult putMessageResult, MessageExt messageExt) { // Synchronization flush  if (FlushDiskType.SYNC_FLUSH == this.defaultMessageStore.getMessageStoreConfig().getFlushDiskType()) { // ...  } // Asynchronous flush  else { if (!this.defaultMessageStore.getMessageStoreConfig().isTransientStorePoolEnable()) { // 消息追加成功后，立即唤醒服务  flushCommitLogService.wakeup(); } else { // ...  } } } } (2) 同步刷盘 当配置为同步刷盘策略的时候，Broker 运行一个叫做 GroupCommitService 服务。在这个服务内部维护了一个写请求队列和一个读请求队列，其中这两个队列每隔 10ms 就交换一下“身份”，这么做的目的其实也是为了读写分离:\n在这个服务内部，每隔 10ms 就会检查读请求队列是否不为空，如果不为空，则会将读队列中的所有请求执行刷盘，并清空读请求队列:\nclass GroupCommitService extends FlushCommitLogService { private void doCommit() { // 检查所有读队列中的请求  for (GroupCommitRequest req : this.requestsRead) { // 每个请求执行刷盘  CommitLog.this.mappedFileQueue.flush(0); req.wakeupCustomer(flushOK); } this.requestsRead.clear(); } } 在追加消息完毕之后，通过创建一个请求刷盘的对象，然后通过 putRequest() 方法放入写请求队列中，这个时候会立即唤醒这个服务，写队列和读队列的角色会进行交换，交换角色之后，读请求队列就不为空，继而可以执行所有刷盘请求了。而在这期间，Broker 会一直阻塞等待最多 5 秒钟，在这期间如果完不成刷盘请求的话，那么视作刷盘超时:\npublic class CommitLog { public void handleDiskFlush(AppendMessageResult result, PutMessageResult putMessageResult, MessageExt messageExt) { // Synchronization flush  if (FlushDiskType.SYNC_FLUSH == this.defaultMessageStore.getMessageStoreConfig().getFlushDiskType()) { // ...  if (messageExt.isWaitStoreMsgOK()) { GroupCommitRequest request = new GroupCommitRequest(result.getWroteOffset() + result.getWroteBytes()); service.putRequest(request); // 等待刷盘成功  boolean flushOK = request.waitForFlush(this.defaultMessageStore.getMessageStoreConfig().getSyncFlushTimeout()); if (!flushOK) { // 刷盘超时  putMessageResult.setPutMessageStatus(PutMessageStatus.FLUSH_DISK_TIMEOUT); } } else { // ...  } } // Asynchronous flush  else { // ...  } } } 通过方法 putRequest 放入请求后的服务执行流程:\n七、消息刷盘理念 我们在这里已经知道消息刷盘有同步刷盘和异步刷盘策略，对应的是 GroupCommitService 和 FlushRealTimeService 这两种不同的服务。\n这两种服务都有定时请求刷盘的机制，但是机制背后最终调用的刷盘方式全部都集中在 flush 这个方法上:\npublic class MappedFileQueue { public boolean flush(final int flushLeastPages) { // ...  } } 再继续向下分析这个方法之前，我们先对照着这张图说明一下使用 MappedByteBuffer 来简要阐述读和写文件的简单过程：\n操作系统为了能够使多个进程同时使用内存，又保证各个进程访问内存互相独立，于是为每个进程引入了地址空间的概念，地址空间上的地址叫做虚拟地址，而程序想要运行必须放到物理地址上运行才可以。地址空间为进程营造出了一种假象：”整台计算机只有我一个程序在运行，这台计算机内存很大”。一个地址空间内包含着这个进程所需要的全部状态信息。通常一个进程的地址空间会按照逻辑分成好多段，比如代码段、堆段、栈段等。为了进一步有效利用内存，每一段又细分成了不同的页 (page)。与此相对应，计算机的物理内存被切成了页帧 (page frame)，文件被分成了块 (block)。既然程序实际运行的时候还是得依赖物理内存的地址，那么就需要将虚拟地址转换为物理地址，这个映射关系是由**页表 (page table)**来完成的。\n另外在操作系统中，还有一层磁盘缓存 (disk cache)的概念，它主要是用来减少对磁盘的 I/O 操作。磁盘缓存是以页为单位的，内容就是磁盘上的物理块，所以又称之为页缓存 (page cache)。当进程发起一个读操作 （比如，进程发起一个 read() 系统调用），它首先会检查需要的数据是否在页缓存中。如果在，则放弃访问磁盘，而直接从页缓存中读取。如果数据没在缓存中，那么内核必须调度块 I/O 操作从磁盘去读取数据，然后将读来的数据放入页缓存中。系统并不一定要将整个文件都缓存，它可以只存储一个文件的一页或者几页。\n如图所示，当调用 FileChannel.map() 方法的时候，会将这个文件映射进用户空间的地址空间中，注意，建立映射不会拷贝任何数据。我们前面提到过 Broker 启动的时候会有一个消息文件加载的过程，当第一次开始读取数据的时候:\n// 首次读取数据 int totalSize = byteBuffer.getInt(); 这个时候，操作系统通过查询页表，会发现文件的这部分数据还不在内存中。于是就会触发一个缺页异常 (page faults)，这个时候操作系统会开始从磁盘读取这一页数据，然后先放入到页缓存中，然后再放入内存中。在第一次读取文件的时候，操作系统会读入所请求的页面，并读入紧随其后的少数几个页面（不少于一个页面，通常是三个页面），这时的预读称为同步预读 (如下图所示，红色部分是需要读取的页面，蓝色的那三个框是操作系统预先读取的):\n当然随着时间推移，预读命中的话，那么相应的预读页面数量也会增加，但是能够确认的是，一个文件至少有 4 个页面处在页缓存中。当文件一直处于顺序读取的情况下，那么基本上可以保证每次预读命中:\n下面我们来说文件写，正常情况下，当尝试调用 writeInt() 写数据到文件里面的话，其写到页缓存层，这个方法就会返回了。这个时候数据还没有真正的保存到文件中去，Linux 仅仅将页缓存中的这一页数据标记为“脏”，并且被加入到脏页链表中。然后由一群进程（flusher 回写进程）周期性将脏页链表中的页写会到磁盘，从而让磁盘中的数据和内存中保持一致，最后清理“脏”标识。在以下三种情况下，脏页会被写回磁盘:\n 空闲内存低于一个特定阈值 脏页在内存中驻留超过一个特定的阈值时 当用户进程调用 sync() 和 fsync() 系统调用时  可见，在正常情况下，即使不采用刷盘策略，数据最终也是会被同步到磁盘中去的:\n但是，即便有 flusher 线程来定时同步数据，如果此时机器断电的话，消息依然有可能丢失。RocketMQ 为了保证消息尽可能的不丢失，为了最大的高可靠性，做了同步和异步刷盘策略，来手动进行同步:\n八、消息刷盘过程 在介绍完上述消息刷盘背后的一些机制和理念后，我们再来分析刷盘整个过程。首先，无论同步刷盘还是异步刷盘，其线程都在一直周期性的尝试执行刷盘，在真正执行刷盘函数的调用之前，Broker 会检查文件的写位置是否大于 flush 位置，避免执行无意义的刷盘：\n其次，对于异步刷盘来讲，Broker 执行了更为严格的刷盘限制策略，当在某个时间点尝试执行刷盘之后，在接下来 10 秒内，如果想要继续刷盘，那么脏页面数量必须不小于 4 页，如下图所示:\n下面是执行刷盘前最后检查的刷盘条件：\npublic class MappedFile extends ReferenceResource { private boolean isAbleToFlush(final int flushLeastPages) { int flush = this.flushedPosition.get(); int write = getReadPosition(); if (this.isFull()) { return true; } if (flushLeastPages \u0026gt; 0) { // 计算当前脏页面算法  return ((write / OS_PAGE_SIZE) - (flush / OS_PAGE_SIZE)) \u0026gt;= flushLeastPages; } // wrotePosition \u0026gt; flushedPosition  return write \u0026gt; flush; } } 当刷盘完毕之后，首先会更新这个文件的 flush 位置，然后再更新 MappedFileQueue 的整体的 flush 位置:\n当刷盘完毕之后，便会将结果通知给客户端，告知发送消息成功。至此，整个存储过程完毕。\n"});index.add({'id':18,'href':'/docs/rocketmq/','title':"RocketMQ 源码分析",'content':"RocketMQ RocketMQ 是阿里巴巴集团开源的一款分布式消息中间件，其采用纯 Java 语言编写，本博客基于 RocketMQ 4.2.0 版本，为大家分析和讲解其内部几个关键模块的运行原理。\n目录：\n RocketMQ 消息发送流程 RocketMQ 消息存储流程 RocketMQ 消息接受流程 RocketMQ 消息过滤流程 RocketMQ 消息索引流程 RocketMQ 定时消息和重试消息 RocketMQ 主备同步  "});index.add({'id':19,'href':'/docs/books/history_of_quantum_physics/','title':"上帝掷骰子吗",'content':"上帝掷骰子吗-量子物理史话 1887年德国，赫兹在实验室证实了电磁波的存在，也证实了光其实是电磁波的一种，两者具有共同的波的特性，古老的光学终于可以被完全包容于新兴的电磁学里面。1901年，赫兹死后的第 7 年，无线电报已经可以穿越大西洋，实现两地的实时通讯了。\n赫兹铜环接收器的缺口之间不停地爆发着电火花，明白无误地昭示着电磁波的存在。但偶然间，赫兹又发现了一个奇怪的现象：当有光照射到这个缺口上的时候，似乎火花就出现得更容易一些。\n 量子就是能量的最小单位，就是能量里的一美分。一切能量的传输，都只能以这个量为单位来进行，它可以传输一个量子，两个量子，任意整数个量子，但却不能传输1 又1/2 个量子，那个状态是不允许的，就像你不能用现钱支付1 又1/2 美分一样。这个值，现在已经成为了自然科学中最为 重要的常数之一，以它的发现者命名，称为“普朗克常数”，用 h 来表示。\n在后来十几年的时间里，普朗克一直认为量子的假设并不是一个物理真实，而纯粹是一个为了方便而引入的假设而已。他不断地告诫人们，在引用普朗克常数 h 的时候，要尽量小心谨慎，不到万不得已千万不要胡思乱想。\n"});index.add({'id':20,'href':'/docs/cloud-plus-bbs/suikang-mini-program-design/','title':"穗康小程序口罩预约前后端架构及产品设计",'content':"穗康小程序口罩预约前后端架构及产品设计 在战“疫”期间，腾讯与广州市政府合作，在小程序“穗康”上，2天内上线了全国首款口罩预约功能，上线首日访问量1.7亿，累计参与口罩预约人次1400万+。那么，它是如何在2天内开发上线，扛住了超大并发量呢？其背后的前后端架构是怎样的？\n无损服务设计 整个流程下来需要 3 个实时接口：\n 药店当前口罩的库存情况 哪个时间段有名额 提交预约实时返回结果  有损服务设计 结果，口罩预约关注度远超预期：\n下面展示的 UI 的设计：\n为什么有 “损” 平衡的理论就是 CAP 理论、BASE 最终一致性：\n牺牲强一致换取高可用 两个机房需要同步，并发性差。以下是优化后的代码，引入计时器：\n降低了专线依赖。\n怎么 \u0026ldquo;损\u0026rdquo;  放弃绝对一致，追求高可用和快速响应 万有一失，用户重试 伸缩调度，降级服务  （1）穗康小程序 引入消息队列，最终一致：\n（2）QQ 相册负载高 选择扩容？带宽和存储成本高。\n（3）转账 用户重试极少量消息。再想一下微信的红色感叹号，点一下重新发送。\n（4）穗康的预约重试 （5）QQ 相册降级 "});index.add({'id':21,'href':'/posts/consistency-problem-of-the-distrubuted-system/','title':"分布式系统一致性问题",'content':"描述解决分布式系统一致性问题的典型思路!\n一致性问题 思考下面几个分布式系统中可能存在的一致性问题:\n (1) 先下订单还是先扣库存?下订单成功扣库存失败则超卖;下订单失败扣库存成功则多卖。 (2) 系统 A 同步调用系统 B 服务超时后，这个时候系统 A 应该做什么? (3) 系统 B 异步回调系统 A 超时后，系统 A 迟迟没有收到回调结果怎么办? (4) 某个订单在系统 A 中能查询到，但是系统 B 中不存在。 (5) 系统间都存在请求，只是状态不一致。 (6) 交易系统依赖于数据库的 ACID，缓存和数据库之间如何保持一致性?强一致性还是弱一致性? (7) 多个节点上缓存的内容不一致怎么办?请求恰好在这个时间窗口进来了。 (8) 缓存数据结构不一致。某个数据由多个数据元素组成，如果其中某个子数据依赖于从其它服务中获取数据，假设这部分数据获取失败，那么就会导致数据不完整，可能会出现 NullPointerException 等。  酸碱平衡理论 ACID 具有 ACID 特性的数据库支持强一致性。这意味着每个事务都是原子的，或者成功或者失败，事物间是隔离的，互相完全不受影响，而且最终状态是持久落盘的。Oracle、MySQL、DB2 都能保证强一致性。一般而言，强一致性通常是通过多版本控制协议 (MVCC) 来实现的。\n交易系统只考虑: 关系型数据库 + 强悍硬件。 NoSQL完全不适合交易场景，一般用来作数据分析、ETL、报表、数据挖掘、推荐、日志处理、调用链分析等非核心交易场景。 ACID 是数据库事务完整性的理论。\nCAP 分布式系统设计理论  C (Consistency): A read is guaranteed to return the most recent write for a given client. 读操作保证能够返回最新的写操作结果。 A (Availability): A non-failing node will return a reasonable response within a reasonable amount of time (no error or no timeout). 合理时间返回合理响应。 P (Partition Tolerance): The system will continue to function when network partitions occur. 当出现网络分区后，系统能够继续“履行职责”。 虽然 CAP 理论定义是三个要素中只能取两个，但放到分布式环境下来思考，我们会发现必须选择 P（分区容忍）要素，因为网络本身无法做到 100% 可靠，有可能出故障，所以分区是一个必然的现象。如果我们选择了 CA 而放弃了 P，那么当发生分区现象时，为了保证 C，系统需要禁止写入，当有写入请求时，系统返回 error（例如，当前系统不允许写入），这又和 A 冲突了，因为 A 要求返回 no error 和 no timeout。因此，分布式系统理论上不可能选择 CA 架构，只能选择 CP 或者 AP 架构。  1.CP - Consistency/Partition Tolerance\n如下图所示，为了保证一致性，当发生分区现象后，N1 节点上的数据已经更新到 y，但由于 N1 和 N2 之间的复制通道中断，数据 y 无法同步到 N2，N2 节点上的数据还是 x。这时客户端 C 访问 N2 时，N2 需要返回 Error，提示客户端 C“系统现在发生了错误”，这种处理方式违背了可用性（Availability）的要求，因此 CAP 三者只能满足 CP。\n2.AP - Availability/Partition Tolerance\n如下图所示，为了保证可用性，当发生分区现象后，N1 节点上的数据已经更新到 y，但由于 N1 和 N2 之间的复制通道中断，数据 y 无法同步到 N2，N2 节点上的数据还是 x。这时客户端 C 访问 N2 时，N2 将当前自己拥有的数据 x 返回给客户端 C 了，而实际上当前最新的数据已经是 y 了，这就不满足一致性（Consistency）的要求了，因此 CAP 三者只能满足 AP。注意：这里 N2 节点返回 x，虽然不是一个“正确”的结果，但是一个“合理”的结果，因为 x 是旧的数据，并不是一个错乱的值，只是不是最新的数据而已。\nBASE - CAP 理论中 AP 方案的延伸  BA (Basically Available): 出现故障时，允许损失部分可用性，保证核心可用，例如登录功能大于注册功能。 S (Soft State): 允许存在中间状态，中间状态不会影响系统整体可用性。 E (Eventual Consistency): 所有数据副本经过一段时间后，最终能够达到一致的状态。  牺牲强一致性而获得可用性，一般应用于服务化系统的应用层或者大数据处理系统中，通过达到最终一致性来尽量满足业务的绝大多数需求。由于不保证强一致性，因此系统在处理请求的过程中可以存在短暂的不一致，在这个时间窗口内，请求的每一步操作，都需要记录下来，以便在出现故障的时候可以从这些中间状态恢复过来。\n下面是解决一致性问题的三条实践经验:\n 单个数据库能够保证强一致性 将数据库进行水平伸缩和分片，相关数据分到数据库的同一个片上 记录每一步操作  CAP 理论实践 CAP 关注的粒度是数据，而不是整个系统 在实际设计过程中，每个系统不可能只处理一种数据，而是包含多种类型的数据，有的数据必须选择 CP，有的数据必须选择 AP。而如果我们做设计时，从整个系统的角度去选择 CP 还是 AP，就会发现顾此失彼，无论怎么做都是有问题的。\n以一个最简单的用户管理系统为例，用户管理系统包含用户账号数据（用户 ID、密码）、用户信息数据（昵称、兴趣、爱好、性别、自我介绍等）。通常情况下，用户账号数据会选择 CP，而用户信息数据会选择 AP，如果限定整个系统为 CP，则不符合用户信息数据的应用场景；如果限定整个系统为 AP，则又不符合用户账号数据的应用场景。\n所以在 CAP 理论落地实践时，我们需要将系统内的数据按照不同的应用场景和要求进行分类，每类数据选择不同的策略（CP 还是 AP），而不是直接限定整个系统所有数据都是同一策略。\nCAP 是忽略网络延迟的 这是一个非常隐含的假设，布鲁尔在定义一致性时，并没有将延迟考虑进去。也就是说，当事务提交时，数据能够瞬间复制到所有节点。但实际情况下，从节点 A 复制数据到节点 B，总是需要花费一定时间的。如果是相同机房，耗费时间可能是几毫秒；如果是跨地域的机房，例如北京机房同步到广州机房，耗费的时间就可能是几十毫秒。这就意味着，CAP 理论中的 C 在实践中是不可能完美实现的，在数据复制的过程中，节点 A 和节点 B 的数据并不一致。\n不要小看了这几毫秒或者几十毫秒的不一致，对于某些严苛的业务场景，例如和金钱相关的用户余额，或者和抢购相关的商品库存，技术上是无法做到分布式场景下完美的一致性的。而业务上必须要求一致性，因此单个用户的余额、单个商品的库存，理论上要求选择 CP 而实际上 CP 都做不到，只能选择 CA。也就是说，只能单点写入，其他节点做备份，无法做到分布式情况下多点写入。\n需要注意的是，这并不意味着这类系统无法应用分布式架构，只是说“单个用户余额、单个商品库存”无法做分布式，但系统整体还是可以应用分布式架构的。例如，下面的架构图是常见的将用户分区的分布式架构:\n我们可以将用户 id 为 0 ~ 100 的数据存储在 Node 1，将用户 id 为 101 ~ 200 的数据存储在 Node 2，Client 根据用户 id 来决定访问哪个 Node。对于单个用户来说，读写操作都只能在某个节点上进行；对所有用户来说，有一部分用户的读写操作在 Node 1 上，有一部分用户的读写操作在 Node 2 上。\n这样的设计有一个很明显的问题就是某个节点故障时，这个节点上的用户就无法进行读写操作了，但站在整体上来看，这种设计可以降低节点故障时受影响的用户的数量和范围，毕竟只影响 20% 的用户肯定要比影响所有用户要好。这也是为什么挖掘机挖断光缆后，支付宝只有一部分用户会出现业务异常，而不是所有用户业务异常的原因。\n正常运行情况下，不存在 CP 和 AP 的选择，可以同时满足 CA CAP 理论告诉我们分布式系统只能选择 CP 或者 AP，但其实这里的前提是系统发生了“分区”现象。如果系统没有发生分区现象，也就是说 P 不存在的时候（节点间的网络连接一切正常），我们没有必要放弃 C 或者 A，应该 C 和 A 都可以保证，这就要求架构设计的时候既要考虑分区发生时选择 CP 还是 AP，也要考虑分区没有发生时如何保证 CA。\n同样以用户管理系统为例，即使是实现 CA，不同的数据实现方式也可能不一样：用户账号数据可以采用“消息队列”的方式来实现 CA，因为消息队列可以比较好地控制实时性，但实现起来就复杂一些；而用户信息数据可以采用“数据库同步”的方式来实现 CA，因为数据库的方式虽然在某些场景下可能延迟较高，但使用起来简单。\n放弃并不等于什么都不做，需要为分区恢复后做准备 我们可以在分区期间进行一些操作，从而让分区故障解决后，系统能够重新达到 CA 的状态。\n最典型的就是在分区期间记录一些日志，当分区故障解决后，系统根据日志进行数据恢复，使得重新达到 CA 状态。同样以用户管理系统为例，对于用户账号数据，假设我们选择了 CP，则分区发生后，节点 1 可以继续注册新用户，节点 2 无法注册新用户（这里就是不符合 A 的原因，因为节点 2 收到注册请求后会返回 error），此时节点 1 可以将新注册但未同步到节点 2 的用户记录到日志中。当分区恢复后，节点 1 读取日志中的记录，同步给节点 2，当同步完成后，节点 1 和节点 2 就达到了同时满足 CA 的状态。\n而对于用户信息数据，假设我们选择了 AP，则分区发生后，节点 1 和节点 2 都可以修改用户信息，但两边可能修改不一样。例如，用户在节点 1 中将爱好改为“旅游、美食、跑步”，然后用户在节点 2 中将爱好改为“美食、游戏”，节点 1 和节点 2 都记录了未同步的爱好数据，当分区恢复后，系统按照某个规则来合并数据。例如，按照“最后修改优先规则”将用户爱好修改为“美食、游戏”，按照“字数最多优先规则”则将用户爱好修改为“旅游，美食、跑步”，也可以完全将数据冲突报告出来，由人工来选择具体应该采用哪一条。\n分布式一致性协议 两阶段提交协议 二阶段提交的算法思路可以概括为：协调者询问参与者是否准备好了提交，并根据所有参与者的反馈情况决定向所有参与者发送 commit 或者 rollback 指令（协调者向所有参与者发送相同的指令）。\n三阶段提交协议 三阶段提交协议是两阶段提交协议的改进版本。它通过超时机制解决了阻塞的问题，并且把两个阶段增加为三个阶段。\n不同点:\n 增加询问阶段:尽可能早地发现无法执行操作而需要中止的行为。 准备阶段以后，协调者和参与者执行任务中都增加了超时，一旦超时，则协调者和参与者都会继续提交事务，默认为成功，这也是根据概率统计超时后默认为成功的正确性最大。  存在问题:\n 在 doCommit 阶段，如果参与者没有及时接收到来自协调者的 doCommit 或者 rebort 请求时，会在等待超时之后，会继续进行事务的提交。所以，由于网络原因，协调者发送的 abort 响应没有及时被参与者接收到，那么参与者在等待超时之后执行了 commit 操作。这样就和其他接到 abort 命令并执行回滚的参与者之间存在数据不一致的情况。  TCC 协议 上述两个协议实现复杂，操作步骤多，性能也是一个很大问题，因此在互联网高并发系统中，鲜有使用两阶段提交和三阶段提交协议的场景。\nTCC 协议将一个任务拆分为 Try、Confirm、Cancel 三个步骤，没有单独的准备阶段， Try 操作兼备资源操作与准备能力，另外 Confirm 操作和 Cancel 操作要满足幂等性。虽然没有解决极端情况下不一致和脑裂的问题，然而 TCC 通过自动化补偿，将需要人工处理的不一致情况降低到最少，也是一种非常有用的解决方案。\nTCC 协议相比其它两个协议更简单且更容易实现。\n保证最终一致性的模式 一致性在现实系统实践中，仅仅需要达到最终一致性，并不需要专业的、复杂的一致性协议。实现最终一致性有一些有效、简单的模式如下:\n查询模式 通过查询模式，我们可以清楚地知道某个任务或者操作处于一个什么样的状态，是执行成功还是失败，还是正在执行，这样也方便其他系统依据当前返回的状态进行下一步操作。为了能够实现查询，每个服务操作都需要唯一的流水号标识，例如请求流水号、订单号等。\n补偿模式 我们修正系统以让其达到最终一致状态的过程，称之为补偿。而支持补偿模式，那么这个服务针对特定任务需要提供重试操作和取消操作:\n定期校对模式 在分布式系统中构建了唯一 ID、调用链等基础设施后，我们很容易对系统间的不一致进行核对，发现不一致，则利用补偿来修复即可。定期校对模式多用于金融系统中，涉及资金安全的，需要保证准确性。\n超时处理模式 超时补偿原则 超时补偿原则确定的是调用方和被调用方谁应该负责重试或补偿的问题。\n被调用方补偿:\n如果服务 2 告诉服务 1 消息已经接受，那么服务 1 任务就已经结束了，如果服务 2 处理失败，那么服务 2 应该负责重试或者补偿。\nvoid service2() { while (i \u0026lt; tryTimes) { // 任务没有执行成功，则自己补偿  if (!doTask()) { i++; continue; } break; } } 调用方补偿:\n如果服务 2 无明确接受响应，那么服务 1 应该持续进行重试，直到服务 2 明确表示已经接受消息:\nvoid service1() { while (true) { try { scheduleTaskToService2(); // 保证幂等性  } catch (TimeOutException e) { continue; // 无明确接受响应，调用方负责重试  } break; } } 解决 (1) 扣库存问题\n数据量小，可以利用关系数据库的强一致性解决，也就是把订单和库存表放到一个关系型数据库中。单机难以满足的话，就分片，尽量保证订单和库存放入同一个数据库分片中。\n(2) 超时无结果\n需要依据操作 ID 来主动查询任务的当前状态，以便决定下一步做什么。\n(3) 回调无结果\n需要依据操作 ID 来主动查询任务的当前状态，以便决定下一步做什么。\n(4) 订单不存在\n查询处理情况，定期校对，补偿修复。\n(5) 状态不一致\n查询处理情况，定期校对，补偿修复。\n(6) 缓存一致性\n为了提高性能，数据库与缓存只需要保持弱一致性，而不需要保持强一致性，否则违背了使用缓存的初衷。\n(7) 缓存时间窗口\n如果性能要求不是非常高，则尽量使用分布式缓存，而不要使用本地缓存。另外读的顺序是先读缓存，再读数据库；写的顺序是先写数据库，再写缓存。\n(8) 数据完整性\n写缓存时数据一定要完整，如果缓存数据的一部分有效，另一部分无效，则能可在需要时回源数据库，也不要把部分数据放入缓存中。\nboolean cacheData() { Object o1 = readFromDB1(); Object o2 = readFromDB2(); // 确保缓存数据完整性，不要缓存一部分数据  if (o1 != null \u0026amp;\u0026amp; o2 != null) { return cacheData(o1, o2); } return false; } 参考  《分布式服务架构：原理、设计与实战》 极客时间订阅:从0开始学架构 "});index.add({'id':22,'href':'/docs/programmer-interview/algorithm/best-time-to-buy-and-sell-stock-3/','title':"Best Time to Buy and Sell Stock Ⅲ",'content':"Best Time to Buy and Sell Stock Ⅲ 题目 LeetCode 地址：Best Time to Buy and Sell Stock Ⅲ\n有一个数组，第 i 个元素的值代表第 i 天的股票价格，如果你最多只能进行两次交易（某天买入一支股票，然后过几天卖掉），请问你能收获的最大利润是多少？\n分析 参考 Best Time to Buy and Sell Stock 思路上状态机，状态机应用两次即可。\n答案 // 最多两次交易 // 且不能同时持有，必须卖掉这个，然后持有另外一个 // https://leetcode.com/problems/best-time-to-buy-and-sell-stock-iii/ // public class BestTimetoBuyandSellStockIII { // Buy Sell Buy Sell  // s0 ----\u0026gt; s1 -----\u0026gt; s2 -----\u0026gt; s3 ------\u0026gt; s4 (end)  // ↑___| ↑__| ↑____| ↑___|  //  public int maxProfit(int[] prices) { if (prices == null || prices.length \u0026lt;= 1) { return 0; } int s0 = 0; int s1 = -prices[0]; int s2 = 0; int s3 = -prices[0]; int s4 = 0; for (int i = 1; i \u0026lt; prices.length; i++) { s0 = s0; s1 = Math.max(s1, s0 - prices[i]); s2 = Math.max(s2, s1 + prices[i]); s3 = Math.max(s3, s2 - prices[i]); s4 = Math.max(s4, s3 + prices[i]); } return s4; } } 扫描下面二维码，在手机上阅读这篇文章：\n"});index.add({'id':23,'href':'/docs/tutorial/front-end-optimization-guide/css-optimization/','title':"CSS 优化",'content':"CSS 优化 本文讲述在实际工作中如何优化 CSS，提升页面加载的性能！\n避免使用 @import @import url(\u0026#34;base.css\u0026#34;); @import url(\u0026#34;layout.css\u0026#34;); @import url(\u0026#34;carousel.css\u0026#34;); 由于 @import 属性允许相互之间嵌套引入，因此浏览器必须串行的去下载每一个 @import 引入的文件，因此会增加下载 CSS 文件的时间，而使用 \u0026lt;link\u0026gt; 就可以并行下载 CSS 文件，可有效提升 CSS 加载的性能：\n\u0026lt;link rel=\u0026#34;stylesheet\u0026#34; href=\u0026#34;base.css\u0026#34;\u0026gt; \u0026lt;link rel=\u0026#34;stylesheet\u0026#34; href=\u0026#34;layout.css\u0026#34;\u0026gt; \u0026lt;link rel=\u0026#34;stylesheet\u0026#34; href=\u0026#34;carousel.css\u0026#34;\u0026gt; 简化 CSS 选择器 浏览器是从右向左逐步解析选择器表达式的，例如 #id .class \u0026gt; ul a 。首先找到页面上所有匹配 a 的节点，然后找到所有 ul 元素，并且将 a 元素恰好是 ul 元素子节点的元素过滤出来，直至解析到最左侧的选择器 #id 。\n如下是在网站上针对 50000 个元素使用不同 CSS 选择器选择元素的时间对比：\n   选择器 查询时间(ms)     div 4.8740   .box 3.625   .box \u0026gt; .title 4.4587   .box .title 4.5161   .box ~ .box 4.7082   .box + .box 4.6611   .box:last-of-type 3.944   .box:nth-of-type(2n - 1) 16.8491   .box:not(:last-of-type) 5.8947   .box:not(:empty):last-of-type .title 8.0202   .box:nth-last-child(n+6) ~ div 20.8710    最慢的选择器接近 20ms，而最快的仅需 3.5ms 左右，由此可见 CSS 选择器越短，解析速度越快！\n避免使用 CSS 表达式 IE5 引入了 CSS 表达式，或者称之为 \u0026ldquo;动态属性\u0026rdquo;，这样可以让开发人员以更为紧凑的方式在 CSS 中就可以完成高级样式处理。然而，CSS 表达式带来的性能损失是相当大的，因为每当触发任何事件（如窗口大小调整、鼠标移动等）时，浏览器都会重新运行每个表达式，这也是它在 IE8 被弃用的原因之一。如果在页面中使用了 CSS 表达式，则应尽一切努力删除它们，并使用其他方法来实现相同的功能。\n避免使用 expensive 的属性 有些属性生来渲染速度就慢于其它属性，下面这些属性在绘制之前可能会导致其它计算，因此尽量避免使用！\n border-radius box-shadow opacity transform filter position: fixed  精简 CSS 代码 精简 CSS 代码意味着对 CSS 源文件，采取移除无关的空白字符、换行符、注释、去除不必要的单位、去除不必要的零等方法。其可以有效压缩 CSS 文件的大小，减少浏览器下载和执行文件所需的时间。\n通过使用近几年来出现的新的页面布局方式，例如 Flexbox 和 Grid 布局，可以有效减少达到之前使用 float 属性进行的相同布局所需要的代码量，以前自己需要做的事情，现在浏览器在底层可以更快的帮你完成。\n在引入 CSS 库的时候，也要去仔细对比，在满足要求的条件下，应该尽量选择 size 比较小的库。\n优化 CSS 动画  同时进行多个 CSS 动画可能不会工作地很好，极有可能导致延迟出现，适当地给一些动画增加 transition-delay 属性以避免同时运行多个动画。 浏览器加载网页地时候非常忙，因此尽可能地将所有动画延迟到初始加载事件之后的几百毫秒，可以有效提升页面的整体性能。 SVG 非常适合动画，因为它们可以在不降低分辨率的情况下进行缩放。 只在最后才考虑使用 will-change 属性，毕竟它也消耗资源！  参考  20 Tips for Optimizing CSS Performance Tips for Improving CSS and JS Animation Performance PageSpeed: Avoid CSS expressions (deprecated)  扫描下面二维码，在手机端阅读本文：\n"});index.add({'id':24,'href':'/docs/javascript/','title':"JavaScript 专栏",'content':"JavaScript 专栏 本专栏用于整理在 JavaScript 中最常使用的、必知必会的基础知识点，方便大家温故而知新。\n"});index.add({'id':25,'href':'/docs/rocketmq/rocketmq-message-receive-flow/','title':"RocketMQ 消息接受流程",'content':"RocketMQ 消息接受流程 本篇讲述 RocketMQ 消息接受流程\n一、消费者注册 生产者负责往服务器 Broker 发送消息，消费者则从 Broker 获取消息。消费者获取消息采用的是订阅者模式，即消费者客户端可以任意订阅一个或者多个话题来消费消息:\npublic class Consumer { public static void main(String[] args) throws InterruptedException, MQClientException { /* * 订阅一个或者多个话题 */ consumer.subscribe(\u0026#34;TopicTest\u0026#34;, \u0026#34;*\u0026#34;); } } 当消费者客户端启动以后，其会每隔 30 秒从命名服务器查询一次用户订阅的所有话题路由信息:\npublic class MQClientInstance { private void startScheduledTask() { this.scheduledExecutorService.scheduleAtFixedRate(new Runnable() { @Override public void run() { // 从命名服务器拉取话题信息  MQClientInstance.this.updateTopicRouteInfoFromNameServer(); } }, 10, this.clientConfig.getPollNameServerInterval(), TimeUnit.MILLISECONDS); } } 我们由 RocketMQ 消息发送流程 这篇文章知道 RocketMQ 在发送消息的时候，每条消息会以轮循的方式均衡地分发的不同 Broker 的不同队列中去。由此，消费者客户端从服务器命名服务器获取下来的便是话题的所有消息队列:\n在获取话题路由信息的时候，客户端还会将话题路由信息中的所有 Broker 地址保存到本地:\npublic class MQClientInstance { public boolean updateTopicRouteInfoFromNameServer(final String topic, boolean isDefault, DefaultMQProducer defaultMQProducer) { // ...  if (changed) { TopicRouteData cloneTopicRouteData = topicRouteData.cloneTopicRouteData(); // 更新 Broker 地址列表  for (BrokerData bd : topicRouteData.getBrokerDatas()) { this.brokerAddrTable.put(bd.getBrokerName(), bd.getBrokerAddrs()); } return true; } // ...  } } 当消费者客户端获取到了 Broker 地址列表之后，其便会每隔 30 秒给服务器发送一条心跳数据包，告知所有 Broker 服务器这台消费者客户端的存在。在每次发送心跳包的同时，其数据包内还会捎带这个客户端消息订阅的一些组信息，比如用户订阅了哪几个话题等，与此相对应，每台 Broker 服务器会在内存中维护一份当前所有的消费者客户端列表信息:\npublic class ConsumerManager { private final ConcurrentMap\u0026lt;String/* Group */, ConsumerGroupInfo\u0026gt; consumerTable = new ConcurrentHashMap\u0026lt;String, ConsumerGroupInfo\u0026gt;(1024); } 消费者客户端与 Broker 服务器进行沟通的整体流程如下图所示：\n二、消息队列负载均衡 我们知道无论发送消息还是接受消息都需要指定消息的话题，然而实际上消息在 Broker 服务器上并不是以话题为单位进行存储的，而是采用了比话题更细粒度的队列来进行存储的。当你发送了 10 条相同话题的消息，这 10 条话题可能存储在了不同 Broker 服务器的不同队列中。由此，我们说 RocketMQ 管理消息的单位不是话题，而是队列。\n当我们讨论消息队列负载均衡的时候，就是在讨论服务器端的所有队列如何给所有消费者消费的问题。在 RocketMQ 中，客户端有两种消费模式，一种是广播模式，另外一种是集群模式。\n我们现在假设总共有两台 Broker 服务器，假设用户使用 Producer 已经发送了 8 条消息，这 8 条消息现在均衡的分布在两台 Broker 服务器的 8 个队列中，每个队列中有一个消息。现在有 3 台都订阅了 Test 话题的消费者实例，我们来看在不同消费模式下，不同的消费者会收到哪几条消息。\n(1) 广播模式 广播模式是指所有消息队列中的消息都会广播给所有的消费者客户端，如下图所示，每一个消费者都能收到这 8 条消息:\n(2) 集群模式 集群模式是指所有的消息队列会按照某种分配策略来分给不同的消费者客户端，比如消费者 A 消费前 3 个队列中的消息，消费者 B 消费中间 3 个队列中的消息等等。我们现在着重看 RocketMQ 为我们提供的三个比较重要的消息队列分配策略:\n1. 平均分配策略 平均分配策略下，三个消费者的消费情况如下所示：\n Consumer-1 消费前 3 个消息队列中的消息 Consumer-2 消费中间 3 个消息队列中的消息 Consumer-3 消费最后 2 个消息队列中的消息  2. 平均分配轮循策略 平均分配轮循策略下，三个消费者的消费情况如下所示：\n Consumer-1 消费 1、4、7消息队列中的消息 Consumer-2 消费 2、5、8消息队列中的消息 Consumer-3 消费 3、6消息队列中的消息  3. 一致性哈希策略 一致性哈希算法是根据这三台消费者各自的某个有代表性的属性(我们假设就是客户端ID)来计算出三个 Hash 值，此处为了减少由于 Hash 函数选取的不理想的情况， RocketMQ 算法对于每个消费者通过在客户端ID后面添加 1、2、3 索引来使每一个消费者多生成几个哈希值。那么现在我们需要哈希的就是九个字符串:\n Consumer-1-1 Consumer-1-2 Consumer-1-3 Consumer-2-1 Consumer-2-2 Consumer-2-3 Consumer-3-1 Consumer-3-2 Consumer-3-3  计算完这 9 个哈希值以后，我们按照从小到大的顺序来排列成一个环 (如图所示)。这个时候我们需要一一对这 8 个消息队列也要计算一下 Hash 值，当 Hash 值落在两个圈之间的时候，我们就选取沿着环的方向的那个节点作为这个消息队列的消费者。如下图所示 (注意: 图只是示例，并非真正的消费情况):\n在一致性哈希策略下，三个消费者的消费情况如下所示：\n Consumer-1 消费 1、2、3、4消息队列中的消息 Consumer-2 消费 5、8消息队列中的消息 Consumer-3 消费 6、7消息队列中的消息  消息队列的负载均衡是由一个不停运行的均衡服务来定时执行的:\npublic class RebalanceService extends ServiceThread { // 默认 20 秒一次  private static long waitInterval = Long.parseLong(System.getProperty(\u0026#34;rocketmq.client.rebalance.waitInterval\u0026#34;, \u0026#34;20000\u0026#34;)); @Override public void run() { while (!this.isStopped()) { this.waitForRunning(waitInterval); // 重新执行消息队列的负载均衡  this.mqClientFactory.doRebalance(); } } } 接着往下看，会知道在广播模式下，当前这台消费者消费和话题相关的所有消息队列，而集群模式会先按照某种分配策略来进行消息队列的分配，得到的结果就是当前这台消费者需要消费的消息队列:\npublic abstract class RebalanceImpl { private void rebalanceByTopic(final String topic, final boolean isOrder) { switch (messageModel) { // 广播模式  case BROADCASTING: { // 消费这个话题的所有消息队列  Set\u0026lt;MessageQueue\u0026gt; mqSet = this.topicSubscribeInfoTable.get(topic); if (mqSet != null) { // ...  } break; } // 集群模式  case CLUSTERING: { // ...  // 按照某种负载均衡策略进行消息队列和消费客户端之间的分配  // allocateResult 就是当前这台消费者被分配到的消息队列  allocateResult = strategy.allocate( this.consumerGroup, this.mQClientFactory.getClientId(), mqAll, cidAll); // ...  } break; } } } 三、Broker 消费队列文件 现在我们再来看 Broker 服务器端。首先我们应该知道，消息往 Broker 存储就是在向 CommitLog 消息文件中写入数据的一个过程。在 Broker 启动过程中，其会启动一个叫做 ReputMessageService 的服务，这个服务每隔 1 秒会检查一下这个 CommitLog 是否有新的数据写入。ReputMessageService 自身维护了一个偏移量 reputFromOffset，用以对比和 CommitLog 文件中的消息总偏移量的差距。当这两个偏移量不同的时候，就代表有新的消息到来了:\nclass ReputMessageService extends ServiceThread { private volatile long reputFromOffset = 0; private boolean isCommitLogAvailable() { // 看当前有没有新的消息到来  return this.reputFromOffset \u0026lt; DefaultMessageStore.this.commitLog.getMaxOffset(); } @Override public void run() { while (!this.isStopped()) { try { Thread.sleep(1); this.doReput(); } catch (Exception e) { DefaultMessageStore.log.warn(this.getServiceName() + \u0026#34; service has exception. \u0026#34;, e); } } } } 在有新的消息到来之后，doReput() 函数会取出新到来的所有消息，每一条消息都会封装为一个 DispatchRequest 请求，进而将这条请求分发给不同的请求消费者，我们在这篇文章中只会关注利用消息创建消费队列的服务 CommitLogDispatcherBuildConsumeQueue:\nclass ReputMessageService extends ServiceThread { // ... 部分代码有删减  private void doReput() { SelectMappedBufferResult result = DefaultMessageStore.this.commitLog.getData(reputFromOffset); if (result != null) { this.reputFromOffset = result.getStartOffset(); for (int readSize = 0; readSize \u0026lt; result.getSize() \u0026amp;\u0026amp; doNext; ) { // 读取一条消息，然后封装为 DispatchRequest  DispatchRequest dispatchRequest = DefaultMessageStore.this.commitLog.checkMessageAndReturnSize(result.getByteBuffer(), false, false); int size = dispatchRequest.getMsgSize(); if (dispatchRequest.isSuccess()) { // 分发这个 DispatchRequest 请求  DefaultMessageStore.this.doDispatch(dispatchRequest); this.reputFromOffset += size; readSize += size; } // ...  } } } } CommitLogDispatcherBuildConsumeQueue 服务会根据这条请求按照不同的队列 ID 创建不同的消费队列文件，并在内存中维护一份消费队列列表。然后将 DispatchRequest 请求中这条消息的消息偏移量、消息大小以及消息在发送时候附带的标签的 Hash 值写入到相应的消费队列文件中去。\n消费队列文件的创建与消息存储 CommitLog 文件的创建过程是一致的，只是路径不同，这里不再赘述。\n寻找消费队列的代码如下:\npublic class DefaultMessageStore implements MessageStore { private final ConcurrentMap\u0026lt;String/* topic */, ConcurrentMap\u0026lt;Integer/* queueId */, ConsumeQueue\u0026gt;\u0026gt; consumeQueueTable; public void putMessagePositionInfo(DispatchRequest dispatchRequest) { ConsumeQueue cq = this.findConsumeQueue(dispatchRequest.getTopic(), dispatchRequest.getQueueId()); cq.putMessagePositionInfoWrapper(dispatchRequest); } } 向消费队列文件中存储数据的代码如下:\npublic class ConsumeQueue { private boolean putMessagePositionInfo(final long offset, final int size, final long tagsCode, final long cqOffset) { // 存储偏移量、大小、标签码  this.byteBufferIndex.flip(); this.byteBufferIndex.limit(CQ_STORE_UNIT_SIZE); this.byteBufferIndex.putLong(offset); this.byteBufferIndex.putInt(size); this.byteBufferIndex.putLong(tagsCode); // 获取消费队列文件  final long expectLogicOffset = cqOffset * CQ_STORE_UNIT_SIZE; MappedFile mappedFile = this.mappedFileQueue.getLastMappedFile(expectLogicOffset); if (mappedFile != null) { // ...  return mappedFile.appendMessage(this.byteBufferIndex.array()); } return false; } } 以上阐述了消费队列创建并存储消息的一个过程，但是消费队列文件中的消息是需要持久化到磁盘中去的。持久化的过程是通过后台服务 FlushConsumeQueueService 来定时持久化的:\nclass FlushConsumeQueueService extends ServiceThread { private void doFlush(int retryTimes) { // ...  ConcurrentMap\u0026lt;String, ConcurrentMap\u0026lt;Integer, ConsumeQueue\u0026gt;\u0026gt; tables = DefaultMessageStore.this.consumeQueueTable; for (ConcurrentMap\u0026lt;Integer, ConsumeQueue\u0026gt; maps : tables.values()) { for (ConsumeQueue cq : maps.values()) { boolean result = false; for (int i = 0; i \u0026lt; retryTimes \u0026amp;\u0026amp; !result; i++) { // 刷新到磁盘  result = cq.flush(flushConsumeQueueLeastPages); } } } // ...  } } 上述过程体现在磁盘文件的变化如下图所示，commitLog 文件夹下面存放的是完整的消息，来一条消息，向文件中追加一条消息。同时，根据这一条消息属于 TopicTest 话题下的哪一个队列，又会往相应的 consumequeue 文件下的相应消费队列文件中追加消息的偏移量、消息大小和标签码:\n总流程图如下所示:\n四、消息队列偏移量 Broker 服务器存储了各个消费队列，客户端需要消费每个消费队列中的消息。消费模式的不同，每个客户端所消费的消息队列也不同。那么客户端如何记录自己所消费的队列消费到哪里了呢？答案就是消费队列偏移量。\n针对同一话题，在集群模式下，由于每个客户端所消费的消息队列不同，所以每个消息队列已经消费到哪里的消费偏移量是记录在 Broker 服务器端的。而在广播模式下，由于每个客户端分配消费这个话题的所有消息队列，所以每个消息队列已经消费到哪里的消费偏移量是记录在客户端本地的。\n下面分别讲述两种模式下偏移量是如何获取和更新的:\n(1) 集群模式 在集群模式下，消费者客户端在内存中维护了一个 offsetTable 表:\npublic class RemoteBrokerOffsetStore implements OffsetStore { private ConcurrentMap\u0026lt;MessageQueue, AtomicLong\u0026gt; offsetTable = new ConcurrentHashMap\u0026lt;MessageQueue, AtomicLong\u0026gt;(); } 同样在 Broker 服务器端也维护了一个偏移量表:\npublic class ConsumerOffsetManager extends ConfigManager { private ConcurrentMap\u0026lt;String/* topic@group */, ConcurrentMap\u0026lt;Integer, Long\u0026gt;\u0026gt; offsetTable = new ConcurrentHashMap\u0026lt;String, ConcurrentMap\u0026lt;Integer, Long\u0026gt;\u0026gt;(512); } 在消费者客户端，RebalanceService 服务会定时地 (默认 20 秒) 从 Broker 服务器获取当前客户端所需要消费的消息队列，并与当前消费者客户端的消费队列进行对比，看是否有变化。对于每个消费队列，会从 Broker 服务器查询这个队列当前的消费偏移量。然后根据这几个消费队列，创建对应的拉取请求 PullRequest 准备从 Broker 服务器拉取消息，如下图所示:\n当从 Broker 服务器拉取下来消息以后，只有当用户成功消费的时候，才会更新本地的偏移量表。本地的偏移量表再通过定时服务每隔 5 秒同步到 Broker 服务器端:\npublic class MQClientInstance { private void startScheduledTask() { this.scheduledExecutorService.scheduleAtFixedRate(new Runnable() { @Override public void run() { MQClientInstance.this.persistAllConsumerOffset(); } }, 1000 * 10, this.clientConfig.getPersistConsumerOffsetInterval(), TimeUnit.MILLISECONDS); } } 而维护在 Broker 服务器端的偏移量表也会每隔 5 秒钟序列化到磁盘中:\npublic class BrokerController { public boolean initialize() throws CloneNotSupportedException { this.scheduledExecutorService.scheduleAtFixedRate(new Runnable() { @Override public void run() { BrokerController.this.consumerOffsetManager.persist(); } }, 1000 * 10, this.brokerConfig.getFlushConsumerOffsetInterval(), TimeUnit.MILLISECONDS); } } 保存的格式如下所示：\n上述整体流程如下所示，红框框住的是这个话题下面的队列的 ID，箭头指向的分别是每个队列的消费偏移量：\n(2) 广播模式 对于广播模式而言，每个消费队列的偏移量肯定不能存储在 Broker 服务器端，因为多个消费者对于同一个队列的消费可能不一致，偏移量会互相覆盖掉。因此，在广播模式下，每个客户端的消费偏移量是存储在本地的，然后每隔 5 秒将内存中的 offsetTable 持久化到磁盘中。当首次从服务器获取可消费队列的时候，偏移量不像集群模式下是从 Broker 服务器读取的，而是直接从本地文件中读取的:\npublic class LocalFileOffsetStore implements OffsetStore { @Override public long readOffset(final MessageQueue mq, final ReadOffsetType type) { if (mq != null) { switch (type) { case READ_FROM_STORE: { // 本地读取  offsetSerializeWrapper = this.readLocalOffset(); // ...  } } } // ...  } } 当消息消费成功后，偏移量的更新也是持久化到本地，而非更新到 Broker 服务器中。这里提一下，在广播模式下，消息队列的偏移量默认放在用户目录下的 .rocketmq_offsets 目录下:\npublic class LocalFileOffsetStore implements OffsetStore { @Override public void persistAll(Set\u0026lt;MessageQueue\u0026gt; mqs) { // ...  String jsonString = offsetSerializeWrapper.toJson(true); MixAll.string2File(jsonString, this.storePath); // ...  } } 存储格式如下：\n简要流程图如下：\n五、拉取消息 在客户端运行着一个专门用来拉取消息的后台服务 PullMessageService，其接受每个队列创建 PullRequest 拉取消息请求，然后拉取消息:\npublic class PullMessageService extends ServiceThread { @Override public void run() { while (!this.isStopped()) { PullRequest pullRequest = this.pullRequestQueue.take(); if (pullRequest != null) { this.pullMessage(pullRequest); } } } } 每一个 PullRequest 都关联着一个 MessageQueue 和一个 ProcessQueue，在 ProcessQueue 的内部还维护了一个用来等待用户消费的消息树，如下代码所示:\npublic class PullRequest { private MessageQueue messageQueue; private ProcessQueue processQueue; } public class ProcessQueue { private final TreeMap\u0026lt;Long, MessageExt\u0026gt; msgTreeMap = new TreeMap\u0026lt;Long, MessageExt\u0026gt;(); } 当真正尝试拉取消息之前，其会检查当前请求的内部缓存的消息数量、消息大小、消息阈值跨度是否超过了某个阈值，如果超过某个阈值，则推迟 50 毫秒重新执行这个请求:\npublic class DefaultMQPushConsumerImpl implements MQConsumerInner { public void pullMessage(final PullRequest pullRequest) { // ...  final ProcessQueue processQueue = pullRequest.getProcessQueue(); long cachedMessageCount = processQueue.getMsgCount().get(); long cachedMessageSizeInMiB = processQueue.getMsgSize().get() / (1024 * 1024); // 缓存消息数量阈值，默认为 1000  if (cachedMessageCount \u0026gt; this.defaultMQPushConsumer.getPullThresholdForQueue()) { this.executePullRequestLater(pullRequest, PULL_TIME_DELAY_MILLS_WHEN_FLOW_CONTROL); return; } // 缓存消息大小阈值，默认为 100 MB  if (cachedMessageSizeInMiB \u0026gt; this.defaultMQPushConsumer.getPullThresholdSizeForQueue()) { this.executePullRequestLater(pullRequest, PULL_TIME_DELAY_MILLS_WHEN_FLOW_CONTROL); return; } if (!this.consumeOrderly) { // 最小偏移量和最大偏移量的阈值跨度，默认为 2000 偏移量，消费速度不能太慢  if (processQueue.getMaxSpan() \u0026gt; this.defaultMQPushConsumer.getConsumeConcurrentlyMaxSpan()) { this.executePullRequestLater(pullRequest, PULL_TIME_DELAY_MILLS_WHEN_FLOW_CONTROL); return; } } // ...  } } 当执行完一些必要的检查之后，客户端会将用户指定的过滤信息以及一些其它必要消费字段封装到请求信息体中，然后才开始从 Broker 服务器拉取这个请求从当前偏移量开始的消息，默认一次性最多拉取 32 条，服务器返回的响应会告诉客户端这个队列下次开始拉取时的偏移量。客户端每次都会注册一个 PullCallback 回调，用以接受服务器返回的响应信息，根据响应信息的不同状态信息，然后修正这个请求的偏移量，并进行下次请求:\npublic void pullMessage(final PullRequest pullRequest) { PullCallback pullCallback = new PullCallback() { @Override public void onSuccess(PullResult pullResult) { if (pullResult != null) { // ...  switch (pullResult.getPullStatus()) { case FOUND: // ...  break; case NO_NEW_MSG: // ...  break; case NO_MATCHED_MSG: // ...  break; case OFFSET_ILLEGAL: // ...  break; default: break; } } } @Override public void onException(Throwable e) { // ...  } }; } 上述是客户端拉取消息时的一些机制，现在再说一下 Broker 服务器端与此相对应的逻辑。\n服务器在收到客户端的请求之后，会根据话题和队列 ID 定位到对应的消费队列。然后根据这条请求传入的 offset 消费队列偏移量，定位到对应的消费队列文件。偏移量指定的是消费队列文件的消费下限，而最大上限是由如下算法来进行约束的:\nfinal int maxFilterMessageCount = Math.max(16000, maxMsgNums * ConsumeQueue.CQ_STORE_UNIT_SIZE); 有了上限和下限，客户端便会开始从消费队列文件中取出每个消息的偏移量和消息大小，然后再根据这两个值去 CommitLog 文件中寻找相应的完整的消息，并添加到最后的消息队列中，精简过的代码如下所示：\npublic class DefaultMessageStore implements MessageStore { public GetMessageResult getMessage(final String group, final String topic, final int queueId, final long offset, final int maxMsgNums, final MessageFilter messageFilter) { // ...  ConsumeQueue consumeQueue = findConsumeQueue(topic, queueId); if (consumeQueue != null) { // 首先根据消费队列的偏移量定位消费队列  SelectMappedBufferResult bufferConsumeQueue = consumeQueue.getIndexBuffer(offset); if (bufferConsumeQueue != null) { try { status = GetMessageStatus.NO_MATCHED_MESSAGE; // 最大消息长度  final int maxFilterMessageCount = Math.max(16000, maxMsgNums * ConsumeQueue.CQ_STORE_UNIT_SIZE); // 取消息  for (; i \u0026lt; bufferConsumeQueue.getSize() \u0026amp;\u0026amp; i \u0026lt; maxFilterMessageCount; i += ConsumeQueue.CQ_STORE_UNIT_SIZE) { long offsetPy = bufferConsumeQueue.getByteBuffer().getLong(); int sizePy = bufferConsumeQueue.getByteBuffer().getInt(); // 根据消息的偏移量和消息的大小从 CommitLog 文件中取出一条消息  SelectMappedBufferResult selectResult = this.commitLog.getMessage(offsetPy, sizePy); getResult.addMessage(selectResult); status = GetMessageStatus.FOUND; } // 增加下次开始的偏移量  nextBeginOffset = offset + (i / ConsumeQueue.CQ_STORE_UNIT_SIZE); } finally { bufferConsumeQueue.release(); } } } // ...  } } 客户端和 Broker 服务器端完整拉取消息的流程图如下所示：\n六、消费消息 依赖于用户指定的消息回调函数的不同，消息的消费分为两种: 并发消费和有序消费。\n并发消费没有考虑消息发送的顺序，客户端从服务器获取到消息就会直接回调给用户。而有序消费会考虑每个队列消息发送的顺序，注意此处并不是每个话题消息发送的顺序，一定要记住 RocketMQ 控制消息的最细粒度是消息队列。当我们讲有序消费的时候，就是在说对于某个话题的某个队列，发往这个队列的消息，客户端接受消息的顺序与发送的顺序完全一致。\n下面我们分别看这两种消费模式是如何实现的。\n(1) 并发消费 当用户注册消息回调类的时候，如果注册的是 MessageListenerConcurrently 回调类，那么就认为用户不关心消息的顺序问题。我们在上文提到过每个 PullRequest 都关联了一个处理队列 ProcessQueue，而每个处理队列又都关联了一颗消息树 msgTreeMap。当客户端拉取到新的消息以后，其先将消息放入到这个请求所关联的处理队列的消息树中，然后提交一个消息消费请求，用以回调用户端的代码消费消息:\npublic class DefaultMQPushConsumerImpl implements MQConsumerInner { public void pullMessage(final PullRequest pullRequest) { PullCallback pullCallback = new PullCallback() { @Override public void onSuccess(PullResult pullResult) { if (pullResult != null) { switch (pullResult.getPullStatus()) { case FOUND: // 消息放入处理队列的消息树中  boolean dispathToConsume = processQueue .putMessage(pullResult.getMsgFoundList()); // 提交一个消息消费请求  DefaultMQPushConsumerImpl.this .consumeMessageService .submitConsumeRequest( pullResult.getMsgFoundList(), processQueue, pullRequest.getMessageQueue(), dispathToConsume); break; } } } }; } } 当提交一个消息消费请求后，对于并发消费，其实现如下:\npublic class ConsumeMessageConcurrentlyService implements ConsumeMessageService { class ConsumeRequest implements Runnable { @Override public void run() { // ...  status = listener.consumeMessage(Collections.unmodifiableList(msgs), context); // ...  } } } 我们可以看到 msgs 是直接从服务器端拿到的最新消息，直接喂给了客户端进行消费，并未做任何有序处理。当消费成功后，会从消息树中将这些消息再给删除掉:\npublic class ConsumeMessageConcurrentlyService implements ConsumeMessageService { public void processConsumeResult(final ConsumeConcurrentlyStatus status, /** 其它参数 **/) { // 从消息树中删除消息  long offset = consumeRequest.getProcessQueue().removeMessage(consumeRequest.getMsgs()); if (offset \u0026gt;= 0 \u0026amp;\u0026amp; !consumeRequest.getProcessQueue().isDropped()) { this.defaultMQPushConsumerImpl.getOffsetStore() .updateOffset(consumeRequest.getMessageQueue(), offset, true); } } } (2) 有序消费 RocketMQ 的有序消费主要依靠两把锁，一把是维护在 Broker 端，一把维护在消费者客户端。Broker 端有一个 RebalanceLockManager 服务，其内部维护了一个 mqLockTable 消息队列锁表:\npublic class RebalanceLockManager { private final ConcurrentMap\u0026lt;String/* group */, ConcurrentHashMap\u0026lt;MessageQueue, LockEntry\u0026gt;\u0026gt; mqLockTable = new ConcurrentHashMap\u0026lt;String, ConcurrentHashMap\u0026lt;MessageQueue, LockEntry\u0026gt;\u0026gt;(1024); } 在有序消费的时候，Broker 需要确保任何一个队列在任何时候都只有一个客户端在消费它，都在被一个客户端所锁定。当客户端在本地根据消息队列构建 PullRequest 之前，会与 Broker 沟通尝试锁定这个队列，另外当进行有序消费的时候，客户端也会周期性地 (默认是 20 秒) 锁定所有当前需要消费的消息队列:\npublic class ConsumeMessageOrderlyService implements ConsumeMessageService { public void start() { if (MessageModel.CLUSTERING.equals(ConsumeMessageOrderlyService.this.defaultMQPushConsumerImpl.messageModel())) { this.scheduledExecutorService.scheduleAtFixedRate(new Runnable() { @Override public void run() { ConsumeMessageOrderlyService.this.lockMQPeriodically(); } }, 1000 * 1, ProcessQueue.REBALANCE_LOCK_INTERVAL, TimeUnit.MILLISECONDS); } } } 由上述这段代码也能看出，只在集群模式下才会周期性地锁定 Broker 端的消息队列，因此在广播模式下是不支持进行有序消费的。\n而在 Broker 这端，每个客户端所锁定的消息队列对应的锁项 LogEntry 有一个上次锁定时的时间戳，当超过锁的超时时间 (默认是 60 秒) 后，也会判定这个客户端已经不再持有这把锁，以让其他客户端能够有序消费这个队列。\n在前面我们说到过 RebalanceService 均衡服务会定时地依据不同消费者数量分配消费队列。我们假设 Consumer-1 消费者客户端一开始需要消费 3 个消费队列，这个时候又加入了 Consumer-2 消费者客户端，并且分配到了 MessageQueue-2 消费队列。当 Consumer-1 内部的均衡服务检测到当前消费队列需要移除 MessageQueue-2 队列，这个时候，会首先解除 Broker 端的锁，确保新加入的 Consumer-2 消费者客户端能够成功锁住这个队列，以进行有序消费。\npublic abstract class RebalanceImpl { private boolean updateProcessQueueTableInRebalance(final String topic, final Set\u0026lt;MessageQueue\u0026gt; mqSet, final boolean isOrder) { while (it.hasNext()) { // ...  if (mq.getTopic().equals(topic)) { // 当前客户端不需要处理这个消息队列了  if (!mqSet.contains(mq)) { pq.setDropped(true); // 解锁  if (this.removeUnnecessaryMessageQueue(mq, pq)) { // ...  } } // ...  } } } } 消费者客户端每一次拉取消息请求，如果有发现新的消息，那么都会将这些消息封装为 ConsumeRequest 来喂给消费线程池，以待消费。如果消息特别多，这样一个队列可能有多个消费请求正在等待客户端消费，用户可能会先消费偏移量大的消息，后消费偏移量小的消息。所以消费同一队列的时候，需要一把锁以消费请求顺序化:\npublic class ConsumeMessageOrderlyService implements ConsumeMessageService { class ConsumeRequest implements Runnable { @Override public void run() { final Object objLock = messageQueueLock.fetchLockObject(this.messageQueue); synchronized (objLock) { // ...  } } } } RocketMQ 的消息树是用 TreeMap 实现的，其内部基于消息偏移量维护了消息的有序性。每次消费请求都会从消息树中拿取偏移量最小的几条消息 (默认为 1 条)给用户，以此来达到有序消费的目的:\npublic class ConsumeMessageOrderlyService implements ConsumeMessageService { class ConsumeRequest implements Runnable { @Override public void run() { // ...  final int consumeBatchSize = ConsumeMessageOrderlyService.this .defaultMQPushConsumer .getConsumeMessageBatchMaxSize(); List\u0026lt;MessageExt\u0026gt; msgs = this.processQueue.takeMessags(consumeBatchSize); } } } "});index.add({'id':26,'href':'/docs/books/clean_code/','title':"代码整洁之道",'content':"代码整洁之道 勒布朗法则：Later equals never.\n随着混乱的增加，团队生产力也持续下降，趋近于零。生产力下降的时候，管理层只能增加更多的人手，期望提高生产力。\n什么是整洁代码  我喜欢优雅和高效的代码。代码逻辑应当直截了当，叫缺陷难以隐藏；尽量减少依赖关系，使之便于维护；依据某种分层战略完善错误处理代码；性能调至最优，省得引诱别人做没规矩的优化，搞出一堆混乱来。整洁的代码只做好一件事。\u0026mdash; Bjarne Stroustrup，C++ 语言发明者\n  整洁的代码应可由作者之外的开发者阅读和增补。它应有单元测试和验收测试。它使用有意义的命名。它只提供一种而非多种做一件事的途径。它只有尽量少的依赖关系，且要明确地定义和提供清晰、尽量少的 API。代码应通过其表面表达含义，因为不同的语言导致并非所有必需信息均可通过代码自身清晰表达。\u0026mdash; Dave Thomas, OTI 公司创始人\n  整洁的代码总是看起来像是某位特别在意它的人写的。几乎没有改进的余地，代码作者什么都想到了。\u0026mdash; 《修改代码的艺术》作者\n 有意义的命名 对于变量，如果其需要注释来补充，那就不算是名副其实。比如你需要定义一个变量，这个变量存储的是消逝的时间，其单位是天，那么下面是一些比较好的命名：\nint elapsedTimeInDays; int daysSinceCreation; int daysSinceModification; int fileAgeInDays; 别用 accountList 来指一组账号，除非它真的是 List 类型，List 一词对于程序员有特殊意义，所以用 accountGroup 或 bunchOfAcounts，甚至用 accounts 都会好一些。\n别说废话，废话都是冗余。假如你有一个 Product 类，如果还有一个 ProductInfo 或 ProductData 类，它们虽然名称不同，意思却无区别。Info 和 Data 就像 a、an 和 the 一样，是意义含混的废话。下面三个函数的命名，我们怎么知道应该调用哪个呢？\ngetActiveAccount(); getActiveAccounts(); getActiveAccountInfo(); 使用常量，WORK_DAYS_PER_WEEK 比数字 5 要好找的多。\n 对于类名，其应该是名词或名词短语，如 Customer、WikiPage、Account 和 AddressParser，避免使用 Manager、Processor、Data 或 Info 这样的类名。类名不应当是动词。\n 对于方法名，其应当是动词或动词短语，如 postPayment、deletePage 或 save。\n 为每一个抽象概念选一个词，并且一以贯之。例如使用 fetch、retrieve 和 get 来给在多个类中的同种方法命名，你怎么记得住哪个类是哪个方法呢？在一堆代码中，有 controller，又有 manager，还有 driver，就会令人困惑。\n多数变量都依赖一个类、一个函数来给读者提供语境，但如果做不到的话，你可能就需要加上前缀。例如 addrFirstName 比 firstName 更能说明，你想表达的是地址的一部分，当然更好的方案是创建一个名为 Address 的类。当然也没必要添加不必要的语境，只要短名称足够清楚，就比长名称好。\n语境不明确的变量  有语境的变量   如何写好函数 函数的第一个规则是短小。第二条规则还是要短小。\n函数应该做一件事，做好这件事，只做这一件事。如何判断函数做了是否不止一件事，看是否能再拆出一个函数。要确保函数只做一件事，函数中的语句都要在同一抽象层级上。getHtml() 位于较高抽象层级，PathParser.render(pagePath) 位于中间抽象层，.append(\u0026quot;\\n\u0026quot;) 位于相当低的抽象层。函数中混杂了不同的抽象层级，往往容易让人迷惑，读者无法判断出某个表达式是基础概念还是细节。\n像如下带有 switch 函数的代码，有几个问题。太长、违反单一原则、违反开放闭合原则（添加新类型，必须修改）等，该问题的解决方案是将 switch 语句埋到抽象工厂底下，不让任何人看到。\nSwitch 语句  用多态封装 Switch 语句   好名称的价值怎么好评都不为过，别害怕长名称，长而具有描述性的名称，要比短而令人费解的名称好，要比描述性的长注释好。别害怕花时间取名字。\n关于函数参数，除非你有足够特殊的理由，才能用三个以上的参数。对于有一个参数的函数，如果要对这个参数进行某种转换操作，那么应该使用返回值来返回转换后的值：StringBuffer transform(StringBuffer in) 要比 void transform(StringBuffer out) 强。\n如果函数看来需要两个、三个或三个以上的参数，说明其中一些参数就需要封装为类了：\nCircle makeCircle(double x, double y, double radius); Circle makeCircle(Point center, double radius); 给函数起一个好名字，能够解释函数意图、参数顺序的名字。writeField(name) 要比 write(name) 强，assertExpectedEqualsActual(expected, actual) 要比 assertEqual 强，这大大减轻了记忆参数的负担。\n确保函数无副作用，函数承诺做这件事，不要在其内部偷偷地做其它事情。\ntry/catch 代码块丑陋不堪，最好把 try 和 catch 代码块的主题部分抽离出来，另外形成函数。错误处理本身就是一件事，这意味着在 try 应该是函数的第一个单词，catch/finally 是这个函数的最后的内容。\n注释 代码在变动，在演化，但注释不能总是随之变动，注释会撒谎。注释不能美化糟糕的代码。\n直接把代码注释掉是讨厌的做法，其他人不敢删除注释掉的代码，他们会想代码依然放在那儿，一定有其原因。\n格式 代码每行展现一个表达式或一个子句，每组代码行展示一条完整的思路。这些思路用空白行区隔开来。每个空白行都是一条线索，标识出新的独立概念。往下读代码时，你的目光总会停留于空白行之后的那一行。\n若某个函数调用了另外一个，就应该把他们放到一起，而且调用者应该尽可能放在被调用者上面，这样，程序有一个自然的顺序。\n对象和数据结构 乱加 set 和 get 时最坏的选择，不要暴露数据细节，而要以抽象形态表述数据。\n暴露了数据细节的车辆  百分比抽象   过程式代码便于在不改动现有数据结构的前提下添加新的函数，面向对象代码便于在不改动现有函数的前提下添加新的类。\nThe Law of Demeter 认为模块不应了解它所操作对象的内部情形，对象应该隐藏数据，暴露操作。下面代码违反了：\nfinal String outputDir = ctxt.getOptions().getScratchDir().getAbsolutePath(); 最为精炼的数据结构，是一个只有公共变量、没有函数的类，这种数据结构就是 DTO（Data Transfer Objects），这种数据结构在与数据库通信、解析套接字传递的消息之类场景中，非常有用。\n错误处理 使用 Checked Exception 的依赖成本要高于收益，每个调用该函数的函数都要捕获它，或者添加合适的 throw 语句，最终得到的时一个从软件最底端贯穿到最高端的修改链，封装被打破，抛出路径上的每个函数都要去了解下一层的异常细节。\n将第三方 API 打包是个良好的实践手段，降低了对它的依赖，未来可以不太痛苦地改用其它代码库，你也可以不必绑死在某个特定厂商的 API 设计上。\n返回 null 的时候，考虑是否可以直接抛出异常，或者返回一个特定的对象，尽量不要返回 null，它在给调用者添乱。返回 null 是糟糕的做法，那么传递 null 值给其它方法就是更糟糕的了。\n单元测试 测试带来一切好处。\n类 系统应该由许多短小的类而不是少量巨大的类组成。\n对类加以组织，可以降低修改的风险。\n一个必须打开修改的类  一组封闭类   "});index.add({'id':27,'href':'/posts/java-lock/','title':"Java 并发 - 锁",'content':"Java 世界中都有哪些锁？锁的分类？如何减少锁的竞争等问题。\n线程安全的三种实现方式 互斥同步 (Blocking Synchronization)，属于悲观并发策略:\n非阻塞同步 (Non-Blocking Synchronization)，属于乐观并发策略:\n无同步 - 线程本地存储 (Thread Local Storage):\nJava 主内存与工作内存交互 从主内存读取变量到工作内存:\n将工作内存的变量写入到主内存:\n内置锁 Synchronized Java 提供了一种内置锁 (Intrinsic Lock)机制来支持原子性: 同步代码块 (Synchronized Block)。每个 Java 对象都可以用做一个实现同步的锁，这些锁被称为内置锁 (Instrinsic Lock) 或监视器锁 (Monitor Lock)。Java 的内置锁相当于一种互斥体(或互斥锁)，这意味着最多只有一个线程能持有这种锁。但是，加锁的含义不仅仅局限于互斥行为，还包括内存可见性，为了确保所有线程都能看到共享变量的最新值，所有执行读操作或者写操作的线程都必须在同一个锁上同步。\nJava synchronized 语句 是基于 monitorenter/monitorexit 机制来实现的。当你写下面这段代码的时候:\nstatic void Sort(int [] array) { // synchronize this operation so that some other thread can\u0026#39;t  // manipulate the array while we are sorting it. This assumes that other  // threads also synchronize their accesses to the array.  synchronized(array) { // now sort elements in array  } } 实际上 JVM 可能会生成下面的代码:\n.method static Sort([I)V aload_0 monitorenter ; lock object in local variable 0 ; now sort elements in array aload_0 monitorexit ; finished with object in local variable 0 return .end method monitorenter 在对象的引用上获取了一个 exclusive lock (独占锁)\n 内置锁 synchronized 是可重入的，某个线程试图获取一个已经由它自己持有的锁，那么这个请求就会成功。\n死锁 在数据库系统的设计中考虑了监测死锁以及从死锁中恢复。在执行一个事务 (Transaction) 时可能需要获取多个锁，并一直持有这些锁直到事务提交。当数据库服务器监测到一组事务发生了死锁时 (通过在表示等待关系的有向图中搜索循环)，将 选择一个牺牲者并放弃这个事务。作为牺牲者的事务会释放它所持有的资源，从而让其它事务继续进行。应用程序可以重新执行被强行中止的事务，而这个事务现在也可以成功完成。\n死锁的四大必要条件 (必须全部满足):\n 互斥 持有并等待资源 不可抢占 循环等待  如果所有的线程以固定的顺序来获得锁，那么在程序中就不会出现锁顺序死锁问题:\n// 不要这么做 public class LeftRightDeadlock { private final Object left = new Object(); private final Object right = new Object(); public void leftRight() { synchronized (left) { synchronized (right) { doSomething(); } } } public void rightLeft() { synchronized (right) { synchronized (left) { doSomethingElse(); } } } } 有时候，你并不能清除地知道是否在锁顺序上有足够的控制权来避免死锁的发生:\n// 动态的锁顺序 // Warning: deadlock-prone! public void transferMoney(Account fromAccount, Account toAccount, DollarAmount amount) throws InsufficientFundsException { synchronized (fromAccount) { synchronized (toAccount) { if (fromAccount.getBalance().compareTo(amount) \u0026lt; 0) throw new InsufficientFundsException(); else { fromAccount.debit(amount); toAccount.credit(amount); } } } } 在这里锁的顺序取决于参数顺序，而这些参数顺序又取决于外部输入，考虑下面代码就有可能发生死锁:\nA: transferMoney(myAccount, yourAccount, 10); B: transferMoney(yourAccount, myAccount, 20); 使用 System.identityHashCode 来定义锁的顺序:\nprivate static final Object tieLock = new Object(); public void transferMoney(final Account fromAcct, final Account toAcct, final DollarAmount amount) throws InsufficientFundsException { class Helper { public void transfer() throws InsufficientFundsException { if (fromAcct.getBalance().compareTo(amount) \u0026lt; 0) throw new InsufficientFundsException(); else { fromAcct.debit(amount); toAcct.credit(amount); } } } // 如果 Account 中包含一个唯一的、不可变的，并且具备可比性的键值，例如  // 账号，那么制定锁的顺序就更加容易了。  int fromHash = System.identityHashCode(fromAcct); int toHash = System.identityHashCode(toAcct); if (fromHash \u0026lt; toHash) { synchronized (fromAcct) { synchronized (toAcct) { new Helper().transfer(); } } } else if (fromHash \u0026gt; toHash) { synchronized (toAcct) { synchronized (fromAcct) { new Helper().transfer(); } } } else { // 在极少数情况下，两个对象可能拥有相同的散列值，  // 此时可以通过某种任意的方法来决定锁的顺序，  // 而这有可能重新引入死锁。为了避免这种情况，可以使用  // “加时赛”锁  synchronized (tieLock) { synchronized (fromAcct) { synchronized (toAcct) { new Helper().transfer(); } } } } } 某些获取多个锁的操作并不像 LeftRightDeadLock 或 transferMoney 中那么明显，这两个锁并不一定必须在同一个方法中被获取:\nclass Taxi { @GuardedBy(\u0026#34;this\u0026#34;) private Point location, destination; private final Dispatcher dispatcher; public Taxi(Dispatcher dispatcher) { this.dispatcher = dispatcher; } public synchronized Point getLocation() { return location; } // 先获取 Taxi 锁  // 再获取 Dispatcher 锁  public synchronized void setLocation(Point location) { this.location = location; if (location.equals(destination)) dispatcher.notifyAvailable(this); } } class Dispatcher { @GuardedBy(\u0026#34;this\u0026#34;) private final Set\u0026lt;Taxi\u0026gt; taxis; @GuardedBy(\u0026#34;this\u0026#34;) private final Set\u0026lt;Taxi\u0026gt; availableTaxis; public Dispatcher() { taxis = new HashSet\u0026lt;Taxi\u0026gt;(); availableTaxis = new HashSet\u0026lt;Taxi\u0026gt;(); } public synchronized void notifyAvailable(Taxi taxi) { availableTaxis.add(taxi); } // 先获取 Dispatcher 锁  // 再获取每一个 Taxi 锁  public synchronized Image getImage() { Image image = new Image(); for (Taxi t : taxis) image.drawMarker(t.getLocation()); return image; } } 通过将上述代码修改为开放调用 (调用某个方法时不需要使用锁)，从而消除发生死锁的风险:\n@ThreadSafe class Taxi { @GuardedBy(\u0026#34;this\u0026#34;) private Point location, destination; private final Dispatcher dispatcher; ... public synchronized Point getLocation() { return location; } public synchronized void setLocation(Point location) { boolean reachedDestination; synchronized (this) { this.location = location; reachedDestination = location.equals(destination); } if (reachedDestination) dispatcher.notifyAvailable(this); } } @ThreadSafe class Dispatcher { @GuardedBy(\u0026#34;this\u0026#34;) private final Set\u0026lt;Taxi\u0026gt; taxis; @GuardedBy(\u0026#34;this\u0026#34;) private final Set\u0026lt;Taxi\u0026gt; availableTaxis; ... public synchronized void notifyAvailable(Taxi taxi) { availableTaxis.add(taxi); } public Image getImage() { Set\u0026lt;Taxi\u0026gt; copy; synchronized (this) { copy = new HashSet\u0026lt;Taxi\u0026gt;(taxis); } Image image = new Image(); for (Taxi t : copy) image.drawMarker(t.getLocation()); return image; } } 在程序中应该尽量使用开放调用。与那些在持有锁时调用外部方法的程序相比，更易于对依赖于开放调用的程序进行死锁分析。通过使用定时锁能够有效地应对死锁问题，通过 Thread Dump 能够帮助你识别死锁的发生。\n减少锁的竞争 有三种方式可以降低锁的竞争程度:\n 减少锁的持有时间 降低锁的请求频率 使用带有协调机制的独占锁，这些机制允许更高的并发性  重入锁 ReentrantLock ReentrantLock 的 tryLock 方法为你提供了轮询锁与定时锁的锁获取模式，与无条件的锁获取模式相比，它具有更完善的错误恢复机制。方法 lockInterruptibly 方法能够在获得锁的同时保持对中断的响应。ReentrantLock 的构造函数中提供了两种公平性选择: 创建一个非公平的锁 (默认) 或者一个公平的锁。在公平的锁上，线程将按照它们发出请求的顺序来获得锁，但在非公平的锁上，则允许“插队”。在大多数情况下，非公平锁的性能要高于公平锁的性能。\npublic class ReentrantLock implements Lock, java.io.Serializable { /** Synchronizer providing all implementation mechanics */ private final Sync sync; abstract static class Sync extends AbstractQueuedSynchronizer { } public ReentrantLock(boolean fair) { sync = fair ? new FairSync() : new NonfairSync(); } public boolean tryLock() { return sync.nonfairTryAcquire(1); } public void unlock() { sync.release(1); } } 读写锁 ReadWriteLock public class ReentrantReadWriteLock implements ReadWriteLock, java.io.Serializable { public ReentrantReadWriteLock(boolean fair) { sync = fair ? new FairSync() : new NonfairSync(); readerLock = new ReadLock(this); writerLock = new WriteLock(this); } } 记录锁 Record Locking Record Locking 更好的叫法应该被称为: byte-range locking，目的是为了防止两个进程同时修改一个文件的某块区域。函数原型如下:\n#include \u0026lt;fcntl.h\u0026gt;// 出错返回 -1 int fcntl(int fd, int cmd, ... /* struct flock *flockptr */ ); 其中 flock 结构体定义如下:\nstruct flock { short l_type; /* F_RDLCK, F_WRLCK, or F_UNLCK */ short l_whence; /*SEEK_SET, SEEK_CUR, or SEEK_END */ off_t l_start; /*offset in bytes, relative to l_whence */ off_t l_len; /*length, in bytes; 0 means lock to EOF */ pid_t l_pid; /*returned with F_GETLK */ };  F_RDLCK: 共享读锁 F_WRLCK: 排斥写锁 F_UNLCK: 取消某个区域的锁  锁优化 自旋锁 SpinLock 互斥同步对性能最大的影响就是阻塞的实现，挂起线程和恢复线程的操作都需要转入内核态中完成，这些操作给系统的并发性能带来了很大的压力。同时，虚拟机的开发团队也注意到在许多应用上，共享数据的锁定状态只会持续很短的一段时间，为了这段时间去挂起和恢复线程并不值得。为了能让线程稍微等一会，我们只需让线程执行一个忙循环 (自旋)，这项技术就是所谓的自旋锁。\n现在我们假设硬件上有一种能够保证原子性的 TestAndSet 指令实现函数:\nint TestAndSet(int *x){ register int temp = *x; *x = 1; return temp; } TestAndSet 是一种常用的用于支持并发的原子操作指令。另外一种经常使用的指令是原子 Exchange 操作:\nvoid Exchange(int *a, int *b) { int temp = *a; *a = *b; *b = temp; } 这些所有的原子性操作中最重要的是 CompareAndSwap (CAS) 操作，它经常被用于 lock-free and wait-free algorithms 算法中。\nboolean CAS(int *a, int old, int new) { int temp = *a; if (temp == old) { *a = new; return true; } else return false; } 使用 CAS 来实现 temp++:\nint temp = x; while (!CAS(\u0026amp;x, temp, temp+1)) { temp = x; } 使用 CAS 来实现更链表头插法:\nwhile (1) { Node *q = *head; p-\u0026gt;next = q; if (CAS(head, q, p)) break; } 一般而言，SpinLock 是一种抽象的数据类型，其通常提供三种操作:\n InitLock Lock UnLock  Lock(mutex); Si; UnLock(mutex); 实现 SpinLock 的伪代码如下:\ntypedef int SpinLock; void InitLock(SpinLock *L) { *L = 0; } void Lock(SpinLock *L) { while (TestAndSet(L)) ; } void UnLock(SpinLock *L) { *L = 0; } 一种使用 Exchange 操作的可能实现:\ntypedef int SpinLock; void InitLock(SpinLock *s) { *s = 0; } void Lock (SpinLock *s) { int L = 1; do { Exchange(\u0026amp;L, s); } while (L == 1); } void UnLock (SpinLock *s) { *s = 0; } 另外一种使用 CompareAndSwap 指令的实现:\ntypedef int SpinLock; void InitLock(SpinLock *s) { *s = 0; } void Lock (SpinLock *s) { do { } until (CompareAndSwap(s, 0, 1)); } void UnLock (SpinLock *s) { *s = 0; } 自旋锁最大的问题就是可能会占用比较高的 memory bus 带宽，另外它也不保证公平性，即无法保证先后进入临界区的两个进程 P 和 Q 按照 FIFO 顺序来服务。\n锁消除 Lock Elimination 虚拟机 JIT 在运行时，对一些代码要求同步，但是被检测到不可能存在共享数据竞争的锁进行消除。主要判定依据来自于逃逸分析的数据支持。\n锁粗化 Lock Coarsening 轻量级锁 Lightweight Locking 偏向锁 Biased Locking 偏向锁的\u0026quot;偏\u0026rdquo;，是偏心的\u0026quot;偏\u0026rdquo;，它的意思就是这个锁会偏向于第一个获得它的线程，如果在接下来的执行过程中，该锁没有被其他的线程获取，则持有偏向锁的线程将永远不需要再进行同步。当有另外一个线程去尝试获取这个锁时，偏向模式就宣告结束。\nJDK 1.6 默认开启 -XX:+UseBiasedLocking，使用 -XX:-UseBiasedLocking 来关闭。\n偏向锁转为轻量级锁的流程图:\n锁升级 Lock Escalation 所谓的锁升级（lock escalation），是数据库的一种作用机制，该机制普遍见于各大数据库产品。 为了节约内存的开销，其会将为数众多并占用大量资源的细粒度的锁转化为数量较少的且占用相对较少资源的粗粒度的锁，多数情况下主要指将为数众多的行锁升级为一个表锁。当然，DB2 支持很多粒度的锁，如**表空间（table space），表（table），行（row）以及索引（index）**等。MySQL 的 InnoDB 存储引擎支持事务，默认是行锁。得益于这些特性，数据库支持高并发。\n锁升级与两种事情有关:\n 事务的隔离级别 索引  常用的索引有三类：主键、唯一索引、普通索引。主键 不由分说，自带最高效的索引属性；唯一索引 指的是该属性值重复率为0，一般可作为业务主键，例如学号；普通索引 与前者不同的是，属性值的重复率大于0，不能作为唯一指定条件，例如学生姓名。当“值重复率”低时，甚至接近主键或者唯一索引的效果，“普通索引”依然是行锁；当“值重复率”高时，MySQL 不会把这个“普通索引”当做索引，即造成了一个没有索引的 SQL，此时引发表锁。索引不是越多越好，索引存在一个和这个表相关的文件里，占用硬盘空间，宁缺勿滥，每个表都有主键（id），操作能使用主键尽量使用主键。同 JVM 自动优化 java 代码一样，MySQL 也具有自动优化 SQL 的功能。低效的索引将被忽略，这也就倒逼开发者使用正确且高效的索引。\n参考  《Java 并发编程实战》 Deadlock 《Advanced Programming in the UNIX》 《深入理解 Java 虚拟机》 CIS 4307: Spinlocks and Semaphores enter synchronized region of code 关于 DB2 锁升级 (lock escalation) 相关问题的探讨 MySQL 避免行锁升级为表锁——使用高效的索引 Innodb中的事务隔离级别和锁的关系 MySQL数据库事务各隔离级别加锁情况\u0026ndash;read uncommitted篇 Thread Synchronization "});index.add({'id':28,'href':'/docs/programmer-interview/algorithm/best-time-to-buy-and-sell-stock-4/','title':"Best Time to Buy and Sell Stock Ⅳ",'content':"Best Time to Buy and Sell Stock Ⅳ 题目 LeetCode 地址：Best Time to Buy and Sell Stock Ⅳ\n有一个数组，第 i 个元素的值代表第 i 天的股票价格，如果你最多只能进行K次交易（某天买入一支股票，然后过几天卖掉），请问你能收获的最大利润是多少？\n分析 参考 Best Time to Buy and Sell Stock 思路上状态机，状态机应用K次即可。\n答案 // 最多交易 k 次 // https://leetcode.com/problems/best-time-to-buy-and-sell-stock-iv/ // public class BestTimetoBuyandSellStockIV { public int maxProfit(int k, int[] prices) { if (prices == null || prices.length \u0026lt;= 1 || k \u0026lt;= 0) { return 0; } if (k \u0026gt;= prices.length / 2) { // 这就相当于怎样，可交易任意多次  // 问题转为 BestTimetoBuyandSellStockII  return maxProfitQuestion2(prices); } int s0 = 0; int[] sArray = new int[k * 2]; initStateArray(prices, sArray); for (int i = 1; i \u0026lt; prices.length; i++) { s0 = s0; sArray[0] = Math.max(sArray[0], s0 - prices[i]); for (int j = 1; j \u0026lt; sArray.length; j++) { if (j % 2 == 1) { sArray[j] = Math.max(sArray[j - 1] - prices[i], sArray[j]); } else { sArray[j] = Math.max(sArray[j - 1] + prices[i], sArray[j]); } } } return sArray[sArray.length - 1]; } private void initStateArray(int[] prices, int[] sArray) { for (int i = 0; i \u0026lt; sArray.length; i += 2) { sArray[i] = -prices[0]; } } public int maxProfitQuestion2(int[] prices) { int max = 0; for (int i = 1; i \u0026lt; prices.length; i++) { int diff = prices[i] - prices[i - 1]; if (diff \u0026gt; 0) { max += diff; } } return max; } } 扫描下面二维码，在手机上阅读这篇文章：\n"});index.add({'id':29,'href':'/docs/rocketmq/rocketmq-message-filter-flow/','title':"RocketMQ 消息过滤流程",'content':"RocketMQ 消息过滤流程 讲述 RocketMQ 消息过滤流程\n一、消息过滤类型 Producer 在发送消息的时候可以指定消息的标签类型，还可以为每一个消息添加一个或者多个额外的属性:\n// 指定标签 Message msg = new Message(\u0026#34;TopicTest\u0026#34;, \u0026#34;TagA\u0026#34;, (\u0026#34;Hello RocketMQ\u0026#34;).getBytes(RemotingHelper.DEFAULT_CHARSET)); // 添加属性 a msg.putUserProperty(\u0026#34;a\u0026#34;, 5); 根据标签和属性的不同，RocketMQ 客户端在消费消息的时候有三种消息过滤类型:\n(1) 标签匹配 consumer.subscribe(\u0026#34;TopicTest\u0026#34;, \u0026#34;TagA | TagB | TagC\u0026#34;); (2) SQL 匹配 consumer.subscribe(\u0026#34;TopicTest\u0026#34;, MessageSelector.bySql( \u0026#34;(TAGS is not null and TAGS in (\u0026#39;TagA\u0026#39;, \u0026#39;TagB\u0026#39;))\u0026#34; + \u0026#34;and (a is not null and a between 0 3)\u0026#34;)); (3) 自定义匹配 客户端实现 MessageFilter 类，自定义过滤逻辑:\nClassLoader classLoader = Thread.currentThread().getContextClassLoader(); File classFile = new File(classLoader.getResource(\u0026#34;MessageFilterImpl.java\u0026#34;).getFile()); String filterCode = MixAll.file2String(classFile); consumer.subscribe(\u0026#34;TopicTest\u0026#34;, \u0026#34;org.apache.rocketmq.example.filter.MessageFilterImpl\u0026#34;,filterCode); 对于 MessageFilter 类实现 match 方法即可:\npublic class MessageFilterImpl implements MessageFilter { @Override public boolean match(MessageExt msg, FilterContext context) { String property = msg.getProperty(\u0026#34;SequenceId\u0026#34;); if (property != null) { int id = Integer.parseInt(property); if (((id % 10) == 0) \u0026amp;\u0026amp; (id \u0026gt; 100)) { return true; } } return false; } } 下面我们一一讲解各自背后的机制与实现原理。\n二、标签匹配 当为消息指定消息标签类型的时候，实际上所指定的标签例如 TagA 是作为一个属性放入到了这条消息中的:\npublic class Message implements Serializable { public void setTags(String tags) { this.putProperty(MessageConst.PROPERTY_TAGS, tags); } } 当这条消息到达 Broker 服务器端后，用户设置的标签会计算为标签码，默认的计算方式采用的标签字符串的 hashCode() 作为计算结果的:\npublic class CommitLog { public DispatchRequest checkMessageAndReturnSize(java.nio.ByteBuffer byteBuffer, final boolean checkCRC, final boolean readBody) { // ...  String tags = propertiesMap.get(MessageConst.PROPERTY_TAGS); if (tags != null \u0026amp;\u0026amp; tags.length() \u0026gt; 0) { tagsCode = MessageExtBrokerInner .tagsString2tagsCode(MessageExt.parseTopicFilterType(sysFlag), tags); } // ...  } } 当计算出来标签码之后，这条消息的标签码会被存放至消费队列文件中，用来与消费者客户端消费队列的标签码进行匹配。消费者客户端订阅消费话题的时候，会指定想要匹配的标签类型:\nconsumer.subscribe(\u0026#34;TopicTest\u0026#34;, \u0026#34;TagA | TagB | TagC\u0026#34;); 这段代码在内部实现中利用 FilterAPI 构建了一个 SubscriptionData 对象:\npublic class DefaultMQPushConsumerImpl implements MQConsumerInner { public void subscribe(String topic, String subExpression) throws MQClientException { SubscriptionData subscriptionData = FilterAPI .buildSubscriptionData(this.defaultMQPushConsumer.getConsumerGroup(), topic, subExpression); // ...  } } 当用户未指定标签或者指定为星号标签的时候，则代表用户接受所有标签的消息。如果用户指定了一个或者多个标签，那么会将每一个标签取其 hashCode() 放入到 codeSet 中。SubscriptionData 还有一个 expressionType 字段，在使用标签匹配的时候，其不会设置这个这个字段的值，因此其保留为 null。在这些信息设置好以后，当客户端发送心跳包的时候，会将这些话题的注册信息一并上传至 Broker 服务器端，方便在 Broker 端进行匹配。\npublic class SubscriptionData implements Comparable\u0026lt;SubscriptionData\u0026gt; { public final static String SUB_ALL = \u0026#34;*\u0026#34;; private Set\u0026lt;String\u0026gt; tagsSet = new HashSet\u0026lt;String\u0026gt;(); private Set\u0026lt;Integer\u0026gt; codeSet = new HashSet\u0026lt;Integer\u0026gt;(); private String expressionType; } 当 Broker 端服务器在取消息的时候，每取出来一条消息，都会执行两道过滤机制:\n ConsumeQueue 文件匹配 CommitLog 文件匹配  任一检查没有通过后，绝不会放行这条消息给客户端:\npublic class DefaultMessageStore implements MessageStore { public GetMessageResult getMessage(final String group, /** 其他参数 **/) { for (; i \u0026lt; bufferConsumeQueue.getSize() \u0026amp;\u0026amp; i \u0026lt; maxFilterMessageCount; i += ConsumeQueue.CQ_STORE_UNIT_SIZE) { // ConsumeQueue 文件匹配  if (messageFilter != null \u0026amp;\u0026amp; !messageFilter.isMatchedByConsumeQueue(isTagsCodeLegal ? tagsCode : null, extRet ? cqExtUnit : null)) { if (getResult.getBufferTotalSize() == 0) { status = GetMessageStatus.NO_MATCHED_MESSAGE; } continue; } // CommitLog 文件匹配  if (messageFilter != null \u0026amp;\u0026amp; !messageFilter.isMatchedByCommitLog(selectResult.getByteBuffer().slice(), null)) { if (getResult.getBufferTotalSize() == 0) { status = GetMessageStatus.NO_MATCHED_MESSAGE; } // release...  selectResult.release(); continue; } } } } 消息过滤器的默认实现是 ExpressionMessageFilter ，消息过滤的默认实现策略就是看这个话题的标签码集合中是否包括当前这条消息的标签码:\npublic class ExpressionMessageFilter implements MessageFilter { @Override public boolean isMatchedByConsumeQueue(Long tagsCode, ConsumeQueueExt.CqExtUnit cqExtUnit) { // ...  if (ExpressionType.isTagType(subscriptionData.getExpressionType())) { if (tagsCode == null) { return true; } if (subscriptionData.getSubString().equals(SubscriptionData.SUB_ALL)) { return true; } return subscriptionData.getCodeSet().contains(tagsCode.intValue()); } // ...  return true; } @Override public boolean isMatchedByCommitLog(ByteBuffer msgBuffer, Map\u0026lt;String, String\u0026gt; properties) { if (ExpressionType.isTagType(subscriptionData.getExpressionType())) { return true; } // ...  } } 下图是一幅标签匹配的简要流程图:\n三、SQL 匹配 在发送消息的时候，可以为每一条消息附带一个或者多个属性值，SQL 匹配指的就是依据这些属性值和 TAG 标签 是否满足一定的 SQL 语句条件，来过滤消息。用户如果想要开启 SQL 匹配，那么需要在 Broker 启动的时候，启用如下几个配置信息:\nbrokerConfig.setEnablePropertyFilter(true); brokerConfig.setEnableCalcFilterBitMap(true); messageStoreConfig.setEnableConsumeQueueExt(true); (1) 注册过滤信息 我们在消费者如何接受消息一文中提到过，消费者启动之后，会通过心跳包定时给 Broker 服务器汇报自己的信息。而 Broker 服务器在收到消费者的心跳包之后，会产生一个注册事件，如下所示:\npublic class ConsumerManager { public boolean registerConsumer(final String group, /** 其他参数 **/) { // ...  this.consumerIdsChangeListener.handle(ConsumerGroupEvent.REGISTER, group, subList); // ...  } } DefaultConsumerIdsChangeListener 是默认的消费者列表注册事件通知器的实现类，其在收到注册事件以后，会将用户在消费者端订阅的话题信息注册到 ConsumerFilterManager 中:\npublic class DefaultConsumerIdsChangeListener implements ConsumerIdsChangeListener { @Override public void handle(ConsumerGroupEvent event, String group, Object... args) { switch (event) { case REGISTER: Collection\u0026lt;SubscriptionData\u0026gt; subscriptionDataList = (Collection\u0026lt;SubscriptionData\u0026gt;) args[0]; this.brokerController.getConsumerFilterManager().register(group, subscriptionDataList); break; // ...  } } } ConsumerFilterData 中包含了消费者客户端注册的 SQL 表达式，由上图我们可以看到对于每一个话题所对应的 FilterDataMapByTopic ，可以注册多个 SQL 表达式。但是这里需要注意的是，这多个 SQL 表达式是按照组来做区分的，就是说一个组只能有一个 SQL 表达式，客户端如果在一个组中注册了多个不同的 SQL 表达式，那么后注册的会覆盖掉前注册的。因此，如果想要对同一个组使用不同的 SQL 语句来过滤自己想要的信息，这些不同的 SQL 语句必须划分到不同的组里面才可行。\n(2) 生成 BloomFilterData 布隆过滤器 (BloomFilter) 是一种空间效率很高的数据结构，其可以用来判断某个元素是否可能存在于某个集合中。当判断结果返回 true 的时候，表示可能存在，当返回 false 的时候，表示这个元素一定不存在于这个集合中。\n它的原理是当一个元素被加入集合时，通过 k 个 Hash 函数将这个元素映射成一个长度为 m 位数组（Bit array）中的 k 个点，把它们置为 1。检索时，我们只要看看这些点是不是都是 1 就（大约）知道集合中有没有它了：\n 如果这些点有任何一个 0，则被检索元素一定不在。 如果都是 1， 则被检索元素很可能在。  如下是一个采用位数组长度为 m=18 以及哈希函数个数为 k=3 实现的布隆过滤器，”x,y,z” 每一个字母都需要经过 3 次哈希函数的计算，然后映射到 3 个不同的槽中。由于字母 “w” 在经过 3 次哈希函数计算后，其中一次产生的哈希值并未命中已有的槽，因此可以确定的是 “w” 肯定不存在于这个集合中。\n在 RocketMQ 的实现中，其有四个最关键的值:\npublic class BloomFilter { // 最大错误率  private int f; // 可能插入 n 个元素  private int n; // k 个哈希函数  private int k; // 数组总共 m 位  private int m; } RocketMQ 实现的布隆过滤器是根据错误率 f 和可能插入的元素数量 n 计算出来的 k 和 m，在默认配置情况下，即如下 n = 32 和 f = 20，计算出来需要 k = 3 个哈希函数和 m = 112 位的数组。\npublic class BrokerConfig { // Expect num of consumers will use filter.  private int expectConsumerNumUseFilter = 32; // Error rate of bloom filter, 1~100.  private int maxErrorRateOfBloomFilter = 20; } 我们这里大致了解以下布隆过滤器的一个基本想法即可，具体算法比较复杂，也不在讨论范畴以内。当客户端注册过滤信息的时候，其会根据 “组#话题” 这个字符串计算出相应的位映射数据，也即这个字符串经过布隆过滤器中的若干个哈希函数得到的几个不同的哈希值:\npublic class ConsumerFilterManager extends ConfigManager { public boolean register(final String topic, /** 其它参数 **/) { // ...  BloomFilterData bloomFilterData = bloomFilter.generate(consumerGroup + \u0026#34;#\u0026#34; + topic); // ...  } } ConsumerFilterManager 中的话题过滤信息数据，每隔 10 秒进行一次磁盘持久化:\npublic class BrokerController { public boolean initialize() throws CloneNotSupportedException { this.scheduledExecutorService.scheduleAtFixedRate(new Runnable() { @Override public void run() { BrokerController.this.consumerFilterManager.persist(); } }, 1000 * 10, 1000 * 10, TimeUnit.MILLISECONDS); } } 磁盘文件 consumerFilter.json 中保存的数据信息如下示例:\n上述大致流程图如下所示：\n(3) 编译 SQL 语句 JavaCC (Java Compiler Compiler) 是一个能生成语法和词法分析器的生成程序，它通过阅读一个自定义的语法标准文件 (通常以 jj 为后缀名) ，然后就能生成能够解析该语法的扫描器和解析器的代码。\n通过执行 javacc SelectorParser.jj 命令以后，其会生成如下七个 Java 文件，用以解析 SQL 语法:\n过滤器工厂 FilterFactory 在初次使用的时候，会注册一个 SqlFilter 类，这个类能够将消费者端指定的 SQL 语句编译解析为 Expression 表达式对象，方便后续消息的快速匹配与过滤。\npublic class SqlFilter implements FilterSpi { @Override public Expression compile(final String expr) throws MQFilterException { return SelectorParser.parse(expr); } } (4) 计算位映射 当 Broker 服务器接收到新的消息到来之后，一直在后台运行的 ReputMessageService 会负责将这条消息封装为一个 DispatchRequest 分发请求，这个请求会传递给提前构建好的分发请求链。在 DefaultMessageStore 的构造函数中，我们看到依次添加了构建消费队列和构建索引的分发请求服务:\npublic class DefaultMessageStore implements MessageStore { public DefaultMessageStore(final MessageStoreConfig messageStoreConfig, /** 其它参数 **/) throws IOException { this.dispatcherList = new LinkedList\u0026lt;\u0026gt;(); this.dispatcherList.addLast(new CommitLogDispatcherBuildConsumeQueue()); this.dispatcherList.addLast(new CommitLogDispatcherBuildIndex()); } } 而在 Broker 初始化的时候，我们看到其又添加了计算位映射的分发请求服务，并且将此分发服务放在链表的第一个位置:\npublic class BrokerController { public boolean initialize() throws CloneNotSupportedException { this.messageStore.getDispatcherList() .addFirst(new CommitLogDispatcherCalcBitMap(this.brokerConfig, this.consumerFilterManager)); } } 由此，在每次收到新的消息之后，分发请求的需要经过如下三个分发请求服务进行处理:\n我们在这部分只介绍计算位映射的服务类实现。如下，dispatch 方法用来分发请求里面的消息，对于这每一条消息，首先根据话题取得所有的消费过滤数据。这每一条数据代表的就是一条 SQL 过滤语句信息。我们在这个地方，需要一一遍历这些过滤信息，从而完成计算位服务的需求:\npublic class CommitLogDispatcherCalcBitMap implements CommitLogDispatcher { @Override public void dispatch(DispatchRequest request) { Collection\u0026lt;ConsumerFilterData\u0026gt; filterDatas = consumerFilterManager.get(request.getTopic()); Iterator\u0026lt;ConsumerFilterData\u0026gt; iterator = filterDatas.iterator(); while (iterator.hasNext()) { ConsumerFilterData filterData = iterator.next(); // ...  } } } 在拿到 ConsumerFilterData 信息之后，其会根据这条信息内的 SQL 语句编译后的表达式来对这条消息进行检查匹配 (evaluate)，看这条消息是否满足 SQL 语句所设置的条件。如果满足，那么会将先前在客户端注册阶段计算好的 BloomFilterData 中的映射位信息设置到 filterBitMap 中，即将相应的位数组 BitsArray 中的相应位设置为 1 。在验证完所有的 SQL 语句之后，会将这些所有的字节数组放置到 request 请求之中，以便交由下一个请求分发服务进行使用:\n@Override public void dispatch(DispatchRequest request) { BitsArray filterBitMap = BitsArray.create(this.consumerFilterManager.getBloomFilter().getM()); while (iterator.hasNext()) { ConsumerFilterData filterData = iterator.next(); MessageEvaluationContext context = new MessageEvaluationContext(request.getPropertiesMap()); Object ret = filterData.getCompiledExpression().evaluate(context); // eval true  if (ret != null \u0026amp;\u0026amp; ret instanceof Boolean \u0026amp;\u0026amp; (Boolean) ret) { consumerFilterManager .getBloomFilter() .hashTo(filterData.getBloomFilterData(), filterBitMap); } } request.setBitMap(filterBitMap.bytes()); } (5) 存储位映射 MessageStore 在开启扩展消费队列的配置之后，每一个消费队列在创建的时候，都会额外创建一个扩展消费队列。每一个扩展消费队列文件的大小默认为 48MB:\npublic class ConsumeQueue { public ConsumeQueue(final String topic, /** 其它参数 **/) { // ...  if (defaultMessageStore.getMessageStoreConfig().isEnableConsumeQueueExt()) { this.consumeQueueExt = new ConsumeQueueExt(topic, /** 其它参数 **/); } } } 在计算位映射一节中，计算好位字节数组之后，我们这里需要通过第二个分发请求服务 CommitLogDispatcherBuildConsumeQueue 来存储这些字节信息。通过如下代码，我们知道它将请求中的位映射信息、消息存储时间、标签码这三条信息封装为 ConsumeQueueExt.CqExtUnit ，然后放入到扩展消费队列文件中。\npublic class ConsumeQueue { public void putMessagePositionInfoWrapper(DispatchRequest request) { long tagsCode = request.getTagsCode(); if (isExtWriteEnable()) { ConsumeQueueExt.CqExtUnit cqExtUnit = new ConsumeQueueExt.CqExtUnit(); cqExtUnit.setFilterBitMap(request.getBitMap()); cqExtUnit.setMsgStoreTime(request.getStoreTimestamp()); cqExtUnit.setTagsCode(request.getTagsCode()); long extAddr = this.consumeQueueExt.put(cqExtUnit); if (isExtAddr(extAddr)) { tagsCode = extAddr; } } } } 我们注意到在上述代码中，put 函数返回的是一个 long 类型的扩展地址，当这个数值满足 isExtAddr 要求后，其会将当前的标签码设置为刚才返回的扩展地址。那么这是为什么呢?\n我们首先来看 ConsumeQueueExt 文件在存放数据成功后是如何返回信息的:\npublic class ConsumeQueueExt { public static final long MAX_ADDR = Integer.MIN_VALUE - 1L; public long put(final CqExtUnit cqExtUnit) { if (mappedFile.appendMessage(cqExtUnit.write(this.tempContainer), 0, size)) { return decorate(wrotePosition + mappedFile.getFileFromOffset()); } return 1; } public long decorate(final long offset) { if (!isExtAddr(offset)) { return offset + Long.MIN_VALUE; } return offset; } public static boolean isExtAddr(final long address) { return address \u0026lt;= MAX_ADDR; } } MAX_ADDR 是一个很小很小的值，为 -2147483649， 即写入位置如果不小于这个值，那么我们就认定为它不是扩展地址。需要将修正后的 写入偏移量 + Long.MIN_VALUE 确定为扩展地址。当读取信息的时候，其先读取 ConsumeQueue 文件中的最后的 Hash 标签码值，如果其通过 isExtAddr() 函数返回的是 true，那么我们就可以使用这个地址，再通过一个叫做 unDecorate() 函数将其修正为正确的 ConsumeQueueExt 文件的写入地址，从而接着读取想要的信息:\npublic long unDecorate(final long address) { if (isExtAddr(address)) { return address - Long.MIN_VALUE; } return address; } 这个地方，我们发现 ConsumeQueue 中的最后一个 long 型数值，可能存储的是标签 Hash 码，也可能存储的是扩展消费队列的写入地址，所以需要通过 isExtAddr() 来分情况判断。\n下图为 ConsumeQueue 文件和 ConsumeQueueExt 文件中存取信息的不同:\n(6) 消息过滤 在上小节我们提到了有关扩展消费队列地址和标签 Hash 码存储的不同，所以当在取消息的时候，先得从消费队列文件中取出 tagsCode，然后检查是否是扩展消费队列地址，如果是，那么就需要从扩展消费队列文件中读取正确的标签 Hash 码，如下代码所示：\npublic class DefaultMessageStore implements MessageStore { public GetMessageResult getMessage(final String group, /** 其它参数 **/) { ConsumeQueueExt.CqExtUnit cqExtUnit = new ConsumeQueueExt.CqExtUnit(); for (; i \u0026lt; bufferConsumeQueue.getSize() \u0026amp;\u0026amp; i \u0026lt; maxFilterMessageCount; i += ConsumeQueue.CQ_STORE_UNIT_SIZE) { long tagsCode = bufferConsumeQueue.getByteBuffer().getLong(); boolean extRet = false, isTagsCodeLegal = true; if (consumeQueue.isExtAddr(tagsCode)) { extRet = consumeQueue.getExt(tagsCode, cqExtUnit); if (extRet) { tagsCode = cqExtUnit.getTagsCode(); } else { isTagsCodeLegal = false; } } } } } 当获取到这条消息在扩展消费队列文件中存取的信息后，就会和标签匹配一节所讲述的一致，会进行两道过滤机制。我们先来看第一道 ConsumeQueue 文件匹配:\npublic class ExpressionMessageFilter implements MessageFilter { @Override public boolean isMatchedByConsumeQueue(Long tagsCode, ConsumeQueueExt.CqExtUnit cqExtUnit) { byte[] filterBitMap = cqExtUnit.getFilterBitMap(); BloomFilter bloomFilter = this.consumerFilterManager.getBloomFilter(); BitsArray bitsArray = BitsArray.create(filterBitMap); return bloomFilter.isHit(consumerFilterData.getBloomFilterData(), bitsArray); } } ExpressionMessageFilter 依据 CqExtUnit 中存储的位数组重新创建了比特数组 bitsArray，这个数组信息中已经存储了不同 SQL 表达式是否匹配这条消息的结果。isHit() 函数会一一检查 BloomFilterData 中存储的位信息是否映射在 BitsArray 中。只要有任何一位没有映射，那么就可以立刻判断出这条消息肯定不符合 SQL 语句的条件。\n因为布隆过滤器有一定的错误率，其只能精确的判断消息是否一定不在集合中，返回成功的只能确定为消息可能在集合中。因此通过布隆过滤器检查后还需要经过第二道过滤机制，即 SQL 编译后的表达式亲自验证是否匹配:\npublic class ExpressionMessageFilter implements MessageFilter { @Override public boolean isMatchedByCommitLog(ByteBuffer msgBuffer, Map\u0026lt;String, String\u0026gt; properties) { MessageEvaluationContext context = new MessageEvaluationContext(tempProperties); Object ret = realFilterData.getCompiledExpression().evaluate(context); if (ret == null || !(ret instanceof Boolean)) { return false; } return (Boolean) ret; } } 通过在验证 SQL 表达式是否满足之前，提前验证是否命中布隆过滤器，可以有效的避免许多不必要的验证:\n四、自定义匹配 消息的自定义匹配需要开启过滤服务器、上传过滤类、过滤服务器委托过滤消息等步骤，下面我们一一进行说明。\n(1) 过滤服务器 在启动 Broker 服务器的时候，如果指定了下面一行设置:\nbrokerConfig.setFilterServerNums(int filterServerNums); 即将过滤服务器的数量设定为大于 0，那么 Broker 服务器在启动的时候，将会启动 filterServerNums 个过滤服务器。过滤服务器是通过调用 shell 命令的方式，启用独立进程进行启动的。\npublic class FilterServerManager { public void createFilterServer() { int more = this.brokerController.getBrokerConfig().getFilterServerNums() - this.filterServerTable.size(); String cmd = this.buildStartCommand(); for (int i = 0; i \u0026lt; more; i++) { FilterServerUtil.callShell(cmd, log); } } } 过滤服务器在初始化的时候，会启动定时器每隔 10 秒注册一次到 Broker 服务器:\npublic class FiltersrvController { public boolean initialize() { this.scheduledExecutorService.scheduleAtFixedRate(new Runnable() { @Override public void run() { FiltersrvController.this.registerFilterServerToBroker(); } }, 3, 10, TimeUnit.SECONDS); } } Broker 服务器在收到来自过滤服务器的注册信息之后，会把过滤服务器的地址信息、注册时间等放到过滤服务器表中:\npublic class FilterServerManager { private final ConcurrentMap\u0026lt;Channel, FilterServerInfo\u0026gt; filterServerTable = new ConcurrentHashMap\u0026lt;Channel, FilterServerInfo\u0026gt;(16); } 同样，Broker 服务器也需要定时将过滤服务器地址信息同步给所有 Namesrv 命名服务器，上述整个流程如下图所示:\n(2) 过滤类 当消费者通过使用自定义匹配过滤消息的时候，这个时候会将存储订阅信息的 SubscriptionData 中的 filterClassSource 设置为 true，以表征这个客户端需要过滤类来进行消息的匹配和过滤。\n消费者客户端在启动过程中，还会定时地上传本地的过滤类源码到过滤服务器:\npublic class MQClientInstance { private void startScheduledTask() { this.scheduledExecutorService.scheduleAtFixedRate(new Runnable() { @Override public void run() { MQClientInstance.this.sendHeartbeatToAllBrokerWithLock(); } }, 1000, this.clientConfig.getHeartbeatBrokerInterval(), TimeUnit.MILLISECONDS); } public void sendHeartbeatToAllBrokerWithLock() { // ...  this.uploadFilterClassSource(); } } 其中过滤服务器的地址列表是在从 Namesrv 服务器获取话题路由信息的时候取得的，话题路由信息不光存储了消息队列数据，还存储了各个 Broker 所关联的过滤服务器列表:\npublic class TopicRouteData extends RemotingSerializable { // ...  private HashMap\u0026lt;String/* brokerAddr */, List\u0026lt;String\u0026gt;/* Filter Server */\u0026gt; filterServerTable; } 当过滤服务器接收到来自消费者客户端的源码之后，其会首先首先生成一个键为 话题@组 的字符串来查阅过滤类信息是否已经存在于内存里面的 filterClassTable 表中且文件通过 CRC 校验。如果没有存在或校验失败，那么就需要先编译并加载这个类:\npublic class DynaCode { public void compileAndLoadClass() throws Exception { String[] sourceFiles = this.uploadSrcFile(); this.compile(sourceFiles); this.loadClass(this.loadClass.keySet()); } } 默认情况下，编译后的类存放于 $HOME/rocketmq_filter_class/$PID 目录下，类的源文件和类的字节码文件名也会相应的加上当前时间戳来确定:\n上述流程图如下:\n(3) 过滤消息 当消费者客户端启用自定义匹配过滤消息后，发往服务器的数据中也包含了过滤标志位，这样每次拉取消息的服务器也由原来的 Broker 服务器变更为 Filtersrv 过滤服务器，其中过滤服务器地址的选择是随机确定的:\npublic class PullAPIWrapper { public PullResult pullKernelImpl(final MessageQueue mq, /** 其它参数 **/) throws Exception { // ...  if (findBrokerResult != null) { if (PullSysFlag.hasClassFilterFlag(sysFlagInner)) { // 从过滤服务器拉取消息  brokerAddr = computPullFromWhichFilterServer(mq.getTopic(), brokerAddr); } // ...  } } } 过滤服务器在启动的时候，内部还启动了一个 PullConsumer 客户端，用以从 Broker 服务器拉取消息:\npublic class FiltersrvController { private final DefaultMQPullConsumer defaultMQPullConsumer = new DefaultMQPullConsumer(MixAll.FILTERSRV_CONSUMER_GROUP); public void start() throws Exception { this.defaultMQPullConsumer.start(); // ...  } } 当过滤服务器收到真正的消费者发来的消费消息的请求之后，其会委托内部的 PullConsumer 使用包含在请求体内的偏移量去 Broker 服务器拉取所有消息，此时这些消息是完全没有过滤的：\npublic class DefaultRequestProcessor implements NettyRequestProcessor { private RemotingCommand pullMessageForward(final ChannelHandlerContext ctx, final RemotingCommand request) throws Exception { MessageQueue mq = new MessageQueue(); mq.setTopic(requestHeader.getTopic()); mq.setQueueId(requestHeader.getQueueId()); mq.setBrokerName(this.filtersrvController.getBrokerName()); // 设置偏移量和最大数量  long offset = requestHeader.getQueueOffset(); int maxNums = requestHeader.getMaxMsgNums(); // 委托内部消费者从 Broker 服务器拉取消息  pullConsumer.pullBlockIfNotFound(mq, null, offset, maxNums, pullCallback); } } 过滤服务器从 Broker 服务器获取到完整的消息列表之后，会遍历消息列表，然后使用过滤类一一进行匹配，最终将匹配成功的消息列表返回给客户端:\npublic class DefaultRequestProcessor implements NettyRequestProcessor { private RemotingCommand pullMessageForward(final ChannelHandlerContext ctx, final RemotingCommand request) throws Exception { final PullCallback pullCallback = new PullCallback() { @Override public void onSuccess(PullResult pullResult) { switch (pullResult.getPullStatus()) { case FOUND: List\u0026lt;MessageExt\u0026gt; msgListOK = new ArrayList\u0026lt;MessageExt\u0026gt;(); for (MessageExt msg : pullResult.getMsgFoundList()) { // 使用过滤类过滤消息  boolean match = findFilterClass.getMessageFilter().match(msg, filterContext); if (match) { msgListOK.add(msg); } } break; // ...  } } }; // ...  } } 上述流程如下图所示:\n"});index.add({'id':30,'href':'/docs/books/','title':"书籍",'content':"书籍  书籍是人类进步的阶梯。\u0026ndash; 高尔基\n "});index.add({'id':31,'href':'/docs/books/the_transformation_of_enterprise_it_architecture/','title':"企业 IT 架构转型之道",'content':"企业 IT 架构转型之道 共享服务体系搭建 SOA 的主要特性：\n 面向服务的分布式计算。 服务间松散耦合。 支持服务的组装。 服务注册和自动发现。 以服务契约方式定义服务交互方式。  基于 “中心化” 的 ESB 服务调用方式  “去中心化” 服务架构调用方式   数据拆分实现数据库能力线性扩展 数据库的读写分离 读写分离基本原理是让主数据库处理事务性增、改、删（INSERT、UPDATE、DELETE）操作，而从数据库专门负责处理查询（SELECT）操作，在数据库的后台会把事务性操作导致的主数据库中的数据变更同步到集群中的从数据库。\n数据库分库分表 采用分库分表的方式将业务数据拆分后，如果每一条SQL语句中都能带有分库分表键，SQL语句的执行效率最高：\n但不是所有的业务场景在进行数据库访问时每次都能带分库分表键的。比如在买家中心的界面中，要显示买家test1过去三个月的订单列表信息。此时就出现了我们所说的全表扫描，一条SQL语句同时被推送到后端所有数据库中运行。如果是高并发情况下同时请求的话，为了数据库整体的扩展能力，则要考虑下面描述的异构索引手段来避免这样的情况发生。对于在内存中要进行大数据量聚合操作和计算的SQL请求，如果这类SQL的不是大量并发或频繁调用的话，平台本身的性能影响也不会太大，如果这类SQL请求有并发或频繁访问的要求，则要考虑采用其他的平台来满足这一类场景的要求，比如Hadoop这类做大数据量离线分析的产品，如果应用对请求的实时性要求比较高，则可采用如内存数据库或HBase这类平台。\n所谓“异构索引表”，就是采用异步机制将原表内的每一次创建或更新，都换另一个维度保存一份完整的数据表或索引表。本质上这是互联网公司很多时候都采用的一个解决思路：“拿空间换时间”。也就是应用在创建或更新一条按照订单ID为分库分表键的订单数据时，也会再保存一份按照买家ID为分库分表键的订单索引数据。\n基于订单索引表实现买家订单列表查看流程示意：\n实现对数据的异步索引创建有多种实现方式，其中一种就是从数据库层采用 binlog 数据复制的方式实现。\n采用数据异构索引的方式在实战中基本能解决和避免90%以上的跨join或全表扫描的情况，是在分布式数据场景下，提升数据库服务性能和处理吞吐能力的最有效技术手段。但在某些场景下，比如淘宝商品的搜索和高级搜索，因为商品搜索几乎是访问淘宝用户都会进行的操作，所以调用非常频繁，如果采用SQL语句的方式在商品数据库进行全表扫描的操作，则必然对数据库的整体性能和数据库连接资源带来巨大的压力。面对此类场景，我们不建议采用数据库的方式提供这样的搜索服务，而是采用专业的搜索引擎平台来行使这样的职能，如Lucene、Solr、ElasticSearch 等。\n异步化与缓存原则 业务流程异步化 以淘宝的交易订单为例，目前淘宝的订单创建流程需要调用超过200个服务，就算所有服务的调用时间都控制在20ms内返回结果，整个订单创建的时间也会超过4s：\n以异步化方式将上述交易创建过程中，对于有严格先后调用关系的服务保持顺序执行，对于能够同步执行的所有服务均采用异步化方式处理。阿里巴巴内部使用消息中间件的方式实现了业务异步化，提高了服务的并发处理，从而大大减少整个业务请求处理所花的时间。\n数据库事务异步化 扣款是一个要求事务一致性的典型场景，稍微数据不一致带来的后果都可能是成百上千（可能在某些借款项目中达到上百万的金额）的金额差异。所以在传统的实现方式中，整个扣款的逻辑代码都是在一个大的事务中，通过数据库的事务特性来实现这样一个稍显复杂的业务一致性。\n数据库事务的异步化：通俗来说，就是将大事务拆分成小事务，降低数据库的资源被长时间事务锁占用而造成的数据库瓶颈，就能大大提升平台的处理吞吐量和事务操作的响应时间。\n在实际的改造方案中，同样基于消息服务提供的异步机制，将整个还款流程进行异步化的处理：\n事务与柔性事务 不管是业务流程异步化，还是数据库事务异步化，其实都面临一个如何保证业务事务一致性的问题。面对这个问题目前并没有完美的解决方案，本节会介绍淘宝是如何对订单创建场景实现业务一致的实践，以及近一两年来我们在分布式事务上所作出的创新尝试，供各技术同行在解决此类问题时借鉴和参考。\n关于数据库事务，核心是体现数据库ACID（原子性、一致性、隔离性和持久性）属性，即作为一个事务中包含的所有逻辑处理操作在作用到数据库上时，只有这个事务中所有的操作都成功，对数据库的修改才会永久更新到数据库中，任何一个操作失败，对于数据库之前的修改都会失效。在分布式领域，基于CAP理论和在其基础上延伸出的BASE理论，有人提出了“柔性事务”的概念。\n（1）CAP理论\n一个分布式系统最多只能同时满足一致性（Consistency）、可用性（Availability）和分区容错性（Partition tolerance）这三项中的两项。“一致性”指更新操作成功并返回客户端完成后，所有节点在同一时间的数据完全一致。“可用性”指用户在访问数据时可以得到及时的响应。“分区容错性”指分布式系统在遇到某节点或网络分区故障的时候，仍然能够对外提供满足一致性和可用性的服务。\nCAP定理并不意味着所有系统的设计都必须抛弃三个要素之中的一个。CAP三者可以在一定程度上衡量，并不是非黑即白的，例如可用性从0%到100%有不同等级。\n（2）BASE理论\nBASE理论是对CAP理论的延伸，核心思想是即使无法做到强一致性（Strong Consistency, CAP的一致性就是强一致性），但应用可以采用适合的方式达到最终一致性（EventualConsitency）。BASE是指基本可用（Basically Available）、柔性状态（Soft State）、最终一致性（Eventual Consistency）。\n  “基本可用”是指分布式系统在出现故障的时候，允许损失部分可用性，即保证核心可用。电商大促时，为了应对访问量激增，部分用户可能会被引导到降级页面，服务层也可能只提供降级服务。这就是损失部分可用性的体现。\n  “柔性状态”是指允许系统存在中间状态，而该中间状态不会影响系统整体可用性。分布式存储中一般一份数据至少会有三个副本，允许不同节点间副本同步的延时就是柔性状态的体现。MySQLReplication的异步复制也是一种柔性状态体现。\n  “最终一致性”是指系统中的所有数据副本经过一定时间后，最终能够达到一致的状态。弱一致性和强一致性相反，最终一致性是弱一致性的一种特殊情况。\n  对于如何实现高可用，我们认为：\n 高可用=系统构建在多机分布式系统 高性能=分布式系统的副产品  分布式系统内通信和单机内通信最大的区别是：单机系统总线不会丢消息，而网络会。一台向另一台机器通信的结果可能是收到、未收到、不知道收到没收到。消息不可靠带来的副作用是：数据或者状态在多机之间同步的成本很高。大家都知道Paxos协议。在多机间通信不存在伪造或篡改的前提下，可以经由Paxos协议达成一致性。成本是发给Paxos系统的信息（数据）需要至少同步发送到一半以上多数（Quorum）的机器确认后，才能认为是成功。这样大幅增加了信息更新的延迟，因此分布式系统的首选不是这种强同步而是最终一致。\n（3）两阶段提交\n数据在按照业务领域（用户中心、交易中心）的不同被拆分到不同的数据库后，在某些业务场景（比如订单创建）下，就必然会出现同一个事务上下文中，需要协调多个资源（数据库）以保证业务的事务一致性，对于这样的场景，业界早就有基于两阶段提交方式实现的分布式事务，两阶段提交协议包含了两个阶段：第一阶段（也称准备阶段）和第二阶段（也称提交阶段）。\nX/Open组织为基于两阶段协议的分布式事务处理系统提出了标准的系统参考模型（X/Open事务模型）以及不同组件间与事务协调相关的接口，使不同厂商的产品能够互操作。X/Open事务模型如图所示。\n从图中可以看出，X/Open模型定义了两个标准接口：TX接口用于应用程序向事务管理器发起事务、提交事务和回滚事务（即确定事务的边界和结果）; XA接口形成了事务管理器和资源管理器之间的通信桥梁，用于事务管理器将资源管理器（如数据库、消息队列等）加入事务、并控制两阶段提交。\n事务管理器一般由专门的中间件提供，或者在应用服务器中作为一个重要的组件提供。资源管理器如数据库、消息队列等产品一般也会提供对XA接口的支持，通过使用符合X/Open标准的分布式事务处理，能够简化分布式事务类应用的开发。\n两阶段提交协议的关键在于“预备”操作。分布式事务协调者在第一阶段通过对所有的分布式事务参与者请求“预备”操作，达成关于分布式事务一致性的共识。分布式事务参与者在预备阶段必须完成所有的约束检查，并且确保后续提交或放弃时所需要的数据已持久化。在第二队段，分布式事务协调者根据之前达到的提交或放弃的共识，请求所有的分布式事务参与者完成相应的操作。很显然，在提交事务的过程中需要在多个资源节点之间进行协调，而各节点对锁资源的释放必须等到事务最终提交时，这样，比起一阶段提交，两阶段提交在执行同样的事务时会消耗更多时间。\n事务执行时间的延长意味着锁资源发生冲突的概率增加，当事务的并发量达到一定数量的时候，就会出现大量事务积压甚至出现死锁，系统性能和处理吞吐率就会严重下滑，也就是系统处理的吞吐率与资源上的时间消耗成反比（参考阿姆达尔定理）。这就是为什么今天在互联网应用场景中鲜有人会选择这样传统的分布式事务方式，而选择柔性事务处理业务事务的主要原因。\n（4）柔性事务如何解决分布式事务问题\n  引入日志和补偿机制。类似传统数据库，柔性事务的原子性主要由日志保证。事务日志记录事务的开始、结束状态，可能还包括事务参与者信息。参与者节点也需要根据重做或回滚需求记录REDO/UNDO日志。当事务重试、回滚时，可以根据这些日志最终将数据恢复到一致状态。为避免单点，事务日志是记录在分布式节点上的，数据REDO/UNDO日志一般记录在业务数据库上，可以保证日志与业务操作同时成功/失败。通常柔性事务能通过日志记录找回事务的当前执行状态，并根据状态决定是重试异常步骤（正向补偿），还是回滚前序步骤（反向补偿）。\n  可靠消息传递。根据“不知道成功还是失败”状态的处理，消息投递只有两种模式：1）消息仅投递一次，但是可能会没有收到；2）消息至少投递一次，但可能会投递多次。在业务一致性的高优先级下，第一种投递方式肯定是无法接受的，因此只能选择第二种投递方式。由于消息可能会重复投递，这就要求消息处理程序必须实现幂等（幂等=同一操作反复执行多次结果不变）。每种业务场景不同，实现幂等的方法也会有所不同，最简单的幂等实现方式是根据业务流水号写日志，阿里内部一般把这种日志叫做排重表。\n  实现无锁。如何很好地解决数据库锁问题是实现高性能的关键所在。所以选择放弃锁是一个解决问题的思路，但是放弃锁并不意味着放弃隔离性。实现事务隔离的方法有很多，在实际的业务场景中可灵活选择以下几种典型的实现方式。\n 避免事务进入回滚。如果事务在出现异常时，可以不回滚也能满足业务的要求，也就是要求业务不管出现任何情况，只能继续朝事务处理流程的顺向继续处理，这样中间状态即使对外可见，由于事务不会回滚，也不会导致脏读。 辅助业务变化明细表。比如对资金或商品库存进行增减处理时，可采用记录这些增减变化的明细表的方式，避免所有事务均对同一数据表进行更新操作，造成数据访问热点，同时使得不同事务中处理的数据互不干扰，实现对资金或库存信息处理的隔离。 乐观锁。数据库的悲观锁对数据访问具有极强的排他性，也是产生数据库处理瓶颈的重要原因，采用乐观锁则在一定程度上解决了这个问题。乐观锁大多是基于**数据版本（Version）**记录机制实现。例如通过在商品表中增加记录版本号的字段，在事务开始前获取到该商品记录的版本号，在事务处理最后对该商品数据进行数据更新时，可通过在执行最后的修改update语句时进行之前获取版本号的比对，如果版本号一致，则update更新数据成功，修改该数据到新的版本号；如果版本号不一致，则表示数据已经被其他事务修改了，则重试或放弃当前事务。     （5）柔性事务在阿里巴巴内部的几种实现\n 消息分布式事务  基于消息实现的分布式事务仅支持正向补偿，即不会像传统事务方式出现异常时依次进行回滚，会通过消息的不断重试或人工干预的方式让该事务链路继续朝前执行，而避免出现事务回滚。\n 支付宝XTS框架  XTS是TCC（Try/Confirm/Cancel）型事务，属于典型的补偿型事务。\n 阿里巴巴AliWare TXC事务服务  标准模式下无需开发人员自行进行事务回滚或补偿的代码，平台支持自动按事务中事务操作的顺序依次回滚和补偿。关键原理：\n大促秒杀活动催生缓存技术的高度使用 首先一定要让负责秒杀场景的商品中心应用实例（图中“秒杀IC”）与满足普通商品正常访问的商品中心应用实例（图中IC）隔离部署，通过服务分组方式，保持两个运行环境的隔离，避免因为秒杀产生的过大访问流量造成整个商品中心的服务实例均受影响，产生太大范围的影响。\n因为秒杀在正式开始前，一定会有大量的用户停留在商品的详情页（图中Detail）等待着秒杀活动的开始，同时伴随有大量的页面刷新访问（心急或担心页面没有正常刷新的买家们），此时，如果每一次刷新都要从后端的商品数据库（图中ICDB）中获取商品相关信息，则一定会给数据库带来巨大的压力，在淘宝早期举办秒杀活动时就出现了秒杀活动还没开始，因为商品详情页访问太大，造成平台提前进入不可访问状态的情况。所以一定是通过缓存服务器（图中Tair），将商品的详细信息（包括库存信息）保存在缓存服务器上，商品详情页和购买页所有有关商品的信息均是通过缓存服务器获取，则无需访问后端数据库。\n如图中“本地缓存”所示，可通过给网页资源设置Expires和Last-Modified返回头信息进行有效控制，从而尽可能减少对后端服务端的访问次数。\n避免商品出现超卖（即成功下单的订单中商品的库存数量大于商品现有的库存量，则称为商品超卖），核心技术是利用数据库的事务锁机制，即不允许同一商品的库存记录在同一时间被不同的两个数据库事务修改。在前柔性事务介绍中所提到的，用户在进行商品下单操作中，会进行一系列的业务逻辑判断和操作，对于商品库存信息这一访问热点数据，如果采用数据库的悲观锁（比如select语句带for update）模式，则会给订单处理带来很大的性能阻塞，所以会采用乐观锁的方式实现商品库存的操作。实现的方式也比较简单，也就是在最后执行库存扣减操作时，将事务开始前获取的库存数量带入到SQL语句中与目前数据库记录中的库存数量进行判断，如果数量相等，则该条更新库存的语句成功执行；如果不相等，则表示该商品的库存信息在当前事务执行过程中已经被其他事务修改，则会放弃该条update的执行，可以采用重试的机制重新执行该事务，避免商品超卖的发生，具体的SQL语句示意如下：\nupdate auction_auctions set quantity = #inQuantity#, where auction_id = #itemId# and quantity = #dbQuantity# 如果参与大促的商品拥有较大库存数量的时候，需要将之前仅仅作为商品信息浏览的缓存的作用，提升到为库存操作提供事务支持的角色。\n打造数字化运营能力 每一个URL请求都会生成一个全局唯一的ID，鹰眼（类似于 Twitter 的 Zipkin）平台中称为TraceID，这个ID会出现在该请求中所有服务调用、数据库、缓存、消息服务访问时生成的所有日志中。因为上述所有的资源访问均是在分布式环境下进行的，如何将该TraceID平滑地传递到各个服务节点上呢？如果要求应用程序中实现服务链路日志的打印和TraceID的传递，则在程序中有大量的日志打印代码，而且需要将TraceID采用业务数据的方式传递给下一服务节点，这些都给应用带来了非常大的代码侵入。\n阿里巴巴在中间件层面上统一实现了鹰眼的上下文创建以及日志埋点功能，让调用上下文在中间件的网络请求中传递，同时将调用上下文信息保存在了本地ThreadLocal中，从而实现了鹰眼平台所需的调用上下文和日志信息对于应用开发人员完全透明。\n埋点日志一般包含：\n TraceID、RPCID、开始时间、调用类型、对端IP。 处理耗时。 处理结果（ResultCode）。 数据传输量：请求大小/响应大小。  打造平台稳定性能力 限流和降级 淘宝技术团队开发的开源模块nginx-http-sysguard，主要用于当访问负载和内存达到一定的阀值之时，会执行相应的动作，比如直接返回503,504或者其他URL请求返回代码，一直等到内存或者负载回到阀值的范围内，站点恢复可用。\n流量调度 流量调度的核心是通过秒级获取服务器系统运行指标以及业务指标，通过流量调度平台设置的决策算法以及规则，当发现满足规则条件的指标状态发生时，对线上环境的服务器进行下线等操作，以屏蔽这些单点或局部出现故障的应用实例对整体平台产生扩展式的影响。\n业务开关 Switch 平台本身所提供的功能比较简单，但对于业务场景和环境复杂的分布式架构，这个平台确实能大大提升应用适应各种不同场景的自动化能力，比如通过开关的方式将正常环境下的应用逻辑切换到适配秒杀场景；当发现升级后的应用出现问题时，只需通过开关切换的方式就能让升级后的应用秒级切换到升级前的业务代码中。最重要的是在平台处于大促秒杀、应用异常时，业务开关在服务降级中所起的作用，相当于平台的最后一道保护屏障。\n"});index.add({'id':32,'href':'/docs/programmer-interview/algorithm/best-time-to-buy-and-sell-stock-with-cooldown/','title':"Best Time to Buy and Sell Stock With Cooldown",'content':"Best Time to Buy and Sell Stock With Cooldown 题目 LeetCode 地址：Best Time to Buy and Sell Stock With Cooldown\n有一个数组，第 i 个元素的值代表第 i 天的股票价格，如果你最多只能进行任意次交易（某天买入一支股票，然后过几天卖掉），你卖出一只股票后，接下来的一天不能买，必须要到后天才能买。也就是说有冷静期1天。请问你能收获的最大利润是多少？\n答案 // https://leetcode.com/problems/best-time-to-buy-and-sell-stock-with-cooldown/ // 交易任意多次，只不过 buy sell 之后的第二天必须 cooldown 隔天才能再次 buy // // https://leetcode.com/problems/best-time-to-buy-and-sell-stock-with-cooldown/discuss/240277/Java-solution-in-Chinese public class BestTimetoBuyandSellStockwithCooldown { public int maxProfit(int[] prices) { if (prices == null || prices.length \u0026lt;= 1) { return 0; } // 买入只能是从前天买入 buy[i] = sell[i - 2] - prices[i];  // 卖出可以昨天卖出 sell[i] = buy[i - 1] + prices[i];  int[] sell = new int[prices.length]; int[] buy = new int[prices.length]; buy[0] = -prices[0]; for (int i = 1; i \u0026lt; prices.length; i++) { // 前天卖出后，剩下 sell 钱，然后又接着买入 sell[i - 2] - prices[1]  // 维持昨天的  buy[i] = Math.max(buy[i - 1] /** 不买 */, (i \u0026gt;= 2 ? sell[i - 2] : 0) - prices[i] /** 从前天卖出的接着买入 */); // 接着买：buy[i - 1] + prices[i]  // 维持昨天的 sell  sell[i] = Math.max(sell[i - 1] /** 不卖 */, buy[i - 1] + prices[i] /** 从昨天接着买入 */); } return sell[prices.length - 1]; } } 扫描下面二维码，在手机上阅读这篇文章：\n"});index.add({'id':33,'href':'/docs/books/redis_5_source_code/','title':"Redis 5 设计与源码分析",'content':"Redis 5 设计与源码分析 Redis 5.0 新特性  新增Streams数据类型，这是 Redis 5.0 最重要的改进之一。可以把Streams当作消息队列。 新的模块API、定时器、集群及字典。 RDB中持久化存储LFU和LRU的信息。 将集群管理功能完全用C语言集成到redis-cli中，Redis 3.x 和 Redis4.x 的集群管理是通过Ruby脚本实现的。 有序集合新增命令ZPOPMIN/ZPOPMAX。 改进HyperLogLog的实现。 新增Client Unblock和Client ID。 新增LOLWUT命令。 Redis主从复制中的从不再称为Slave，改称Replicas。 Redis 5.0引入动态哈希，以平衡CPU的使用率和相应性能，可以通过配置文件进行配置。Redis 5.0默认使用动态哈希。 Redis核心代码进行了部分重构和优化。  简单动态字符串 （1） 长度小于 32 的短字符串\nstruct __attribute__ ((__packed__))sdshdr5 { unsigned char flags; // 低 3 位存储类型，高 5 位存储长度  char buf[]; // 柔性数组 } 结构如下：\n（2） 长度大于 31 的字符串\n此处仅展示一个示例：\nstruct __attribute__ ((__packed__))sdshdr8 { uint8_t len; // 已使用长度  uint8_t alloc; // 已分配的字节总长度  unsigned char flags; // 低 3 位存储类型  char buf[]; // 柔性数组 } SDS 读操作的复杂度多为O(1)，直接读取成员变量；涉及修改的写操作，则可能会触发扩容。\n跳跃表 对于有序集合的底层实现，我们可以使用数组、链表、平衡树等结构。数组不便于元素的插入和删除；链表的查询效率低，需要遍历所有元素；平衡树或者红黑树等结构虽然效率高但实现复杂。Redis采用了一种新型的数据结构——跳跃表。跳跃表的效率堪比红黑树，然而其实现却远比红黑树简单。\ntypedef struct zskiplistNode { sds ele; double score; struct zskiplistNode *backward; struct zskiplistLevel { struct zskiplistNode *forward; unsigned int span; } level[]; } zskiplistNode; typedef struct zskiplist { struct zskiplistNode *header, *tail; unsigned long length; int level; } zkiplist; 在Redis中，跳跃表主要应用于有序集合的底层实现（有序集合的另一种实现方式为压缩列表）。zset插入第一个元素时，会判断下面两种条件：\n zset-max-ziplist-entries的值是否等于0； zset-max-ziplist-value小于要插入元素的字符串长度。  满足任一条件Redis就会采用跳跃表作为底层实现，否则采用压缩列表作为底层实现方式。一般情况下，不会将zset-max-ziplist-entries配置成0，元素的字符串长度也不会太长，所以在创建有序集合时，默认使用压缩列表的底层实现。\nzset新插入元素时，会判断以下两种条件：\n zset中元素个数大于zset_max_ziplist_entries； 插入元素的字符串长度大于zset_max_ziplist_value。  当满足任一条件时，Redis便会将zset的底层实现由压缩列表转为跳跃表。值得注意的是，zset在转为跳跃表之后，即使元素被逐渐删除，也不会重新转为压缩列表。\n跳跃表的原理简单，其查询、插入、删除的平均复杂度都为O(logN)。\n压缩列表 压缩列表ziplist本质上就是一个字节数组，是Redis为了节约内存而设计的一种线性数据结构，可以包含多个元素，每个元素可以是一个字节数组或一个整数。\nRedis的有序集合、散列和列表都直接或者间接使用了压缩列表。当有序集合或散列表的元素个数比较少，且元素都是短字符串时，Redis便使用压缩列表作为其底层数据存储结构。\n元素的结构示意图：\n字典 Redis自带客户端就是使用times 33散列函数来计算字符串的Hash值，Redis服务端的Hash函数使用的是siphash算法，主要功能与客户端Hash函数类似，其优点是针对有规律的键计算出来的Hash值也具有强随机分布性，但算法较为复杂。\n整数集合 整数集合（intset）是一个有序的、存储整型数据的结构。\n127.0.0.1:6379\u0026gt; sadd testset 1 2 1 6 (integer) 4 127.0.0.1:6379\u0026gt; object encoding testset \u0026#34;intset\u0026#34; intset是按从小到大有序排列的，所以通过防御性判断之后使用二分法进行元素的查找。\nquicklist的实现 quicklist是Redis底层最重要的数据结构之一，它是Redis对外提供的6种基本数据结构中List的底层实现，在Redis 3.2版本中引入，能够在时间效率和空间效率间实现较好的折中。quicklist由List和ziplist结合而成。quicklist是一个双向链表，链表中的每个节点是一个ziplist结构。quicklist可以看成是用双向链表将若干小型的ziplist连接到一起组成的一种数据结构。\nStream Redis Stream的结构如图所示，它主要由消息、生产者、消费者、消费组4部分组成。\nxadd mystream1 * name zk age 20 mystream1为Stream的名称；*代表由Redis自行生成消息ID;name、age为该消息的field; zk、20则为对应的field的值。\n每个消息都由以下两部分组成。\n 每个消息有唯一的消息ID，消息ID严格递增。 消息内容由多个field-value对组成。  "});index.add({'id':34,'href':'/docs/rocketmq/rocketmq-message-indexing-flow/','title':"RocketMQ 消息索引流程",'content':"RocketMQ 消息索引流程 讲述 RocketMQ 消息索引服务\n一、消息查询方式 对于 Producer 发送到 Broker 服务器的消息，RocketMQ 支持多种方式来方便地查询消息:\n(1) 根据键查询消息 如下所示，在构建消息的时候，指定了这条消息的键为 “OrderID001”:\nMessage msg = new Message(\u0026#34;TopicTest\u0026#34;, \u0026#34;TagA\u0026#34;, \u0026#34;OrderID001\u0026#34;, // Keys  \u0026#34;Hello world\u0026#34;.getBytes(RemotingHelper.DEFAULT_CHARSET)); 那么，当这条消息发送成功后，我们可以使用 queryMsgByKey 命令查询到这条消息的详细信息:\nMQAdminStartup.main(new String[] { \u0026#34;queryMsgByKey\u0026#34;, \u0026#34;-n\u0026#34;, \u0026#34;localhost:9876\u0026#34;, \u0026#34;-t\u0026#34;, \u0026#34;TopicTest\u0026#34;, \u0026#34;-k\u0026#34;, \u0026#34;OrderID001\u0026#34; }); (2) 根据ID(偏移量)查询消息 消息在发送成功之后，其返回的 SendResult 类中包含了这条消息的唯一偏移量 ID (注意此处指的是 offsetMsgId):\n用户可以使用 queryMsgById 命令查询这条消息的详细信息:\nMQAdminStartup.main(new String[] { \u0026#34;queryMsgById\u0026#34;, \u0026#34;-n\u0026#34;, \u0026#34;localhost:9876\u0026#34;, \u0026#34;-i\u0026#34;, \u0026#34;0A6C73D900002A9F0000000000004010\u0026#34; }); (3) 根据唯一键查询消息 消息在发送成功之后，其返回的 SendResult 类中包含了这条消息的唯一 ID:\n用户可以使用 queryMsgByUniqueKey 命令查询这条消息的详细信息:\nMQAdminStartup.main(new String[] { \u0026#34;queryMsgByUniqueKey\u0026#34;, \u0026#34;-n\u0026#34;, \u0026#34;localhost:9876\u0026#34;, \u0026#34;-i\u0026#34;, \u0026#34;0A6C73D939B318B4AAC20CBA5D920000\u0026#34;, \u0026#34;-t\u0026#34;, \u0026#34;TopicTest\u0026#34; }); (4) 根据消息队列偏移量查询消息 消息发送成功之后的 SendResult 中还包含了消息队列的其它信息，如消息队列 ID、消息队列偏移量等信息:\nSendResult [sendStatus=SEND_OK, msgId=0A6C73D93EC518B4AAC20CC4ACD90000, offsetMsgId=0A6C73D900002A9F000000000000484E, messageQueue=MessageQueue [topic=TopicTest, brokerName=zk-pc, queueId=3], queueOffset=24] 根据这些信息，使用 queryMsgByOffset 命令也可以查询到这条消息的详细信息:\nMQAdminStartup.main(new String[] { \u0026#34;queryMsgByOffset\u0026#34;, \u0026#34;-n\u0026#34;, \u0026#34;localhost:9876\u0026#34;, \u0026#34;-t\u0026#34;, \u0026#34;TopicTest\u0026#34;, \u0026#34;-b\u0026#34;, \u0026#34;zk-pc\u0026#34;, \u0026#34;-i\u0026#34;, \u0026#34;3\u0026#34;, \u0026#34;-o\u0026#34;, \u0026#34;24\u0026#34; }); 二、ID (偏移量) 查询 (1) 生成 ID ID (偏移量) 是在消息发送到 Broker 服务器存储的时候生成的，其包含如下几个字段：\n Broker 服务器 IP 地址 Broker 服务器端口号 消息文件 CommitLog 写偏移量  public class CommitLog { class DefaultAppendMessageCallback implements AppendMessageCallback { public AppendMessageResult doAppend(final long fileFromOffset, /** 其它参数 **/) { String msgId = MessageDecoder .createMessageId(this.msgIdMemory, msgInner.getStoreHostBytes(hostHolder), wroteOffset); // ...  } } } (2) 使用 ID 查询 Admin 端查询的时候，首先对 msgId 进行解析，取出 Broker 服务器的 IP 、端口号和消息偏移量:\npublic class MessageDecoder { public static MessageId decodeMessageId(final String msgId) throws UnknownHostException { byte[] ip = UtilAll.string2bytes(msgId.substring(0, 8)); byte[] port = UtilAll.string2bytes(msgId.substring(8, 16)); // offset  byte[] data = UtilAll.string2bytes(msgId.substring(16, 32)); // ...  } } 获取到偏移量之后，Admin 会对 Broker 服务器发送一个 VIEW_MESSAGE_BY_ID 的请求命令，Broker 服务器在收到请求后，会依据偏移量定位到 CommitLog 文件中的相应位置,然后取出消息，返回给 Admin 端:\npublic class DefaultMessageStore implements MessageStore { @Override public SelectMappedBufferResult selectOneMessageByOffset(long commitLogOffset) { SelectMappedBufferResult sbr = this.commitLog .getMessage(commitLogOffset, 4); // 1 TOTALSIZE  int size = sbr.getByteBuffer().getInt(); return this.commitLog.getMessage(commitLogOffset, size); } } 三、消息队列偏移量查询 根据队列偏移量查询是最简单的一种查询方式，Admin 会启动一个 PullConsumer ，然后利用用户传递给 Admin 的队列 ID、队列偏移量等信息，从服务器拉取一条消息过来:\npublic class QueryMsgByOffsetSubCommand implements SubCommand { @Override public void execute(CommandLine commandLine, Options options, RPCHook rpcHook) throws SubCommandException { // 根据参数构建 MessageQueue  MessageQueue mq = new MessageQueue(); mq.setTopic(topic); mq.setBrokerName(brokerName); mq.setQueueId(Integer.parseInt(queueId)); // 从 Broker 服务器拉取消息  PullResult pullResult = defaultMQPullConsumer.pull(mq, \u0026#34;*\u0026#34;, Long.parseLong(offset), 1); } } 四、消息索引服务 在继续讲解剩下两种查询方式之前，我们必须先介绍以下 Broker 端的消息索引服务。\n在之前提到过，每当一条消息发送过来之后，其会封装为一个 DispatchRequest 来下发给各个转发服务，而 CommitLogDispatcherBuildIndex 构建索引服务便是其中之一:\nclass CommitLogDispatcherBuildIndex implements CommitLogDispatcher { @Override public void dispatch(DispatchRequest request) { if (DefaultMessageStore.this.messageStoreConfig.isMessageIndexEnable()) { DefaultMessageStore.this.indexService.buildIndex(request); } } } (1) 索引文件结构 消息的索引信息是存放在磁盘上的，文件以时间戳命名的，默认存放在 $HOME/store/index 目录下。由下图来看，一个索引文件的结构被分成了三部分:\n 前 40 个字节存放固定的索引头信息，包含了存放在这个索引文件中的消息的最小/大存储时间、最小/大偏移量等状况 中间一段存储了 500 万个哈希槽位，每个槽内部存储的是索引文件的地址 (索引槽) 最后一段存储了 2000 万个索引内容信息，是实际的索引信息存储的地方。每一个槽位存储了这条消息的键哈希值、存储偏移量、存储时间戳与下一个索引槽地址  RocketMQ 在内存中还维护了一个索引文件列表，对于每一个索引文件，前一个文件的最大存储时间是下一个文件的最小存储时间，前一个文件的最大偏移量是下一个文件的最大偏移量。每一个索引文件都索引了在某个时间段内、某个偏移量段内的所有消息，当文件满了，就会用前一个文件的最大偏移量和最大存储时间作为起始值，创建下一个索引文件:\n(2) 添加消息 当有新的消息过来后，构建索引服务会取出这条消息的键，然后对字符串 “话题#键” 构建索引。构建索引的步骤如下:\n 找出哈希槽: 生成字符串哈希码，取余落到 500W 个槽位之一，并取出其中的值，默认为 0 找出索引槽: IndexHeader 维护了 indexCount，实际存储的索引槽就是直接依次顺延添加的 存储索引内容: 找到索引槽后，放入键哈希值、存储偏移量、存储时间戳与下一个索引槽地址。下一个索引槽地址就是第一步哈希槽中取出的值，0 代表这个槽位是第一次被索引，而不为 0 代表这个槽位之前的索引槽地址。由此，通过索引槽地址可以将相同哈希槽的消息串联起来，像单链表那样。 更新哈希槽: 更新原有哈希槽中存储的值  我们以实际例子来说明。假设我们需要依次为键的哈希值为 “{16,29,29,8,16,16}” 这几条消息构建索引，我们在这个地方忽略了索引信息中存储的存储时间和偏移量字段，只是存储键哈希和下一索引槽信息，那么:\n 放入 16: 将 “16|0” 存储在第 1 个索引槽中，并更新哈希槽为 16 的值为 1，即哈希槽为 16 的第一个索引块的地址为 1 放入 29: 将 “29|0” 存储在第 2 个索引槽中，并更新哈希槽为 29 的值为 2，即哈希槽为 29 的第一个索引块的地址为 2 放入 29: 取出哈希槽为 29 中的值 2，然后将 “29|2” 存储在第 3 个索引槽中，并更新哈希槽为 29 的值为 3，即哈希槽为 29 的第一个索引块的地址为 3。而在找到索引块为 3 的索引信息后，又能取出上一个索引块的地址 2，构成链表为： “[29]-\u0026gt;3-\u0026gt;2” 放入 8: 将 “8|0” 存储在第 4 个索引槽中，并更新哈希槽为 8 的值为 4，即哈希槽为 8 的第一个索引块的地址为 4 放入 16: 取出哈希槽为 16 中的值 1，然后将 “16|1” 存储在第 5 个索引槽中，并更新哈希槽为 16 的值为 5。构成链表为: “[16]-\u0026gt;5-\u0026gt;1” 放入 16: 取出哈希槽为 16 中的值 5，然后将 “16|5” 存储在第 6 个索引槽中，并更新哈希槽为 16 的值为 6。构成链表为: “[16]-\u0026gt;6-\u0026gt;5-\u0026gt;1”  整个过程如下图所示:\n(3) 查询消息 当需要根据键来查询消息的时候，其会按照倒序回溯整个索引文件列表，对于每一个在时间上能够匹配用户传入的 begin 和 end 时间戳参数的索引文件，会一一进行消息查询：\npublic class IndexService { public QueryOffsetResult queryOffset(String topic, String key, int maxNum, long begin, long end) { // 倒序  for (int i = this.indexFileList.size(); i \u0026gt; 0; i--) { // 位于时间段内  if (f.isTimeMatched(begin, end)) { // 消息查询  } } } } 而具体到每一个索引文件，其查询匹配消息的过程如下所示:\n 确定哈希槽: 根据键生成哈希值，定位到哈希槽 定位索引槽: 哈希槽中的值存储的就是链表的第一个索引槽地址 遍历索引槽: 沿着索引槽地址，依次取出下一个索引槽地址，即沿着链表遍历，直至遇见下一个索引槽地址为非法地址 0 停止 收集偏移量: 在遇到匹配的消息之后，会将相应的物理偏移量放到列表中，最后根据物理偏移量，从 CommitLog 文件中取出消息  public class DefaultMessageStore implements MessageStore { @Override public QueryMessageResult queryMessage(String topic, String key, int maxNum, long begin, long end) { for (int m = 0; m \u0026lt; queryOffsetResult.getPhyOffsets().size(); m++) { long offset = queryOffsetResult.getPhyOffsets().get(m); // 根据偏移量从 CommitLog 文件中取出消息  } } } 以查询哈希值 16 的消息为例，图示如下:\n五、唯一键查询消息 (1) 构建键 消息的唯一键是在客户端发送消息前构建的:\npublic class DefaultMQProducerImpl implements MQProducerInner { private SendResult sendKernelImpl(final Message msg, /** 其它参数 **/) throws XXXException { // ...  if (!(msg instanceof MessageBatch)) { MessageClientIDSetter.setUniqID(msg); } } } 创建唯一 ID 的算法:\npublic class MessageClientIDSetter { public static String createUniqID() { StringBuilder sb = new StringBuilder(LEN * 2); sb.append(FIX_STRING); sb.append(UtilAll.bytes2string(createUniqIDBuffer())); return sb.toString(); } } 唯一键是根据客户端的进程 ID、IP 地址、ClassLoader 哈希码、时间戳、计数器这几个值来生成的一个唯一的键，然后作为这条消息的附属属性发送到 Broker 服务器的:\npublic class MessageClientIDSetter { public static void setUniqID(final Message msg) { if (msg.getProperty(MessageConst.PROPERTY_UNIQ_CLIENT_MESSAGE_ID_KEYIDX) == null) { msg.putProperty(MessageConst.PROPERTY_UNIQ_CLIENT_MESSAGE_ID_KEYIDX, createUniqID()); } } } (2) 索引键 当服务器收到客户端发送过来的消息之后，索引服务便会取出客户端生成的 uniqKey 并为之建立索引，放入到索引文件中:\npublic class IndexService { public void buildIndex(DispatchRequest req) { // ...  if (req.getUniqKey() != null) { indexFile = putKey(indexFile, msg, buildKey(topic, req.getUniqKey())); } // ...  } } (3) 使用键查询 客户端在生成消息唯一键的时候，在 ByteBuffer 的第 11 位到第 14 位放置的是当前的时间与当月第一天的时间的毫秒差:\npublic class MessageClientIDSetter { private static byte[] createUniqIDBuffer() { long current = System.currentTimeMillis(); if (current \u0026gt;= nextStartTime) { setStartTime(current); } // 时间差 [当前时间 - 这个月 1 号的时间]  // putInt 占据的是第 11 位到第 14 位  buffer.putInt((int) (System.currentTimeMillis() - startTime)); } private synchronized static void setStartTime(long millis) { Calendar cal = Calendar.getInstance(); cal.setTimeInMillis(millis); cal.set(Calendar.DAY_OF_MONTH, 1); cal.set(Calendar.HOUR_OF_DAY, 0); cal.set(Calendar.MINUTE, 0); cal.set(Calendar.SECOND, 0); cal.set(Calendar.MILLISECOND, 0); // 开始时间设置为这个月的 1 号  startTime = cal.getTimeInMillis(); // ...  } } 我们知道消息索引服务的查询需要用户传入 begin 和 end 这连个时间值，以进行这段时间内的匹配。所以 RocketMQ 为了加速消息的查询，于是在 Admin 端对特定 ID 进行查询的时候，首先取出了这段时间差值，然后与当月时间进行相加得到 begin 时间值:\npublic class MessageClientIDSetter { public static Date getNearlyTimeFromID(String msgID) { ByteBuffer buf = ByteBuffer.allocate(8); byte[] bytes = UtilAll.string2bytes(msgID); buf.put((byte) 0); buf.put((byte) 0); buf.put((byte) 0); buf.put((byte) 0); // 取出第 11 位到 14 位  buf.put(bytes, 10, 4); buf.position(0); // 得到时间差值  long spanMS = buf.getLong(); Calendar cal = Calendar.getInstance(); long now = cal.getTimeInMillis(); cal.set(Calendar.DAY_OF_MONTH, 1); cal.set(Calendar.HOUR_OF_DAY, 0); cal.set(Calendar.MINUTE, 0); cal.set(Calendar.SECOND, 0); cal.set(Calendar.MILLISECOND, 0); long monStartTime = cal.getTimeInMillis(); if (monStartTime + spanMS \u0026gt;= now) { cal.add(Calendar.MONTH, -1); monStartTime = cal.getTimeInMillis(); } // 设置为这个月(或者上个月) + 时间差值  cal.setTimeInMillis(monStartTime + spanMS); return cal.getTime(); } } 由于发送消息的客户端和查询消息的 Admin 端可能不在一台服务器上，而且从函数的命名 getNearlyTimeFromID 与上述实现来看，Admin 端的时间戳得到的是一个近似起始值，它尽可能地加速用户的查询。而且太旧的消息(超过一个月的消息)是查询不到的。\n当 begin 时间戳确定以后，Admin 便会将其它必要的信息如话题、Key等信息封装到 QUERY_MESSAGE 的包中，然后向 Broker 服务器传递这个请求，来进行消息的查询。Broker 服务器在获取到这个查询消息的请求后，便会根据 Key 从索引文件中查询符合的消息，最终返回到 Admin 端。\n六、键查询消息 (1) 构建键 我们提到过，在发送消息的时候，可以填充一个 keys 的值，这个值将会作为消息的一个属性被发送到 Broker 服务器上:\npublic class Message implements Serializable { public void setKeys(String keys) { this.putProperty(MessageConst.PROPERTY_KEYS, keys); } } (2) 索引键 当服务器收到客户端发送过来的消息之后，索引服务便会取出这条消息的 keys 并将其用空格进行分割，分割后的每一个字符串都会作为一个单独的键，创建索引，放入到索引文件中:\npublic class IndexService { public void buildIndex(DispatchRequest req) { // ...  if (keys != null \u0026amp;\u0026amp; keys.length() \u0026gt; 0) { // 使用空格进行分割  String[] keyset = keys.split(MessageConst.KEY_SEPARATOR); for (int i = 0; i \u0026lt; keyset.length; i++) { String key = keyset[i]; if (key.length() \u0026gt; 0) { indexFile = putKey(indexFile, msg, buildKey(topic, key)); } } } } } 由此我们也可以得知，keys 键的设置通过使用空格分割字符串，一条消息可以指定多个键。\n(3) 使用键查询 keys 键查询的方式也是通过将参数封装为 QUERY_MESSAGE 请求包中去请求服务器返回相应的信息。由于键本身不能和时间戳相关联，因此 begin 值设置的是 0，这是和第五节的不同之处:\npublic class QueryMsgByKeySubCommand implements SubCommand { private void queryByKey(final DefaultMQAdminExt admin, final String topic, final String key) throws MQClientException, InterruptedException { // begin: 0  // end: Long.MAX_VALUE  QueryResult queryResult = admin.queryMessage(topic, key, 64, 0, Long.MAX_VALUE); } } "});index.add({'id':35,'href':'/docs/programmer-interview/','title':"程序员面试题",'content':"程序员面试题 "});index.add({'id':36,'href':'/docs/rocketmq/rocketmq-timing-message-and-retry-message/','title':"RocketMQ 定时消息和重试消息",'content':"RocketMQ 定时消息和重试消息 讲述 RocketMQ 定时消息和重试消息\n一、定时消息概述 RocketMQ 支持 Producer 端发送定时消息，即该消息被发送之后，到一段时间之后才能被 Consumer 消费者端消费。但是当前开源版本的 RocketMQ 所支持的定时时间是有限的、不同级别的精度的时间，并不是任意无限制的定时时间。因此在每条消息上设置定时时间的 API 叫做 setDelayTimeLevel，而非 setDelayTime 这样的命名:\nMessage msg = new Message(\u0026#34;TopicTest\u0026#34; /* Topic */, \u0026#34;TagA\u0026#34; /* Tag */, (\u0026#34;Hello RocketMQ \u0026#34; + i).getBytes(RemotingHelper.DEFAULT_CHARSET) /* Message body */); msg.setDelayTimeLevel(i + 1); 默认 Broker 服务器端有 18 个定时级别:\npublic class MessageStoreConfig { private String messageDelayLevel = \u0026#34;1s 5s 10s 30s 1m 2m 3m 4m 5m 6m 7m 8m 9m 10m 20m 30m 1h 2h\u0026#34;; } 这 18 个定时级别在服务器端启动的时候，会被解析并放置到表 delayLevelTable 中。解析的过程就是上述字符串按照空格拆分开，然后根据时间单位的不同再进一步进行计算，得到最终的毫秒时间。级别就是根据这些毫秒时间的顺序而确定的，例如上述 1s 延迟就是级别 1， 5s 延迟就是级别 2，以此类推:\npublic class ScheduleMessageService extends ConfigManager { public boolean parseDelayLevel() { for (int i = 0; i \u0026lt; levelArray.length; i++) { // ...  int level = i + 1; long delayTimeMillis = tu * num; // 级别:延迟时间  this.delayLevelTable.put(level, delayTimeMillis); } } } 二、定时消息预存储 客户端在为某条消息设置上定时级别的时候，实际上级别这个字段会被作为附属属性放到消息中:\npublic class Message implements Serializable { public void setDelayTimeLevel(int level) { this.putProperty(MessageConst.PROPERTY_DELAY_TIME_LEVEL, String.valueOf(level)); } } 我们先前的文章提到过，发送到 Broker 服务器的消息会被存储到 CommitLog 消息文件中。那么在此处即使是定时消息也不例外，将定时消息存储下来是为了保证消息最大程度地不丢失。然而毕竟和普通消息不同，在遇到定时消息后，CommitLog 会将这条消息的话题和队列 ID 替换成专门用于定时的话题和相应的级别对应的队列 ID。真实的话题和队列 ID 会作为属性放置到这条消息中。\npublic class CommitLog { public PutMessageResult putMessage(final MessageExtBrokerInner msg) { // Delay Delivery  if (msg.getDelayTimeLevel() \u0026gt; 0) { topic = ScheduleMessageService.SCHEDULE_TOPIC; queueId = ScheduleMessageService.delayLevel2QueueId(msg.getDelayTimeLevel()); // Backup real topic, queueId  MessageAccessor.putProperty(msg, MessageConst.PROPERTY_REAL_TOPIC, msg.getTopic()); MessageAccessor.putProperty(msg, MessageConst.PROPERTY_REAL_QUEUE_ID, String.valueOf(msg.getQueueId())); msg.setPropertiesString(MessageDecoder.messageProperties2String(msg.getProperties())); // 替换 Topic 和 QueueID  msg.setTopic(topic); msg.setQueueId(queueId); } } } 随后，这条消息会被存储在 CommitLog 消息文件中。而我们知道后台重放消息服务 ReputMessageService 会一直监督 CommitLog 文件是否添加了新的消息。当有了新的消息后，重放消息服务会取出消息并封装为 DispatchRequest 请求，然后将其分发给不同的三个分发服务，建立消费队列文件服务就是这其中之一。而此处当取消息封装为 DispatchRequest 的时候，当遇到定时消息时，又多做了一些额外的事情。\n当遇见定时消息时，CommitLog 计算 tagsCode 标签码与普通消息不同。对于定时消息，tagsCode 值设置的是这条消息的投递时间，即建立消费队列文件的时候，文件中的 tagsCode 存储的是这条消息未来在什么时候被投递:\npublic class CommitLog { public DispatchRequest checkMessageAndReturnSize(java.nio.ByteBuffer byteBuffer, final boolean checkCRC, final boolean readBody) { // Timing message processing  { String t = propertiesMap.get(MessageConst.PROPERTY_DELAY_TIME_LEVEL); if (ScheduleMessageService.SCHEDULE_TOPIC.equals(topic) \u0026amp;\u0026amp; t != null) { int delayLevel = Integer.parseInt(t); if (delayLevel \u0026gt; 0) { tagsCode = this.defaultMessageStore.getScheduleMessageService() .computeDeliverTimestamp(delayLevel,storeTimestamp); } } } } } 如下是，发送了 10 条定时级别分别为 1-10 的消息以后，$HOME/store/consumequeue 文件下的消费队列文件的分布情况:\n不同的定时级别对应于不同的队列 ID，定时级别减 1 得到的就是队列 ID 的值。因此级别 1-10 对应的是 0-9 的队列 ID:\npublic class ScheduleMessageService extends ConfigManager { public static int delayLevel2QueueId(final int delayLevel) { return delayLevel - 1; } } 三、定时消息再存储 Broker 启动的时候，会开启一个调度消息服务，此服务会监控所有定时消息队列，每一个消息队列会创建一个专门的延时消息投递任务用以到达规定时间后投递此消息:\npublic class ScheduleMessageService extends ConfigManager { public void start() { for (Map.Entry\u0026lt;Integer, Long\u0026gt; entry : this.delayLevelTable.entrySet()) { Integer level = entry.getKey(); Long timeDelay = entry.getValue(); Long offset = this.offsetTable.get(level); if (timeDelay != null) { this.timer.schedule(new DeliverDelayedMessageTimerTask(level, offset), FIRST_DELAY_TIME); } } } } 每个消息队里的消息投递任务，会检查自己跟踪的消息队列，并从此消息队列所对应的定时级别的偏移量中检查是否有新的定时消息到来。其中定时级别的偏移量是维护在内存中的偏移量表 offsetTable 中。每隔 10 秒钟，这个表会被持久化到磁盘上的 delayOffset.json 文件中一次:\npublic class ScheduleMessageService extends ConfigManager { private final ConcurrentMap\u0026lt;Integer /* level */, Long/* offset */\u0026gt; offsetTable = new ConcurrentHashMap\u0026lt;Integer, Long\u0026gt;(32); public void start() { // 每隔 10 秒钟持久化一次  this.timer.scheduleAtFixedRate(new TimerTask() { @Override public void run() { ScheduleMessageService.this.persist(); } }, 10000, this.defaultMessageStore.getMessageStoreConfig().getFlushDelayOffsetInterval()); } } delayOffset.json 文件中存储的示例信息如下所示：\nDeliverDelayedMessageTimerTask 任务会从消费任务队列文件中取出最新的定时消息的 tagsCode ，并计算出的当前是否已经到了这条消息投递的时间。如果到了，即 countdown \u0026lt; 0，那么便会从 CommitLog 文件中取出消息，修正消息的话题和队列 ID 等信息，然后重新存储此条消息。如果还没有到，那么便会重新执行一个定时时间设置为 countdown 毫秒的定时任务。在完成之后，会更新当前的偏移量表，为下一次做准备:\nclass DeliverDelayedMessageTimerTask extends TimerTask { public void executeOnTimeup() { // ...  for (; i \u0026lt; bufferCQ.getSize(); i += ConsumeQueue.CQ_STORE_UNIT_SIZE) { // 是否到时间  long countdown = deliverTimestamp - now; if (countdown \u0026lt;= 0) { // 取出消息  MessageExt msgExt = ScheduleMessageService.this.defaultMessageStore.lookMessageByOffset(offsetPy, sizePy); // 修正消息，设置上正确的话题和队列 ID  MessageExtBrokerInner msgInner = this.messageTimeup(msgExt); // 重新存储消息  PutMessageResult putMessageResult = ScheduleMessageService.this.defaultMessageStore .putMessage(msgInner); } else { // countdown 后投递此消息  ScheduleMessageService.this .timer .schedule(new DeliverDelayedMessageTimerTask(this.delayLevel, nextOffset), countdown); // 更新偏移量  } } // end of for  // 更新偏移量  } } 四、消息重试概述 消息重试分为消息发送重试和消息接受重试，消息发送重试是指消息从 Producer 端发送到 Broker 服务器的失败以后的重试情况，消息接受重试是指 Consumer 在消费消息的时候出现异常或者失败的重试情况。\nProducer 端通过配置如下这两个两个 API 可以分别配置在同步发送和异步发送消息失败的时候的重试次数:\nDefaultMQProducer producer = new DefaultMQProducer(\u0026#34;please_rename_unique_group_name\u0026#34;); producer.setRetryTimesWhenSendAsyncFailed(3); producer.setRetryTimesWhenSendFailed(3); Consumer 端在消费的时候，如果接收消息的回调函数出现了以下几种情况:\n 抛出异常 返回 NULL 状态 返回 RECONSUME_LATER 状态 超时 15 分钟没有响应  那么 Consumer 便会将消费失败的消息重新调度直到成功消费:\nconsumer.registerMessageListener(new MessageListenerConcurrently() { @Override public ConsumeConcurrentlyStatus consumeMessage(List\u0026lt;MessageExt\u0026gt; msgs, ConsumeConcurrentlyContext context) { // 抛出异常  // 返回 NULL 或者 RECONSUME_LATER 状态  return ConsumeConcurrentlyStatus.RECONSUME_LATER; } }); 五、Producer 消息发送重试 发送失败的重试方式，主要表现在发送消息的时候，会最多尝试 getRetryTimesWhenSendFailed() 次发送，当成功发送以后，会直接返回发送结果给调用者。当发送失败以后，会继续进行下一次发送尝试，核心代码如下所示：\npublic class DefaultMQProducerImpl implements MQProducerInner { private SendResult sendDefaultImpl(Message msg, /** 其他参数 **/) throws MQClientException, RemotingException, MQBrokerException, InterruptedException { int timesTotal = communicationMode == CommunicationMode.SYNC ? 1 + this.defaultMQProducer.getRetryTimesWhenSendFailed() : 1; int times = 0; for (; times \u0026lt; timesTotal; times++) { // 尝试发送消息，发送成功 return，发送失败 continue  } } } 六、Consumer 消息接受重试 (1) 订阅重试话题 Consumer 在启动的时候，会执行一个函数 copySubscription() ，当用户注册的消息模型为集群模式的时候，会根据用户指定的组创建重试组话题并放入到注册信息中:\npublic class DefaultMQPushConsumerImpl implements MQConsumerInner { public synchronized void start() throws MQClientException { switch (this.serviceState) { case CREATE_JUST: // ...  this.copySubscription(); // ...  this.serviceState = ServiceState.RUNNING; break; } } private void copySubscription() throws MQClientException { switch (this.defaultMQPushConsumer.getMessageModel()) { case BROADCASTING: break; case CLUSTERING: // 重试话题组  final String retryTopic = MixAll.getRetryTopic(this.defaultMQPushConsumer.getConsumerGroup()); SubscriptionData subscriptionData = FilterAPI.buildSubscriptionData(this.defaultMQPushConsumer.getConsumerGroup(), retryTopic, SubscriptionData.SUB_ALL); this.rebalanceImpl.getSubscriptionInner().put(retryTopic, subscriptionData); break; default: break; } } } 假设用户指定的组为 “ORDER”，那么重试话题则为 “%RETRY%ORDER”，即前面加上了 “%RETRY%” 这个字符串。\nConsumer 在一开始启动的时候，就为用户自动注册了订阅组的重试话题。即用户不单单只接受这个组的话题的消息，也接受这个组的重试话题的消息。这样一来，就为下文用户如何重试接受消息奠定了基础。\n(2) 失败消息发往重试话题 当 Consumer 客户端在消费消息的时候，抛出了异常、返回了非正确消费的状态等错误的时候，这个时候 ConsumeMessageConcurrentlyService 会收集所有失败的消息，然后将每一条消息封装进 CONSUMER_SEND_MSG_BACK 的请求中，并将其发送到 Broker 服务器:\npublic class ConsumeMessageConcurrentlyService implements ConsumeMessageService { public void processConsumeResult(final ConsumeConcurrentlyStatus status, /** 其他参数 **/) { switch (this.defaultMQPushConsumer.getMessageModel()) { case BROADCASTING: // ...  break; case CLUSTERING: for (int i = ackIndex + 1; i \u0026lt; consumeRequest.getMsgs().size(); i++) { MessageExt msg = consumeRequest.getMsgs().get(i); // 重新将消息发往 Broker 服务器  boolean result = this.sendMessageBack(msg, context); } // ...  break; default: break; } } } 当消费失败的消息重新发送到服务器后，Broker 会为其指定新的话题重试话题，并根据当前这条消息的已有的重试次数来选择定时级别，即将这条消息变成定时消息投放到重试话题消息队列中。可见消息消费失败后并不是立即进行新的投递，而是有一定的延迟时间的。延迟时间随着重试次数的增加而增加，也即投递的时间的间隔也越来越长:\npublic class SendMessageProcessor extends AbstractSendMessageProcessor implements NettyRequestProcessor { private RemotingCommand consumerSendMsgBack(final ChannelHandlerContext ctx, final RemotingCommand request) throws RemotingCommandException { // 指定为重试话题  String newTopic = MixAll.getRetryTopic(requestHeader.getGroup()); int queueIdInt = Math.abs(this.random.nextInt() % 99999999) % subscriptionGroupConfig.getRetryQueueNums(); // 指定为延时信息，设定延时级别  if (0 == delayLevel) { delayLevel = 3 + msgExt.getReconsumeTimes(); } msgExt.setDelayTimeLevel(delayLevel); // 重试次数增加  msgInner.setReconsumeTimes(msgExt.getReconsumeTimes() + 1); // 重新存储  PutMessageResult putMessageResult = this.brokerController.getMessageStore().putMessage(msgInner); // ...  } } 当然，消息如果一直消费不成功，那也不会一直无限次的尝试重新投递的。当重试次数大于最大重试次数 (默认为 16 次) 的时候，该消息将会被送往死信话题队列，认定这条话题投递无门:\npublic class SendMessageProcessor extends AbstractSendMessageProcessor implements NettyRequestProcessor { private RemotingCommand consumerSendMsgBack(final ChannelHandlerContext ctx, final RemotingCommand request) throws RemotingCommandException { // 重试次数大于最大重试次数  if (msgExt.getReconsumeTimes() \u0026gt;= maxReconsumeTimes || delayLevel \u0026lt; 0) { // 死信队列话题  newTopic = MixAll.getDLQTopic(requestHeader.getGroup()); queueIdInt = Math.abs(this.random.nextInt() % 99999999) % DLQ_NUMS_PER_GROUP; } // ...  } } 上述客户端消费失败信息的流程图如下所示:\n"});index.add({'id':37,'href':'/docs/cloud-plus-bbs/','title':"云+社区技术沙龙",'content':"云+社区技术沙龙 云+社区沙龙 online，是腾讯云推出的一系列由技术专家、高级工程师、技术总监等在线直播的技术分享沙龙。本专栏整理收录了观看部分课程的心得体会。如需更多课程请访问腾讯云沙龙 。\n"});index.add({'id':38,'href':'/docs/books/in-depth_analysis_of_the_core_technology_of_apache_dubbo/','title':"深度剖析 Apache Dubbo 核心技术",'content':"深度剖析 Apache Dubbo 核心技术 SPI 扩展 Dubbo 支持扩展的核心接口上，都会通过类似 @SPI(\u0026quot;dubbo\u0026quot;) 这样的注解，来标识当前接口的默认实现。如果你想替换掉这个默认实现，那么需要两个步骤。第一，实现 Protocol 接口，然后在 META-INF/dubbo 目录下创建一个名字为 org.apache.dubbo.rpc.Protocol 的文本文件。这个 META-INF 目录如果使用的是 IDEA 开发，那么其应该放到 resources 目录下的顶层，这样打 jar 包的时候，其也会被复制到 jar 包的第一级目录。内容如下：\nmyProtocol = com.zk.MyProtocol 第二，需要在 XML 配置文件中，声明使用这个扩展实现：\n\u0026lt;dubbo:protocol name=\u0026#34;myProtocol\u0026#34;\u0026gt; 其实 JDK 本身也提供了 SPI 扩展，Dubbo 之所以没有使用默认提供的实现，是因为：\n JDK 标准的 SPI 一次性实例化扩展点的所有实现，如果有些没有使用到，那么会浪费资源。 扩展点加载失败的异常提示不是很好。 增强了 Ioc 和 AOP 的支持。  性能 Dubbo 会给每个服务提供者的实现类生产一个 Wrapper 类，这个 Wrapper 类里面最终调用服务提供者的接口实现类，Wrapper 类的存在是为了减少反射的调用。当服务提供方收到消费方发来的请求后，需要根据消费者传递过来的方法名和参数反射调用服务提供者的实现类，而反射本身是有性能开销的，Dubbo 把每个服务提供者的实现类通过 JavaAssist 包装为一个 Wrapper 类以减少反射调用开销。\n其实就是由反射改为了比较方法名称，然后调用，伪代码如下：\nGreetingServiceImpl impl = (GreetingServiceImpl) object; if (\u0026#34;sayHello\u0026#34;.equals(methodName) \u0026amp;\u0026amp; argClass.length == 1) { return impl.sayHello((String) argObject[0]); } if (\u0026#34;testGeneric\u0026#34;.equals(methodName) \u0026amp;\u0026amp; argClass.length == 1) { return impl.testGeneric((Pojo) arrObject[0]); } 容错 异常情况下的，代码逻辑应该怎么走？Dubbo 提供了如下几种容错方案：\n 失败重试：通常用于读操作或者具有幂等的写操作。需要注意的是，重试会带来更长延迟。 快速失败：抛出异常。 安全失败：忽略异常，场景：写入审计日志。 失败自动恢复：后台记录失败请求，并按照策略后期再重试，场景：消息通知。 并行调用：通常用于实时性要求较高的读操作，但需要浪费更多服务资源。 广播调用：通常用于通知所有提供者更新缓存或日志等本地资源信息。  负载均衡  随机策略 轮循策略 最少活跃调用数 一致性 Hash 策略  协议设计 服务消费端如何把服务请求信息序列化为二进制数据、服务提供方如何把消费端发送的二进制数据反序列化为可识别的POJO对象、Dubbo的应用层协议是怎么样的？\n看一下这个 \u0026ldquo;request flag and serialization id\u0026rdquo;：高四位标示请求类型：\n低四位标示序列化方式，其枚举值如下：\n再后面的一字节是只在响应报文里才设置（在请求报文里不设置），用来标示响应的结果码，具体定义如下：\n在此列出这个编码格式，是想要学习 Dubbo 是如果用较少的字节头，编码较多的信息的。还有编码的粒度，响应码这部分，并没有直接定义与业务紧密关联的状态码，比如 \u0026ldquo;磁盘存储失败\u0026rdquo; 等状态码，相反定义的是较为粗粒度的状态码，更为细粒度的可以放到 \u0026ldquo;body\u0026rdquo; 里面。\n"});index.add({'id':39,'href':'/docs/rocketmq/rocketmq-master-slave-sync/','title':"RocketMQ 主备同步",'content':"RocketMQ 主备同步 介绍 RocketMQ 的主备同步机制\n一、简介 RocketMQ 通过 Master-Slave 主备机制，来实现整个系统的高可用，具体表现在:\n Master 磁盘坏掉，Slave 依然保存了一份 Master 宕机，不影响消费者继续消费  二、搭建环境 我们在一台机器上搭建一个 Master 一个 Slave 的环境:\n为了能够将 Master 和 Slave 搭建在同一台计算机上，我们除了需要将 Broker 的角色设置为 SLAVE ，还需要为其指定单独的 brokerId、 storePathRootDir、 storePathCommitLog。\n// SLAVE 角色 messageStoreConfig.setBrokerRole(BrokerRole.SLAVE); // 一个机器如果要启动多个 Broker，那么每个 Broker 的 store 根目录必须不同 messageStoreConfig.setStorePathRootDir(storePathRootDir); // 一个机器如果要启动多个 Broker，那么每个 Broker 的 storePathCommitLog 根目录必须不同 messageStoreConfig.setStorePathCommitLog(storePathCommitLog); // 设置 Slave 的 Master HA 地址 messageStoreConfig.setHaMasterAddress(\u0026#34;localhost:10912\u0026#34;); // SLAVE 角色的 brokerId 必须大于 0 brokerConfig.setBrokerId(1); 注意 Slave 和 Master 的 brokerName 必须一致，即它们必须处于同一个 BrokerData 数据结构里面。实际上在做了如上的修改之后， Slave 和 Master 依旧不能同时运行在同一台机器上，因为 Slave 本身也可以称为 Master，接受来自其他 Slave 的请求，因此当运行 Slave 的时候，需要将 HAService 里面的启动 AcceptSocketService 运行的相关方法注释掉。\n三、建立连接 当一个 Broker 在启动的时候，会调用 HAService 的 start() 方法:\npublic class HAService { public void start() throws Exception { this.acceptSocketService.beginAccept(); this.acceptSocketService.start(); this.groupTransferService.start(); this.haClient.start(); } } AcceptSocketService 服务的功能是 Master 等待接受来自其它客户端 Slave 的连接，当成功建立连接后，会将这条连接 HAConnection 放入到 connectionList 连接列表里面。而 HAClient 服务的功能是 Slave 主动发起同其它 Master 的连接。\n四、数据传输 当启动 HAService 之后，一旦 Master 发现和 Slave 不同步，那么Master 会自动开始同步消息到 Slave，无需其它的触发机制。\n(1) 消息异步传输 如果 Master Broker 的角色是 ASYNC_MASTER，那么消息等待从 Master 同步到 Slave 的方式是异步传输的方式。这意味当一条消息发送到 Master Broker 的时候，Master Broker 在存储完这条消息到本地之后，并不会等待消息同步到 Slave Broker 才返回。这种方式会缩短发送消息的响应时间。\n(2) 消息同步传输 如果 Master Broker 的角色是 SYNC_MASTER，那么消息等待从 Master 同步到 Slave 的方式是同步传输的方式。除此之外，进入同步方式还得满足另外两个条件：\n 消息体的 PROPERTY_WAIT_STORE_MSG_OK 属性值为 true，即这条消息允许等待 Slave 相比 Master 落下的同步进度不能超过 256MB  public class CommitLog { public void handleHA(AppendMessageResult result, PutMessageResult putMessageResult, MessageExt messageExt) { if (BrokerRole.SYNC_MASTER == this.defaultMessageStore.getMessageStoreConfig().getBrokerRole()) { HAService service = this.defaultMessageStore.getHaService(); // 消息是否允许等待同步  if (messageExt.isWaitStoreMsgOK()) { // Slave 是否没有落下 Master 太多  if (service.isSlaveOK(result.getWroteOffset() + result.getWroteBytes())) { // 等待同步完成  // ...  } // Slave problem  else { // Tell the producer, slave not available  putMessageResult.setPutMessageStatus(PutMessageStatus.SLAVE_NOT_AVAILABLE); } } } } } 其中 isSlaveOK 方法就是用来检测 Slave 和 Master 落下的同步进度是否太大的:\npublic class HAService { public boolean isSlaveOK(final long masterPutWhere) { boolean result = this.connectionCount.get() \u0026gt; 0; result = result \u0026amp;\u0026amp; ((masterPutWhere - this.push2SlaveMaxOffset.get()) \u0026lt; this.defaultMessageStore .getMessageStoreConfig() .getHaSlaveFallbehindMax()); // 默认 256 * 1024 * 1024 = 256 MB  return result; } } 如果上面两个条件不满足的话，那么 Master 便不会再等待消息同步到 Slave 之后再返回，能尽早返回便尽早返回了。\n消息等待是否同步到 Slave 是借助 CountDownLatch 来实现的。当消息需要等待的时候，便会构建一个 GroupCommitRequest ，每个请求在其内部都维护了一个 CountDownLatch ，然后通过调用 await(timeout) 方法来等待消息同步到 Slave 之后，或者超时之后自动返回。\npublic static class GroupCommitRequest { private final CountDownLatch countDownLatch = new CountDownLatch(1); public void wakeupCustomer(final boolean flushOK) { this.flushOK = flushOK; this.countDownLatch.countDown(); } public boolean waitForFlush(long timeout) { try { this.countDownLatch.await(timeout, TimeUnit.MILLISECONDS); return this.flushOK; } catch (InterruptedException e) { log.error(\u0026#34;Interrupted\u0026#34;, e); return false; } } } 我们再重点来看几个循环体和唤醒点:\n GroupTransferService 服务的是否处理请求的循环体和唤醒点:  class GroupTransferService extends ServiceThread { public synchronized void putRequest(final CommitLog.GroupCommitRequest request) { // ...  // 放入请求，唤醒  if (hasNotified.compareAndSet(false, true)) { waitPoint.countDown(); // notify  } } public void run() { // 循环体  while (!this.isStopped()) { try { // putRequest 会提前唤醒这句话  this.waitForRunning(10); this.doWaitTransfer(); } catch (Exception e) { log.warn(this.getServiceName() + \u0026#34; service has exception. \u0026#34;, e); } } } }  HAConnection 的是否进行消息传输的循环体和唤醒点：  class WriteSocketService extends ServiceThread { @Override public void run() { // 循环体  while (!this.isStopped()) { SelectMappedBufferResult selectResult = HAConnection.this.haService.getDefaultMessageStore().getCommitLogData(this.nextTransferFromWhere); if (selectResult != null) { // 传输（写入）消息  } else { // 等待 100 毫秒或者提前被唤醒  HAConnection.this.haService.getWaitNotifyObject().allWaitForRunning(100); } } } } public class CommitLog { public void handleHA(AppendMessageResult result, PutMessageResult putMessageResult, MessageExt messageExt) { GroupCommitRequest request = new GroupCommitRequest(result.getWroteOffset() + result.getWroteBytes()); service.putRequest(request); // 提前唤醒 WriteSocketService  service.getWaitNotifyObject().wakeupAll(); } }  Slave 汇报进度唤醒 GroupTransferService， 等待同步完成唤醒 GroupCommitRequest 的 CountDownLatch:  class ReadSocketService extends ServiceThread { private boolean processReadEvent() { // 唤醒 GroupTransferService  HAConnection.this.haService.notifyTransferSome(HAConnection.this.slaveAckOffset); } } class GroupTransferService extends ServiceThread { // 被唤醒  public void notifyTransferSome() { this.notifyTransferObject.wakeup(); } private void doWaitTransfer() { for (CommitLog.GroupCommitRequest req : this.requestsRead) { boolean transferOK = HAService.this.push2SlaveMaxOffset.get() \u0026gt;= req.getNextOffset(); // 5 次重试  for (int i = 0; !transferOK \u0026amp;\u0026amp; i \u0026lt; 5; i++) { // 等待被唤醒或者超时  this.notifyTransferObject.waitForRunning(1000); transferOK = HAService.this.push2SlaveMaxOffset.get() \u0026gt;= req.getNextOffset(); } // 唤醒 GroupCommitRequest 的 CountDownLatch  req.wakeupCustomer(transferOK); } } } public static class GroupCommitRequest { // 被唤醒  public void wakeupCustomer(final boolean flushOK) { this.flushOK = flushOK; this.countDownLatch.countDown(); } } 下图是上图一个完整的消息唤醒链:\n五、主备消费 当消费者在消费的时候，如果 Master 突然宕机，那么消费者会自动切换到 Slave 机器上继续进行消费。\n六、消费建议 RocketMQ 提供了自动从 Slave 读取老数据的功能。这个功能主要由 slaveReadEnable 这个参数控制。默认是关的（slaveReadEnable = false）。推荐把它打开，主从都要开。这个参数打开之后，在客户端消费数据时，会判断，当前读取消息的物理偏移量跟最新的位置的差值，是不是超过了内存容量的一个百分比（accessMessageInMemoryMaxRatio = 40 by default）。如果超过了，就会告诉客户端去备机上消费数据。如果采用异步主从，也就是 brokerRole 等于 ASYNC_AMSTER 的时候，你的备机 IO 打爆，其实影响不太大。但是如果你采用同步主从，那还是有影响。所以这个时候，最好挂两个备机。因为 RocketMQ 的主从同步复制，只要一个备机响应了确认写入就可以了，一台 IO 打爆，问题不大。参考自阿里中间件团队博客。\n七、异常处理 Q: Master(Slave) 读取来自 Slave(Master) 的消息异常 (IOException、 read() 返回 -1 等) 的时候怎么处理? A: 打印日志 + 关闭这条连接\nQ: Master(Slave) 长时间没有收到来自 Slave(Master) 的进度汇报怎么处理? A: 每次读取之后更新 lastReadTimestamp 或者 lastWriteTimestamp，一旦发现在 haHousekeepingInterval 间隔内 (默认 20秒) 这个时间戳都没有改变的话，关闭这条连接\nQ: Slave 检测到来自 Master 汇报的本次传输偏移量和本地的传输偏移量不同时怎么处理? A: 打印日志 + 关闭这条连接\nQ: Master 如何知道 Slave 是否真正的存储了刚才发送过去的消息? A: Slave 存储完毕之后，通过向 Master 汇报进度来完成。相当于 TCP 的 ACK 机制。\nQ: Master 宕掉 A: 无论 Maser 是主动关闭 Mater，还是 Master 因为异常而退出，Slave 都会每隔 5 秒重连一次 Master\n"});index.add({'id':40,'href':'/docs/books/everyone-is-architect/','title':"人人都是架构师 (一)",'content':"人人都是架构师 - 分布式系统架构落地与瓶颈突破 分布式系统应对高并发、大流量的常用手段：\n 扩容 动静分离 缓存 服务降级 限流  限流 常见算法：\n 令牌桶，Nginx 限流模块用的是这个：限制的是流量的平均流入速率，允许一定程度上的突发流量。 漏桶：限制的是流出速率，并且这个速率还是保持不变的，不允许突发流量。  Nginx 限流 http { # 每个 IP 的 session 空间大小 limit_zone one $binary_remote_addr 20m; # 每个 IP 每秒允许发起的请求数 limit_req_zone $binary_remote_addr zone=req_one:20m rate=10r/s; # 每个 IP 能够发起的并发连接数 limit_conn one 10; # 缓存还没有来得及处理的请求 limit_req zone=req_one burst=100; } 消峰  活动分时段 答题验证  高并发读 \u0026ldquo;马某出轨王某\u0026rdquo;、\u0026ldquo;iPhone SE 2020 发布\u0026rdquo; 等这种热点新闻的 key 会始终落在同一个缓存节点上，分布式缓存一定会出现单点瓶颈，其资源连接容易瞬间耗尽。有如下两种方案解决这个问题：\n 基于 Redis 的集群多写多读方案。  多写如何保持一致性：将 Key 配置在 ZooKeeper，客户端监听 ZNode，一旦变化，全量更新本地持有的 Key   LocalCache 结合 Redis 集群的多级 Cache 方案。  LocalCache 拉取下来的商品数量有 5 个，但是实际上只有 4 个了，怎么解决？对于这种读场景，允许接受一定程度上的数据脏读，最终扣减库存的时候再提示商品已经售罄即可。    实时热点自动发现 交易系统产生的相关数据、上游系统中埋点上报的数据这两个，异步写入日志，对日志进行次数统计和热点分析\n高并发写 InnoDB 行锁 乐观锁扣减：\nSELECT stock, version FROM item WHERE item_id = 1; UPDATE ITEM SET version = version + 1, stock = stock - 1 WHERE item_id = 1 AND version = version; 引入条件 \u0026ldquo;实际库存数 \u0026gt;= 扣减库存数\u0026rdquo;：\nUPDATE item SET stock = stock - 1 WHERE item_id = 1 AND stock \u0026gt;= 1; 查询队列中等待拿锁的线程：\nSELECT * FROM information_schema.INNODB_TRX WHERE trx_state = \u0026#39;LOCK_WAIT\u0026#39;; Redis Redis 读写能力远胜任何类型的关心型数据库。使用 Redission 实现分布式锁，避免超卖：\nRedissionClient redission = null; try { redission = Redission.create(config); RLock lock = redission.getLock(\u0026#34;testLock\u0026#34;); // lock(long leaseTime, TimeUnit unit)  // 某个线程没有获取到锁，那么这个线程只能在队列中阻塞等待，与 InnoDB 如出一辙  lock.lock(20, TimeUnit.MILLISECONDS); lock.unlock(); // tryLock(long waitTime, long leaseTime, TimeUnit unit)  // 并发较大的情况下，建议使用这个  boolean result = lock.tryLock(10, 20, TimeUnit.MILLISECONDS); if (result) { lock.forceUnlock(); } } finally { if (null != redission) { redission.shutdown(); } } 扣除库存成功后的消息，通过消息队列写入到数据库中，由于才用了排队机制，并发写入数据库的流量可控，数据库负载压力始终保持在一个恒定的范围内。\n批处理 如何有效减少获取锁的次数，提升系统整体的 TPS？\n批量提交扣减商品库：先收集扣减请求，达到某个阈值，对请求进行合并，获取一次分布式锁。缺点：库存不足，这一批全部扣减失败。\n控制单机并发写  单机排队串行写 抢购限流  分布式 SequenceID 生成 Shark（一款开源的 MySQL 分库分表中间件）内部提供了生成 SequenceID 的 API （底层支持数据库和 ZooKeeper 作为申请 SequenceID 的存储系统）：\nCREATE TABLE shark_sequenceid( s_id INT NOT NULL AUTO_INCREMENT COMMENT \u0026#39;主键\u0026#39;, s_type INT NOT NULL COMMENT \u0026#39;类型\u0026#39;, s_useData BIGINT NOT NULL COMMENT \u0026#39;申请占位数量\u0026#39;, PRIMARY KEY(s_id) ) ENGINE = InnoDB DEFAULT CHARSET = utf8mb4 COLLATE utf8mb4_bin; 通过如下 API 获取：\n// (int idcNum, int type, long memData) SequenceIDManager.getSequenceId(100, 10, 5000); 第一个参数：IDC 机房编码，第二个参数：业务类别，第三个参数：向数据库申请的 ID 缓存数，返回一个长度为 19 位的 SequenceID。\nShark 只是负责封装 ID 的生成逻辑，真正保证唯一性和连续性的还是单点数据库。\n多维度复杂查询 Solr 的目的就是要替换 SQL 中的 like '%香水%' 这种模糊查询，因为数据库会采用全表扫描。\n"});index.add({'id':41,'href':'/docs/tools/','title':"实用工具",'content':"阮一峰周刊提到的工具集 阮一峰《科技爱好者周刊》中列举的所有好用的工具集，持续收录，目前已经将前 28 期的所有实用的工具收录整理在下表中，方便小伙伴们使用。直接在本文 Ctrl(Command) + F 查找工具集的名字，即可快速搜索定位到你想找的工具。\n   类别 🍄 🍄     Resource 吴恩达《Machine Learning Yearning》 Google 面试自学手册    Android 开发工程师面试指南 《React in patterns》    《技术面试需掌握的基础知识整理》 各大互联网公司技术架构    收集开源书籍：love2.io Facebook 机器学习教程    AWK 编程语言 Python 100天从新手到大师    14000种鸟叫 网页设计常见错误    GO 高级教程 《Node.js 调试指南》    网站架构101 Google 数据集搜索    V8引擎官方网站    工具 火焰🔥图生成: flamebearer 合并多张图片    Tabler - Dashboard 浏览器自动化框架: Remote Browser    网页日历库 优化图片下载: img-2    开源图标库 PNG 图片压缩    AutoCAD 在线版 自动生成背景图片    各种 CSS 使用技巧 手绘风格组件库    HTML转PDF：ReLaXed 自动格式化 Python 代码    代理服务器：goproxy Terminal 显示 Dashboard    免费存储 JSON: jsonstore.io MAC 免费软件    生成 .gitignore 生成 localhost 证书    React 拖放库 开源代码片段管理服务    各种软件的 Cheatsheet 开源的在线图片编辑器    查找重复代码 命令行画出柱状图    设计原型产品 UI 开源短网址服务    命令行操作录制成SVG Crontab UI    APK安装在Ubuntu 任何网页转为 RSS    下载 Youtube 视频     "});index.add({'id':42,'href':'/categories/','title':"Categories",'content':""});index.add({'id':43,'href':'/tags/','title':"Tags",'content':""});index.add({'id':44,'href':'/posts/','title':"博客",'content':""});index.add({'id':45,'href':'/tags/%E7%BC%93%E5%AD%98/','title':"缓存",'content':""});index.add({'id':46,'href':'/categories/%E7%BC%96%E7%A8%8B/','title':"编程",'content':""});index.add({'id':47,'href':'/','title':"首页",'content':"赵坤的个人网站 本博客将致力于整理、分析 Java、前端 等开发者生态圈的开源项目的教程、源码等，我会参阅大量书籍，一一对这些基础知识点抽丝剥茧，并匹配大量图表，为大家呈现出它们最本质的面目。\n通过阅读和分析开源项目等，可以增长自己的工程实践能力，可以让自己从代码中汲取养分，也可以学习到他人的设计权衡之道，其对于自己成长的重要性不言而喻！\n欢迎大家关注【我是前端喵】公众号，这里有最新、最全、更新最及时的前端文章收录：\n"});index.add({'id':48,'href':'/tags/nginx/','title':"Nginx",'content':""});index.add({'id':49,'href':'/tags/%E4%BF%A1%E6%81%AF/','title':"信息",'content':""});index.add({'id':50,'href':'/categories/%E7%A7%91%E6%8A%80/','title':"科技",'content':""});index.add({'id':51,'href':'/tags/%E7%B3%BB%E7%BB%9F%E4%B8%80%E8%87%B4%E6%80%A7/','title':"系统一致性",'content':""});index.add({'id':52,'href':'/tags/java/','title':"Java",'content':""});index.add({'id':53,'href':'/docs/','title':"Docs",'content':""});})();