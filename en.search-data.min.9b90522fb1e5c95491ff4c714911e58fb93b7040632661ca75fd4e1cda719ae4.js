'use strict';(function(){const indexCfg={cache:true};indexCfg.doc={id:'id',field:['title','content'],store:['title','href'],};const index=FlexSearch.create('balance',indexCfg);window.bookSearchIndex=index;index.add({'id':0,'href':'/docs/rocketmq/rocketmq-send-message-flow/','title':"RocketMQ 消息发送流程",'content':"RocketMQ 消息发送流程 本文讲述 RocketMQ 发送一条普通消息的流程。\n一、服务器启动 我们可以参考官方文档来启动服务:\n 启动 Name 服务器:  sh bin/mqnamesrv  启动 Broker 服务器:  sh bin/mqbroker -n localhost:9876 二、构建消息体 一条消息体最少需要指定两个值:\n 所属话题 消息内容  如下就是创建了一条话题为 “Test”，消息体为 “Hello World” 的消息:\nMessage msg = new Message( \u0026#34;Test\u0026#34;, \u0026#34;Hello World\u0026#34;.getBytes() ); 三、启动 Producer 准备发送消息 如果我们想要发送消息呢，我们还需要再启动一个 DefaultProducer (生产者) 类来发消息:\nDefaultMQProducer producer = new DefaultMQProducer(); producer.start(); 现在我们所启动的服务如下所示:\n四、Name 服务器的均等性 注意我们上述开启的是单个服务，也即一个 Broker 和一个 Name 服务器，但是实际上使用消息队列的时候，我们可能需要搭建的是一个集群，如下所示:\n在 RocketMQ 的设计中，客户端需要首先询问 Name 服务器才能确定一个合适的 Broker 以进行消息的发送:\n然而这么多 Name 服务器，客户端是如何选择一个合适的 Name 服务器呢?\n首先，我们要意识到很重要的一点，Name 服务器全部都是处于相同状态的，保存的都是相同的信息。在 Broker 启动的时候，其会将自己在本地存储的话题配置文件 (默认位于 $HOME/store/config/topics.json 目录) 中的所有话题加载到内存中去，然后会将这些所有的话题全部同步到所有的 Name 服务器中。与此同时，Broker 也会启动一个定时任务，默认每隔 30 秒来执行一次话题全同步:\n五、选择 Name 服务器 由于 Name 服务器每台机器存储的数据都是一致的。因此我们客户端任意选择一台服务器进行沟通即可。\n其中客户端一开始选择 Name 服务器的源码如下所示:\npublic class NettyRemotingClient extends NettyRemotingAbstract implements RemotingClient { private final AtomicInteger namesrvIndex = new AtomicInteger(initValueIndex()); private static int initValueIndex() { Random r = new Random(); return Math.abs(r.nextInt() % 999) % 999; } private Channel getAndCreateNameserverChannel() throws InterruptedException { // ...  for (int i = 0; i \u0026lt; addrList.size(); i++) { int index = this.namesrvIndex.incrementAndGet(); index = Math.abs(index); index = index % addrList.size(); String newAddr = addrList.get(index); this.namesrvAddrChoosed.set(newAddr); Channel channelNew = this.createChannel(newAddr); if (channelNew != null) return channelNew; } // ...  } } 以后，如果 namesrvAddrChoosed 选择的服务器如果一直处于连接状态，那么客户端就会一直与这台服务器进行沟通。否则的话，如上源代码所示，就会自动轮寻下一台可用服务器。\n六、寻找话题路由信息 当客户端发送消息的时候，其首先会尝试寻找话题路由信息。即这条消息应该被发送到哪个地方去。\n客户端在内存中维护了一份和话题相关的路由信息表 topicPublishInfoTable，当发送消息的时候，会首先尝试从此表中获取信息。如果此表不存在这条话题的话，那么便会从 Name 服务器获取路由消息。\npublic class DefaultMQProducerImpl implements MQProducerInner { private TopicPublishInfo tryToFindTopicPublishInfo(final String topic) { TopicPublishInfo topicPublishInfo = this.topicPublishInfoTable.get(topic); if (null == topicPublishInfo || !topicPublishInfo.ok()) { this.topicPublishInfoTable.putIfAbsent(topic, new TopicPublishInfo()); this.mQClientFactory.updateTopicRouteInfoFromNameServer(topic); topicPublishInfo = this.topicPublishInfoTable.get(topic); } // ...  } } 当尝试从 Name 服务器获取路由信息的时候，其可能会返回两种情况:\n(1) 新建话题 这个话题是新创建的，Name 服务器不存在和此话题相关的信息：\n(2) 已存话题 话题之前创建过，Name 服务器存在此话题信息：\n服务器返回的话题路由信息包括以下内容:\n“broker-1”、”broker-2” 分别为两个 Broker 服务器的名称，相同名称下可以有主从 Broker，因此每个 Broker 又都有 brokerId 。默认情况下，BrokerId 如果为 MixAll.MASTER_ID （值为 0） 的话，那么认为这个 Broker 为 MASTER 主机，其余的位于相同名称下的 Broker 为这台 MASTER 主机的 SLAVE 主机。\npublic class MQClientInstance { public String findBrokerAddressInPublish(final String brokerName) { HashMap\u0026lt;Long/* brokerId */, String/* address */\u0026gt; map = this.brokerAddrTable.get(brokerName); if (map != null \u0026amp;\u0026amp; !map.isEmpty()) { return map.get(MixAll.MASTER_ID); } return null; } } 每个 Broker 上面可以绑定多个可写消息队列和多个可读消息队列，客户端根据返回的所有 Broker 地址列表和每个 Broker 的可写消息队列列表会在内存中构建一份所有的消息队列列表。之后客户端每次发送消息，都会在消息队列列表上轮循选择队列 (我们假设返回了两个 Broker，每个 Broker 均有 4 个可写消息队列):\npublic class TopicPublishInfo { public MessageQueue selectOneMessageQueue() { int index = this.sendWhichQueue.getAndIncrement(); int pos = Math.abs(index) % this.messageQueueList.size(); if (pos \u0026lt; 0) pos = 0; return this.messageQueueList.get(pos); } } 七、给 Broker 发送消息 在确定了 Master Broker 地址和这个 Broker 的消息队列以后，客户端才开始真正地发送消息给这个 Broker，也是从这里客户端才开始与 Broker 进行交互:\n这里我们暂且先忽略消息体格式的具体编/解码过程，因为我们并不想一开始就卷入这些繁枝细节中，现在先从大体上了解一下整个消息的发送流程，后续会写专门的文章来说明。\n八、Broker 检查话题信息 刚才说到，如果话题信息在 Name 服务器不存在的话，那么会使用默认话题信息进行消息的发送。然而一旦这条消息到来之后，Broker 端还并没有这个话题。所以 Broker 需要检查话题的存在性:\npublic abstract class AbstractSendMessageProcessor implements NettyRequestProcessor { protected RemotingCommand msgCheck(final ChannelHandlerContext ctx, final SendMessageRequestHeader requestHeader, final RemotingCommand response) { // ...  TopicConfig topicConfig = this.brokerController .getTopicConfigManager() .selectTopicConfig(requestHeader.getTopic()); if (null == topicConfig) { // ...  topicConfig = this.brokerController .getTopicConfigManager() .createTopicInSendMessageMethod( ... ); } } } 如果话题不存在的话，那么便会创建一个话题信息存储到本地，并将所有话题再进行一次同步给所有的 Name 服务器:\npublic class TopicConfigManager extends ConfigManager { public TopicConfig createTopicInSendMessageMethod(final String topic, /** params **/) { // ...  topicConfig = new TopicConfig(topic); this.topicConfigTable.put(topic, topicConfig); this.persist(); // ...  this.brokerController.registerBrokerAll(false, true); return topicConfig; } } 话题检查的整体流程如下所示:\n九、消息存储 当 Broker 对消息的一些字段做过一番必要的检查之后，便会存储到磁盘中去:\n十、整体流程 发送消息的整体流程:\n"});index.add({'id':1,'href':'/docs/rocketmq/','title':"RocketMQ 源码分析",'content':"RocketMQ RocketMQ 是阿里巴巴集团开源的一款分布式消息中间件，其采用纯 Java 语言编写，本博客基于 RocketMQ 4.2.0 版本，为大家分析和讲解其内部几个关键模块的运行原理。\n"});index.add({'id':2,'href':'/docs/programmer-interview/front-end/vue/','title':"VUE 面试题",'content':"VUE 面试题 整理 VUE 相关的常见面试题\n介绍一下 VUE 介绍一下 VUEX VUE 2.X 和 3.0 的区别 （1）数据监听方式变化\nVUE 2.X 使用 ES5 的 Object.defineProperty() 的 get() 和 set(newValue) 实现，VUE 3.0 基于 Proxy 监听实现，同时更为强大：\n 可以检测属性的新增和删除 可以检测数组索引的变化和 length 的变化 支持 Map、Set、WeakMap 和 WeakSet   优点：速度加倍，内存占用减半。\n （2）体积更小\n支持 Tree Shaking，内置组件、内置指令按需引入。\n（3）速度更快\n参考：vue3.0和vue2.x的区别、Vue 3.0 和 Vue 2.0的对比以及Vue 2.0精讲以及Vue全家桶精讲\nVUE 的生命周期 VUE 数据双向绑定原理 VUE 采用发布者-订阅者模式的方式来实现双向绑定。\n（1）视图更新数据：\ninput 标签监听 input 事件即可。\n（2）数据更新视图：\nObject.defineProperty() 监听数据变化，通过消息订阅器发布消息，订阅者收到消息执行相应的操纵 DOM 的函数，从而更新视图。\nVUE 的路由机制  hash 和 history 区别  v-if 和 v-show 的区别  v-show：无论值是 true 还是 false，元素都会存在于 HTML 代码中。 v-if：只有值为 true 的时候，元素才会存在于 HTML 代码中。  VUE 组件通信方式  引申：如果有多层的父子组件，用什么通信  VUE 的 v-for 中的 key 的作用 一句话回答：为了高效的更新虚拟 DOM。\nnextTick 原理与应用场景 Vue 在修改数据后，视图不会立刻更新，而是等同一事件循环中的所有数据变化完成之后，再统一进行视图更新。\n//改变数据 vm.message = \u0026#39;changed\u0026#39; //想要立即使用更新后的DOM。这样不行，因为设置message后DOM还没有更新 console.log(vm.$el.textContent) // 并不会得到\u0026#39;changed\u0026#39;  //这样可以，nextTick里面的代码会在DOM更新后执行 Vue.nextTick(function(){ console.log(vm.$el.textContent) //可以得到\u0026#39;changed\u0026#39; }) 应用场景：需要在 DOM 视图更新之后，基于新的 DOM 视图进行操作。\n参考：Vue.nextTick 的原理和用途\nVUE 的虚拟 DOM  VUE 是如何实现 VDOM 的 vue中keep-alive缓存的真实结点还是虚拟结点 vue改变组件的key值, 原来的组件会被销毁么 为什么要用虚拟结点 diff 原理  vue 从 data 改变到页面渲染的过程 参考  诚意满满的前端面试总结（回馈牛客）  "});index.add({'id':3,'href':'/docs/programmer-interview/front-end/','title':"前端",'content':"前端面试题 "});index.add({'id':4,'href':'/docs/books/beauty_of_mathematics/','title':"数学之美",'content':"数学之美 2000多年前，古埃及人在罗塞塔石碑上，用三种文字记录了托勒密五世登基的诏书，这帮助后人破解了古埃及的象形文字，让我们了解了5000年前古埃及的历史。可见信息冗余是信息安全的保障，这对于信息编码具有重要指导意义。\n犹太人为了避免抄错《圣经》，发明了一种校验码的方法，他们把每一个希伯来字母对应于一个数字，这样每行文字加起来便得到一个特殊的数字，这样的数字变成为了这一行的校验码。\n隐含马尔可夫链成功应用在机器翻译、拼写纠错、手写体识别、图像处理、基因序列分析、股票预测和投资等方面。\n如何准确的识别出一个快递地址，写一个分析器去分析这些描述恐怕是不行的，因为地址是比较复杂的上下文有关的文法。答案是使用有限状态机。当用户输入的地址不太标准或有错别字的时候，有限状态机会束手无措，因为有限状态机是严格匹配的，所以科学家提出了基于概率的有限状态机。\n2002 年，Google 想要做一个全新的中、日、韩搜索算法，吴军写的算法比较简单，但是占用内存比较多，Google 服务器数量还没有那么多。辛格提出，用一个拟合函数替换很耗内存的语言模型，无需增加任何服务器，但是搜索质量会降到 80%。辛格指出，这样可以提早两个月将这个新算法提供给中国的用户，用户体验会有质的提高。辛格做事情的哲学，先帮助用户解决 80% 的问题，再慢慢解决剩下的 20% 的问题，是在工业界成功的秘诀之一。\n新闻分类的关键在于计算出两篇新闻的相似度，每篇新闻变成一个向量，最后余弦定理可以计算出来相似度。但两两计算的迭代次数太多，如何一次性就把所有新闻的相关性计算出来呢？答案是矩阵运算中的奇异值分解。\n如何判断两个集合是否相同？一种答案是双层 for 循环一一比较，复杂度 O(N^2)；稍好一点的办法是对集合进行排序，然后顺序比较，时间复杂度 O(NlogN)；还可以将一个集合的元素放到散列表里面，另外一个与之一一对比，时间复杂度 O(N)，但是额外使用了 O(N) 的空间，不完美；最完美的是计算这两个集合的指纹，对一个集合中的元素分别计算指纹，然后一一相加。\n如何判断两个集合基本相同？答案是 Simhash。判断两个网页是否重复，也没有必要完全从头比到尾，只需要每个网页挑选出几个词 (IDF 最大的几个词)，构成特征词，然后计算信息指纹即可。判断一篇文章是否抄袭另外一篇文章，每篇文章切成小的片段，挑选特征词，并计算指纹。YouTuBe 如何从上百万视频中找出一个视频是否另外一个视频的盗版？其核心在于关键帧的提取和特征的提取。关键帧对于视频的重要性，就如同主题词对于新闻的重要性一样。\n最大熵原理指出，对一个随机事件的概率分布进行预测时，我们的预测应当满足全部已知的条件，而对未知的情况不要做任何主观假设，这种情况下，概率分布最均匀，预测的风险最小。例如拼音输入法，Wang-Xiao-Bo 转换为王晓波和王小波，唯一确定用户需要的是哪一个，非常难。\n"});index.add({'id':5,'href':'/docs/javascript/understand-this-keyword/','title':"理解 This 关键字",'content':"理解 This 关键字 JavaScript 中的 this 所指向的对象，取决于上下文以及函数被调用的方式，本文列举了几种常见的情况，帮助大家理解。\n一、全局上下文 当直接在一个全局的上下文中，使用 this 指针的时候，this 指针会指向到全局对象上。例如在浏览器的调试工具栏中直接打印 this 指针，其指向的是 Window 对象：\n在 node 中打印 this 指针，其指向的是 node 提供的全局对象，其中包含了进程信息等：\n二、Function 上下文 在 Function 上下文中，this 的值取决于 function 是如何被调用的。\n(1) Function 调用 当 this 指针定义在一个 function 中，那么此 this 仍然会指向全局对象：\nfunction foo() { console.log(this) } foo(); // Window {parent: Window, postMessage: ƒ, blur: ƒ, focus: ƒ, close: ƒ, …} (2) 严格模式下的 Function 调用 如果在严格模式下定义的 function 的话，this 指针的值将会是 undefined：\nfunction foo() { \u0026#39;use strict\u0026#39;; console.log(this) } foo(); // undefined (3) Method 调用 Method 调用指的是，function 作为一个对象的属性而存在。当 this 指针被定义在一个对象内的时候，那么其将会指向紧紧包裹自己的这个对象。\nvar obj = { name: \u0026#39;outerObj\u0026#39;, innerObj: { name: \u0026#39;innerObj\u0026#39;, foo: function() { console.log(this.name) } } }; console.log(obj.innerObj.foo()) // innerObj (4) 构造器调用 当 function 被用于构造器的时候，那么定义在构造器内部的 this 指针将会指向此构造器新 new 出来的实例对象。\nfunction Person(name) { this.name = name console.log(this) } console.log(new Person(\u0026#34;Tom\u0026#34;)) // Person {name: \u0026#34;Tom\u0026#34;} (5) call()、apply()、bind() 调用 这三个函数最大的特点就是，你可以通过参数为他们指定 this 指针所需要指向的对象：\nfunction add(inc1, inc2) { var value = this.a + inc1 + inc2; console.log(this) return value; } var o = { a : 4 }; console.log(add.call(o, 5, 6)) // {a: 4} console.log(add.apply(o, [5, 6])) // {a: 4}  var g = add.bind(o, 5, 6) console.log(g()) // {a: 4} (6) ES6 箭头函数调用 当你使用 ES6 箭头函数的时候，this 指针返回的总是箭头函数定义所在位置的上一级的函数作用域的 this 对象，是箭头函数被 function() { } 包裹的作用域中的 this 对象。如下面示例，this 指向的是 log() 函数内部的 this 指针的值：\nclass Student { log() { // 这个地方的 this 的值  setTimeout(() =\u0026gt; console.log(this === student), 100) } } const student = new Student() student.log() // true 但是如果上一级并不是位于函数作用域中，而是位于 Object 对象嵌套层级中，则需要继续向上找函数作用域，因为 Object 嵌套层级不构成单独的作用域。如下所示 this 指针指向的是 Window 对象，而非 o 对象：\nvar o = { b: () =\u0026gt; { console.log(\u0026#39;this is\u0026#39;, this); // this is Window  } } o.b(); 三、参考  How does the “this” keyword work? Gentle Explanation of \u0026ldquo;this\u0026rdquo; in JavaScript MDN this 箭头函数this的指向问题  "});index.add({'id':6,'href':'/docs/javascript/','title':"JavaScript 专栏",'content':"JavaScript 专栏 本专栏用于整理在 JavaScript 中最常使用的、必知必会的基础知识点，方便大家温故而知新。\n"});index.add({'id':7,'href':'/docs/javascript/javascript-array/','title':"JavaScript 数组",'content':"JavaScript 数组 使用 JavaScript 在编程的时候，我们有很大一部分时间都是在与数组打交道，因此对数组常见的方法做到灵活的运用至关重要。本文整理了和 JavaScript 数组相关的，日常经常需要的功能和使用技巧，供大家参阅。\n从数组中移除指定元素 查阅 JavaScript 的数组 API，发现其并没有提供一个像 remove(obj) 或 removeAll(obj) 此类的方法，供我们方便的删除对象，因此我们需要通过使用其它的 API 来达到我们移出元素的目的。\n(1) 使用 splice 方法 splice 方法可以从指定索引处，向数组中添加元素或者删除元素，其会直接在原数组上改变，因此通过此方法可以达到我们的目的。但是在移除元素之前，我们必须首先通过 indexOf 方法找到我们的元素在数组中处于的索引位置。\nconst array = [2, 5, 9]; const index = array.indexOf(5); if (index \u0026gt; -1) { array.splice(index, 1); // 1 代表删除 1 个元素 } console.log(array) 当然，如果你不想使用 indexOf 的话，也可以直接从后向前遍历整个数组，对每个符合要求的元素都使用 splice 方法：\nconst array = [2, 5, 9]; for (var i = array.length; i--; ) { if (array[i] === 5) { array.splice(i, 1) } } console.log(array) 之所以需要从后向前移除，是因为在移除过程中，数组的 length 和 index 索引都是会改变的。\n(2) 使用 filter 方法 在 ES6 中，你可以使用 filter 函数遍历数组，对不符合元素值的对象进行过滤。filter 方法会返回一个新的数组，并不会直接在原数组上进行操作。\nlet value = 3; let array = [1, 2, 3, 4, 5, 3]; console.log(array.filter(item =\u0026gt; item !== value)) 如何遍历数组元素 JavaScript 数组提供了非常多的方法，这些方法都可以用来遍历数组：\n(1) 使用 forEach 方法 var a = [\u0026#34;a\u0026#34;, \u0026#34;b\u0026#34;, \u0026#34;c\u0026#34;]; a.forEach(function(entry) { console.log(entry) }) (2) 使用 for 遍历 var a = [\u0026#34;a\u0026#34;, \u0026#34;b\u0026#34;, \u0026#34;c\u0026#34;]; for (var index = 0; index \u0026lt; a.length; ++index) { console.log(a[index]) } (3) 使用 for 反向遍历 for (var i = array.length; i--; ) { // ... } 上述反向遍历的原理是：i-- 是属于测试条件的一部分，在每一次开始执行方法体之前，i 的值已经提前执行了 -- 这个操作了。当最后一次迭代，发现 i 等于 0 的时候，这个循环自然会停下来。\n(4) 使用 for-of 遍历 ES6 添加了迭代器的概念，当你使用 for-of 遍历的时候，其实已经隐形的在使用迭代器了：\nvar a = [\u0026#34;a\u0026#34;, \u0026#34;b\u0026#34;, \u0026#34;c\u0026#34;]; for (const val of a) { console.log(val); } (5) 不要使用 for-in 遍历 你或许听到过一些其它人的观点告诉你，使用 for-in 同样可以做到遍历数组。但是 for-in 是为了遍历对象用的，它并不保证按照数组的索引顺序来一一地遍历元素。所以在遍历数组的时候不推荐使用这种做法。\nfor (key in obj) { if (obj.hasOwnProperty(key)) { // ...  } } 如何清空数组 (1) 直接赋值一个空数组 如果你确实不在使用这个数组的话，也能保证其它地方没有引用这个数组，那么完全可以通过为其赋上一个新的空数组，从而置位空。\narr = [] (2) 将长度置为 0 arr.length = 0 (3) 使用 splice 方法 arr.splice(0, arr.length) (4) 使用 pop 方法 一一将元素 pop 出去，可能是最慢的一个方法了。\nwhile (arr.length) { arr.pop(); } 从头部插入元素 (1) 使用 unshift 方法  unshift 方法从头部插入一个元素到数组中 shift 方法从头部删除一个元素 push 方法从尾部插入一个元素到数组中 pop 方法从尾部删除一个元素  JavaScript 提供的从头部删除元素的方法名叫做 unshift，而不是叫做 insertAtHead 之类的，的确是在用到的时候不太容易想到这个名称。之所以这样命名，是因为 JavaScript 的数组的命名方式参考了 C 语言的栈的命名方式:\n array_unshift() array_shift() array_push() array_pop()  (2) 使用 concat 方法 concat() 方法可以用来连接两个数组：\nvar arr = [1, 2, 3, 4, 5, 6, 7]; console.log([0].concat(arr)); (3) 使用 Spread 操作符 在 ES6 中，可以使用 Spread 操作符 \u0026hellip; 来新增元素：\nvar arr = [23, 45, 12, 67]; arr = [34, ...arr]; 提前 break 数组循环 (1) 使用 Exception 对于 forEach 而言，使用 break 是不管用的，需要抛出异常强制终止循环，最好的建议是如果你需要 break 循环，在这种情况下就不要使用 forEach 来循环数组了：\nvar BreakException = {}; try { [1, 2, 3].forEach(function(el) { console.log(el); if (el === 2) throw BreakException; }); } catch (e) { if (e !== BreakException) throw e; } (2) 使用 for-of for (const [index, el] of arr.entries()) { if ( index === 5 ) break; } (3) 使用普通的循环 var array = [1, 2, 3]; for (var i = 0; i \u0026lt; array.length; i++) { if (array[i] === 1){ break; } } 数组去重 (1) 使用 filter 方法 var myArray = [\u0026#39;a\u0026#39;, 1, \u0026#39;a\u0026#39;, 2, \u0026#39;1\u0026#39;]; var unique = myArray.filter((value, index, arr) =\u0026gt; arr.indexOf(value) === index); (2) 使用 Set 构造器 var myArray = [\u0026#39;a\u0026#39;, 1, \u0026#39;a\u0026#39;, 2, \u0026#39;1\u0026#39;]; // unique = Array.from(new Set(myArray)) let unique = [...new Set(myArray)]; 参考  How do I remove a particular element from an array in JavaScript For-each over an array in JavaScript How do I empty an array in JavaScript How can I add new array elements at the beginning of an array in Javascript? Short circuit Array.forEach like calling break Get all unique values in a JavaScript array  "});index.add({'id':8,'href':'/docs/rocketmq/rocketmq-message-store-flow/','title':"RocketMQ 消息存储流程",'content':"RocketMQ 消息存储流程 本文讲述 RocketMQ 存储一条消息的流程。\n一、存储位置 当有一条消息过来之后，Broker 首先需要做的是确定这条消息应该存储在哪个文件里面。在 RocketMQ 中，这个用来存储消息的文件被称之为 MappedFile。这个文件默认创建的大小为 1GB。\n一个文件为 1GB 大小，也即 1024 * 1024 * 1024 = 1073741824 字节，这每个文件的命名是按照总的字节偏移量来命名的。例如第一个文件偏移量为 0，那么它的名字为 00000000000000000000；当当前这 1G 文件被存储满了之后，就会创建下一个文件，下一个文件的偏移量则为 1GB，那么它的名字为 00000000001073741824，以此类推。\n默认情况下这些消息文件位于 $HOME/store/commitlog 目录下，如下图所示:\n二、文件创建 当 Broker 启动的时候，其会将位于存储目录下的所有消息文件加载到一个列表中:\n当有新的消息到来的时候，其会默认选择列表中的最后一个文件来进行消息的保存:\npublic class MappedFileQueue { public MappedFile getLastMappedFile() { MappedFile mappedFileLast = null; while (!this.mappedFiles.isEmpty()) { try { mappedFileLast = this.mappedFiles.get(this.mappedFiles.size() - 1); break; } catch (IndexOutOfBoundsException e) { //continue;  } catch (Exception e) { log.error(\u0026#34;getLastMappedFile has exception.\u0026#34;, e); break; } } return mappedFileLast; } } 当然如果这个 Broker 之前从未接受过消息的话，那么这个列表肯定是空的。这样一旦有新的消息需要存储的时候，其就得需要立即创建一个 MappedFile 文件来存储消息。\nRocketMQ 提供了一个专门用来实例化 MappedFile 文件的服务类 AllocateMappedFileService。在内存中，也同时维护了一张请求表 requestTable 和一个优先级请求队列 requestQueue 。当需要创建文件的时候，Broker 会创建一个 AllocateRequest 对象，其包含了文件的路径、大小等信息。然后先将其放入 requestTable 表中，再将其放入优先级请求队列 requestQueue 中:\npublic class AllocateMappedFileService extends ServiceThread { public MappedFile putRequestAndReturnMappedFile(String nextFilePath, String nextNextFilePath, int fileSize) { // ...  AllocateRequest nextReq = new AllocateRequest(nextFilePath, fileSize); boolean nextPutOK = this.requestTable.putIfAbsent(nextFilePath, nextReq) == null; if (nextPutOK) { // ...  boolean offerOK = this.requestQueue.offer(nextReq); } } } 服务类会一直等待优先级队列是否有新的请求到来，如果有，便会从队列中取出请求，然后创建对应的 MappedFile，并将请求表 requestTable 中 AllocateRequest 对象的字段 mappedFile 设置上值。最后将 AllocateRequest 对象上的 CountDownLatch 的计数器减 1 ，以标明此分配申请的 MappedFile 已经创建完毕了:\npublic class AllocateMappedFileService extends ServiceThread { public void run() { // 一直运行  while (!this.isStopped() \u0026amp;\u0026amp; this.mmapOperation()) { } } private boolean mmapOperation() { req = this.requestQueue.take(); if (req.getMappedFile() == null) { MappedFile mappedFile; // ...  mappedFile = new MappedFile(req.getFilePath(), req.getFileSize()); // 设置上值  req.setMappedFile(mappedFile); } // ...  // 计数器减 1  req.getCountDownLatch().countDown(); // ...  return true; } } 其上述整体流程如下所示:\n等待 MappedFile 创建完毕之后，其便会从请求表 requestTable 中取出并删除表中记录:\npublic class AllocateMappedFileService extends ServiceThread { public MappedFile putRequestAndReturnMappedFile(String nextFilePath, String nextNextFilePath, int fileSize) { // ...  AllocateRequest result = this.requestTable.get(nextFilePath); if (result != null) { // 等待 MappedFile 的创建完成  boolean waitOK = result.getCountDownLatch().await(waitTimeOut, TimeUnit.MILLISECONDS); if (!waitOK) { return null; } else { // 从请求表中删除  this.requestTable.remove(nextFilePath); return result.getMappedFile(); } } } } 然后再将其放到列表中去:\npublic class MappedFileQueue { public MappedFile getLastMappedFile(final long startOffset, boolean needCreate) { MappedFile mappedFile = null; if (this.allocateMappedFileService != null) { // 创建 MappedFile  mappedFile = this.allocateMappedFileService .putRequestAndReturnMappedFile(nextFilePath, nextNextFilePath, this.mappedFileSize); } if (mappedFile != null) { // ...  // 添加至列表中  this.mappedFiles.add(mappedFile); } return mappedFile; } } 至此，MappedFile 已经创建完毕，也即可以进行下一步的操作了。\n三、文件初始化 在 MappedFile 的构造函数中，其使用了 FileChannel 类提供的 map 函数来将磁盘上的这个文件映射到进程地址空间中。然后当通过 MappedByteBuffer 来读入或者写入文件的时候，磁盘上也会有相应的改动。采用这种方式，通常比传统的基于文件 IO 流的方式读取效率高。\npublic class MappedFile extends ReferenceResource { public MappedFile(final String fileName, final int fileSize) throws IOException { init(fileName, fileSize); } private void init(final String fileName, final int fileSize) throws IOException { // ...  this.fileChannel = new RandomAccessFile(this.file, \u0026#34;rw\u0026#34;).getChannel(); this.mappedByteBuffer = this.fileChannel.map(MapMode.READ_WRITE, 0, fileSize); // ...  } } 四、消息文件加载 前面提到过，Broker 在启动的时候，会加载磁盘上的文件到一个 mappedFiles 列表中。但是加载完毕后，其还会对这份列表中的消息文件进行验证 (恢复)，确保没有错误。\n验证的基本想法是通过一一读取列表中的每一个文件，然后再一一读取每个文件中的每个消息，在读取的过程中，其会更新整体的消息写入的偏移量，如下图中的红色箭头 (我们假设最终读取的消息的总偏移量为 905):\n当确定消息整体的偏移量之后，Broker 便会确定每一个单独的 MappedFile 文件的各自的偏移量，每一个文件的偏移量是通过取余算法确定的:\npublic class MappedFileQueue { public void truncateDirtyFiles(long offset) { for (MappedFile file : this.mappedFiles) { long fileTailOffset = file.getFileFromOffset() + this.mappedFileSize; if (fileTailOffset \u0026gt; offset) { if (offset \u0026gt;= file.getFileFromOffset()) { // 确定每个文件的各自偏移量  file.setWrotePosition((int) (offset % this.mappedFileSize)); file.setCommittedPosition((int) (offset % this.mappedFileSize)); file.setFlushedPosition((int) (offset % this.mappedFileSize)); } else { // ...  } } } // ...  } } 在确定每个消息文件各自的写入位置的同时，其还会删除起始偏移量大于当前总偏移量的消息文件，这些文件可以视作脏文件，或者也可以说这些文件里面一条消息也没有。这也是上述文件 1073741824 被打上红叉的原因:\npublic void truncateDirtyFiles(long offset) { List\u0026lt;MappedFile\u0026gt; willRemoveFiles = new ArrayList\u0026lt;MappedFile\u0026gt;(); for (MappedFile file : this.mappedFiles) { long fileTailOffset = file.getFileFromOffset() + this.mappedFileSize; if (fileTailOffset \u0026gt; offset) { if (offset \u0026gt;= file.getFileFromOffset()) { // ...  } else { // 总偏移量 \u0026lt; 文件起始偏移量  // 加入到待删除列表中  file.destroy(1000); willRemoveFiles.add(file); } } } this.deleteExpiredFile(willRemoveFiles); } 五、写入消息 一旦我们获取到 MappedFile 文件之后，我们便可以往这个文件里面写入消息了。写入消息可能会遇见如下两种情况，一种是这条消息可以完全追加到这个文件中，另外一种是这条消息完全不能或者只有一小部分只能存放到这个文件中，其余的需要放到新的文件中。我们对于这两种情况分别讨论:\n(1) 文件可以完全存储消息 MappedFile 类维护了一个用以标识当前写位置的指针 wrotePosition，以及一个用来映射文件到进程地址空间的 mappedByteBuffer:\npublic class MappedFile extends ReferenceResource { protected final AtomicInteger wrotePosition = new AtomicInteger(0); private MappedByteBuffer mappedByteBuffer; } 由这两个数据结构我们可以看出来，单个文件的消息写入过程其实是非常简单的。首先获取到这个文件的写入位置，然后将消息内容追加到 byteBuffer 中，然后再更新写入位置。\npublic class MappedFile extends ReferenceResource { public AppendMessageResult appendMessagesInner(final MessageExt messageExt, final AppendMessageCallback cb) { // ...  int currentPos = this.wrotePosition.get(); if (currentPos \u0026lt; this.fileSize) { ByteBuffer byteBuffer = writeBuffer != null ? writeBuffer.slice() : this.mappedByteBuffer.slice(); // 更新 byteBuffer 位置  byteBuffer.position(currentPos); // 写入消息内容  // ...  // 更新 wrotePosition 指针的位置  this.wrotePosition.addAndGet(result.getWroteBytes()); return result; } } } 示例流程如下所示:\n(2) 文件不可以完全存储消息 在写入消息之前，如果判断出文件已经满了的情况下，其会直接尝试创建一个新的 MappedFile:\npublic class CommitLog { public PutMessageResult putMessage(final MessageExtBrokerInner msg) { // 文件为空 || 文件已经满了  if (null == mappedFile || mappedFile.isFull()) { mappedFile = this.mappedFileQueue.getLastMappedFile(0); } // ...  result = mappedFile.appendMessage(msg, this.appendMessageCallback); } } 如果文件未满，那么在写入之前会先计算出消息体长度 msgLen，然后判断这个文件剩下的空间是否有能力容纳这条消息。在这个地方我们还需要介绍下每条消息的存储方式。\n每条消息的存储是按照一个 4 字节的长度来做界限的，这个长度本身就是整个消息体的长度，当读完这整条消息体的长度之后，下一次再取出来的一个 4 字节的数字，便又是下一条消息的长度:\n围绕着一条消息，还会存储许多其它内容，我们在这里只需要了解前两位是 4 字节的长度和 4 字节的 MAGICCODE 即可:\nMAGICCODE 的可选值有:\n CommitLog.MESSAGE_MAGIC_CODE CommitLog.BLANK_MAGIC_CODE  当这个文件有能力容纳这条消息体的情况下，其便会存储 MESSAGE_MAGIC_CODE 值；当这个文件没有能力容纳这条消息体的情况下，其便会存储 BLANK_MAGIC_CODE 值。所以这个 MAGICCODE 是用来界定这是空消息还是一条正常的消息。\n当判定这个文件不足以容纳整个消息的时候，其将消息体长度设置为这个文件剩余的最大空间长度，将 MAGICCODE 设定为这是一个空消息文件 (需要去下一个文件去读)。由此我们可以看出消息体长度 和 MAGICCODE 是判别一条消息格式的最基本要求，这也是 END_FILE_MIN_BLANK_LENGTH 的值为 8 的原因:\n// CommitLog.java class DefaultAppendMessageCallback implements AppendMessageCallback { // File at the end of the minimum fixed length empty  private static final int END_FILE_MIN_BLANK_LENGTH = 4 + 4; public AppendMessageResult doAppend(final long fileFromOffset, final ByteBuffer byteBuffer, final int maxBlank, final MessageExtBrokerInner msgInner) { // ...  if ((msgLen + END_FILE_MIN_BLANK_LENGTH) \u0026gt; maxBlank) { // ...  // 1 TOTALSIZE  this.msgStoreItemMemory.putInt(maxBlank); // 2 MAGICCODE  this.msgStoreItemMemory.putInt(CommitLog.BLANK_MAGIC_CODE); // 3 The remaining space may be any value  byteBuffer.put(this.msgStoreItemMemory.array(), 0, maxBlank); return new AppendMessageResult(AppendMessageStatus.END_OF_FILE, /** other params **/ ); } } } 由上述方法我们看出在这种情况下返回的结果是 END_OF_FILE。当检测到这种返回结果的时候，CommitLog 接着又会申请创建新的 MappedFile 并尝试写入消息。追加方法同 (1) 相同，不再赘述:\n 注: 在消息文件加载的过程中，其也是通过判断 MAGICCODE 的类型，来判断是否继续读取下一个 MappedFile 来计算整体消息偏移量的。\n 六、消息刷盘策略 当消息体追加到 MappedFile 以后，这条消息实际上还只是存储在内存中，因此还需要将内存中的内容刷到磁盘上才算真正的存储下来，才能确保消息不丢失。一般而言，刷盘有两种策略: 异步刷盘和同步刷盘。\n(1) 异步刷盘 当配置为异步刷盘策略的时候，Broker 会运行一个服务 FlushRealTimeService 用来刷新缓冲区的消息内容到磁盘，这个服务使用一个独立的线程来做刷盘这件事情，默认情况下每隔 500ms 来检查一次是否需要刷盘:\nclass FlushRealTimeService extends FlushCommitLogService { public void run() { // 不停运行  while (!this.isStopped()) { // interval 默认值是 500ms  if (flushCommitLogTimed) { Thread.sleep(interval); } else { this.waitForRunning(interval); } // 刷盘  CommitLog.this.mappedFileQueue.flush(flushPhysicQueueLeastPages); } } } 在追加消息完毕之后，通过唤醒这个服务立即检查以下是否需要刷盘:\npublic class CommitLog { public void handleDiskFlush(AppendMessageResult result, PutMessageResult putMessageResult, MessageExt messageExt) { // Synchronization flush  if (FlushDiskType.SYNC_FLUSH == this.defaultMessageStore.getMessageStoreConfig().getFlushDiskType()) { // ...  } // Asynchronous flush  else { if (!this.defaultMessageStore.getMessageStoreConfig().isTransientStorePoolEnable()) { // 消息追加成功后，立即唤醒服务  flushCommitLogService.wakeup(); } else { // ...  } } } } (2) 同步刷盘 当配置为同步刷盘策略的时候，Broker 运行一个叫做 GroupCommitService 服务。在这个服务内部维护了一个写请求队列和一个读请求队列，其中这两个队列每隔 10ms 就交换一下“身份”，这么做的目的其实也是为了读写分离:\n在这个服务内部，每隔 10ms 就会检查读请求队列是否不为空，如果不为空，则会将读队列中的所有请求执行刷盘，并清空读请求队列:\nclass GroupCommitService extends FlushCommitLogService { private void doCommit() { // 检查所有读队列中的请求  for (GroupCommitRequest req : this.requestsRead) { // 每个请求执行刷盘  CommitLog.this.mappedFileQueue.flush(0); req.wakeupCustomer(flushOK); } this.requestsRead.clear(); } } 在追加消息完毕之后，通过创建一个请求刷盘的对象，然后通过 putRequest() 方法放入写请求队列中，这个时候会立即唤醒这个服务，写队列和读队列的角色会进行交换，交换角色之后，读请求队列就不为空，继而可以执行所有刷盘请求了。而在这期间，Broker 会一直阻塞等待最多 5 秒钟，在这期间如果完不成刷盘请求的话，那么视作刷盘超时:\npublic class CommitLog { public void handleDiskFlush(AppendMessageResult result, PutMessageResult putMessageResult, MessageExt messageExt) { // Synchronization flush  if (FlushDiskType.SYNC_FLUSH == this.defaultMessageStore.getMessageStoreConfig().getFlushDiskType()) { // ...  if (messageExt.isWaitStoreMsgOK()) { GroupCommitRequest request = new GroupCommitRequest(result.getWroteOffset() + result.getWroteBytes()); service.putRequest(request); // 等待刷盘成功  boolean flushOK = request.waitForFlush(this.defaultMessageStore.getMessageStoreConfig().getSyncFlushTimeout()); if (!flushOK) { // 刷盘超时  putMessageResult.setPutMessageStatus(PutMessageStatus.FLUSH_DISK_TIMEOUT); } } else { // ...  } } // Asynchronous flush  else { // ...  } } } 通过方法 putRequest 放入请求后的服务执行流程:\n七、消息刷盘理念 我们在这里已经知道消息刷盘有同步刷盘和异步刷盘策略，对应的是 GroupCommitService 和 FlushRealTimeService 这两种不同的服务。\n这两种服务都有定时请求刷盘的机制，但是机制背后最终调用的刷盘方式全部都集中在 flush 这个方法上:\npublic class MappedFileQueue { public boolean flush(final int flushLeastPages) { // ...  } } 再继续向下分析这个方法之前，我们先对照着这张图说明一下使用 MappedByteBuffer 来简要阐述读和写文件的简单过程：\n操作系统为了能够使多个进程同时使用内存，又保证各个进程访问内存互相独立，于是为每个进程引入了地址空间的概念，地址空间上的地址叫做虚拟地址，而程序想要运行必须放到物理地址上运行才可以。地址空间为进程营造出了一种假象：”整台计算机只有我一个程序在运行，这台计算机内存很大”。一个地址空间内包含着这个进程所需要的全部状态信息。通常一个进程的地址空间会按照逻辑分成好多段，比如代码段、堆段、栈段等。为了进一步有效利用内存，每一段又细分成了不同的页 (page)。与此相对应，计算机的物理内存被切成了页帧 (page frame)，文件被分成了块 (block)。既然程序实际运行的时候还是得依赖物理内存的地址，那么就需要将虚拟地址转换为物理地址，这个映射关系是由**页表 (page table)**来完成的。\n另外在操作系统中，还有一层磁盘缓存 (disk cache)的概念，它主要是用来减少对磁盘的 I/O 操作。磁盘缓存是以页为单位的，内容就是磁盘上的物理块，所以又称之为页缓存 (page cache)。当进程发起一个读操作 （比如，进程发起一个 read() 系统调用），它首先会检查需要的数据是否在页缓存中。如果在，则放弃访问磁盘，而直接从页缓存中读取。如果数据没在缓存中，那么内核必须调度块 I/O 操作从磁盘去读取数据，然后将读来的数据放入页缓存中。系统并不一定要将整个文件都缓存，它可以只存储一个文件的一页或者几页。\n如图所示，当调用 FileChannel.map() 方法的时候，会将这个文件映射进用户空间的地址空间中，注意，建立映射不会拷贝任何数据。我们前面提到过 Broker 启动的时候会有一个消息文件加载的过程，当第一次开始读取数据的时候:\n// 首次读取数据 int totalSize = byteBuffer.getInt(); 这个时候，操作系统通过查询页表，会发现文件的这部分数据还不在内存中。于是就会触发一个缺页异常 (page faults)，这个时候操作系统会开始从磁盘读取这一页数据，然后先放入到页缓存中，然后再放入内存中。在第一次读取文件的时候，操作系统会读入所请求的页面，并读入紧随其后的少数几个页面（不少于一个页面，通常是三个页面），这时的预读称为同步预读 (如下图所示，红色部分是需要读取的页面，蓝色的那三个框是操作系统预先读取的):\n当然随着时间推移，预读命中的话，那么相应的预读页面数量也会增加，但是能够确认的是，一个文件至少有 4 个页面处在页缓存中。当文件一直处于顺序读取的情况下，那么基本上可以保证每次预读命中:\n下面我们来说文件写，正常情况下，当尝试调用 writeInt() 写数据到文件里面的话，其写到页缓存层，这个方法就会返回了。这个时候数据还没有真正的保存到文件中去，Linux 仅仅将页缓存中的这一页数据标记为“脏”，并且被加入到脏页链表中。然后由一群进程（flusher 回写进程）周期性将脏页链表中的页写会到磁盘，从而让磁盘中的数据和内存中保持一致，最后清理“脏”标识。在以下三种情况下，脏页会被写回磁盘:\n 空闲内存低于一个特定阈值 脏页在内存中驻留超过一个特定的阈值时 当用户进程调用 sync() 和 fsync() 系统调用时  可见，在正常情况下，即使不采用刷盘策略，数据最终也是会被同步到磁盘中去的:\n但是，即便有 flusher 线程来定时同步数据，如果此时机器断电的话，消息依然有可能丢失。RocketMQ 为了保证消息尽可能的不丢失，为了最大的高可靠性，做了同步和异步刷盘策略，来手动进行同步:\n八、消息刷盘过程 在介绍完上述消息刷盘背后的一些机制和理念后，我们再来分析刷盘整个过程。首先，无论同步刷盘还是异步刷盘，其线程都在一直周期性的尝试执行刷盘，在真正执行刷盘函数的调用之前，Broker 会检查文件的写位置是否大于 flush 位置，避免执行无意义的刷盘：\n其次，对于异步刷盘来讲，Broker 执行了更为严格的刷盘限制策略，当在某个时间点尝试执行刷盘之后，在接下来 10 秒内，如果想要继续刷盘，那么脏页面数量必须不小于 4 页，如下图所示:\n下面是执行刷盘前最后检查的刷盘条件：\npublic class MappedFile extends ReferenceResource { private boolean isAbleToFlush(final int flushLeastPages) { int flush = this.flushedPosition.get(); int write = getReadPosition(); if (this.isFull()) { return true; } if (flushLeastPages \u0026gt; 0) { // 计算当前脏页面算法  return ((write / OS_PAGE_SIZE) - (flush / OS_PAGE_SIZE)) \u0026gt;= flushLeastPages; } // wrotePosition \u0026gt; flushedPosition  return write \u0026gt; flush; } } 当刷盘完毕之后，首先会更新这个文件的 flush 位置，然后再更新 MappedFileQueue 的整体的 flush 位置:\n当刷盘完毕之后，便会将结果通知给客户端，告知发送消息成功。至此，整个存储过程完毕。\n"});index.add({'id':9,'href':'/docs/books/history_of_quantum_physics/','title':"上帝掷骰子吗",'content':"上帝掷骰子吗-量子物理史话 1887年德国，赫兹在实验室证实了电磁波的存在，也证实了光其实是电磁波的一种，两者具有共同的波的特性，古老的光学终于可以被完全包容于新兴的电磁学里面。1901年，赫兹死后的第 7 年，无线电报已经可以穿越大西洋，实现两地的实时通讯了。\n赫兹铜环接收器的缺口之间不停地爆发着电火花，明白无误地昭示着电磁波的存在。但偶然间，赫兹又发现了一个奇怪的现象：当有光照射到这个缺口上的时候，似乎火花就出现得更容易一些。\n 量子就是能量的最小单位，就是能量里的一美分。一切能量的传输，都只能以这个量为单位来进行，它可以传输一个量子，两个量子，任意整数个量子，但却不能传输1 又1/2 个量子，那个状态是不允许的，就像你不能用现钱支付1 又1/2 美分一样。这个值，现在已经成为了自然科学中最为 重要的常数之一，以它的发现者命名，称为“普朗克常数”，用 h 来表示。\n在后来十几年的时间里，普朗克一直认为量子的假设并不是一个物理真实，而纯粹是一个为了方便而引入的假设而已。他不断地告诫人们，在引用普朗克常数 h 的时候，要尽量小心谨慎，不到万不得已千万不要胡思乱想。\n"});index.add({'id':10,'href':'/docs/rocketmq/rocketmq-message-receive-flow/','title':"RocketMQ 消息接受流程",'content':"RocketMQ 消息接受流程 本篇讲述 RocketMQ 消息接受流程\n一、消费者注册 生产者负责往服务器 Broker 发送消息，消费者则从 Broker 获取消息。消费者获取消息采用的是订阅者模式，即消费者客户端可以任意订阅一个或者多个话题来消费消息:\npublic class Consumer { public static void main(String[] args) throws InterruptedException, MQClientException { /* * 订阅一个或者多个话题 */ consumer.subscribe(\u0026#34;TopicTest\u0026#34;, \u0026#34;*\u0026#34;); } } 当消费者客户端启动以后，其会每隔 30 秒从命名服务器查询一次用户订阅的所有话题路由信息:\npublic class MQClientInstance { private void startScheduledTask() { this.scheduledExecutorService.scheduleAtFixedRate(new Runnable() { @Override public void run() { // 从命名服务器拉取话题信息  MQClientInstance.this.updateTopicRouteInfoFromNameServer(); } }, 10, this.clientConfig.getPollNameServerInterval(), TimeUnit.MILLISECONDS); } } 我们由 RocketMQ 消息发送流程 这篇文章知道 RocketMQ 在发送消息的时候，每条消息会以轮循的方式均衡地分发的不同 Broker 的不同队列中去。由此，消费者客户端从服务器命名服务器获取下来的便是话题的所有消息队列:\n在获取话题路由信息的时候，客户端还会将话题路由信息中的所有 Broker 地址保存到本地:\npublic class MQClientInstance { public boolean updateTopicRouteInfoFromNameServer(final String topic, boolean isDefault, DefaultMQProducer defaultMQProducer) { // ...  if (changed) { TopicRouteData cloneTopicRouteData = topicRouteData.cloneTopicRouteData(); // 更新 Broker 地址列表  for (BrokerData bd : topicRouteData.getBrokerDatas()) { this.brokerAddrTable.put(bd.getBrokerName(), bd.getBrokerAddrs()); } return true; } // ...  } } 当消费者客户端获取到了 Broker 地址列表之后，其便会每隔 30 秒给服务器发送一条心跳数据包，告知所有 Broker 服务器这台消费者客户端的存在。在每次发送心跳包的同时，其数据包内还会捎带这个客户端消息订阅的一些组信息，比如用户订阅了哪几个话题等，与此相对应，每台 Broker 服务器会在内存中维护一份当前所有的消费者客户端列表信息:\npublic class ConsumerManager { private final ConcurrentMap\u0026lt;String/* Group */, ConsumerGroupInfo\u0026gt; consumerTable = new ConcurrentHashMap\u0026lt;String, ConsumerGroupInfo\u0026gt;(1024); } 消费者客户端与 Broker 服务器进行沟通的整体流程如下图所示：\n二、消息队列负载均衡 我们知道无论发送消息还是接受消息都需要指定消息的话题，然而实际上消息在 Broker 服务器上并不是以话题为单位进行存储的，而是采用了比话题更细粒度的队列来进行存储的。当你发送了 10 条相同话题的消息，这 10 条话题可能存储在了不同 Broker 服务器的不同队列中。由此，我们说 RocketMQ 管理消息的单位不是话题，而是队列。\n当我们讨论消息队列负载均衡的时候，就是在讨论服务器端的所有队列如何给所有消费者消费的问题。在 RocketMQ 中，客户端有两种消费模式，一种是广播模式，另外一种是集群模式。\n我们现在假设总共有两台 Broker 服务器，假设用户使用 Producer 已经发送了 8 条消息，这 8 条消息现在均衡的分布在两台 Broker 服务器的 8 个队列中，每个队列中有一个消息。现在有 3 台都订阅了 Test 话题的消费者实例，我们来看在不同消费模式下，不同的消费者会收到哪几条消息。\n(1) 广播模式 广播模式是指所有消息队列中的消息都会广播给所有的消费者客户端，如下图所示，每一个消费者都能收到这 8 条消息:\n(2) 集群模式 集群模式是指所有的消息队列会按照某种分配策略来分给不同的消费者客户端，比如消费者 A 消费前 3 个队列中的消息，消费者 B 消费中间 3 个队列中的消息等等。我们现在着重看 RocketMQ 为我们提供的三个比较重要的消息队列分配策略:\n1. 平均分配策略 平均分配策略下，三个消费者的消费情况如下所示：\n Consumer-1 消费前 3 个消息队列中的消息 Consumer-2 消费中间 3 个消息队列中的消息 Consumer-3 消费最后 2 个消息队列中的消息  2. 平均分配轮循策略 平均分配轮循策略下，三个消费者的消费情况如下所示：\n Consumer-1 消费 1、4、7消息队列中的消息 Consumer-2 消费 2、5、8消息队列中的消息 Consumer-3 消费 3、6消息队列中的消息  3. 一致性哈希策略 一致性哈希算法是根据这三台消费者各自的某个有代表性的属性(我们假设就是客户端ID)来计算出三个 Hash 值，此处为了减少由于 Hash 函数选取的不理想的情况， RocketMQ 算法对于每个消费者通过在客户端ID后面添加 1、2、3 索引来使每一个消费者多生成几个哈希值。那么现在我们需要哈希的就是九个字符串:\n Consumer-1-1 Consumer-1-2 Consumer-1-3 Consumer-2-1 Consumer-2-2 Consumer-2-3 Consumer-3-1 Consumer-3-2 Consumer-3-3  计算完这 9 个哈希值以后，我们按照从小到大的顺序来排列成一个环 (如图所示)。这个时候我们需要一一对这 8 个消息队列也要计算一下 Hash 值，当 Hash 值落在两个圈之间的时候，我们就选取沿着环的方向的那个节点作为这个消息队列的消费者。如下图所示 (注意: 图只是示例，并非真正的消费情况):\n在一致性哈希策略下，三个消费者的消费情况如下所示：\n Consumer-1 消费 1、2、3、4消息队列中的消息 Consumer-2 消费 5、8消息队列中的消息 Consumer-3 消费 6、7消息队列中的消息  消息队列的负载均衡是由一个不停运行的均衡服务来定时执行的:\npublic class RebalanceService extends ServiceThread { // 默认 20 秒一次  private static long waitInterval = Long.parseLong(System.getProperty(\u0026#34;rocketmq.client.rebalance.waitInterval\u0026#34;, \u0026#34;20000\u0026#34;)); @Override public void run() { while (!this.isStopped()) { this.waitForRunning(waitInterval); // 重新执行消息队列的负载均衡  this.mqClientFactory.doRebalance(); } } } 接着往下看，会知道在广播模式下，当前这台消费者消费和话题相关的所有消息队列，而集群模式会先按照某种分配策略来进行消息队列的分配，得到的结果就是当前这台消费者需要消费的消息队列:\npublic abstract class RebalanceImpl { private void rebalanceByTopic(final String topic, final boolean isOrder) { switch (messageModel) { // 广播模式  case BROADCASTING: { // 消费这个话题的所有消息队列  Set\u0026lt;MessageQueue\u0026gt; mqSet = this.topicSubscribeInfoTable.get(topic); if (mqSet != null) { // ...  } break; } // 集群模式  case CLUSTERING: { // ...  // 按照某种负载均衡策略进行消息队列和消费客户端之间的分配  // allocateResult 就是当前这台消费者被分配到的消息队列  allocateResult = strategy.allocate( this.consumerGroup, this.mQClientFactory.getClientId(), mqAll, cidAll); // ...  } break; } } } 三、Broker 消费队列文件 现在我们再来看 Broker 服务器端。首先我们应该知道，消息往 Broker 存储就是在向 CommitLog 消息文件中写入数据的一个过程。在 Broker 启动过程中，其会启动一个叫做 ReputMessageService 的服务，这个服务每隔 1 秒会检查一下这个 CommitLog 是否有新的数据写入。ReputMessageService 自身维护了一个偏移量 reputFromOffset，用以对比和 CommitLog 文件中的消息总偏移量的差距。当这两个偏移量不同的时候，就代表有新的消息到来了:\nclass ReputMessageService extends ServiceThread { private volatile long reputFromOffset = 0; private boolean isCommitLogAvailable() { // 看当前有没有新的消息到来  return this.reputFromOffset \u0026lt; DefaultMessageStore.this.commitLog.getMaxOffset(); } @Override public void run() { while (!this.isStopped()) { try { Thread.sleep(1); this.doReput(); } catch (Exception e) { DefaultMessageStore.log.warn(this.getServiceName() + \u0026#34; service has exception. \u0026#34;, e); } } } } 在有新的消息到来之后，doReput() 函数会取出新到来的所有消息，每一条消息都会封装为一个 DispatchRequest 请求，进而将这条请求分发给不同的请求消费者，我们在这篇文章中只会关注利用消息创建消费队列的服务 CommitLogDispatcherBuildConsumeQueue:\nclass ReputMessageService extends ServiceThread { // ... 部分代码有删减  private void doReput() { SelectMappedBufferResult result = DefaultMessageStore.this.commitLog.getData(reputFromOffset); if (result != null) { this.reputFromOffset = result.getStartOffset(); for (int readSize = 0; readSize \u0026lt; result.getSize() \u0026amp;\u0026amp; doNext; ) { // 读取一条消息，然后封装为 DispatchRequest  DispatchRequest dispatchRequest = DefaultMessageStore.this.commitLog.checkMessageAndReturnSize(result.getByteBuffer(), false, false); int size = dispatchRequest.getMsgSize(); if (dispatchRequest.isSuccess()) { // 分发这个 DispatchRequest 请求  DefaultMessageStore.this.doDispatch(dispatchRequest); this.reputFromOffset += size; readSize += size; } // ...  } } } } CommitLogDispatcherBuildConsumeQueue 服务会根据这条请求按照不同的队列 ID 创建不同的消费队列文件，并在内存中维护一份消费队列列表。然后将 DispatchRequest 请求中这条消息的消息偏移量、消息大小以及消息在发送时候附带的标签的 Hash 值写入到相应的消费队列文件中去。\n消费队列文件的创建与消息存储 CommitLog 文件的创建过程是一致的，只是路径不同，这里不再赘述。\n寻找消费队列的代码如下:\npublic class DefaultMessageStore implements MessageStore { private final ConcurrentMap\u0026lt;String/* topic */, ConcurrentMap\u0026lt;Integer/* queueId */, ConsumeQueue\u0026gt;\u0026gt; consumeQueueTable; public void putMessagePositionInfo(DispatchRequest dispatchRequest) { ConsumeQueue cq = this.findConsumeQueue(dispatchRequest.getTopic(), dispatchRequest.getQueueId()); cq.putMessagePositionInfoWrapper(dispatchRequest); } } 向消费队列文件中存储数据的代码如下:\npublic class ConsumeQueue { private boolean putMessagePositionInfo(final long offset, final int size, final long tagsCode, final long cqOffset) { // 存储偏移量、大小、标签码  this.byteBufferIndex.flip(); this.byteBufferIndex.limit(CQ_STORE_UNIT_SIZE); this.byteBufferIndex.putLong(offset); this.byteBufferIndex.putInt(size); this.byteBufferIndex.putLong(tagsCode); // 获取消费队列文件  final long expectLogicOffset = cqOffset * CQ_STORE_UNIT_SIZE; MappedFile mappedFile = this.mappedFileQueue.getLastMappedFile(expectLogicOffset); if (mappedFile != null) { // ...  return mappedFile.appendMessage(this.byteBufferIndex.array()); } return false; } } 以上阐述了消费队列创建并存储消息的一个过程，但是消费队列文件中的消息是需要持久化到磁盘中去的。持久化的过程是通过后台服务 FlushConsumeQueueService 来定时持久化的:\nclass FlushConsumeQueueService extends ServiceThread { private void doFlush(int retryTimes) { // ...  ConcurrentMap\u0026lt;String, ConcurrentMap\u0026lt;Integer, ConsumeQueue\u0026gt;\u0026gt; tables = DefaultMessageStore.this.consumeQueueTable; for (ConcurrentMap\u0026lt;Integer, ConsumeQueue\u0026gt; maps : tables.values()) { for (ConsumeQueue cq : maps.values()) { boolean result = false; for (int i = 0; i \u0026lt; retryTimes \u0026amp;\u0026amp; !result; i++) { // 刷新到磁盘  result = cq.flush(flushConsumeQueueLeastPages); } } } // ...  } } 上述过程体现在磁盘文件的变化如下图所示，commitLog 文件夹下面存放的是完整的消息，来一条消息，向文件中追加一条消息。同时，根据这一条消息属于 TopicTest 话题下的哪一个队列，又会往相应的 consumequeue 文件下的相应消费队列文件中追加消息的偏移量、消息大小和标签码:\n总流程图如下所示:\n四、消息队列偏移量 Broker 服务器存储了各个消费队列，客户端需要消费每个消费队列中的消息。消费模式的不同，每个客户端所消费的消息队列也不同。那么客户端如何记录自己所消费的队列消费到哪里了呢？答案就是消费队列偏移量。\n针对同一话题，在集群模式下，由于每个客户端所消费的消息队列不同，所以每个消息队列已经消费到哪里的消费偏移量是记录在 Broker 服务器端的。而在广播模式下，由于每个客户端分配消费这个话题的所有消息队列，所以每个消息队列已经消费到哪里的消费偏移量是记录在客户端本地的。\n下面分别讲述两种模式下偏移量是如何获取和更新的:\n(1) 集群模式 在集群模式下，消费者客户端在内存中维护了一个 offsetTable 表:\npublic class RemoteBrokerOffsetStore implements OffsetStore { private ConcurrentMap\u0026lt;MessageQueue, AtomicLong\u0026gt; offsetTable = new ConcurrentHashMap\u0026lt;MessageQueue, AtomicLong\u0026gt;(); } 同样在 Broker 服务器端也维护了一个偏移量表:\npublic class ConsumerOffsetManager extends ConfigManager { private ConcurrentMap\u0026lt;String/* topic@group */, ConcurrentMap\u0026lt;Integer, Long\u0026gt;\u0026gt; offsetTable = new ConcurrentHashMap\u0026lt;String, ConcurrentMap\u0026lt;Integer, Long\u0026gt;\u0026gt;(512); } 在消费者客户端，RebalanceService 服务会定时地 (默认 20 秒) 从 Broker 服务器获取当前客户端所需要消费的消息队列，并与当前消费者客户端的消费队列进行对比，看是否有变化。对于每个消费队列，会从 Broker 服务器查询这个队列当前的消费偏移量。然后根据这几个消费队列，创建对应的拉取请求 PullRequest 准备从 Broker 服务器拉取消息，如下图所示:\n当从 Broker 服务器拉取下来消息以后，只有当用户成功消费的时候，才会更新本地的偏移量表。本地的偏移量表再通过定时服务每隔 5 秒同步到 Broker 服务器端:\npublic class MQClientInstance { private void startScheduledTask() { this.scheduledExecutorService.scheduleAtFixedRate(new Runnable() { @Override public void run() { MQClientInstance.this.persistAllConsumerOffset(); } }, 1000 * 10, this.clientConfig.getPersistConsumerOffsetInterval(), TimeUnit.MILLISECONDS); } } 而维护在 Broker 服务器端的偏移量表也会每隔 5 秒钟序列化到磁盘中:\npublic class BrokerController { public boolean initialize() throws CloneNotSupportedException { this.scheduledExecutorService.scheduleAtFixedRate(new Runnable() { @Override public void run() { BrokerController.this.consumerOffsetManager.persist(); } }, 1000 * 10, this.brokerConfig.getFlushConsumerOffsetInterval(), TimeUnit.MILLISECONDS); } } 保存的格式如下所示：\n上述整体流程如下所示，红框框住的是这个话题下面的队列的 ID，箭头指向的分别是每个队列的消费偏移量：\n(2) 广播模式 对于广播模式而言，每个消费队列的偏移量肯定不能存储在 Broker 服务器端，因为多个消费者对于同一个队列的消费可能不一致，偏移量会互相覆盖掉。因此，在广播模式下，每个客户端的消费偏移量是存储在本地的，然后每隔 5 秒将内存中的 offsetTable 持久化到磁盘中。当首次从服务器获取可消费队列的时候，偏移量不像集群模式下是从 Broker 服务器读取的，而是直接从本地文件中读取的:\npublic class LocalFileOffsetStore implements OffsetStore { @Override public long readOffset(final MessageQueue mq, final ReadOffsetType type) { if (mq != null) { switch (type) { case READ_FROM_STORE: { // 本地读取  offsetSerializeWrapper = this.readLocalOffset(); // ...  } } } // ...  } } 当消息消费成功后，偏移量的更新也是持久化到本地，而非更新到 Broker 服务器中。这里提一下，在广播模式下，消息队列的偏移量默认放在用户目录下的 .rocketmq_offsets 目录下:\npublic class LocalFileOffsetStore implements OffsetStore { @Override public void persistAll(Set\u0026lt;MessageQueue\u0026gt; mqs) { // ...  String jsonString = offsetSerializeWrapper.toJson(true); MixAll.string2File(jsonString, this.storePath); // ...  } } 存储格式如下：\n简要流程图如下：\n五、拉取消息 在客户端运行着一个专门用来拉取消息的后台服务 PullMessageService，其接受每个队列创建 PullRequest 拉取消息请求，然后拉取消息:\npublic class PullMessageService extends ServiceThread { @Override public void run() { while (!this.isStopped()) { PullRequest pullRequest = this.pullRequestQueue.take(); if (pullRequest != null) { this.pullMessage(pullRequest); } } } } 每一个 PullRequest 都关联着一个 MessageQueue 和一个 ProcessQueue，在 ProcessQueue 的内部还维护了一个用来等待用户消费的消息树，如下代码所示:\npublic class PullRequest { private MessageQueue messageQueue; private ProcessQueue processQueue; } public class ProcessQueue { private final TreeMap\u0026lt;Long, MessageExt\u0026gt; msgTreeMap = new TreeMap\u0026lt;Long, MessageExt\u0026gt;(); } 当真正尝试拉取消息之前，其会检查当前请求的内部缓存的消息数量、消息大小、消息阈值跨度是否超过了某个阈值，如果超过某个阈值，则推迟 50 毫秒重新执行这个请求:\npublic class DefaultMQPushConsumerImpl implements MQConsumerInner { public void pullMessage(final PullRequest pullRequest) { // ...  final ProcessQueue processQueue = pullRequest.getProcessQueue(); long cachedMessageCount = processQueue.getMsgCount().get(); long cachedMessageSizeInMiB = processQueue.getMsgSize().get() / (1024 * 1024); // 缓存消息数量阈值，默认为 1000  if (cachedMessageCount \u0026gt; this.defaultMQPushConsumer.getPullThresholdForQueue()) { this.executePullRequestLater(pullRequest, PULL_TIME_DELAY_MILLS_WHEN_FLOW_CONTROL); return; } // 缓存消息大小阈值，默认为 100 MB  if (cachedMessageSizeInMiB \u0026gt; this.defaultMQPushConsumer.getPullThresholdSizeForQueue()) { this.executePullRequestLater(pullRequest, PULL_TIME_DELAY_MILLS_WHEN_FLOW_CONTROL); return; } if (!this.consumeOrderly) { // 最小偏移量和最大偏移量的阈值跨度，默认为 2000 偏移量，消费速度不能太慢  if (processQueue.getMaxSpan() \u0026gt; this.defaultMQPushConsumer.getConsumeConcurrentlyMaxSpan()) { this.executePullRequestLater(pullRequest, PULL_TIME_DELAY_MILLS_WHEN_FLOW_CONTROL); return; } } // ...  } } 当执行完一些必要的检查之后，客户端会将用户指定的过滤信息以及一些其它必要消费字段封装到请求信息体中，然后才开始从 Broker 服务器拉取这个请求从当前偏移量开始的消息，默认一次性最多拉取 32 条，服务器返回的响应会告诉客户端这个队列下次开始拉取时的偏移量。客户端每次都会注册一个 PullCallback 回调，用以接受服务器返回的响应信息，根据响应信息的不同状态信息，然后修正这个请求的偏移量，并进行下次请求:\npublic void pullMessage(final PullRequest pullRequest) { PullCallback pullCallback = new PullCallback() { @Override public void onSuccess(PullResult pullResult) { if (pullResult != null) { // ...  switch (pullResult.getPullStatus()) { case FOUND: // ...  break; case NO_NEW_MSG: // ...  break; case NO_MATCHED_MSG: // ...  break; case OFFSET_ILLEGAL: // ...  break; default: break; } } } @Override public void onException(Throwable e) { // ...  } }; } 上述是客户端拉取消息时的一些机制，现在再说一下 Broker 服务器端与此相对应的逻辑。\n服务器在收到客户端的请求之后，会根据话题和队列 ID 定位到对应的消费队列。然后根据这条请求传入的 offset 消费队列偏移量，定位到对应的消费队列文件。偏移量指定的是消费队列文件的消费下限，而最大上限是由如下算法来进行约束的:\nfinal int maxFilterMessageCount = Math.max(16000, maxMsgNums * ConsumeQueue.CQ_STORE_UNIT_SIZE); 有了上限和下限，客户端便会开始从消费队列文件中取出每个消息的偏移量和消息大小，然后再根据这两个值去 CommitLog 文件中寻找相应的完整的消息，并添加到最后的消息队列中，精简过的代码如下所示：\npublic class DefaultMessageStore implements MessageStore { public GetMessageResult getMessage(final String group, final String topic, final int queueId, final long offset, final int maxMsgNums, final MessageFilter messageFilter) { // ...  ConsumeQueue consumeQueue = findConsumeQueue(topic, queueId); if (consumeQueue != null) { // 首先根据消费队列的偏移量定位消费队列  SelectMappedBufferResult bufferConsumeQueue = consumeQueue.getIndexBuffer(offset); if (bufferConsumeQueue != null) { try { status = GetMessageStatus.NO_MATCHED_MESSAGE; // 最大消息长度  final int maxFilterMessageCount = Math.max(16000, maxMsgNums * ConsumeQueue.CQ_STORE_UNIT_SIZE); // 取消息  for (; i \u0026lt; bufferConsumeQueue.getSize() \u0026amp;\u0026amp; i \u0026lt; maxFilterMessageCount; i += ConsumeQueue.CQ_STORE_UNIT_SIZE) { long offsetPy = bufferConsumeQueue.getByteBuffer().getLong(); int sizePy = bufferConsumeQueue.getByteBuffer().getInt(); // 根据消息的偏移量和消息的大小从 CommitLog 文件中取出一条消息  SelectMappedBufferResult selectResult = this.commitLog.getMessage(offsetPy, sizePy); getResult.addMessage(selectResult); status = GetMessageStatus.FOUND; } // 增加下次开始的偏移量  nextBeginOffset = offset + (i / ConsumeQueue.CQ_STORE_UNIT_SIZE); } finally { bufferConsumeQueue.release(); } } } // ...  } } 客户端和 Broker 服务器端完整拉取消息的流程图如下所示：\n六、消费消息 依赖于用户指定的消息回调函数的不同，消息的消费分为两种: 并发消费和有序消费。\n并发消费没有考虑消息发送的顺序，客户端从服务器获取到消息就会直接回调给用户。而有序消费会考虑每个队列消息发送的顺序，注意此处并不是每个话题消息发送的顺序，一定要记住 RocketMQ 控制消息的最细粒度是消息队列。当我们讲有序消费的时候，就是在说对于某个话题的某个队列，发往这个队列的消息，客户端接受消息的顺序与发送的顺序完全一致。\n下面我们分别看这两种消费模式是如何实现的。\n(1) 并发消费 当用户注册消息回调类的时候，如果注册的是 MessageListenerConcurrently 回调类，那么就认为用户不关心消息的顺序问题。我们在上文提到过每个 PullRequest 都关联了一个处理队列 ProcessQueue，而每个处理队列又都关联了一颗消息树 msgTreeMap。当客户端拉取到新的消息以后，其先将消息放入到这个请求所关联的处理队列的消息树中，然后提交一个消息消费请求，用以回调用户端的代码消费消息:\npublic class DefaultMQPushConsumerImpl implements MQConsumerInner { public void pullMessage(final PullRequest pullRequest) { PullCallback pullCallback = new PullCallback() { @Override public void onSuccess(PullResult pullResult) { if (pullResult != null) { switch (pullResult.getPullStatus()) { case FOUND: // 消息放入处理队列的消息树中  boolean dispathToConsume = processQueue .putMessage(pullResult.getMsgFoundList()); // 提交一个消息消费请求  DefaultMQPushConsumerImpl.this .consumeMessageService .submitConsumeRequest( pullResult.getMsgFoundList(), processQueue, pullRequest.getMessageQueue(), dispathToConsume); break; } } } }; } } 当提交一个消息消费请求后，对于并发消费，其实现如下:\npublic class ConsumeMessageConcurrentlyService implements ConsumeMessageService { class ConsumeRequest implements Runnable { @Override public void run() { // ...  status = listener.consumeMessage(Collections.unmodifiableList(msgs), context); // ...  } } } 我们可以看到 msgs 是直接从服务器端拿到的最新消息，直接喂给了客户端进行消费，并未做任何有序处理。当消费成功后，会从消息树中将这些消息再给删除掉:\npublic class ConsumeMessageConcurrentlyService implements ConsumeMessageService { public void processConsumeResult(final ConsumeConcurrentlyStatus status, /** 其它参数 **/) { // 从消息树中删除消息  long offset = consumeRequest.getProcessQueue().removeMessage(consumeRequest.getMsgs()); if (offset \u0026gt;= 0 \u0026amp;\u0026amp; !consumeRequest.getProcessQueue().isDropped()) { this.defaultMQPushConsumerImpl.getOffsetStore() .updateOffset(consumeRequest.getMessageQueue(), offset, true); } } } (2) 有序消费 RocketMQ 的有序消费主要依靠两把锁，一把是维护在 Broker 端，一把维护在消费者客户端。Broker 端有一个 RebalanceLockManager 服务，其内部维护了一个 mqLockTable 消息队列锁表:\npublic class RebalanceLockManager { private final ConcurrentMap\u0026lt;String/* group */, ConcurrentHashMap\u0026lt;MessageQueue, LockEntry\u0026gt;\u0026gt; mqLockTable = new ConcurrentHashMap\u0026lt;String, ConcurrentHashMap\u0026lt;MessageQueue, LockEntry\u0026gt;\u0026gt;(1024); } 在有序消费的时候，Broker 需要确保任何一个队列在任何时候都只有一个客户端在消费它，都在被一个客户端所锁定。当客户端在本地根据消息队列构建 PullRequest 之前，会与 Broker 沟通尝试锁定这个队列，另外当进行有序消费的时候，客户端也会周期性地 (默认是 20 秒) 锁定所有当前需要消费的消息队列:\npublic class ConsumeMessageOrderlyService implements ConsumeMessageService { public void start() { if (MessageModel.CLUSTERING.equals(ConsumeMessageOrderlyService.this.defaultMQPushConsumerImpl.messageModel())) { this.scheduledExecutorService.scheduleAtFixedRate(new Runnable() { @Override public void run() { ConsumeMessageOrderlyService.this.lockMQPeriodically(); } }, 1000 * 1, ProcessQueue.REBALANCE_LOCK_INTERVAL, TimeUnit.MILLISECONDS); } } } 由上述这段代码也能看出，只在集群模式下才会周期性地锁定 Broker 端的消息队列，因此在广播模式下是不支持进行有序消费的。\n而在 Broker 这端，每个客户端所锁定的消息队列对应的锁项 LogEntry 有一个上次锁定时的时间戳，当超过锁的超时时间 (默认是 60 秒) 后，也会判定这个客户端已经不再持有这把锁，以让其他客户端能够有序消费这个队列。\n在前面我们说到过 RebalanceService 均衡服务会定时地依据不同消费者数量分配消费队列。我们假设 Consumer-1 消费者客户端一开始需要消费 3 个消费队列，这个时候又加入了 Consumer-2 消费者客户端，并且分配到了 MessageQueue-2 消费队列。当 Consumer-1 内部的均衡服务检测到当前消费队列需要移除 MessageQueue-2 队列，这个时候，会首先解除 Broker 端的锁，确保新加入的 Consumer-2 消费者客户端能够成功锁住这个队列，以进行有序消费。\npublic abstract class RebalanceImpl { private boolean updateProcessQueueTableInRebalance(final String topic, final Set\u0026lt;MessageQueue\u0026gt; mqSet, final boolean isOrder) { while (it.hasNext()) { // ...  if (mq.getTopic().equals(topic)) { // 当前客户端不需要处理这个消息队列了  if (!mqSet.contains(mq)) { pq.setDropped(true); // 解锁  if (this.removeUnnecessaryMessageQueue(mq, pq)) { // ...  } } // ...  } } } } 消费者客户端每一次拉取消息请求，如果有发现新的消息，那么都会将这些消息封装为 ConsumeRequest 来喂给消费线程池，以待消费。如果消息特别多，这样一个队列可能有多个消费请求正在等待客户端消费，用户可能会先消费偏移量大的消息，后消费偏移量小的消息。所以消费同一队列的时候，需要一把锁以消费请求顺序化:\npublic class ConsumeMessageOrderlyService implements ConsumeMessageService { class ConsumeRequest implements Runnable { @Override public void run() { final Object objLock = messageQueueLock.fetchLockObject(this.messageQueue); synchronized (objLock) { // ...  } } } } RocketMQ 的消息树是用 TreeMap 实现的，其内部基于消息偏移量维护了消息的有序性。每次消费请求都会从消息树中拿取偏移量最小的几条消息 (默认为 1 条)给用户，以此来达到有序消费的目的:\npublic class ConsumeMessageOrderlyService implements ConsumeMessageService { class ConsumeRequest implements Runnable { @Override public void run() { // ...  final int consumeBatchSize = ConsumeMessageOrderlyService.this .defaultMQPushConsumer .getConsumeMessageBatchMaxSize(); List\u0026lt;MessageExt\u0026gt; msgs = this.processQueue.takeMessags(consumeBatchSize); } } } "});index.add({'id':11,'href':'/docs/books/','title':"书籍",'content':"书籍  书籍是人类进步的阶梯。\u0026ndash; 高尔基\n "});index.add({'id':12,'href':'/docs/books/clean_code/','title':"代码整洁之道",'content':"代码整洁之道 勒布朗法则：Later equals never.\n随着混乱的增加，团队生产力也持续下降，趋近于零。生产力下降的时候，管理层只能增加更多的人手，期望提高生产力。\n什么是整洁代码  我喜欢优雅和高效的代码。代码逻辑应当直截了当，叫缺陷难以隐藏；尽量减少依赖关系，使之便于维护；依据某种分层战略完善错误处理代码；性能调至最优，省得引诱别人做没规矩的优化，搞出一堆混乱来。整洁的代码只做好一件事。\u0026mdash; Bjarne Stroustrup，C++ 语言发明者\n  整洁的代码应可由作者之外的开发者阅读和增补。它应有单元测试和验收测试。它使用有意义的命名。它只提供一种而非多种做一件事的途径。它只有尽量少的依赖关系，且要明确地定义和提供清晰、尽量少的 API。代码应通过其表面表达含义，因为不同的语言导致并非所有必需信息均可通过代码自身清晰表达。\u0026mdash; Dave Thomas, OTI 公司创始人\n  整洁的代码总是看起来像是某位特别在意它的人写的。几乎没有改进的余地，代码作者什么都想到了。\u0026mdash; 《修改代码的艺术》作者\n 有意义的命名 对于变量，如果其需要注释来补充，那就不算是名副其实。比如你需要定义一个变量，这个变量存储的是消逝的时间，其单位是天，那么下面是一些比较好的命名：\nint elapsedTimeInDays; int daysSinceCreation; int daysSinceModification; int fileAgeInDays; 别用 accountList 来指一组账号，除非它真的是 List 类型，List 一词对于程序员有特殊意义，所以用 accountGroup 或 bunchOfAcounts，甚至用 accounts 都会好一些。\n别说废话，废话都是冗余。假如你有一个 Product 类，如果还有一个 ProductInfo 或 ProductData 类，它们虽然名称不同，意思却无区别。Info 和 Data 就像 a、an 和 the 一样，是意义含混的废话。下面三个函数的命名，我们怎么知道应该调用哪个呢？\ngetActiveAccount(); getActiveAccounts(); getActiveAccountInfo(); 使用常量，WORK_DAYS_PER_WEEK 比数字 5 要好找的多。\n 对于类名，其应该是名词或名词短语，如 Customer、WikiPage、Account 和 AddressParser，避免使用 Manager、Processor、Data 或 Info 这样的类名。类名不应当是动词。\n 对于方法名，其应当是动词或动词短语，如 postPayment、deletePage 或 save。\n 为每一个抽象概念选一个词，并且一以贯之。例如使用 fetch、retrieve 和 get 来给在多个类中的同种方法命名，你怎么记得住哪个类是哪个方法呢？在一堆代码中，有 controller，又有 manager，还有 driver，就会令人困惑。\n多数变量都依赖一个类、一个函数来给读者提供语境，但如果做不到的话，你可能就需要加上前缀。例如 addrFirstName 比 firstName 更能说明，你想表达的是地址的一部分，当然更好的方案是创建一个名为 Address 的类。当然也没必要添加不必要的语境，只要短名称足够清楚，就比长名称好。\n语境不明确的变量  有语境的变量   如何写好函数 函数的第一个规则是短小。第二条规则还是要短小。\n函数应该做一件事，做好这件事，只做这一件事。如何判断函数做了是否不止一件事，看是否能再拆出一个函数。要确保函数只做一件事，函数中的语句都要在同一抽象层级上。getHtml() 位于较高抽象层级，PathParser.render(pagePath) 位于中间抽象层，.append(\u0026quot;\\n\u0026quot;) 位于相当低的抽象层。函数中混杂了不同的抽象层级，往往容易让人迷惑，读者无法判断出某个表达式是基础概念还是细节。\n像如下带有 switch 函数的代码，有几个问题。太长、违反单一原则、违反开放闭合原则（添加新类型，必须修改）等，该问题的解决方案是将 switch 语句埋到抽象工厂底下，不让任何人看到。\nSwitch 语句  用多态封装 Switch 语句   好名称的价值怎么好评都不为过，别害怕长名称，长而具有描述性的名称，要比短而令人费解的名称好，要比描述性的长注释好。别害怕花时间取名字。\n关于函数参数，除非你有足够特殊的理由，才能用三个以上的参数。对于有一个参数的函数，如果要对这个参数进行某种转换操作，那么应该使用返回值来返回转换后的值：StringBuffer transform(StringBuffer in) 要比 void transform(StringBuffer out) 强。\n如果函数看来需要两个、三个或三个以上的参数，说明其中一些参数就需要封装为类了：\nCircle makeCircle(double x, double y, double radius); Circle makeCircle(Point center, double radius); 给函数起一个好名字，能够解释函数意图、参数顺序的名字。writeField(name) 要比 write(name) 强，assertExpectedEqualsActual(expected, actual) 要比 assertEqual 强，这大大减轻了记忆参数的负担。\n确保函数无副作用，函数承诺做这件事，不要在其内部偷偷地做其它事情。\ntry/catch 代码块丑陋不堪，最好把 try 和 catch 代码块的主题部分抽离出来，另外形成函数。错误处理本身就是一件事，这意味着在 try 应该是函数的第一个单词，catch/finally 是这个函数的最后的内容。\n注释 代码在变动，在演化，但注释不能总是随之变动，注释会撒谎。注释不能美化糟糕的代码。\n直接把代码注释掉是讨厌的做法，其他人不敢删除注释掉的代码，他们会想代码依然放在那儿，一定有其原因。\n格式 代码每行展现一个表达式或一个子句，每组代码行展示一条完整的思路。这些思路用空白行区隔开来。每个空白行都是一条线索，标识出新的独立概念。往下读代码时，你的目光总会停留于空白行之后的那一行。\n若某个函数调用了另外一个，就应该把他们放到一起，而且调用者应该尽可能放在被调用者上面，这样，程序有一个自然的顺序。\n对象和数据结构 乱加 set 和 get 时最坏的选择，不要暴露数据细节，而要以抽象形态表述数据。\n暴露了数据细节的车辆  百分比抽象   过程式代码便于在不改动现有数据结构的前提下添加新的函数，面向对象代码便于在不改动现有函数的前提下添加新的类。\nThe Law of Demeter 认为模块不应了解它所操作对象的内部情形，对象应该隐藏数据，暴露操作。下面代码违反了：\nfinal String outputDir = ctxt.getOptions().getScratchDir().getAbsolutePath(); 最为精炼的数据结构，是一个只有公共变量、没有函数的类，这种数据结构就是 DTO（Data Transfer Objects），这种数据结构在与数据库通信、解析套接字传递的消息之类场景中，非常有用。\n错误处理 使用 Checked Exception 的依赖成本要高于收益，每个调用该函数的函数都要捕获它，或者添加合适的 throw 语句，最终得到的时一个从软件最底端贯穿到最高端的修改链，封装被打破，抛出路径上的每个函数都要去了解下一层的异常细节。\n将第三方 API 打包是个良好的实践手段，降低了对它的依赖，未来可以不太痛苦地改用其它代码库，你也可以不必绑死在某个特定厂商的 API 设计上。\n返回 null 的时候，考虑是否可以直接抛出异常，或者返回一个特定的对象，尽量不要返回 null，它在给调用者添乱。返回 null 是糟糕的做法，那么传递 null 值给其它方法就是更糟糕的了。\n单元测试 测试带来一切好处。\n类 系统应该由许多短小的类而不是少量巨大的类组成。\n对类加以组织，可以降低修改的风险。\n一个必须打开修改的类  一组封闭类   "});index.add({'id':13,'href':'/docs/rocketmq/rocketmq-message-filter-flow/','title':"RocketMQ 消息过滤流程",'content':"RocketMQ 消息过滤流程 讲述 RocketMQ 消息过滤流程\n一、消息过滤类型 Producer 在发送消息的时候可以指定消息的标签类型，还可以为每一个消息添加一个或者多个额外的属性:\n// 指定标签 Message msg = new Message(\u0026#34;TopicTest\u0026#34;, \u0026#34;TagA\u0026#34;, (\u0026#34;Hello RocketMQ\u0026#34;).getBytes(RemotingHelper.DEFAULT_CHARSET)); // 添加属性 a msg.putUserProperty(\u0026#34;a\u0026#34;, 5); 根据标签和属性的不同，RocketMQ 客户端在消费消息的时候有三种消息过滤类型:\n(1) 标签匹配 consumer.subscribe(\u0026#34;TopicTest\u0026#34;, \u0026#34;TagA | TagB | TagC\u0026#34;); (2) SQL 匹配 consumer.subscribe(\u0026#34;TopicTest\u0026#34;, MessageSelector.bySql( \u0026#34;(TAGS is not null and TAGS in (\u0026#39;TagA\u0026#39;, \u0026#39;TagB\u0026#39;))\u0026#34; + \u0026#34;and (a is not null and a between 0 3)\u0026#34;)); (3) 自定义匹配 客户端实现 MessageFilter 类，自定义过滤逻辑:\nClassLoader classLoader = Thread.currentThread().getContextClassLoader(); File classFile = new File(classLoader.getResource(\u0026#34;MessageFilterImpl.java\u0026#34;).getFile()); String filterCode = MixAll.file2String(classFile); consumer.subscribe(\u0026#34;TopicTest\u0026#34;, \u0026#34;org.apache.rocketmq.example.filter.MessageFilterImpl\u0026#34;,filterCode); 对于 MessageFilter 类实现 match 方法即可:\npublic class MessageFilterImpl implements MessageFilter { @Override public boolean match(MessageExt msg, FilterContext context) { String property = msg.getProperty(\u0026#34;SequenceId\u0026#34;); if (property != null) { int id = Integer.parseInt(property); if (((id % 10) == 0) \u0026amp;\u0026amp; (id \u0026gt; 100)) { return true; } } return false; } } 下面我们一一讲解各自背后的机制与实现原理。\n二、标签匹配 当为消息指定消息标签类型的时候，实际上所指定的标签例如 TagA 是作为一个属性放入到了这条消息中的:\npublic class Message implements Serializable { public void setTags(String tags) { this.putProperty(MessageConst.PROPERTY_TAGS, tags); } } 当这条消息到达 Broker 服务器端后，用户设置的标签会计算为标签码，默认的计算方式采用的标签字符串的 hashCode() 作为计算结果的:\npublic class CommitLog { public DispatchRequest checkMessageAndReturnSize(java.nio.ByteBuffer byteBuffer, final boolean checkCRC, final boolean readBody) { // ...  String tags = propertiesMap.get(MessageConst.PROPERTY_TAGS); if (tags != null \u0026amp;\u0026amp; tags.length() \u0026gt; 0) { tagsCode = MessageExtBrokerInner .tagsString2tagsCode(MessageExt.parseTopicFilterType(sysFlag), tags); } // ...  } } 当计算出来标签码之后，这条消息的标签码会被存放至消费队列文件中，用来与消费者客户端消费队列的标签码进行匹配。消费者客户端订阅消费话题的时候，会指定想要匹配的标签类型:\nconsumer.subscribe(\u0026#34;TopicTest\u0026#34;, \u0026#34;TagA | TagB | TagC\u0026#34;); 这段代码在内部实现中利用 FilterAPI 构建了一个 SubscriptionData 对象:\npublic class DefaultMQPushConsumerImpl implements MQConsumerInner { public void subscribe(String topic, String subExpression) throws MQClientException { SubscriptionData subscriptionData = FilterAPI .buildSubscriptionData(this.defaultMQPushConsumer.getConsumerGroup(), topic, subExpression); // ...  } } 当用户未指定标签或者指定为星号标签的时候，则代表用户接受所有标签的消息。如果用户指定了一个或者多个标签，那么会将每一个标签取其 hashCode() 放入到 codeSet 中。SubscriptionData 还有一个 expressionType 字段，在使用标签匹配的时候，其不会设置这个这个字段的值，因此其保留为 null。在这些信息设置好以后，当客户端发送心跳包的时候，会将这些话题的注册信息一并上传至 Broker 服务器端，方便在 Broker 端进行匹配。\npublic class SubscriptionData implements Comparable\u0026lt;SubscriptionData\u0026gt; { public final static String SUB_ALL = \u0026#34;*\u0026#34;; private Set\u0026lt;String\u0026gt; tagsSet = new HashSet\u0026lt;String\u0026gt;(); private Set\u0026lt;Integer\u0026gt; codeSet = new HashSet\u0026lt;Integer\u0026gt;(); private String expressionType; } 当 Broker 端服务器在取消息的时候，每取出来一条消息，都会执行两道过滤机制:\n ConsumeQueue 文件匹配 CommitLog 文件匹配  任一检查没有通过后，绝不会放行这条消息给客户端:\npublic class DefaultMessageStore implements MessageStore { public GetMessageResult getMessage(final String group, /** 其他参数 **/) { for (; i \u0026lt; bufferConsumeQueue.getSize() \u0026amp;\u0026amp; i \u0026lt; maxFilterMessageCount; i += ConsumeQueue.CQ_STORE_UNIT_SIZE) { // ConsumeQueue 文件匹配  if (messageFilter != null \u0026amp;\u0026amp; !messageFilter.isMatchedByConsumeQueue(isTagsCodeLegal ? tagsCode : null, extRet ? cqExtUnit : null)) { if (getResult.getBufferTotalSize() == 0) { status = GetMessageStatus.NO_MATCHED_MESSAGE; } continue; } // CommitLog 文件匹配  if (messageFilter != null \u0026amp;\u0026amp; !messageFilter.isMatchedByCommitLog(selectResult.getByteBuffer().slice(), null)) { if (getResult.getBufferTotalSize() == 0) { status = GetMessageStatus.NO_MATCHED_MESSAGE; } // release...  selectResult.release(); continue; } } } } 消息过滤器的默认实现是 ExpressionMessageFilter ，消息过滤的默认实现策略就是看这个话题的标签码集合中是否包括当前这条消息的标签码:\npublic class ExpressionMessageFilter implements MessageFilter { @Override public boolean isMatchedByConsumeQueue(Long tagsCode, ConsumeQueueExt.CqExtUnit cqExtUnit) { // ...  if (ExpressionType.isTagType(subscriptionData.getExpressionType())) { if (tagsCode == null) { return true; } if (subscriptionData.getSubString().equals(SubscriptionData.SUB_ALL)) { return true; } return subscriptionData.getCodeSet().contains(tagsCode.intValue()); } // ...  return true; } @Override public boolean isMatchedByCommitLog(ByteBuffer msgBuffer, Map\u0026lt;String, String\u0026gt; properties) { if (ExpressionType.isTagType(subscriptionData.getExpressionType())) { return true; } // ...  } } 下图是一幅标签匹配的简要流程图:\n三、SQL 匹配 在发送消息的时候，可以为每一条消息附带一个或者多个属性值，SQL 匹配指的就是依据这些属性值和 TAG 标签 是否满足一定的 SQL 语句条件，来过滤消息。用户如果想要开启 SQL 匹配，那么需要在 Broker 启动的时候，启用如下几个配置信息:\nbrokerConfig.setEnablePropertyFilter(true); brokerConfig.setEnableCalcFilterBitMap(true); messageStoreConfig.setEnableConsumeQueueExt(true); (1) 注册过滤信息 我们在消费者如何接受消息一文中提到过，消费者启动之后，会通过心跳包定时给 Broker 服务器汇报自己的信息。而 Broker 服务器在收到消费者的心跳包之后，会产生一个注册事件，如下所示:\npublic class ConsumerManager { public boolean registerConsumer(final String group, /** 其他参数 **/) { // ...  this.consumerIdsChangeListener.handle(ConsumerGroupEvent.REGISTER, group, subList); // ...  } } DefaultConsumerIdsChangeListener 是默认的消费者列表注册事件通知器的实现类，其在收到注册事件以后，会将用户在消费者端订阅的话题信息注册到 ConsumerFilterManager 中:\npublic class DefaultConsumerIdsChangeListener implements ConsumerIdsChangeListener { @Override public void handle(ConsumerGroupEvent event, String group, Object... args) { switch (event) { case REGISTER: Collection\u0026lt;SubscriptionData\u0026gt; subscriptionDataList = (Collection\u0026lt;SubscriptionData\u0026gt;) args[0]; this.brokerController.getConsumerFilterManager().register(group, subscriptionDataList); break; // ...  } } } ConsumerFilterData 中包含了消费者客户端注册的 SQL 表达式，由上图我们可以看到对于每一个话题所对应的 FilterDataMapByTopic ，可以注册多个 SQL 表达式。但是这里需要注意的是，这多个 SQL 表达式是按照组来做区分的，就是说一个组只能有一个 SQL 表达式，客户端如果在一个组中注册了多个不同的 SQL 表达式，那么后注册的会覆盖掉前注册的。因此，如果想要对同一个组使用不同的 SQL 语句来过滤自己想要的信息，这些不同的 SQL 语句必须划分到不同的组里面才可行。\n(2) 生成 BloomFilterData 布隆过滤器 (BloomFilter) 是一种空间效率很高的数据结构，其可以用来判断某个元素是否可能存在于某个集合中。当判断结果返回 true 的时候，表示可能存在，当返回 false 的时候，表示这个元素一定不存在于这个集合中。\n它的原理是当一个元素被加入集合时，通过 k 个 Hash 函数将这个元素映射成一个长度为 m 位数组（Bit array）中的 k 个点，把它们置为 1。检索时，我们只要看看这些点是不是都是 1 就（大约）知道集合中有没有它了：\n 如果这些点有任何一个 0，则被检索元素一定不在。 如果都是 1， 则被检索元素很可能在。  如下是一个采用位数组长度为 m=18 以及哈希函数个数为 k=3 实现的布隆过滤器，”x,y,z” 每一个字母都需要经过 3 次哈希函数的计算，然后映射到 3 个不同的槽中。由于字母 “w” 在经过 3 次哈希函数计算后，其中一次产生的哈希值并未命中已有的槽，因此可以确定的是 “w” 肯定不存在于这个集合中。\n在 RocketMQ 的实现中，其有四个最关键的值:\npublic class BloomFilter { // 最大错误率  private int f; // 可能插入 n 个元素  private int n; // k 个哈希函数  private int k; // 数组总共 m 位  private int m; } RocketMQ 实现的布隆过滤器是根据错误率 f 和可能插入的元素数量 n 计算出来的 k 和 m，在默认配置情况下，即如下 n = 32 和 f = 20，计算出来需要 k = 3 个哈希函数和 m = 112 位的数组。\npublic class BrokerConfig { // Expect num of consumers will use filter.  private int expectConsumerNumUseFilter = 32; // Error rate of bloom filter, 1~100.  private int maxErrorRateOfBloomFilter = 20; } 我们这里大致了解以下布隆过滤器的一个基本想法即可，具体算法比较复杂，也不在讨论范畴以内。当客户端注册过滤信息的时候，其会根据 “组#话题” 这个字符串计算出相应的位映射数据，也即这个字符串经过布隆过滤器中的若干个哈希函数得到的几个不同的哈希值:\npublic class ConsumerFilterManager extends ConfigManager { public boolean register(final String topic, /** 其它参数 **/) { // ...  BloomFilterData bloomFilterData = bloomFilter.generate(consumerGroup + \u0026#34;#\u0026#34; + topic); // ...  } } ConsumerFilterManager 中的话题过滤信息数据，每隔 10 秒进行一次磁盘持久化:\npublic class BrokerController { public boolean initialize() throws CloneNotSupportedException { this.scheduledExecutorService.scheduleAtFixedRate(new Runnable() { @Override public void run() { BrokerController.this.consumerFilterManager.persist(); } }, 1000 * 10, 1000 * 10, TimeUnit.MILLISECONDS); } } 磁盘文件 consumerFilter.json 中保存的数据信息如下示例:\n上述大致流程图如下所示：\n(3) 编译 SQL 语句 JavaCC (Java Compiler Compiler) 是一个能生成语法和词法分析器的生成程序，它通过阅读一个自定义的语法标准文件 (通常以 jj 为后缀名) ，然后就能生成能够解析该语法的扫描器和解析器的代码。\n通过执行 javacc SelectorParser.jj 命令以后，其会生成如下七个 Java 文件，用以解析 SQL 语法:\n过滤器工厂 FilterFactory 在初次使用的时候，会注册一个 SqlFilter 类，这个类能够将消费者端指定的 SQL 语句编译解析为 Expression 表达式对象，方便后续消息的快速匹配与过滤。\npublic class SqlFilter implements FilterSpi { @Override public Expression compile(final String expr) throws MQFilterException { return SelectorParser.parse(expr); } } (4) 计算位映射 当 Broker 服务器接收到新的消息到来之后，一直在后台运行的 ReputMessageService 会负责将这条消息封装为一个 DispatchRequest 分发请求，这个请求会传递给提前构建好的分发请求链。在 DefaultMessageStore 的构造函数中，我们看到依次添加了构建消费队列和构建索引的分发请求服务:\npublic class DefaultMessageStore implements MessageStore { public DefaultMessageStore(final MessageStoreConfig messageStoreConfig, /** 其它参数 **/) throws IOException { this.dispatcherList = new LinkedList\u0026lt;\u0026gt;(); this.dispatcherList.addLast(new CommitLogDispatcherBuildConsumeQueue()); this.dispatcherList.addLast(new CommitLogDispatcherBuildIndex()); } } 而在 Broker 初始化的时候，我们看到其又添加了计算位映射的分发请求服务，并且将此分发服务放在链表的第一个位置:\npublic class BrokerController { public boolean initialize() throws CloneNotSupportedException { this.messageStore.getDispatcherList() .addFirst(new CommitLogDispatcherCalcBitMap(this.brokerConfig, this.consumerFilterManager)); } } 由此，在每次收到新的消息之后，分发请求的需要经过如下三个分发请求服务进行处理:\n我们在这部分只介绍计算位映射的服务类实现。如下，dispatch 方法用来分发请求里面的消息，对于这每一条消息，首先根据话题取得所有的消费过滤数据。这每一条数据代表的就是一条 SQL 过滤语句信息。我们在这个地方，需要一一遍历这些过滤信息，从而完成计算位服务的需求:\npublic class CommitLogDispatcherCalcBitMap implements CommitLogDispatcher { @Override public void dispatch(DispatchRequest request) { Collection\u0026lt;ConsumerFilterData\u0026gt; filterDatas = consumerFilterManager.get(request.getTopic()); Iterator\u0026lt;ConsumerFilterData\u0026gt; iterator = filterDatas.iterator(); while (iterator.hasNext()) { ConsumerFilterData filterData = iterator.next(); // ...  } } } 在拿到 ConsumerFilterData 信息之后，其会根据这条信息内的 SQL 语句编译后的表达式来对这条消息进行检查匹配 (evaluate)，看这条消息是否满足 SQL 语句所设置的条件。如果满足，那么会将先前在客户端注册阶段计算好的 BloomFilterData 中的映射位信息设置到 filterBitMap 中，即将相应的位数组 BitsArray 中的相应位设置为 1 。在验证完所有的 SQL 语句之后，会将这些所有的字节数组放置到 request 请求之中，以便交由下一个请求分发服务进行使用:\n@Override public void dispatch(DispatchRequest request) { BitsArray filterBitMap = BitsArray.create(this.consumerFilterManager.getBloomFilter().getM()); while (iterator.hasNext()) { ConsumerFilterData filterData = iterator.next(); MessageEvaluationContext context = new MessageEvaluationContext(request.getPropertiesMap()); Object ret = filterData.getCompiledExpression().evaluate(context); // eval true  if (ret != null \u0026amp;\u0026amp; ret instanceof Boolean \u0026amp;\u0026amp; (Boolean) ret) { consumerFilterManager .getBloomFilter() .hashTo(filterData.getBloomFilterData(), filterBitMap); } } request.setBitMap(filterBitMap.bytes()); } (5) 存储位映射 MessageStore 在开启扩展消费队列的配置之后，每一个消费队列在创建的时候，都会额外创建一个扩展消费队列。每一个扩展消费队列文件的大小默认为 48MB:\npublic class ConsumeQueue { public ConsumeQueue(final String topic, /** 其它参数 **/) { // ...  if (defaultMessageStore.getMessageStoreConfig().isEnableConsumeQueueExt()) { this.consumeQueueExt = new ConsumeQueueExt(topic, /** 其它参数 **/); } } } 在计算位映射一节中，计算好位字节数组之后，我们这里需要通过第二个分发请求服务 CommitLogDispatcherBuildConsumeQueue 来存储这些字节信息。通过如下代码，我们知道它将请求中的位映射信息、消息存储时间、标签码这三条信息封装为 ConsumeQueueExt.CqExtUnit ，然后放入到扩展消费队列文件中。\npublic class ConsumeQueue { public void putMessagePositionInfoWrapper(DispatchRequest request) { long tagsCode = request.getTagsCode(); if (isExtWriteEnable()) { ConsumeQueueExt.CqExtUnit cqExtUnit = new ConsumeQueueExt.CqExtUnit(); cqExtUnit.setFilterBitMap(request.getBitMap()); cqExtUnit.setMsgStoreTime(request.getStoreTimestamp()); cqExtUnit.setTagsCode(request.getTagsCode()); long extAddr = this.consumeQueueExt.put(cqExtUnit); if (isExtAddr(extAddr)) { tagsCode = extAddr; } } } } 我们注意到在上述代码中，put 函数返回的是一个 long 类型的扩展地址，当这个数值满足 isExtAddr 要求后，其会将当前的标签码设置为刚才返回的扩展地址。那么这是为什么呢?\n我们首先来看 ConsumeQueueExt 文件在存放数据成功后是如何返回信息的:\npublic class ConsumeQueueExt { public static final long MAX_ADDR = Integer.MIN_VALUE - 1L; public long put(final CqExtUnit cqExtUnit) { if (mappedFile.appendMessage(cqExtUnit.write(this.tempContainer), 0, size)) { return decorate(wrotePosition + mappedFile.getFileFromOffset()); } return 1; } public long decorate(final long offset) { if (!isExtAddr(offset)) { return offset + Long.MIN_VALUE; } return offset; } public static boolean isExtAddr(final long address) { return address \u0026lt;= MAX_ADDR; } } MAX_ADDR 是一个很小很小的值，为 -2147483649， 即写入位置如果不小于这个值，那么我们就认定为它不是扩展地址。需要将修正后的 写入偏移量 + Long.MIN_VALUE 确定为扩展地址。当读取信息的时候，其先读取 ConsumeQueue 文件中的最后的 Hash 标签码值，如果其通过 isExtAddr() 函数返回的是 true，那么我们就可以使用这个地址，再通过一个叫做 unDecorate() 函数将其修正为正确的 ConsumeQueueExt 文件的写入地址，从而接着读取想要的信息:\npublic long unDecorate(final long address) { if (isExtAddr(address)) { return address - Long.MIN_VALUE; } return address; } 这个地方，我们发现 ConsumeQueue 中的最后一个 long 型数值，可能存储的是标签 Hash 码，也可能存储的是扩展消费队列的写入地址，所以需要通过 isExtAddr() 来分情况判断。\n下图为 ConsumeQueue 文件和 ConsumeQueueExt 文件中存取信息的不同:\n(6) 消息过滤 在上小节我们提到了有关扩展消费队列地址和标签 Hash 码存储的不同，所以当在取消息的时候，先得从消费队列文件中取出 tagsCode，然后检查是否是扩展消费队列地址，如果是，那么就需要从扩展消费队列文件中读取正确的标签 Hash 码，如下代码所示：\npublic class DefaultMessageStore implements MessageStore { public GetMessageResult getMessage(final String group, /** 其它参数 **/) { ConsumeQueueExt.CqExtUnit cqExtUnit = new ConsumeQueueExt.CqExtUnit(); for (; i \u0026lt; bufferConsumeQueue.getSize() \u0026amp;\u0026amp; i \u0026lt; maxFilterMessageCount; i += ConsumeQueue.CQ_STORE_UNIT_SIZE) { long tagsCode = bufferConsumeQueue.getByteBuffer().getLong(); boolean extRet = false, isTagsCodeLegal = true; if (consumeQueue.isExtAddr(tagsCode)) { extRet = consumeQueue.getExt(tagsCode, cqExtUnit); if (extRet) { tagsCode = cqExtUnit.getTagsCode(); } else { isTagsCodeLegal = false; } } } } } 当获取到这条消息在扩展消费队列文件中存取的信息后，就会和标签匹配一节所讲述的一致，会进行两道过滤机制。我们先来看第一道 ConsumeQueue 文件匹配:\npublic class ExpressionMessageFilter implements MessageFilter { @Override public boolean isMatchedByConsumeQueue(Long tagsCode, ConsumeQueueExt.CqExtUnit cqExtUnit) { byte[] filterBitMap = cqExtUnit.getFilterBitMap(); BloomFilter bloomFilter = this.consumerFilterManager.getBloomFilter(); BitsArray bitsArray = BitsArray.create(filterBitMap); return bloomFilter.isHit(consumerFilterData.getBloomFilterData(), bitsArray); } } ExpressionMessageFilter 依据 CqExtUnit 中存储的位数组重新创建了比特数组 bitsArray，这个数组信息中已经存储了不同 SQL 表达式是否匹配这条消息的结果。isHit() 函数会一一检查 BloomFilterData 中存储的位信息是否映射在 BitsArray 中。只要有任何一位没有映射，那么就可以立刻判断出这条消息肯定不符合 SQL 语句的条件。\n因为布隆过滤器有一定的错误率，其只能精确的判断消息是否一定不在集合中，返回成功的只能确定为消息可能在集合中。因此通过布隆过滤器检查后还需要经过第二道过滤机制，即 SQL 编译后的表达式亲自验证是否匹配:\npublic class ExpressionMessageFilter implements MessageFilter { @Override public boolean isMatchedByCommitLog(ByteBuffer msgBuffer, Map\u0026lt;String, String\u0026gt; properties) { MessageEvaluationContext context = new MessageEvaluationContext(tempProperties); Object ret = realFilterData.getCompiledExpression().evaluate(context); if (ret == null || !(ret instanceof Boolean)) { return false; } return (Boolean) ret; } } 通过在验证 SQL 表达式是否满足之前，提前验证是否命中布隆过滤器，可以有效的避免许多不必要的验证:\n四、自定义匹配 消息的自定义匹配需要开启过滤服务器、上传过滤类、过滤服务器委托过滤消息等步骤，下面我们一一进行说明。\n(1) 过滤服务器 在启动 Broker 服务器的时候，如果指定了下面一行设置:\nbrokerConfig.setFilterServerNums(int filterServerNums); 即将过滤服务器的数量设定为大于 0，那么 Broker 服务器在启动的时候，将会启动 filterServerNums 个过滤服务器。过滤服务器是通过调用 shell 命令的方式，启用独立进程进行启动的。\npublic class FilterServerManager { public void createFilterServer() { int more = this.brokerController.getBrokerConfig().getFilterServerNums() - this.filterServerTable.size(); String cmd = this.buildStartCommand(); for (int i = 0; i \u0026lt; more; i++) { FilterServerUtil.callShell(cmd, log); } } } 过滤服务器在初始化的时候，会启动定时器每隔 10 秒注册一次到 Broker 服务器:\npublic class FiltersrvController { public boolean initialize() { this.scheduledExecutorService.scheduleAtFixedRate(new Runnable() { @Override public void run() { FiltersrvController.this.registerFilterServerToBroker(); } }, 3, 10, TimeUnit.SECONDS); } } Broker 服务器在收到来自过滤服务器的注册信息之后，会把过滤服务器的地址信息、注册时间等放到过滤服务器表中:\npublic class FilterServerManager { private final ConcurrentMap\u0026lt;Channel, FilterServerInfo\u0026gt; filterServerTable = new ConcurrentHashMap\u0026lt;Channel, FilterServerInfo\u0026gt;(16); } 同样，Broker 服务器也需要定时将过滤服务器地址信息同步给所有 Namesrv 命名服务器，上述整个流程如下图所示:\n(2) 过滤类 当消费者通过使用自定义匹配过滤消息的时候，这个时候会将存储订阅信息的 SubscriptionData 中的 filterClassSource 设置为 true，以表征这个客户端需要过滤类来进行消息的匹配和过滤。\n消费者客户端在启动过程中，还会定时地上传本地的过滤类源码到过滤服务器:\npublic class MQClientInstance { private void startScheduledTask() { this.scheduledExecutorService.scheduleAtFixedRate(new Runnable() { @Override public void run() { MQClientInstance.this.sendHeartbeatToAllBrokerWithLock(); } }, 1000, this.clientConfig.getHeartbeatBrokerInterval(), TimeUnit.MILLISECONDS); } public void sendHeartbeatToAllBrokerWithLock() { // ...  this.uploadFilterClassSource(); } } 其中过滤服务器的地址列表是在从 Namesrv 服务器获取话题路由信息的时候取得的，话题路由信息不光存储了消息队列数据，还存储了各个 Broker 所关联的过滤服务器列表:\npublic class TopicRouteData extends RemotingSerializable { // ...  private HashMap\u0026lt;String/* brokerAddr */, List\u0026lt;String\u0026gt;/* Filter Server */\u0026gt; filterServerTable; } 当过滤服务器接收到来自消费者客户端的源码之后，其会首先首先生成一个键为 话题@组 的字符串来查阅过滤类信息是否已经存在于内存里面的 filterClassTable 表中且文件通过 CRC 校验。如果没有存在或校验失败，那么就需要先编译并加载这个类:\npublic class DynaCode { public void compileAndLoadClass() throws Exception { String[] sourceFiles = this.uploadSrcFile(); this.compile(sourceFiles); this.loadClass(this.loadClass.keySet()); } } 默认情况下，编译后的类存放于 $HOME/rocketmq_filter_class/$PID 目录下，类的源文件和类的字节码文件名也会相应的加上当前时间戳来确定:\n上述流程图如下:\n(3) 过滤消息 当消费者客户端启用自定义匹配过滤消息后，发往服务器的数据中也包含了过滤标志位，这样每次拉取消息的服务器也由原来的 Broker 服务器变更为 Filtersrv 过滤服务器，其中过滤服务器地址的选择是随机确定的:\npublic class PullAPIWrapper { public PullResult pullKernelImpl(final MessageQueue mq, /** 其它参数 **/) throws Exception { // ...  if (findBrokerResult != null) { if (PullSysFlag.hasClassFilterFlag(sysFlagInner)) { // 从过滤服务器拉取消息  brokerAddr = computPullFromWhichFilterServer(mq.getTopic(), brokerAddr); } // ...  } } } 过滤服务器在启动的时候，内部还启动了一个 PullConsumer 客户端，用以从 Broker 服务器拉取消息:\npublic class FiltersrvController { private final DefaultMQPullConsumer defaultMQPullConsumer = new DefaultMQPullConsumer(MixAll.FILTERSRV_CONSUMER_GROUP); public void start() throws Exception { this.defaultMQPullConsumer.start(); // ...  } } 当过滤服务器收到真正的消费者发来的消费消息的请求之后，其会委托内部的 PullConsumer 使用包含在请求体内的偏移量去 Broker 服务器拉取所有消息，此时这些消息是完全没有过滤的：\npublic class DefaultRequestProcessor implements NettyRequestProcessor { private RemotingCommand pullMessageForward(final ChannelHandlerContext ctx, final RemotingCommand request) throws Exception { MessageQueue mq = new MessageQueue(); mq.setTopic(requestHeader.getTopic()); mq.setQueueId(requestHeader.getQueueId()); mq.setBrokerName(this.filtersrvController.getBrokerName()); // 设置偏移量和最大数量  long offset = requestHeader.getQueueOffset(); int maxNums = requestHeader.getMaxMsgNums(); // 委托内部消费者从 Broker 服务器拉取消息  pullConsumer.pullBlockIfNotFound(mq, null, offset, maxNums, pullCallback); } } 过滤服务器从 Broker 服务器获取到完整的消息列表之后，会遍历消息列表，然后使用过滤类一一进行匹配，最终将匹配成功的消息列表返回给客户端:\npublic class DefaultRequestProcessor implements NettyRequestProcessor { private RemotingCommand pullMessageForward(final ChannelHandlerContext ctx, final RemotingCommand request) throws Exception { final PullCallback pullCallback = new PullCallback() { @Override public void onSuccess(PullResult pullResult) { switch (pullResult.getPullStatus()) { case FOUND: List\u0026lt;MessageExt\u0026gt; msgListOK = new ArrayList\u0026lt;MessageExt\u0026gt;(); for (MessageExt msg : pullResult.getMsgFoundList()) { // 使用过滤类过滤消息  boolean match = findFilterClass.getMessageFilter().match(msg, filterContext); if (match) { msgListOK.add(msg); } } break; // ...  } } }; // ...  } } 上述流程如下图所示:\n"});index.add({'id':14,'href':'/docs/books/the_transformation_of_enterprise_it_architecture/','title':"企业 IT 架构转型之道",'content':"企业 IT 架构转型之道 共享服务体系搭建 SOA 的主要特性：\n 面向服务的分布式计算。 服务间松散耦合。 支持服务的组装。 服务注册和自动发现。 以服务契约方式定义服务交互方式。  基于 “中心化” 的 ESB 服务调用方式  “去中心化” 服务架构调用方式   数据拆分实现数据库能力线性扩展 数据库的读写分离 读写分离基本原理是让主数据库处理事务性增、改、删（INSERT、UPDATE、DELETE）操作，而从数据库专门负责处理查询（SELECT）操作，在数据库的后台会把事务性操作导致的主数据库中的数据变更同步到集群中的从数据库。\n数据库分库分表 采用分库分表的方式将业务数据拆分后，如果每一条SQL语句中都能带有分库分表键，SQL语句的执行效率最高：\n但不是所有的业务场景在进行数据库访问时每次都能带分库分表键的。比如在买家中心的界面中，要显示买家test1过去三个月的订单列表信息。此时就出现了我们所说的全表扫描，一条SQL语句同时被推送到后端所有数据库中运行。如果是高并发情况下同时请求的话，为了数据库整体的扩展能力，则要考虑下面描述的异构索引手段来避免这样的情况发生。对于在内存中要进行大数据量聚合操作和计算的SQL请求，如果这类SQL的不是大量并发或频繁调用的话，平台本身的性能影响也不会太大，如果这类SQL请求有并发或频繁访问的要求，则要考虑采用其他的平台来满足这一类场景的要求，比如Hadoop这类做大数据量离线分析的产品，如果应用对请求的实时性要求比较高，则可采用如内存数据库或HBase这类平台。\n所谓“异构索引表”，就是采用异步机制将原表内的每一次创建或更新，都换另一个维度保存一份完整的数据表或索引表。本质上这是互联网公司很多时候都采用的一个解决思路：“拿空间换时间”。也就是应用在创建或更新一条按照订单ID为分库分表键的订单数据时，也会再保存一份按照买家ID为分库分表键的订单索引数据。\n基于订单索引表实现买家订单列表查看流程示意：\n实现对数据的异步索引创建有多种实现方式，其中一种就是从数据库层采用 binlog 数据复制的方式实现。\n采用数据异构索引的方式在实战中基本能解决和避免90%以上的跨join或全表扫描的情况，是在分布式数据场景下，提升数据库服务性能和处理吞吐能力的最有效技术手段。但在某些场景下，比如淘宝商品的搜索和高级搜索，因为商品搜索几乎是访问淘宝用户都会进行的操作，所以调用非常频繁，如果采用SQL语句的方式在商品数据库进行全表扫描的操作，则必然对数据库的整体性能和数据库连接资源带来巨大的压力。面对此类场景，我们不建议采用数据库的方式提供这样的搜索服务，而是采用专业的搜索引擎平台来行使这样的职能，如Lucene、Solr、ElasticSearch 等。\n异步化与缓存原则 业务流程异步化 以淘宝的交易订单为例，目前淘宝的订单创建流程需要调用超过200个服务，就算所有服务的调用时间都控制在20ms内返回结果，整个订单创建的时间也会超过4s：\n以异步化方式将上述交易创建过程中，对于有严格先后调用关系的服务保持顺序执行，对于能够同步执行的所有服务均采用异步化方式处理。阿里巴巴内部使用消息中间件的方式实现了业务异步化，提高了服务的并发处理，从而大大减少整个业务请求处理所花的时间。\n数据库事务异步化 扣款是一个要求事务一致性的典型场景，稍微数据不一致带来的后果都可能是成百上千（可能在某些借款项目中达到上百万的金额）的金额差异。所以在传统的实现方式中，整个扣款的逻辑代码都是在一个大的事务中，通过数据库的事务特性来实现这样一个稍显复杂的业务一致性。\n数据库事务的异步化：通俗来说，就是将大事务拆分成小事务，降低数据库的资源被长时间事务锁占用而造成的数据库瓶颈，就能大大提升平台的处理吞吐量和事务操作的响应时间。\n在实际的改造方案中，同样基于消息服务提供的异步机制，将整个还款流程进行异步化的处理：\n事务与柔性事务 不管是业务流程异步化，还是数据库事务异步化，其实都面临一个如何保证业务事务一致性的问题。面对这个问题目前并没有完美的解决方案，本节会介绍淘宝是如何对订单创建场景实现业务一致的实践，以及近一两年来我们在分布式事务上所作出的创新尝试，供各技术同行在解决此类问题时借鉴和参考。\n关于数据库事务，核心是体现数据库ACID（原子性、一致性、隔离性和持久性）属性，即作为一个事务中包含的所有逻辑处理操作在作用到数据库上时，只有这个事务中所有的操作都成功，对数据库的修改才会永久更新到数据库中，任何一个操作失败，对于数据库之前的修改都会失效。在分布式领域，基于CAP理论和在其基础上延伸出的BASE理论，有人提出了“柔性事务”的概念。\n（1）CAP理论\n一个分布式系统最多只能同时满足一致性（Consistency）、可用性（Availability）和分区容错性（Partition tolerance）这三项中的两项。“一致性”指更新操作成功并返回客户端完成后，所有节点在同一时间的数据完全一致。“可用性”指用户在访问数据时可以得到及时的响应。“分区容错性”指分布式系统在遇到某节点或网络分区故障的时候，仍然能够对外提供满足一致性和可用性的服务。\nCAP定理并不意味着所有系统的设计都必须抛弃三个要素之中的一个。CAP三者可以在一定程度上衡量，并不是非黑即白的，例如可用性从0%到100%有不同等级。\n（2）BASE理论\nBASE理论是对CAP理论的延伸，核心思想是即使无法做到强一致性（Strong Consistency, CAP的一致性就是强一致性），但应用可以采用适合的方式达到最终一致性（EventualConsitency）。BASE是指基本可用（Basically Available）、柔性状态（Soft State）、最终一致性（Eventual Consistency）。\n  “基本可用”是指分布式系统在出现故障的时候，允许损失部分可用性，即保证核心可用。电商大促时，为了应对访问量激增，部分用户可能会被引导到降级页面，服务层也可能只提供降级服务。这就是损失部分可用性的体现。\n  “柔性状态”是指允许系统存在中间状态，而该中间状态不会影响系统整体可用性。分布式存储中一般一份数据至少会有三个副本，允许不同节点间副本同步的延时就是柔性状态的体现。MySQLReplication的异步复制也是一种柔性状态体现。\n  “最终一致性”是指系统中的所有数据副本经过一定时间后，最终能够达到一致的状态。弱一致性和强一致性相反，最终一致性是弱一致性的一种特殊情况。\n  对于如何实现高可用，我们认为：\n 高可用=系统构建在多机分布式系统 高性能=分布式系统的副产品  分布式系统内通信和单机内通信最大的区别是：单机系统总线不会丢消息，而网络会。一台向另一台机器通信的结果可能是收到、未收到、不知道收到没收到。消息不可靠带来的副作用是：数据或者状态在多机之间同步的成本很高。大家都知道Paxos协议。在多机间通信不存在伪造或篡改的前提下，可以经由Paxos协议达成一致性。成本是发给Paxos系统的信息（数据）需要至少同步发送到一半以上多数（Quorum）的机器确认后，才能认为是成功。这样大幅增加了信息更新的延迟，因此分布式系统的首选不是这种强同步而是最终一致。\n（3）两阶段提交\n数据在按照业务领域（用户中心、交易中心）的不同被拆分到不同的数据库后，在某些业务场景（比如订单创建）下，就必然会出现同一个事务上下文中，需要协调多个资源（数据库）以保证业务的事务一致性，对于这样的场景，业界早就有基于两阶段提交方式实现的分布式事务，两阶段提交协议包含了两个阶段：第一阶段（也称准备阶段）和第二阶段（也称提交阶段）。\nX/Open组织为基于两阶段协议的分布式事务处理系统提出了标准的系统参考模型（X/Open事务模型）以及不同组件间与事务协调相关的接口，使不同厂商的产品能够互操作。X/Open事务模型如图所示。\n从图中可以看出，X/Open模型定义了两个标准接口：TX接口用于应用程序向事务管理器发起事务、提交事务和回滚事务（即确定事务的边界和结果）; XA接口形成了事务管理器和资源管理器之间的通信桥梁，用于事务管理器将资源管理器（如数据库、消息队列等）加入事务、并控制两阶段提交。\n事务管理器一般由专门的中间件提供，或者在应用服务器中作为一个重要的组件提供。资源管理器如数据库、消息队列等产品一般也会提供对XA接口的支持，通过使用符合X/Open标准的分布式事务处理，能够简化分布式事务类应用的开发。\n两阶段提交协议的关键在于“预备”操作。分布式事务协调者在第一阶段通过对所有的分布式事务参与者请求“预备”操作，达成关于分布式事务一致性的共识。分布式事务参与者在预备阶段必须完成所有的约束检查，并且确保后续提交或放弃时所需要的数据已持久化。在第二队段，分布式事务协调者根据之前达到的提交或放弃的共识，请求所有的分布式事务参与者完成相应的操作。很显然，在提交事务的过程中需要在多个资源节点之间进行协调，而各节点对锁资源的释放必须等到事务最终提交时，这样，比起一阶段提交，两阶段提交在执行同样的事务时会消耗更多时间。\n事务执行时间的延长意味着锁资源发生冲突的概率增加，当事务的并发量达到一定数量的时候，就会出现大量事务积压甚至出现死锁，系统性能和处理吞吐率就会严重下滑，也就是系统处理的吞吐率与资源上的时间消耗成反比（参考阿姆达尔定理）。这就是为什么今天在互联网应用场景中鲜有人会选择这样传统的分布式事务方式，而选择柔性事务处理业务事务的主要原因。\n（4）柔性事务如何解决分布式事务问题\n  引入日志和补偿机制。类似传统数据库，柔性事务的原子性主要由日志保证。事务日志记录事务的开始、结束状态，可能还包括事务参与者信息。参与者节点也需要根据重做或回滚需求记录REDO/UNDO日志。当事务重试、回滚时，可以根据这些日志最终将数据恢复到一致状态。为避免单点，事务日志是记录在分布式节点上的，数据REDO/UNDO日志一般记录在业务数据库上，可以保证日志与业务操作同时成功/失败。通常柔性事务能通过日志记录找回事务的当前执行状态，并根据状态决定是重试异常步骤（正向补偿），还是回滚前序步骤（反向补偿）。\n  可靠消息传递。根据“不知道成功还是失败”状态的处理，消息投递只有两种模式：1）消息仅投递一次，但是可能会没有收到；2）消息至少投递一次，但可能会投递多次。在业务一致性的高优先级下，第一种投递方式肯定是无法接受的，因此只能选择第二种投递方式。由于消息可能会重复投递，这就要求消息处理程序必须实现幂等（幂等=同一操作反复执行多次结果不变）。每种业务场景不同，实现幂等的方法也会有所不同，最简单的幂等实现方式是根据业务流水号写日志，阿里内部一般把这种日志叫做排重表。\n  实现无锁。如何很好地解决数据库锁问题是实现高性能的关键所在。所以选择放弃锁是一个解决问题的思路，但是放弃锁并不意味着放弃隔离性。实现事务隔离的方法有很多，在实际的业务场景中可灵活选择以下几种典型的实现方式。\n 避免事务进入回滚。如果事务在出现异常时，可以不回滚也能满足业务的要求，也就是要求业务不管出现任何情况，只能继续朝事务处理流程的顺向继续处理，这样中间状态即使对外可见，由于事务不会回滚，也不会导致脏读。 辅助业务变化明细表。比如对资金或商品库存进行增减处理时，可采用记录这些增减变化的明细表的方式，避免所有事务均对同一数据表进行更新操作，造成数据访问热点，同时使得不同事务中处理的数据互不干扰，实现对资金或库存信息处理的隔离。 乐观锁。数据库的悲观锁对数据访问具有极强的排他性，也是产生数据库处理瓶颈的重要原因，采用乐观锁则在一定程度上解决了这个问题。乐观锁大多是基于**数据版本（Version）**记录机制实现。例如通过在商品表中增加记录版本号的字段，在事务开始前获取到该商品记录的版本号，在事务处理最后对该商品数据进行数据更新时，可通过在执行最后的修改update语句时进行之前获取版本号的比对，如果版本号一致，则update更新数据成功，修改该数据到新的版本号；如果版本号不一致，则表示数据已经被其他事务修改了，则重试或放弃当前事务。     （5）柔性事务在阿里巴巴内部的几种实现\n 消息分布式事务  基于消息实现的分布式事务仅支持正向补偿，即不会像传统事务方式出现异常时依次进行回滚，会通过消息的不断重试或人工干预的方式让该事务链路继续朝前执行，而避免出现事务回滚。\n 支付宝XTS框架  XTS是TCC（Try/Confirm/Cancel）型事务，属于典型的补偿型事务。\n 阿里巴巴AliWare TXC事务服务  标准模式下无需开发人员自行进行事务回滚或补偿的代码，平台支持自动按事务中事务操作的顺序依次回滚和补偿。关键原理：\n大促秒杀活动催生缓存技术的高度使用 首先一定要让负责秒杀场景的商品中心应用实例（图中“秒杀IC”）与满足普通商品正常访问的商品中心应用实例（图中IC）隔离部署，通过服务分组方式，保持两个运行环境的隔离，避免因为秒杀产生的过大访问流量造成整个商品中心的服务实例均受影响，产生太大范围的影响。\n因为秒杀在正式开始前，一定会有大量的用户停留在商品的详情页（图中Detail）等待着秒杀活动的开始，同时伴随有大量的页面刷新访问（心急或担心页面没有正常刷新的买家们），此时，如果每一次刷新都要从后端的商品数据库（图中ICDB）中获取商品相关信息，则一定会给数据库带来巨大的压力，在淘宝早期举办秒杀活动时就出现了秒杀活动还没开始，因为商品详情页访问太大，造成平台提前进入不可访问状态的情况。所以一定是通过缓存服务器（图中Tair），将商品的详细信息（包括库存信息）保存在缓存服务器上，商品详情页和购买页所有有关商品的信息均是通过缓存服务器获取，则无需访问后端数据库。\n如图中“本地缓存”所示，可通过给网页资源设置Expires和Last-Modified返回头信息进行有效控制，从而尽可能减少对后端服务端的访问次数。\n避免商品出现超卖（即成功下单的订单中商品的库存数量大于商品现有的库存量，则称为商品超卖），核心技术是利用数据库的事务锁机制，即不允许同一商品的库存记录在同一时间被不同的两个数据库事务修改。在前柔性事务介绍中所提到的，用户在进行商品下单操作中，会进行一系列的业务逻辑判断和操作，对于商品库存信息这一访问热点数据，如果采用数据库的悲观锁（比如select语句带for update）模式，则会给订单处理带来很大的性能阻塞，所以会采用乐观锁的方式实现商品库存的操作。实现的方式也比较简单，也就是在最后执行库存扣减操作时，将事务开始前获取的库存数量带入到SQL语句中与目前数据库记录中的库存数量进行判断，如果数量相等，则该条更新库存的语句成功执行；如果不相等，则表示该商品的库存信息在当前事务执行过程中已经被其他事务修改，则会放弃该条update的执行，可以采用重试的机制重新执行该事务，避免商品超卖的发生，具体的SQL语句示意如下：\nupdate auction_auctions set quantity = #inQuantity#, where auction_id = #itemId# and quantity = #dbQuantity# 如果参与大促的商品拥有较大库存数量的时候，需要将之前仅仅作为商品信息浏览的缓存的作用，提升到为库存操作提供事务支持的角色。\n打造数字化运营能力 每一个URL请求都会生成一个全局唯一的ID，鹰眼（类似于 Twitter 的 Zipkin）平台中称为TraceID，这个ID会出现在该请求中所有服务调用、数据库、缓存、消息服务访问时生成的所有日志中。因为上述所有的资源访问均是在分布式环境下进行的，如何将该TraceID平滑地传递到各个服务节点上呢？如果要求应用程序中实现服务链路日志的打印和TraceID的传递，则在程序中有大量的日志打印代码，而且需要将TraceID采用业务数据的方式传递给下一服务节点，这些都给应用带来了非常大的代码侵入。\n阿里巴巴在中间件层面上统一实现了鹰眼的上下文创建以及日志埋点功能，让调用上下文在中间件的网络请求中传递，同时将调用上下文信息保存在了本地ThreadLocal中，从而实现了鹰眼平台所需的调用上下文和日志信息对于应用开发人员完全透明。\n埋点日志一般包含：\n TraceID、RPCID、开始时间、调用类型、对端IP。 处理耗时。 处理结果（ResultCode）。 数据传输量：请求大小/响应大小。  打造平台稳定性能力 限流和降级 淘宝技术团队开发的开源模块nginx-http-sysguard，主要用于当访问负载和内存达到一定的阀值之时，会执行相应的动作，比如直接返回503,504或者其他URL请求返回代码，一直等到内存或者负载回到阀值的范围内，站点恢复可用。\n流量调度 流量调度的核心是通过秒级获取服务器系统运行指标以及业务指标，通过流量调度平台设置的决策算法以及规则，当发现满足规则条件的指标状态发生时，对线上环境的服务器进行下线等操作，以屏蔽这些单点或局部出现故障的应用实例对整体平台产生扩展式的影响。\n业务开关 Switch 平台本身所提供的功能比较简单，但对于业务场景和环境复杂的分布式架构，这个平台确实能大大提升应用适应各种不同场景的自动化能力，比如通过开关的方式将正常环境下的应用逻辑切换到适配秒杀场景；当发现升级后的应用出现问题时，只需通过开关切换的方式就能让升级后的应用秒级切换到升级前的业务代码中。最重要的是在平台处于大促秒杀、应用异常时，业务开关在服务降级中所起的作用，相当于平台的最后一道保护屏障。\n"});index.add({'id':15,'href':'/docs/programmer-interview/','title':"程序员面试题",'content':"程序员面试题 "});index.add({'id':16,'href':'/docs/books/redis_5_source_code/','title':"Redis 5 设计与源码分析",'content':"Redis 5 设计与源码分析 Redis 5.0 新特性  新增Streams数据类型，这是 Redis 5.0 最重要的改进之一。可以把Streams当作消息队列。 新的模块API、定时器、集群及字典。 RDB中持久化存储LFU和LRU的信息。 将集群管理功能完全用C语言集成到redis-cli中，Redis 3.x 和 Redis4.x 的集群管理是通过Ruby脚本实现的。 有序集合新增命令ZPOPMIN/ZPOPMAX。 改进HyperLogLog的实现。 新增Client Unblock和Client ID。 新增LOLWUT命令。 Redis主从复制中的从不再称为Slave，改称Replicas。 Redis 5.0引入动态哈希，以平衡CPU的使用率和相应性能，可以通过配置文件进行配置。Redis 5.0默认使用动态哈希。 Redis核心代码进行了部分重构和优化。  简单动态字符串 （1） 长度小于 32 的短字符串\nstruct __attribute__ ((__packed__))sdshdr5 { unsigned char flags; // 低 3 位存储类型，高 5 位存储长度  char buf[]; // 柔性数组 } 结构如下：\n（2） 长度大于 31 的字符串\n此处仅展示一个示例：\nstruct __attribute__ ((__packed__))sdshdr8 { uint8_t len; // 已使用长度  uint8_t alloc; // 已分配的字节总长度  unsigned char flags; // 低 3 位存储类型  char buf[]; // 柔性数组 } SDS 读操作的复杂度多为O(1)，直接读取成员变量；涉及修改的写操作，则可能会触发扩容。\n跳跃表 对于有序集合的底层实现，我们可以使用数组、链表、平衡树等结构。数组不便于元素的插入和删除；链表的查询效率低，需要遍历所有元素；平衡树或者红黑树等结构虽然效率高但实现复杂。Redis采用了一种新型的数据结构——跳跃表。跳跃表的效率堪比红黑树，然而其实现却远比红黑树简单。\ntypedef struct zskiplistNode { sds ele; double score; struct zskiplistNode *backward; struct zskiplistLevel { struct zskiplistNode *forward; unsigned int span; } level[]; } zskiplistNode; typedef struct zskiplist { struct zskiplistNode *header, *tail; unsigned long length; int level; } zkiplist; 在Redis中，跳跃表主要应用于有序集合的底层实现（有序集合的另一种实现方式为压缩列表）。zset插入第一个元素时，会判断下面两种条件：\n zset-max-ziplist-entries的值是否等于0； zset-max-ziplist-value小于要插入元素的字符串长度。  满足任一条件Redis就会采用跳跃表作为底层实现，否则采用压缩列表作为底层实现方式。一般情况下，不会将zset-max-ziplist-entries配置成0，元素的字符串长度也不会太长，所以在创建有序集合时，默认使用压缩列表的底层实现。\nzset新插入元素时，会判断以下两种条件：\n zset中元素个数大于zset_max_ziplist_entries； 插入元素的字符串长度大于zset_max_ziplist_value。  当满足任一条件时，Redis便会将zset的底层实现由压缩列表转为跳跃表。值得注意的是，zset在转为跳跃表之后，即使元素被逐渐删除，也不会重新转为压缩列表。\n跳跃表的原理简单，其查询、插入、删除的平均复杂度都为O(logN)。\n压缩列表 压缩列表ziplist本质上就是一个字节数组，是Redis为了节约内存而设计的一种线性数据结构，可以包含多个元素，每个元素可以是一个字节数组或一个整数。\nRedis的有序集合、散列和列表都直接或者间接使用了压缩列表。当有序集合或散列表的元素个数比较少，且元素都是短字符串时，Redis便使用压缩列表作为其底层数据存储结构。\n元素的结构示意图：\n字典 Redis自带客户端就是使用times 33散列函数来计算字符串的Hash值，Redis服务端的Hash函数使用的是siphash算法，主要功能与客户端Hash函数类似，其优点是针对有规律的键计算出来的Hash值也具有强随机分布性，但算法较为复杂。\n整数集合 整数集合（intset）是一个有序的、存储整型数据的结构。\n127.0.0.1:6379\u0026gt; sadd testset 1 2 1 6 (integer) 4 127.0.0.1:6379\u0026gt; object encoding testset \u0026#34;intset\u0026#34; intset是按从小到大有序排列的，所以通过防御性判断之后使用二分法进行元素的查找。\nquicklist的实现 quicklist是Redis底层最重要的数据结构之一，它是Redis对外提供的6种基本数据结构中List的底层实现，在Redis 3.2版本中引入，能够在时间效率和空间效率间实现较好的折中。quicklist由List和ziplist结合而成。quicklist是一个双向链表，链表中的每个节点是一个ziplist结构。quicklist可以看成是用双向链表将若干小型的ziplist连接到一起组成的一种数据结构。\nStream Redis Stream的结构如图所示，它主要由消息、生产者、消费者、消费组4部分组成。\nxadd mystream1 * name zk age 20 mystream1为Stream的名称；*代表由Redis自行生成消息ID;name、age为该消息的field; zk、20则为对应的field的值。\n每个消息都由以下两部分组成。\n 每个消息有唯一的消息ID，消息ID严格递增。 消息内容由多个field-value对组成。  "});index.add({'id':17,'href':'/docs/rocketmq/rocketmq-message-indexing-flow/','title':"RocketMQ 消息索引流程",'content':"RocketMQ 消息索引流程 讲述 RocketMQ 消息索引服务\n一、消息查询方式 对于 Producer 发送到 Broker 服务器的消息，RocketMQ 支持多种方式来方便地查询消息:\n(1) 根据键查询消息 如下所示，在构建消息的时候，指定了这条消息的键为 “OrderID001”:\nMessage msg = new Message(\u0026#34;TopicTest\u0026#34;, \u0026#34;TagA\u0026#34;, \u0026#34;OrderID001\u0026#34;, // Keys  \u0026#34;Hello world\u0026#34;.getBytes(RemotingHelper.DEFAULT_CHARSET)); 那么，当这条消息发送成功后，我们可以使用 queryMsgByKey 命令查询到这条消息的详细信息:\nMQAdminStartup.main(new String[] { \u0026#34;queryMsgByKey\u0026#34;, \u0026#34;-n\u0026#34;, \u0026#34;localhost:9876\u0026#34;, \u0026#34;-t\u0026#34;, \u0026#34;TopicTest\u0026#34;, \u0026#34;-k\u0026#34;, \u0026#34;OrderID001\u0026#34; }); (2) 根据ID(偏移量)查询消息 消息在发送成功之后，其返回的 SendResult 类中包含了这条消息的唯一偏移量 ID (注意此处指的是 offsetMsgId):\n用户可以使用 queryMsgById 命令查询这条消息的详细信息:\nMQAdminStartup.main(new String[] { \u0026#34;queryMsgById\u0026#34;, \u0026#34;-n\u0026#34;, \u0026#34;localhost:9876\u0026#34;, \u0026#34;-i\u0026#34;, \u0026#34;0A6C73D900002A9F0000000000004010\u0026#34; }); (3) 根据唯一键查询消息 消息在发送成功之后，其返回的 SendResult 类中包含了这条消息的唯一 ID:\n用户可以使用 queryMsgByUniqueKey 命令查询这条消息的详细信息:\nMQAdminStartup.main(new String[] { \u0026#34;queryMsgByUniqueKey\u0026#34;, \u0026#34;-n\u0026#34;, \u0026#34;localhost:9876\u0026#34;, \u0026#34;-i\u0026#34;, \u0026#34;0A6C73D939B318B4AAC20CBA5D920000\u0026#34;, \u0026#34;-t\u0026#34;, \u0026#34;TopicTest\u0026#34; }); (4) 根据消息队列偏移量查询消息 消息发送成功之后的 SendResult 中还包含了消息队列的其它信息，如消息队列 ID、消息队列偏移量等信息:\nSendResult [sendStatus=SEND_OK, msgId=0A6C73D93EC518B4AAC20CC4ACD90000, offsetMsgId=0A6C73D900002A9F000000000000484E, messageQueue=MessageQueue [topic=TopicTest, brokerName=zk-pc, queueId=3], queueOffset=24] 根据这些信息，使用 queryMsgByOffset 命令也可以查询到这条消息的详细信息:\nMQAdminStartup.main(new String[] { \u0026#34;queryMsgByOffset\u0026#34;, \u0026#34;-n\u0026#34;, \u0026#34;localhost:9876\u0026#34;, \u0026#34;-t\u0026#34;, \u0026#34;TopicTest\u0026#34;, \u0026#34;-b\u0026#34;, \u0026#34;zk-pc\u0026#34;, \u0026#34;-i\u0026#34;, \u0026#34;3\u0026#34;, \u0026#34;-o\u0026#34;, \u0026#34;24\u0026#34; }); 二、ID (偏移量) 查询 (1) 生成 ID ID (偏移量) 是在消息发送到 Broker 服务器存储的时候生成的，其包含如下几个字段：\n Broker 服务器 IP 地址 Broker 服务器端口号 消息文件 CommitLog 写偏移量  public class CommitLog { class DefaultAppendMessageCallback implements AppendMessageCallback { public AppendMessageResult doAppend(final long fileFromOffset, /** 其它参数 **/) { String msgId = MessageDecoder .createMessageId(this.msgIdMemory, msgInner.getStoreHostBytes(hostHolder), wroteOffset); // ...  } } } (2) 使用 ID 查询 Admin 端查询的时候，首先对 msgId 进行解析，取出 Broker 服务器的 IP 、端口号和消息偏移量:\npublic class MessageDecoder { public static MessageId decodeMessageId(final String msgId) throws UnknownHostException { byte[] ip = UtilAll.string2bytes(msgId.substring(0, 8)); byte[] port = UtilAll.string2bytes(msgId.substring(8, 16)); // offset  byte[] data = UtilAll.string2bytes(msgId.substring(16, 32)); // ...  } } 获取到偏移量之后，Admin 会对 Broker 服务器发送一个 VIEW_MESSAGE_BY_ID 的请求命令，Broker 服务器在收到请求后，会依据偏移量定位到 CommitLog 文件中的相应位置,然后取出消息，返回给 Admin 端:\npublic class DefaultMessageStore implements MessageStore { @Override public SelectMappedBufferResult selectOneMessageByOffset(long commitLogOffset) { SelectMappedBufferResult sbr = this.commitLog .getMessage(commitLogOffset, 4); // 1 TOTALSIZE  int size = sbr.getByteBuffer().getInt(); return this.commitLog.getMessage(commitLogOffset, size); } } 三、消息队列偏移量查询 根据队列偏移量查询是最简单的一种查询方式，Admin 会启动一个 PullConsumer ，然后利用用户传递给 Admin 的队列 ID、队列偏移量等信息，从服务器拉取一条消息过来:\npublic class QueryMsgByOffsetSubCommand implements SubCommand { @Override public void execute(CommandLine commandLine, Options options, RPCHook rpcHook) throws SubCommandException { // 根据参数构建 MessageQueue  MessageQueue mq = new MessageQueue(); mq.setTopic(topic); mq.setBrokerName(brokerName); mq.setQueueId(Integer.parseInt(queueId)); // 从 Broker 服务器拉取消息  PullResult pullResult = defaultMQPullConsumer.pull(mq, \u0026#34;*\u0026#34;, Long.parseLong(offset), 1); } } 四、消息索引服务 在继续讲解剩下两种查询方式之前，我们必须先介绍以下 Broker 端的消息索引服务。\n在之前提到过，每当一条消息发送过来之后，其会封装为一个 DispatchRequest 来下发给各个转发服务，而 CommitLogDispatcherBuildIndex 构建索引服务便是其中之一:\nclass CommitLogDispatcherBuildIndex implements CommitLogDispatcher { @Override public void dispatch(DispatchRequest request) { if (DefaultMessageStore.this.messageStoreConfig.isMessageIndexEnable()) { DefaultMessageStore.this.indexService.buildIndex(request); } } } (1) 索引文件结构 消息的索引信息是存放在磁盘上的，文件以时间戳命名的，默认存放在 $HOME/store/index 目录下。由下图来看，一个索引文件的结构被分成了三部分:\n 前 40 个字节存放固定的索引头信息，包含了存放在这个索引文件中的消息的最小/大存储时间、最小/大偏移量等状况 中间一段存储了 500 万个哈希槽位，每个槽内部存储的是索引文件的地址 (索引槽) 最后一段存储了 2000 万个索引内容信息，是实际的索引信息存储的地方。每一个槽位存储了这条消息的键哈希值、存储偏移量、存储时间戳与下一个索引槽地址  RocketMQ 在内存中还维护了一个索引文件列表，对于每一个索引文件，前一个文件的最大存储时间是下一个文件的最小存储时间，前一个文件的最大偏移量是下一个文件的最大偏移量。每一个索引文件都索引了在某个时间段内、某个偏移量段内的所有消息，当文件满了，就会用前一个文件的最大偏移量和最大存储时间作为起始值，创建下一个索引文件:\n(2) 添加消息 当有新的消息过来后，构建索引服务会取出这条消息的键，然后对字符串 “话题#键” 构建索引。构建索引的步骤如下:\n 找出哈希槽: 生成字符串哈希码，取余落到 500W 个槽位之一，并取出其中的值，默认为 0 找出索引槽: IndexHeader 维护了 indexCount，实际存储的索引槽就是直接依次顺延添加的 存储索引内容: 找到索引槽后，放入键哈希值、存储偏移量、存储时间戳与下一个索引槽地址。下一个索引槽地址就是第一步哈希槽中取出的值，0 代表这个槽位是第一次被索引，而不为 0 代表这个槽位之前的索引槽地址。由此，通过索引槽地址可以将相同哈希槽的消息串联起来，像单链表那样。 更新哈希槽: 更新原有哈希槽中存储的值  我们以实际例子来说明。假设我们需要依次为键的哈希值为 “{16,29,29,8,16,16}” 这几条消息构建索引，我们在这个地方忽略了索引信息中存储的存储时间和偏移量字段，只是存储键哈希和下一索引槽信息，那么:\n 放入 16: 将 “16|0” 存储在第 1 个索引槽中，并更新哈希槽为 16 的值为 1，即哈希槽为 16 的第一个索引块的地址为 1 放入 29: 将 “29|0” 存储在第 2 个索引槽中，并更新哈希槽为 29 的值为 2，即哈希槽为 29 的第一个索引块的地址为 2 放入 29: 取出哈希槽为 29 中的值 2，然后将 “29|2” 存储在第 3 个索引槽中，并更新哈希槽为 29 的值为 3，即哈希槽为 29 的第一个索引块的地址为 3。而在找到索引块为 3 的索引信息后，又能取出上一个索引块的地址 2，构成链表为： “[29]-\u0026gt;3-\u0026gt;2” 放入 8: 将 “8|0” 存储在第 4 个索引槽中，并更新哈希槽为 8 的值为 4，即哈希槽为 8 的第一个索引块的地址为 4 放入 16: 取出哈希槽为 16 中的值 1，然后将 “16|1” 存储在第 5 个索引槽中，并更新哈希槽为 16 的值为 5。构成链表为: “[16]-\u0026gt;5-\u0026gt;1” 放入 16: 取出哈希槽为 16 中的值 5，然后将 “16|5” 存储在第 6 个索引槽中，并更新哈希槽为 16 的值为 6。构成链表为: “[16]-\u0026gt;6-\u0026gt;5-\u0026gt;1”  整个过程如下图所示:\n(3) 查询消息 当需要根据键来查询消息的时候，其会按照倒序回溯整个索引文件列表，对于每一个在时间上能够匹配用户传入的 begin 和 end 时间戳参数的索引文件，会一一进行消息查询：\npublic class IndexService { public QueryOffsetResult queryOffset(String topic, String key, int maxNum, long begin, long end) { // 倒序  for (int i = this.indexFileList.size(); i \u0026gt; 0; i--) { // 位于时间段内  if (f.isTimeMatched(begin, end)) { // 消息查询  } } } } 而具体到每一个索引文件，其查询匹配消息的过程如下所示:\n 确定哈希槽: 根据键生成哈希值，定位到哈希槽 定位索引槽: 哈希槽中的值存储的就是链表的第一个索引槽地址 遍历索引槽: 沿着索引槽地址，依次取出下一个索引槽地址，即沿着链表遍历，直至遇见下一个索引槽地址为非法地址 0 停止 收集偏移量: 在遇到匹配的消息之后，会将相应的物理偏移量放到列表中，最后根据物理偏移量，从 CommitLog 文件中取出消息  public class DefaultMessageStore implements MessageStore { @Override public QueryMessageResult queryMessage(String topic, String key, int maxNum, long begin, long end) { for (int m = 0; m \u0026lt; queryOffsetResult.getPhyOffsets().size(); m++) { long offset = queryOffsetResult.getPhyOffsets().get(m); // 根据偏移量从 CommitLog 文件中取出消息  } } } 以查询哈希值 16 的消息为例，图示如下:\n五、唯一键查询消息 (1) 构建键 消息的唯一键是在客户端发送消息前构建的:\npublic class DefaultMQProducerImpl implements MQProducerInner { private SendResult sendKernelImpl(final Message msg, /** 其它参数 **/) throws XXXException { // ...  if (!(msg instanceof MessageBatch)) { MessageClientIDSetter.setUniqID(msg); } } } 创建唯一 ID 的算法:\npublic class MessageClientIDSetter { public static String createUniqID() { StringBuilder sb = new StringBuilder(LEN * 2); sb.append(FIX_STRING); sb.append(UtilAll.bytes2string(createUniqIDBuffer())); return sb.toString(); } } 唯一键是根据客户端的进程 ID、IP 地址、ClassLoader 哈希码、时间戳、计数器这几个值来生成的一个唯一的键，然后作为这条消息的附属属性发送到 Broker 服务器的:\npublic class MessageClientIDSetter { public static void setUniqID(final Message msg) { if (msg.getProperty(MessageConst.PROPERTY_UNIQ_CLIENT_MESSAGE_ID_KEYIDX) == null) { msg.putProperty(MessageConst.PROPERTY_UNIQ_CLIENT_MESSAGE_ID_KEYIDX, createUniqID()); } } } (2) 索引键 当服务器收到客户端发送过来的消息之后，索引服务便会取出客户端生成的 uniqKey 并为之建立索引，放入到索引文件中:\npublic class IndexService { public void buildIndex(DispatchRequest req) { // ...  if (req.getUniqKey() != null) { indexFile = putKey(indexFile, msg, buildKey(topic, req.getUniqKey())); } // ...  } } (3) 使用键查询 客户端在生成消息唯一键的时候，在 ByteBuffer 的第 11 位到第 14 位放置的是当前的时间与当月第一天的时间的毫秒差:\npublic class MessageClientIDSetter { private static byte[] createUniqIDBuffer() { long current = System.currentTimeMillis(); if (current \u0026gt;= nextStartTime) { setStartTime(current); } // 时间差 [当前时间 - 这个月 1 号的时间]  // putInt 占据的是第 11 位到第 14 位  buffer.putInt((int) (System.currentTimeMillis() - startTime)); } private synchronized static void setStartTime(long millis) { Calendar cal = Calendar.getInstance(); cal.setTimeInMillis(millis); cal.set(Calendar.DAY_OF_MONTH, 1); cal.set(Calendar.HOUR_OF_DAY, 0); cal.set(Calendar.MINUTE, 0); cal.set(Calendar.SECOND, 0); cal.set(Calendar.MILLISECOND, 0); // 开始时间设置为这个月的 1 号  startTime = cal.getTimeInMillis(); // ...  } } 我们知道消息索引服务的查询需要用户传入 begin 和 end 这连个时间值，以进行这段时间内的匹配。所以 RocketMQ 为了加速消息的查询，于是在 Admin 端对特定 ID 进行查询的时候，首先取出了这段时间差值，然后与当月时间进行相加得到 begin 时间值:\npublic class MessageClientIDSetter { public static Date getNearlyTimeFromID(String msgID) { ByteBuffer buf = ByteBuffer.allocate(8); byte[] bytes = UtilAll.string2bytes(msgID); buf.put((byte) 0); buf.put((byte) 0); buf.put((byte) 0); buf.put((byte) 0); // 取出第 11 位到 14 位  buf.put(bytes, 10, 4); buf.position(0); // 得到时间差值  long spanMS = buf.getLong(); Calendar cal = Calendar.getInstance(); long now = cal.getTimeInMillis(); cal.set(Calendar.DAY_OF_MONTH, 1); cal.set(Calendar.HOUR_OF_DAY, 0); cal.set(Calendar.MINUTE, 0); cal.set(Calendar.SECOND, 0); cal.set(Calendar.MILLISECOND, 0); long monStartTime = cal.getTimeInMillis(); if (monStartTime + spanMS \u0026gt;= now) { cal.add(Calendar.MONTH, -1); monStartTime = cal.getTimeInMillis(); } // 设置为这个月(或者上个月) + 时间差值  cal.setTimeInMillis(monStartTime + spanMS); return cal.getTime(); } } 由于发送消息的客户端和查询消息的 Admin 端可能不在一台服务器上，而且从函数的命名 getNearlyTimeFromID 与上述实现来看，Admin 端的时间戳得到的是一个近似起始值，它尽可能地加速用户的查询。而且太旧的消息(超过一个月的消息)是查询不到的。\n当 begin 时间戳确定以后，Admin 便会将其它必要的信息如话题、Key等信息封装到 QUERY_MESSAGE 的包中，然后向 Broker 服务器传递这个请求，来进行消息的查询。Broker 服务器在获取到这个查询消息的请求后，便会根据 Key 从索引文件中查询符合的消息，最终返回到 Admin 端。\n六、键查询消息 (1) 构建键 我们提到过，在发送消息的时候，可以填充一个 keys 的值，这个值将会作为消息的一个属性被发送到 Broker 服务器上:\npublic class Message implements Serializable { public void setKeys(String keys) { this.putProperty(MessageConst.PROPERTY_KEYS, keys); } } (2) 索引键 当服务器收到客户端发送过来的消息之后，索引服务便会取出这条消息的 keys 并将其用空格进行分割，分割后的每一个字符串都会作为一个单独的键，创建索引，放入到索引文件中:\npublic class IndexService { public void buildIndex(DispatchRequest req) { // ...  if (keys != null \u0026amp;\u0026amp; keys.length() \u0026gt; 0) { // 使用空格进行分割  String[] keyset = keys.split(MessageConst.KEY_SEPARATOR); for (int i = 0; i \u0026lt; keyset.length; i++) { String key = keyset[i]; if (key.length() \u0026gt; 0) { indexFile = putKey(indexFile, msg, buildKey(topic, key)); } } } } } 由此我们也可以得知，keys 键的设置通过使用空格分割字符串，一条消息可以指定多个键。\n(3) 使用键查询 keys 键查询的方式也是通过将参数封装为 QUERY_MESSAGE 请求包中去请求服务器返回相应的信息。由于键本身不能和时间戳相关联，因此 begin 值设置的是 0，这是和第五节的不同之处:\npublic class QueryMsgByKeySubCommand implements SubCommand { private void queryByKey(final DefaultMQAdminExt admin, final String topic, final String key) throws MQClientException, InterruptedException { // begin: 0  // end: Long.MAX_VALUE  QueryResult queryResult = admin.queryMessage(topic, key, 64, 0, Long.MAX_VALUE); } } "});index.add({'id':18,'href':'/docs/rocketmq/rocketmq-timing-message-and-retry-message/','title':"RocketMQ 定时消息和重试消息",'content':"RocketMQ 定时消息和重试消息 讲述 RocketMQ 定时消息和重试消息\n一、定时消息概述 RocketMQ 支持 Producer 端发送定时消息，即该消息被发送之后，到一段时间之后才能被 Consumer 消费者端消费。但是当前开源版本的 RocketMQ 所支持的定时时间是有限的、不同级别的精度的时间，并不是任意无限制的定时时间。因此在每条消息上设置定时时间的 API 叫做 setDelayTimeLevel，而非 setDelayTime 这样的命名:\nMessage msg = new Message(\u0026#34;TopicTest\u0026#34; /* Topic */, \u0026#34;TagA\u0026#34; /* Tag */, (\u0026#34;Hello RocketMQ \u0026#34; + i).getBytes(RemotingHelper.DEFAULT_CHARSET) /* Message body */); msg.setDelayTimeLevel(i + 1); 默认 Broker 服务器端有 18 个定时级别:\npublic class MessageStoreConfig { private String messageDelayLevel = \u0026#34;1s 5s 10s 30s 1m 2m 3m 4m 5m 6m 7m 8m 9m 10m 20m 30m 1h 2h\u0026#34;; } 这 18 个定时级别在服务器端启动的时候，会被解析并放置到表 delayLevelTable 中。解析的过程就是上述字符串按照空格拆分开，然后根据时间单位的不同再进一步进行计算，得到最终的毫秒时间。级别就是根据这些毫秒时间的顺序而确定的，例如上述 1s 延迟就是级别 1， 5s 延迟就是级别 2，以此类推:\npublic class ScheduleMessageService extends ConfigManager { public boolean parseDelayLevel() { for (int i = 0; i \u0026lt; levelArray.length; i++) { // ...  int level = i + 1; long delayTimeMillis = tu * num; // 级别:延迟时间  this.delayLevelTable.put(level, delayTimeMillis); } } } 二、定时消息预存储 客户端在为某条消息设置上定时级别的时候，实际上级别这个字段会被作为附属属性放到消息中:\npublic class Message implements Serializable { public void setDelayTimeLevel(int level) { this.putProperty(MessageConst.PROPERTY_DELAY_TIME_LEVEL, String.valueOf(level)); } } 我们先前的文章提到过，发送到 Broker 服务器的消息会被存储到 CommitLog 消息文件中。那么在此处即使是定时消息也不例外，将定时消息存储下来是为了保证消息最大程度地不丢失。然而毕竟和普通消息不同，在遇到定时消息后，CommitLog 会将这条消息的话题和队列 ID 替换成专门用于定时的话题和相应的级别对应的队列 ID。真实的话题和队列 ID 会作为属性放置到这条消息中。\npublic class CommitLog { public PutMessageResult putMessage(final MessageExtBrokerInner msg) { // Delay Delivery  if (msg.getDelayTimeLevel() \u0026gt; 0) { topic = ScheduleMessageService.SCHEDULE_TOPIC; queueId = ScheduleMessageService.delayLevel2QueueId(msg.getDelayTimeLevel()); // Backup real topic, queueId  MessageAccessor.putProperty(msg, MessageConst.PROPERTY_REAL_TOPIC, msg.getTopic()); MessageAccessor.putProperty(msg, MessageConst.PROPERTY_REAL_QUEUE_ID, String.valueOf(msg.getQueueId())); msg.setPropertiesString(MessageDecoder.messageProperties2String(msg.getProperties())); // 替换 Topic 和 QueueID  msg.setTopic(topic); msg.setQueueId(queueId); } } } 随后，这条消息会被存储在 CommitLog 消息文件中。而我们知道后台重放消息服务 ReputMessageService 会一直监督 CommitLog 文件是否添加了新的消息。当有了新的消息后，重放消息服务会取出消息并封装为 DispatchRequest 请求，然后将其分发给不同的三个分发服务，建立消费队列文件服务就是这其中之一。而此处当取消息封装为 DispatchRequest 的时候，当遇到定时消息时，又多做了一些额外的事情。\n当遇见定时消息时，CommitLog 计算 tagsCode 标签码与普通消息不同。对于定时消息，tagsCode 值设置的是这条消息的投递时间，即建立消费队列文件的时候，文件中的 tagsCode 存储的是这条消息未来在什么时候被投递:\npublic class CommitLog { public DispatchRequest checkMessageAndReturnSize(java.nio.ByteBuffer byteBuffer, final boolean checkCRC, final boolean readBody) { // Timing message processing  { String t = propertiesMap.get(MessageConst.PROPERTY_DELAY_TIME_LEVEL); if (ScheduleMessageService.SCHEDULE_TOPIC.equals(topic) \u0026amp;\u0026amp; t != null) { int delayLevel = Integer.parseInt(t); if (delayLevel \u0026gt; 0) { tagsCode = this.defaultMessageStore.getScheduleMessageService() .computeDeliverTimestamp(delayLevel,storeTimestamp); } } } } } 如下是，发送了 10 条定时级别分别为 1-10 的消息以后，$HOME/store/consumequeue 文件下的消费队列文件的分布情况:\n不同的定时级别对应于不同的队列 ID，定时级别减 1 得到的就是队列 ID 的值。因此级别 1-10 对应的是 0-9 的队列 ID:\npublic class ScheduleMessageService extends ConfigManager { public static int delayLevel2QueueId(final int delayLevel) { return delayLevel - 1; } } 三、定时消息再存储 Broker 启动的时候，会开启一个调度消息服务，此服务会监控所有定时消息队列，每一个消息队列会创建一个专门的延时消息投递任务用以到达规定时间后投递此消息:\npublic class ScheduleMessageService extends ConfigManager { public void start() { for (Map.Entry\u0026lt;Integer, Long\u0026gt; entry : this.delayLevelTable.entrySet()) { Integer level = entry.getKey(); Long timeDelay = entry.getValue(); Long offset = this.offsetTable.get(level); if (timeDelay != null) { this.timer.schedule(new DeliverDelayedMessageTimerTask(level, offset), FIRST_DELAY_TIME); } } } } 每个消息队里的消息投递任务，会检查自己跟踪的消息队列，并从此消息队列所对应的定时级别的偏移量中检查是否有新的定时消息到来。其中定时级别的偏移量是维护在内存中的偏移量表 offsetTable 中。每隔 10 秒钟，这个表会被持久化到磁盘上的 delayOffset.json 文件中一次:\npublic class ScheduleMessageService extends ConfigManager { private final ConcurrentMap\u0026lt;Integer /* level */, Long/* offset */\u0026gt; offsetTable = new ConcurrentHashMap\u0026lt;Integer, Long\u0026gt;(32); public void start() { // 每隔 10 秒钟持久化一次  this.timer.scheduleAtFixedRate(new TimerTask() { @Override public void run() { ScheduleMessageService.this.persist(); } }, 10000, this.defaultMessageStore.getMessageStoreConfig().getFlushDelayOffsetInterval()); } } delayOffset.json 文件中存储的示例信息如下所示：\nDeliverDelayedMessageTimerTask 任务会从消费任务队列文件中取出最新的定时消息的 tagsCode ，并计算出的当前是否已经到了这条消息投递的时间。如果到了，即 countdown \u0026lt; 0，那么便会从 CommitLog 文件中取出消息，修正消息的话题和队列 ID 等信息，然后重新存储此条消息。如果还没有到，那么便会重新执行一个定时时间设置为 countdown 毫秒的定时任务。在完成之后，会更新当前的偏移量表，为下一次做准备:\nclass DeliverDelayedMessageTimerTask extends TimerTask { public void executeOnTimeup() { // ...  for (; i \u0026lt; bufferCQ.getSize(); i += ConsumeQueue.CQ_STORE_UNIT_SIZE) { // 是否到时间  long countdown = deliverTimestamp - now; if (countdown \u0026lt;= 0) { // 取出消息  MessageExt msgExt = ScheduleMessageService.this.defaultMessageStore.lookMessageByOffset(offsetPy, sizePy); // 修正消息，设置上正确的话题和队列 ID  MessageExtBrokerInner msgInner = this.messageTimeup(msgExt); // 重新存储消息  PutMessageResult putMessageResult = ScheduleMessageService.this.defaultMessageStore .putMessage(msgInner); } else { // countdown 后投递此消息  ScheduleMessageService.this .timer .schedule(new DeliverDelayedMessageTimerTask(this.delayLevel, nextOffset), countdown); // 更新偏移量  } } // end of for  // 更新偏移量  } } 四、消息重试概述 消息重试分为消息发送重试和消息接受重试，消息发送重试是指消息从 Producer 端发送到 Broker 服务器的失败以后的重试情况，消息接受重试是指 Consumer 在消费消息的时候出现异常或者失败的重试情况。\nProducer 端通过配置如下这两个两个 API 可以分别配置在同步发送和异步发送消息失败的时候的重试次数:\nDefaultMQProducer producer = new DefaultMQProducer(\u0026#34;please_rename_unique_group_name\u0026#34;); producer.setRetryTimesWhenSendAsyncFailed(3); producer.setRetryTimesWhenSendFailed(3); Consumer 端在消费的时候，如果接收消息的回调函数出现了以下几种情况:\n 抛出异常 返回 NULL 状态 返回 RECONSUME_LATER 状态 超时 15 分钟没有响应  那么 Consumer 便会将消费失败的消息重新调度直到成功消费:\nconsumer.registerMessageListener(new MessageListenerConcurrently() { @Override public ConsumeConcurrentlyStatus consumeMessage(List\u0026lt;MessageExt\u0026gt; msgs, ConsumeConcurrentlyContext context) { // 抛出异常  // 返回 NULL 或者 RECONSUME_LATER 状态  return ConsumeConcurrentlyStatus.RECONSUME_LATER; } }); 五、Producer 消息发送重试 发送失败的重试方式，主要表现在发送消息的时候，会最多尝试 getRetryTimesWhenSendFailed() 次发送，当成功发送以后，会直接返回发送结果给调用者。当发送失败以后，会继续进行下一次发送尝试，核心代码如下所示：\npublic class DefaultMQProducerImpl implements MQProducerInner { private SendResult sendDefaultImpl(Message msg, /** 其他参数 **/) throws MQClientException, RemotingException, MQBrokerException, InterruptedException { int timesTotal = communicationMode == CommunicationMode.SYNC ? 1 + this.defaultMQProducer.getRetryTimesWhenSendFailed() : 1; int times = 0; for (; times \u0026lt; timesTotal; times++) { // 尝试发送消息，发送成功 return，发送失败 continue  } } } 六、Consumer 消息接受重试 (1) 订阅重试话题 Consumer 在启动的时候，会执行一个函数 copySubscription() ，当用户注册的消息模型为集群模式的时候，会根据用户指定的组创建重试组话题并放入到注册信息中:\npublic class DefaultMQPushConsumerImpl implements MQConsumerInner { public synchronized void start() throws MQClientException { switch (this.serviceState) { case CREATE_JUST: // ...  this.copySubscription(); // ...  this.serviceState = ServiceState.RUNNING; break; } } private void copySubscription() throws MQClientException { switch (this.defaultMQPushConsumer.getMessageModel()) { case BROADCASTING: break; case CLUSTERING: // 重试话题组  final String retryTopic = MixAll.getRetryTopic(this.defaultMQPushConsumer.getConsumerGroup()); SubscriptionData subscriptionData = FilterAPI.buildSubscriptionData(this.defaultMQPushConsumer.getConsumerGroup(), retryTopic, SubscriptionData.SUB_ALL); this.rebalanceImpl.getSubscriptionInner().put(retryTopic, subscriptionData); break; default: break; } } } 假设用户指定的组为 “ORDER”，那么重试话题则为 “%RETRY%ORDER”，即前面加上了 “%RETRY%” 这个字符串。\nConsumer 在一开始启动的时候，就为用户自动注册了订阅组的重试话题。即用户不单单只接受这个组的话题的消息，也接受这个组的重试话题的消息。这样一来，就为下文用户如何重试接受消息奠定了基础。\n(2) 失败消息发往重试话题 当 Consumer 客户端在消费消息的时候，抛出了异常、返回了非正确消费的状态等错误的时候，这个时候 ConsumeMessageConcurrentlyService 会收集所有失败的消息，然后将每一条消息封装进 CONSUMER_SEND_MSG_BACK 的请求中，并将其发送到 Broker 服务器:\npublic class ConsumeMessageConcurrentlyService implements ConsumeMessageService { public void processConsumeResult(final ConsumeConcurrentlyStatus status, /** 其他参数 **/) { switch (this.defaultMQPushConsumer.getMessageModel()) { case BROADCASTING: // ...  break; case CLUSTERING: for (int i = ackIndex + 1; i \u0026lt; consumeRequest.getMsgs().size(); i++) { MessageExt msg = consumeRequest.getMsgs().get(i); // 重新将消息发往 Broker 服务器  boolean result = this.sendMessageBack(msg, context); } // ...  break; default: break; } } } 当消费失败的消息重新发送到服务器后，Broker 会为其指定新的话题重试话题，并根据当前这条消息的已有的重试次数来选择定时级别，即将这条消息变成定时消息投放到重试话题消息队列中。可见消息消费失败后并不是立即进行新的投递，而是有一定的延迟时间的。延迟时间随着重试次数的增加而增加，也即投递的时间的间隔也越来越长:\npublic class SendMessageProcessor extends AbstractSendMessageProcessor implements NettyRequestProcessor { private RemotingCommand consumerSendMsgBack(final ChannelHandlerContext ctx, final RemotingCommand request) throws RemotingCommandException { // 指定为重试话题  String newTopic = MixAll.getRetryTopic(requestHeader.getGroup()); int queueIdInt = Math.abs(this.random.nextInt() % 99999999) % subscriptionGroupConfig.getRetryQueueNums(); // 指定为延时信息，设定延时级别  if (0 == delayLevel) { delayLevel = 3 + msgExt.getReconsumeTimes(); } msgExt.setDelayTimeLevel(delayLevel); // 重试次数增加  msgInner.setReconsumeTimes(msgExt.getReconsumeTimes() + 1); // 重新存储  PutMessageResult putMessageResult = this.brokerController.getMessageStore().putMessage(msgInner); // ...  } } 当然，消息如果一直消费不成功，那也不会一直无限次的尝试重新投递的。当重试次数大于最大重试次数 (默认为 16 次) 的时候，该消息将会被送往死信话题队列，认定这条话题投递无门:\npublic class SendMessageProcessor extends AbstractSendMessageProcessor implements NettyRequestProcessor { private RemotingCommand consumerSendMsgBack(final ChannelHandlerContext ctx, final RemotingCommand request) throws RemotingCommandException { // 重试次数大于最大重试次数  if (msgExt.getReconsumeTimes() \u0026gt;= maxReconsumeTimes || delayLevel \u0026lt; 0) { // 死信队列话题  newTopic = MixAll.getDLQTopic(requestHeader.getGroup()); queueIdInt = Math.abs(this.random.nextInt() % 99999999) % DLQ_NUMS_PER_GROUP; } // ...  } } 上述客户端消费失败信息的流程图如下所示:\n"});index.add({'id':19,'href':'/docs/books/in-depth_analysis_of_the_core_technology_of_apache_dubbo/','title':"深度剖析 Apache Dubbo 核心技术",'content':"深度剖析 Apache Dubbo 核心技术 SPI 扩展 Dubbo 支持扩展的核心接口上，都会通过类似 @SPI(\u0026quot;dubbo\u0026quot;) 这样的注解，来标识当前接口的默认实现。如果你想替换掉这个默认实现，那么需要两个步骤。第一，实现 Protocol 接口，然后在 META-INF/dubbo 目录下创建一个名字为 org.apache.dubbo.rpc.Protocol 的文本文件。这个 META-INF 目录如果使用的是 IDEA 开发，那么其应该放到 resources 目录下的顶层，这样打 jar 包的时候，其也会被复制到 jar 包的第一级目录。内容如下：\nmyProtocol = com.zk.MyProtocol 第二，需要在 XML 配置文件中，声明使用这个扩展实现：\n\u0026lt;dubbo:protocol name=\u0026#34;myProtocol\u0026#34;\u0026gt; 其实 JDK 本身也提供了 SPI 扩展，Dubbo 之所以没有使用默认提供的实现，是因为：\n JDK 标准的 SPI 一次性实例化扩展点的所有实现，如果有些没有使用到，那么会浪费资源。 扩展点加载失败的异常提示不是很好。 增强了 Ioc 和 AOP 的支持。  性能 Dubbo 会给每个服务提供者的实现类生产一个 Wrapper 类，这个 Wrapper 类里面最终调用服务提供者的接口实现类，Wrapper 类的存在是为了减少反射的调用。当服务提供方收到消费方发来的请求后，需要根据消费者传递过来的方法名和参数反射调用服务提供者的实现类，而反射本身是有性能开销的，Dubbo 把每个服务提供者的实现类通过 JavaAssist 包装为一个 Wrapper 类以减少反射调用开销。\n其实就是由反射改为了比较方法名称，然后调用，伪代码如下：\nGreetingServiceImpl impl = (GreetingServiceImpl) object; if (\u0026#34;sayHello\u0026#34;.equals(methodName) \u0026amp;\u0026amp; argClass.length == 1) { return impl.sayHello((String) argObject[0]); } if (\u0026#34;testGeneric\u0026#34;.equals(methodName) \u0026amp;\u0026amp; argClass.length == 1) { return impl.testGeneric((Pojo) arrObject[0]); } 容错 异常情况下的，代码逻辑应该怎么走？Dubbo 提供了如下几种容错方案：\n 失败重试：通常用于读操作或者具有幂等的写操作。需要注意的是，重试会带来更长延迟。 快速失败：抛出异常。 安全失败：忽略异常，场景：写入审计日志。 失败自动恢复：后台记录失败请求，并按照策略后期再重试，场景：消息通知。 并行调用：通常用于实时性要求较高的读操作，但需要浪费更多服务资源。 广播调用：通常用于通知所有提供者更新缓存或日志等本地资源信息。  负载均衡  随机策略 轮循策略 最少活跃调用数 一致性 Hash 策略  协议设计 服务消费端如何把服务请求信息序列化为二进制数据、服务提供方如何把消费端发送的二进制数据反序列化为可识别的POJO对象、Dubbo的应用层协议是怎么样的？\n看一下这个 \u0026ldquo;request flag and serialization id\u0026rdquo;：高四位标示请求类型：\n低四位标示序列化方式，其枚举值如下：\n再后面的一字节是只在响应报文里才设置（在请求报文里不设置），用来标示响应的结果码，具体定义如下：\n在此列出这个编码格式，是想要学习 Dubbo 是如果用较少的字节头，编码较多的信息的。还有编码的粒度，响应码这部分，并没有直接定义与业务紧密关联的状态码，比如 \u0026ldquo;磁盘存储失败\u0026rdquo; 等状态码，相反定义的是较为粗粒度的状态码，更为细粒度的可以放到 \u0026ldquo;body\u0026rdquo; 里面。\n"});index.add({'id':20,'href':'/docs/rocketmq/rocketmq-master-slave-sync/','title':"RocketMQ 主备同步",'content':"RocketMQ 主备同步 介绍 RocketMQ 的主备同步机制\n一、简介 RocketMQ 通过 Master-Slave 主备机制，来实现整个系统的高可用，具体表现在:\n Master 磁盘坏掉，Slave 依然保存了一份 Master 宕机，不影响消费者继续消费  二、搭建环境 我们在一台机器上搭建一个 Master 一个 Slave 的环境:\n为了能够将 Master 和 Slave 搭建在同一台计算机上，我们除了需要将 Broker 的角色设置为 SLAVE ，还需要为其指定单独的 brokerId、 storePathRootDir、 storePathCommitLog。\n// SLAVE 角色 messageStoreConfig.setBrokerRole(BrokerRole.SLAVE); // 一个机器如果要启动多个 Broker，那么每个 Broker 的 store 根目录必须不同 messageStoreConfig.setStorePathRootDir(storePathRootDir); // 一个机器如果要启动多个 Broker，那么每个 Broker 的 storePathCommitLog 根目录必须不同 messageStoreConfig.setStorePathCommitLog(storePathCommitLog); // 设置 Slave 的 Master HA 地址 messageStoreConfig.setHaMasterAddress(\u0026#34;localhost:10912\u0026#34;); // SLAVE 角色的 brokerId 必须大于 0 brokerConfig.setBrokerId(1); 注意 Slave 和 Master 的 brokerName 必须一致，即它们必须处于同一个 BrokerData 数据结构里面。实际上在做了如上的修改之后， Slave 和 Master 依旧不能同时运行在同一台机器上，因为 Slave 本身也可以称为 Master，接受来自其他 Slave 的请求，因此当运行 Slave 的时候，需要将 HAService 里面的启动 AcceptSocketService 运行的相关方法注释掉。\n三、建立连接 当一个 Broker 在启动的时候，会调用 HAService 的 start() 方法:\npublic class HAService { public void start() throws Exception { this.acceptSocketService.beginAccept(); this.acceptSocketService.start(); this.groupTransferService.start(); this.haClient.start(); } } AcceptSocketService 服务的功能是 Master 等待接受来自其它客户端 Slave 的连接，当成功建立连接后，会将这条连接 HAConnection 放入到 connectionList 连接列表里面。而 HAClient 服务的功能是 Slave 主动发起同其它 Master 的连接。\n四、数据传输 当启动 HAService 之后，一旦 Master 发现和 Slave 不同步，那么Master 会自动开始同步消息到 Slave，无需其它的触发机制。\n(1) 消息异步传输 如果 Master Broker 的角色是 ASYNC_MASTER，那么消息等待从 Master 同步到 Slave 的方式是异步传输的方式。这意味当一条消息发送到 Master Broker 的时候，Master Broker 在存储完这条消息到本地之后，并不会等待消息同步到 Slave Broker 才返回。这种方式会缩短发送消息的响应时间。\n(2) 消息同步传输 如果 Master Broker 的角色是 SYNC_MASTER，那么消息等待从 Master 同步到 Slave 的方式是同步传输的方式。除此之外，进入同步方式还得满足另外两个条件：\n 消息体的 PROPERTY_WAIT_STORE_MSG_OK 属性值为 true，即这条消息允许等待 Slave 相比 Master 落下的同步进度不能超过 256MB  public class CommitLog { public void handleHA(AppendMessageResult result, PutMessageResult putMessageResult, MessageExt messageExt) { if (BrokerRole.SYNC_MASTER == this.defaultMessageStore.getMessageStoreConfig().getBrokerRole()) { HAService service = this.defaultMessageStore.getHaService(); // 消息是否允许等待同步  if (messageExt.isWaitStoreMsgOK()) { // Slave 是否没有落下 Master 太多  if (service.isSlaveOK(result.getWroteOffset() + result.getWroteBytes())) { // 等待同步完成  // ...  } // Slave problem  else { // Tell the producer, slave not available  putMessageResult.setPutMessageStatus(PutMessageStatus.SLAVE_NOT_AVAILABLE); } } } } } 其中 isSlaveOK 方法就是用来检测 Slave 和 Master 落下的同步进度是否太大的:\npublic class HAService { public boolean isSlaveOK(final long masterPutWhere) { boolean result = this.connectionCount.get() \u0026gt; 0; result = result \u0026amp;\u0026amp; ((masterPutWhere - this.push2SlaveMaxOffset.get()) \u0026lt; this.defaultMessageStore .getMessageStoreConfig() .getHaSlaveFallbehindMax()); // 默认 256 * 1024 * 1024 = 256 MB  return result; } } 如果上面两个条件不满足的话，那么 Master 便不会再等待消息同步到 Slave 之后再返回，能尽早返回便尽早返回了。\n消息等待是否同步到 Slave 是借助 CountDownLatch 来实现的。当消息需要等待的时候，便会构建一个 GroupCommitRequest ，每个请求在其内部都维护了一个 CountDownLatch ，然后通过调用 await(timeout) 方法来等待消息同步到 Slave 之后，或者超时之后自动返回。\npublic static class GroupCommitRequest { private final CountDownLatch countDownLatch = new CountDownLatch(1); public void wakeupCustomer(final boolean flushOK) { this.flushOK = flushOK; this.countDownLatch.countDown(); } public boolean waitForFlush(long timeout) { try { this.countDownLatch.await(timeout, TimeUnit.MILLISECONDS); return this.flushOK; } catch (InterruptedException e) { log.error(\u0026#34;Interrupted\u0026#34;, e); return false; } } } 我们再重点来看几个循环体和唤醒点:\n GroupTransferService 服务的是否处理请求的循环体和唤醒点:  class GroupTransferService extends ServiceThread { public synchronized void putRequest(final CommitLog.GroupCommitRequest request) { // ...  // 放入请求，唤醒  if (hasNotified.compareAndSet(false, true)) { waitPoint.countDown(); // notify  } } public void run() { // 循环体  while (!this.isStopped()) { try { // putRequest 会提前唤醒这句话  this.waitForRunning(10); this.doWaitTransfer(); } catch (Exception e) { log.warn(this.getServiceName() + \u0026#34; service has exception. \u0026#34;, e); } } } }  HAConnection 的是否进行消息传输的循环体和唤醒点：  class WriteSocketService extends ServiceThread { @Override public void run() { // 循环体  while (!this.isStopped()) { SelectMappedBufferResult selectResult = HAConnection.this.haService.getDefaultMessageStore().getCommitLogData(this.nextTransferFromWhere); if (selectResult != null) { // 传输（写入）消息  } else { // 等待 100 毫秒或者提前被唤醒  HAConnection.this.haService.getWaitNotifyObject().allWaitForRunning(100); } } } } public class CommitLog { public void handleHA(AppendMessageResult result, PutMessageResult putMessageResult, MessageExt messageExt) { GroupCommitRequest request = new GroupCommitRequest(result.getWroteOffset() + result.getWroteBytes()); service.putRequest(request); // 提前唤醒 WriteSocketService  service.getWaitNotifyObject().wakeupAll(); } }  Slave 汇报进度唤醒 GroupTransferService， 等待同步完成唤醒 GroupCommitRequest 的 CountDownLatch:  class ReadSocketService extends ServiceThread { private boolean processReadEvent() { // 唤醒 GroupTransferService  HAConnection.this.haService.notifyTransferSome(HAConnection.this.slaveAckOffset); } } class GroupTransferService extends ServiceThread { // 被唤醒  public void notifyTransferSome() { this.notifyTransferObject.wakeup(); } private void doWaitTransfer() { for (CommitLog.GroupCommitRequest req : this.requestsRead) { boolean transferOK = HAService.this.push2SlaveMaxOffset.get() \u0026gt;= req.getNextOffset(); // 5 次重试  for (int i = 0; !transferOK \u0026amp;\u0026amp; i \u0026lt; 5; i++) { // 等待被唤醒或者超时  this.notifyTransferObject.waitForRunning(1000); transferOK = HAService.this.push2SlaveMaxOffset.get() \u0026gt;= req.getNextOffset(); } // 唤醒 GroupCommitRequest 的 CountDownLatch  req.wakeupCustomer(transferOK); } } } public static class GroupCommitRequest { // 被唤醒  public void wakeupCustomer(final boolean flushOK) { this.flushOK = flushOK; this.countDownLatch.countDown(); } } 下图是上图一个完整的消息唤醒链:\n五、主备消费 当消费者在消费的时候，如果 Master 突然宕机，那么消费者会自动切换到 Slave 机器上继续进行消费。\n六、消费建议 RocketMQ 提供了自动从 Slave 读取老数据的功能。这个功能主要由 slaveReadEnable 这个参数控制。默认是关的（slaveReadEnable = false）。推荐把它打开，主从都要开。这个参数打开之后，在客户端消费数据时，会判断，当前读取消息的物理偏移量跟最新的位置的差值，是不是超过了内存容量的一个百分比（accessMessageInMemoryMaxRatio = 40 by default）。如果超过了，就会告诉客户端去备机上消费数据。如果采用异步主从，也就是 brokerRole 等于 ASYNC_AMSTER 的时候，你的备机 IO 打爆，其实影响不太大。但是如果你采用同步主从，那还是有影响。所以这个时候，最好挂两个备机。因为 RocketMQ 的主从同步复制，只要一个备机响应了确认写入就可以了，一台 IO 打爆，问题不大。参考自阿里中间件团队博客。\n七、异常处理 Q: Master(Slave) 读取来自 Slave(Master) 的消息异常 (IOException、 read() 返回 -1 等) 的时候怎么处理? A: 打印日志 + 关闭这条连接\nQ: Master(Slave) 长时间没有收到来自 Slave(Master) 的进度汇报怎么处理? A: 每次读取之后更新 lastReadTimestamp 或者 lastWriteTimestamp，一旦发现在 haHousekeepingInterval 间隔内 (默认 20秒) 这个时间戳都没有改变的话，关闭这条连接\nQ: Slave 检测到来自 Master 汇报的本次传输偏移量和本地的传输偏移量不同时怎么处理? A: 打印日志 + 关闭这条连接\nQ: Master 如何知道 Slave 是否真正的存储了刚才发送过去的消息? A: Slave 存储完毕之后，通过向 Master 汇报进度来完成。相当于 TCP 的 ACK 机制。\nQ: Master 宕掉 A: 无论 Maser 是主动关闭 Mater，还是 Master 因为异常而退出，Slave 都会每隔 5 秒重连一次 Master\n"});index.add({'id':21,'href':'/categories/','title':"Categories",'content':""});index.add({'id':22,'href':'/docs/','title':"Docs",'content':""});index.add({'id':23,'href':'/tags/','title':"Tags",'content':""});index.add({'id':24,'href':'/','title':"首页",'content':"赵坤的个人网站 本博客将致力于整理、分析 Java、前端 等开发者生态圈的开源项目的教程、源码等，我会参阅大量书籍，一一对这些基础知识点抽丝剥茧，并匹配大量图表，为大家呈现出它们最本质的面目。\n通过阅读和分析开源项目等，可以增长自己的工程实践能力，可以让自己从代码中汲取养分，也可以学习到他人的设计权衡之道，其对于自己成长的重要性不言而喻！\n对于在博客中遇到的问题或其它事项，欢迎通过邮箱 igozhaokun@163.com 与我联系，谢谢！\n"});})();