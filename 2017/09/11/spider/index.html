<html>
<head>
	
	<!-- hexo-inject:begin --><!-- hexo-inject:end --><title>spider</title>
	<meta name="keywords" content="代码人生,程序员,赵坤" />

    <meta http-equiv="content-type" content="text/html; charset=utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

    
    <!--<link rel="stylesheet" href="/css/main.css">-->
	<link href="/css/main.css?v=2" rel="stylesheet" type="text/css" />
    <!--<link rel="stylesheet" href="/css/style.css">-->
    

    <link rel="alternate" type="application/atom+xml" href="/atom.xml" title="Atom feed">

    
	<link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=2"/><!-- hexo-inject:begin --><!-- hexo-inject:end -->
    

</head>

<body>

<!-- hexo-inject:begin --><!-- hexo-inject:end --><h2 id="Spider"><a href="#Spider" class="headerlink" title="Spider"></a>Spider</h2><h3 id="DNS"><a href="#DNS" class="headerlink" title="DNS"></a>DNS</h3><p>DNS 解析是一个网络爬虫性能瓶颈。由于域名服务器的分布式特点，DNS 可能需要多次请求转发，并在互联网上往返，需要几秒有时甚至更长时间解析出 IP 地址。一个补救措施是引入 <strong>DNS 缓存</strong>，这样最近完成 DNS 查询的网址可能会在 DNS 缓存中找到，避免了访问互联网上的 DNS 服务器。JDK 1.6 内部有个 30 秒的 DNS 缓存，通过 <code>sun.net.InetAddressCachePolicy.get()</code> 方法可以查看缓存时间设置。<code>Java</code> 要查找一个域名 IP 地址最方便的办法就是:</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">List&lt;String&gt; ipList = <span class="keyword">new</span> ArrayList&lt;String&gt;();</span><br><span class="line">InetAddress[] addressList = InetAddress.getAllByName(host);</span><br><span class="line"><span class="keyword">for</span> (InetAddress address: addressList) &#123;</span><br><span class="line">    ipList.add(address.getHostAddress());</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<hr>
<p><code>HttpClient</code> 抓取每个 URL 时，JVM 都会自动缓存这个 URL 和对应的 IP，并且<strong>永远缓存</strong>，除非缓存的内容大于 JVM 的限制，如果将来这个 URL 更换了 IP，<code>HttpClient</code> 会首先去 <code>JVM</code> 的缓存里取，如果取到了直接根据这个 IP 去抓取。所以往往某个域名更换了 IP，抓取结果都是 604 错误。</p>
<p>解决办法是在 Java 代码里添加如下所示的代码:</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">java.security.Security.setProperty(<span class="string">"networkaddress.cache.ttl"</span>, <span class="string">"0"</span>);</span><br></pre></td></tr></table></figure>
<h3 id="中文编码问题"><a href="#中文编码问题" class="headerlink" title="中文编码问题"></a>中文编码问题</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">URLEncoder.encode(<span class="string">"http://lietu.com/case/价格搜索.ppt"</span>, <span class="string">"UTF-8"</span>);</span><br></pre></td></tr></table></figure>
<p><code>URLEncoder.encode</code> 方法<strong>处理空格</strong>有问题。空格符 (ASCII 码是 0x20) 经过 <code>java.net.URLEncoder</code> 类 <code>encode</code> 以后，会变成 <code>+</code> 号，而不是 <code>%20</code>，所以使用 <strong><code>java.net.URI</code></strong> 中的编码功能。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">String data = <span class="keyword">new</span> URI(<span class="keyword">null</span>, term, <span class="keyword">null</span>).toASCIIString();</span><br><span class="line">String input = <span class="string">"%E6%B5%B7%E6%8A5%A5%E7%BD%91"</span>;</span><br><span class="line">System.out.println(URLDecoder.decode(input, <span class="string">"utf-8"</span>));</span><br></pre></td></tr></table></figure>
<h3 id="Referer-防止图片盗链"><a href="#Referer-防止图片盗链" class="headerlink" title="Referer 防止图片盗链"></a><code>Referer</code> 防止图片盗链</h3><p>爬虫有时候需要设置这个值:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Referer: http://www.w3.org/hypertext/DataSources/Overview.html</span><br></pre></td></tr></table></figure>
<h3 id="压缩网页"><a href="#压缩网页" class="headerlink" title="压缩网页"></a>压缩网页</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> (header[i].getName().equalsIgnoreCase(<span class="string">"gzip"</span>)) &#123;</span><br><span class="line">    response.setEntity(<span class="keyword">new</span> GzipDecompressingEntity(response.getEntity()));</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">GzipDecompressingEntity</span> <span class="keyword">extends</span> <span class="title">HttpEntityWrapper</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">GzipDecompressingEntity</span><span class="params">(<span class="keyword">final</span> HttpEntity entity)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">super</span>(entity);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> InputStream <span class="title">getContent</span><span class="params">()</span> <span class="keyword">throws</span> IOException, IllegalStateException </span>&#123;</span><br><span class="line">        InputStream wrappedIn = wrappedEntity.getContent();</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> GZIPInputStream(wrappedIn);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">long</span> <span class="title">getContentLength</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="comment">// 解压缩内容的长度未知</span></span><br><span class="line">        <span class="keyword">return</span> -<span class="number">1</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="套接字连接限制"><a href="#套接字连接限制" class="headerlink" title="套接字连接限制"></a>套接字连接限制</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">zk@zk-pc:~$ sysctl net.ipv4.ip_local_port_range</span><br><span class="line">net.ipv4.ip_local_port_range = 32768	60999</span><br><span class="line">zk@zk-pc:~$ sysctl net.ipv4.tcp_fin_timeout</span><br><span class="line">net.ipv4.tcp_fin_timeout = 60</span><br></pre></td></tr></table></figure>
<p>这基本上意味着任何时候系统不能保证多于</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(60999 - 32768) / 60 = 470 socket</span><br></pre></td></tr></table></figure>
<p>可以增加 <code>port_range</code>，设置范围到 <code>15000 60999</code> 很常见。可以通过减少 <code>fin_timeout</code> 进一步增加可获得的连接，同时做到这两部，可以有多于 1500 个连接。</p>
<p>使用 <code>sysctl</code> 能够改变正在运行的 Linux 系统接口:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sysctl -w net.ipv4.tcp_fin_timeout = 30</span><br><span class="line">sysctl -w net.ipv4.ip_local_port_range = <span class="string">"15000 60999"</span></span><br></pre></td></tr></table></figure>
<p>也可以编辑 <code>/etc/sysctl.conf</code> 文件来修改。</p>
<h3 id="网页是否有更新"><a href="#网页是否有更新" class="headerlink" title="网页是否有更新"></a>网页是否有更新</h3><p>可以用 HTTP 的 <code>HEAD</code> 命令查看网页的<strong>最后修改时间</strong>。</p>
<p><img src="2017_09_11_10_00_19.png" alt=""></p>
<p>有些网页头信息没有包括更新时间，这时候也可以通过<strong>判断网页长度</strong>来检测网页是否有更新。当然也可能更新了，但是长度没变，实际上，这种可能性非常小。</p>
<p>条件下载命令可以根据时间条件下载网页。再次请求已经抓取过的页面时，爬虫往 Web 服务器发送 <code>If-Modified-Since</code> 请求头，如果有修改，返回 200，未修改，返回 304。</p>
<p>HTTP/1.1 还有一个 <code>Etag</code> 可以通过发送 <code>If-None-Match</code> 用来判断请求的文件是否被修改，可以把 <code>Etag</code> 看成网页的版本标志。<code>Etag</code> 主要为了解决 <code>Last-Modified</code> 无法解决的一些问题。</p>
<ul>
<li>一些文件的内容不修改，但是修改时间会发生变化。</li>
<li><code>If-Modified-Since</code> 无法判断秒级的变化。</li>
<li>不能精确地得到某些 Web 服务器文件的最后修改时间。</li>
</ul>
<hr>
<p>可以用 <code>Range:bytes=0-500</code> 条件下载部分网页。</p>
<p><img src="2017_09_11_10_17_28.png" alt=""></p>
<p>服务器返回信息如下:</p>
<p><img src="2017_09_11_10_34_40.png" alt=""></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">RandomAccess savedFile = <span class="keyword">new</span> RandomAccessFile(<span class="string">"down.zip"</span>, <span class="string">"rw"</span>);</span><br><span class="line"><span class="keyword">long</span> pos = <span class="number">2000070</span>;</span><br><span class="line">savedFile.seek(pos);</span><br><span class="line"></span><br><span class="line"><span class="keyword">byte</span>[] b = <span class="keyword">new</span> <span class="keyword">byte</span>[<span class="number">1024</span>];</span><br><span class="line"><span class="keyword">int</span> read;</span><br><span class="line"><span class="keyword">while</span> ((read = input.read(b, <span class="number">0</span>, <span class="number">1024</span>)) &gt; <span class="number">0</span>) &#123;</span><br><span class="line">    savedFile.write(b, <span class="number">0</span>, read);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="防止反爬虫"><a href="#防止反爬虫" class="headerlink" title="防止反爬虫"></a>防止反爬虫</h3><p>有些网站专门发布免费的代理列表 (HTTP free proxy list)，可以从这些网站抓到免费代理的 IP 地址以及端口号，然后建立有效代理列表。</p>
<h3 id="相对-URL-转绝对-URL"><a href="#相对-URL-转绝对-URL" class="headerlink" title="相对 URL 转绝对 URL"></a>相对 URL 转绝对 URL</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">URL fromURL = <span class="keyword">new</span> URL(<span class="string">"http://www.lietu.com/news/"</span>);</span><br><span class="line">String url = <span class="string">"../index.html"</span>;</span><br><span class="line"><span class="comment">// http://www.lietu.com/index.html</span></span><br><span class="line">String newUrl = (<span class="keyword">new</span> URL(fromUrl, url)).toString();</span><br></pre></td></tr></table></figure>
<hr>
<p><code>org.apache.http.client.utils.URIUtils</code> 中有一个 <code>resolve</code> 方法可以用来根据 <code>URL</code> 地址生成绝对 <code>URL</code> 地址:</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">URIUtils.resolve(<span class="keyword">this</span>.baseURI, <span class="string">"/g"</span>);</span><br></pre></td></tr></table></figure>
<hr>
<p>URL 地址中的 <code>#</code> 指向内部锚点，对于爬虫没有意义。</p>
<hr>
<p>归一化: 将这个 URL 唯一化。</p>
<h3 id="动态网站"><a href="#动态网站" class="headerlink" title="动态网站"></a>动态网站</h3><p><code>Mozilla</code> 发布了纯 Java 语言编写的 <code>JavaScript</code> 脚本解释引擎 <a href="http://www.mozilla.org/rhino/" target="_blank" rel="noopener"><code>Rhino</code></a>。</p><!-- hexo-inject:begin --><!-- hexo-inject:end -->






</body>
</html>
