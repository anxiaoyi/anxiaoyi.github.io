<html>
<head>
	
	<!-- hexo-inject:begin --><!-- hexo-inject:end --><title>Hadoop</title>
	<meta name="keywords" content="代码人生,程序员,赵坤" />

    <meta http-equiv="content-type" content="text/html; charset=utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

    
    <!--<link rel="stylesheet" href="/css/main.css">-->
	<link href="/css/main.css?v=2" rel="stylesheet" type="text/css" />
    <!--<link rel="stylesheet" href="/css/style.css">-->
    

    <link rel="alternate" type="application/atom+xml" href="/atom.xml" title="Atom feed">

    
	<link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=2"/><!-- hexo-inject:begin --><!-- hexo-inject:end -->
    

</head>

<body>

<!-- hexo-inject:begin --><!-- hexo-inject:end --><h2 id="Hadoop"><a href="#Hadoop" class="headerlink" title="Hadoop"></a>Hadoop</h2><blockquote>
<p>算法再好，通常也难敌更多的数据．</p>
</blockquote>
<h3 id="为什么不能使用数据库加上更多磁盘来做大规模的批量分析"><a href="#为什么不能使用数据库加上更多磁盘来做大规模的批量分析" class="headerlink" title="为什么不能使用数据库加上更多磁盘来做大规模的批量分析"></a>为什么不能使用数据库加上更多磁盘来做大规模的批量分析</h3><p>这个问题来自于磁盘驱动器的发展趋势: <strong>寻址时间的提高速度远远慢于传输速率的提高速度</strong>．</p>
<h3 id="Hadoop-源码最重要的几个库"><a href="#Hadoop-源码最重要的几个库" class="headerlink" title="Hadoop 源码最重要的几个库"></a><code>Hadoop</code> 源码最重要的几个库</h3><p><img src="2017_10_27_20_26_31.png" alt=""></p>
<p>这几个库的系统默认配置文件:</p>
<ul>
<li><code>./hadoop-common-project/hadoop-common/src/main/resources/core-default.xml</code></li>
<li><code>./hadoop-hdfs-project/hadoop-hdfs/src/main/resources/hdfs-default.xml</code></li>
<li><code>./hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/resources/mapred-default.xml</code></li>
</ul>
<p>相应的这几个库的重要配置文件:</p>
<ul>
<li><code>./hadoop-common-project/hadoop-common/src/main/conf/core-site.xml</code></li>
<li><code>./hadoop-hdfs-project/hadoop-hdfs/src/main/conf/hdfs-site.xml</code></li>
<li><code>./hadoop-mapreduce-project/conf/mapred-site.xml</code></li>
</ul>
<p>相应的最重要的几个脚本:</p>
<ul>
<li><code>./hadoop-common-project/hadoop-common/src/main/bin/start-all.sh</code></li>
<li><code>./hadoop-hdfs-project/hadoop-hdfs/src/main/bin/start-dfs.sh</code></li>
</ul>
<p>API 版本兼容问题:</p>
<ul>
<li><code>org.apache.hadoop.mapred.*</code> 这个包下面包含<strong>旧</strong>的对外编程接口和 <code>MapReduce</code> 各个服务实现</li>
<li><code>org.apache.hadoop.mapreduce.*</code> 这个包下面包含<strong>新</strong>的对外编程接口以及一些新特性</li>
</ul>
<p>自带的例子:</p>
<ul>
<li><code>./hadoop-mapreduce-project/hadoop-mapreduce-examples/src/main/java/org/apache/hadoop/examples/WordCount.java</code></li>
</ul>
<hr>
<p>配置文件：</p>
<p><img src="2017_10_31_17_20_21.png" alt=""></p>
<p><code>Configuration</code> 一上来会加载这两个类:</p>
<p><img src="2017_10_31_17_25_47.png" alt=""></p>
<h3 id="WordCount-运行过程"><a href="#WordCount-运行过程" class="headerlink" title="WordCount 运行过程"></a><code>WordCount</code> 运行过程</h3><p><img src="2017_10_27_22_05_31.png" alt=""></p>
<ul>
<li>将数据切分为若干个<strong>输入分片</strong></li>
<li>每个输入分片交给一个<strong>Map Task</strong>处理</li>
<li><code>Map Task</code> 从对应的输入分片中解析出一个个的 <code>key/value</code>,并调用 <code>map()</code> 函数处理</li>
<li>根据 <code>Reduce Task</code> 个数将结果分成若干个分片 <code>Partition</code> 写到本地磁盘</li>
<li>每个 <code>Reduce Task</code> 从每个 <code>Map Task</code> 中读取属于自己的那个 <code>partition</code>,然后用基于排序的方法将 <code>key</code> 相同的数据聚集在一起</li>
<li>调用 <code>reduce()</code> 函数处理,并将结果输出到文件中</li>
</ul>
<p><code>TokenizerMapper</code>:</p>
<p><img src="2017_10_27_22_11_25.png" alt=""></p>
<p><code>IntSumReducer</code>:</p>
<p><img src="2017_10_27_22_12_23.png" alt=""></p>
<h3 id="map-的工作方式"><a href="#map-的工作方式" class="headerlink" title="map 的工作方式"></a><code>map</code> 的工作方式</h3><p><img src="2017_10_26_09_14_46.png" alt=""></p>
<p>这些行以<strong>键/值对</strong>的方式来表示 <code>map</code> 函数:</p>
<p><img src="2017_10_26_09_15_41.png" alt=""></p>
<p>行号会被忽略，<code>map</code> 函数提取年份和气温，并将其作为输出发送:</p>
<p><img src="2017_10_26_09_17_11.png" alt=""></p>
<p><code>map</code> 函数的输出先由　<code>MapReduce</code> 框架处理，然后再被发送到 <code>reduce</code> 函数．这一处理过程根据键来键/值对进行<strong>排序和分组</strong>．<code>reduce</code> 函数会看到如下输入:</p>
<p><img src="2017_10_26_09_18_45.png" alt=""></p>
<p>每年的年份都有一系列气温读数，所有 <code>reduce</code> 函数必须重复这个列表并从中找出最大的读数:</p>
<p><img src="2017_10_26_09_20_42.png" alt=""></p>
<p>整个逻辑数据流:</p>
<p><img src="2017_10_26_09_21_52.png" alt=""></p>
<h3 id="MapReduce-解决的问题"><a href="#MapReduce-解决的问题" class="headerlink" title="MapReduce 解决的问题"></a><code>MapReduce</code> 解决的问题</h3><p>任务可以被分解为多个子问题,且这些子问题相对独立,彼此之间不会有牵制. 基于该特点， <code>MapReduce</code> 编程模型给出了其分布式编程方法， 共分 5 个步骤：</p>
<ul>
<li>迭代（ iteration）。 遍历输入数据， 并将之解析成 key/value 对。</li>
<li>将输入 key/value 对映射（ map） 成另外一些 key/value 对。</li>
<li>依据 key 对中间数据进行分组（ grouping）。</li>
<li>以组为单位对数据进行归约（ reduce）。</li>
<li>迭代。 将最终产生的 key/value 对保存到输出文件中。</li>
</ul>
<p>MapReduce 将计算过程分解成以上 5 个步骤带来的最大好处是<strong>组件化</strong>与<strong>并行化</strong>。</p>
<p><img src="2017_10_27_23_49_07.png" alt=""></p>
<p>应用范围:</p>
<ul>
<li>分布式 <code>grep</code></li>
<li><code>URL</code> 访问频率统计</li>
<li>倒排索引构建</li>
<li>分布式排序</li>
<li><code>Top K</code> 问题</li>
<li><code>K-means</code> 聚类</li>
<li>贝叶斯分类</li>
</ul>
<blockquote>
<p>注: <code>Fibonacci</code> 数值计算不能用 <code>MapReduce</code> 来解决,因为下一个结果依赖于前面的计算结果.</p>
</blockquote>
<h3 id="HDFS-架构"><a href="#HDFS-架构" class="headerlink" title="HDFS 架构"></a><code>HDFS</code> 架构</h3><p><img src="hdfsarchitecture.gif" alt=""></p>
<p>当用户上传一个大的文件到 <code>HDFS</code> 上时， 该文件会被切分成若干个 <code>block</code>， 分别存储到不同的 <code>DataNode</code>； 同时， 为了保证数据可靠， 会将同一个 <code>block</code> 以流水线方式写到<strong>若干个</strong>（ 默认是 3， 该参数可配置） 不同的 <code>DataNode</code> 上。 这种文件切割后存储的过程是对用户透明的。</p>
<h3 id="MapReduce-架构"><a href="#MapReduce-架构" class="headerlink" title="MapReduce 架构"></a><code>MapReduce</code> 架构</h3><p><img src="2017_10_27_22_39_27.png" alt=""></p>
<p><code>Split</code> 和 <code>Block</code> 的对应关系:</p>
<p><img src="2017_10_27_22_45_53.png" alt=""></p>
<p><code>MapTask</code> 执行过程:</p>
<p><img src="2017_10_27_23_26_24.png" alt=""></p>
<p><code>ReduceTask</code> 执行过程:</p>
<p><img src="2017_10_27_23_30_28.png" alt=""></p>
<p><code>Hadoop MapReduce</code> 作业的<strong>生命周期</strong>:</p>
<p><img src="2017_10_27_23_35_58.png" alt=""></p>
<h3 id="提交作业后"><a href="#提交作业后" class="headerlink" title="提交作业后"></a>提交作业后</h3><div class="table-container">
<table>
<thead>
<tr>
<th>字段</th>
<th>默认值</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>mapred.mapper.new-api</code></td>
<td><code>false</code></td>
<td></td>
</tr>
<tr>
<td><code>mapred.reducer.new-api</code></td>
<td><code>false</code></td>
<td></td>
</tr>
<tr>
<td><code>yarn.app.mapreduce.client.job.max-retries</code></td>
<td><code>3</code></td>
<td></td>
</tr>
<tr>
<td><code>yarn.app.mapreduce.client.job.retry-interval</code></td>
<td><code>2000</code></td>
<td></td>
</tr>
<tr>
<td><code>mapreduce.job.reduces</code></td>
<td><code>1</code></td>
<td>the number of reduce tasks for this job</td>
</tr>
</tbody>
</table>
</div>
<ul>
<li>创建 <code>Cluster</code><ul>
<li>使用 <code>YarnClientProtocolProvider</code> 创建 <code>ClientProtocol</code></li>
<li>如果配置文件设置了 <code>mapreduce.framework.name</code> 为 <code>yarn</code>,就返回 <code>YARNRunner</code></li>
<li>TODO: 猜测可能使用的是 <code>LocalJobRunner</code></li>
</ul>
</li>
<li>假设是 <code>LocalJobRunner</code><ul>
<li>本地 <code>mapreduce.jobtracker.system.dir</code> 目录 : <code>/tmp/hadoop/mapred/system</code></li>
<li><code>stageArea 目录</code> = <code>/tmp/hadoop/mapred/staging</code> + <code>groupName</code> + <code>randid</code> + <code>/.staging</code></li>
</ul>
</li>
<li>检查 <code>OutputSpecs</code>:<ul>
<li>保障 <code>Output</code> 目录不存在</li>
<li><code>jobId</code> = <code>new JobID(&quot;local&quot; + randid, ++jobid)</code></li>
<li><code>submit 目录</code> = <code>stageArea 目录</code> + <code>/</code> + <code>jobId</code></li>
</ul>
</li>
<li>上传资源文件夹<ul>
<li><code>sharedCache</code> 只在 <code>Yarn</code> 平台上才可以使用</li>
<li>默认 <code>replication</code> 是 <code>10</code></li>
<li>如果 <code>submit 目录</code> 已经存在于本地的 <code>HDFS</code> 中, 抛出 <code>IOException</code></li>
<li>授予 <code>submit 目录</code> 一个 <code>0700 (rwx------)</code> 权限</li>
<li>创建 <code>submit 目录</code></li>
<li><code>Job 分布式缓存文件目录</code> = <code>submit 目录</code> + <code>/</code> + <code>files</code></li>
<li><code>Job 分布式缓存库目录</code> = <code>submit 目录</code> + <code>/</code> + <code>libjars</code></li>
<li><code>Job 分布式缓存 archives 目录</code> = <code>submit 目录</code> + <code>/</code> + <code>archives</code></li>
<li><code>job.jar 路径</code> = <code>submit 目录</code> + <code>/</code> + <code>job.jar</code></li>
<li>将用户配置的 <code>tmpfiles</code> 文件拷贝到 <code>Job 分布式缓存目录</code></li>
<li>将用户配置的 <code>tmpjars</code> 文件拷贝到 <code>Job 分布式缓存库目录</code></li>
<li>将用户配置的 <code>tmparchives</code> 文件拷贝到 <code>Job 分布式缓存 archives 目录</code></li>
<li>讲用户配置的 <code>jobJar</code> 路径拷贝到 <code>job.jar</code> 路劲下面<ul>
<li>以上拷贝的时候, 特意对比了两个是不是位于同一个文件系统上,仅仅比对 <code>uri</code> 字符串,没有 <code>DNS Lookup</code></li>
</ul>
</li>
</ul>
</li>
<li>获取 <code>submit 目录</code> + <code>/</code> + <code>job.xml</code><ul>
<li><code>InputFormat</code> 转为 <code>InputSplit[]</code><ul>
<li>获得输入 <code>Path</code> 列表</li>
<li>过滤 <code>_</code> 或者 <code>.</code> 开头的文件</li>
<li>计算目标大小: <code>totalSize / numSplits</code></li>
</ul>
</li>
</ul>
</li>
</ul>
<p><strong>(1) 得到 <code>map-reduce</code> 任务的 <code>InputFormat</code> 表示</strong>:</p>
<ul>
<li>对于每一个文件,获取分区信息:</li>
</ul>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">BlockLocation(offset: <span class="number">0</span>, length: BLOCK_SIZE, hosts: &#123;<span class="string">"host1:9866"</span>, <span class="string">"host2:9866, host3:9866"</span>&#125;)</div></pre></td></tr></table></figure>
<ul>
<li>根据文件大小排序,大的排在前面,先运行</li>
</ul>
<p><strong>(2) 获取 <code>Job</code> 提交的队列的名字,默认 <code>default</code></strong>:</p>
<ul>
<li>配置写入 <code>job.xml</code> 文件中</li>
<li>正式提交 <code>Job</code></li>
</ul>
<p><strong>(3) 查询信息:</strong></p>
<ul>
<li>使用 <code>NetworkedJob</code> 封装 <code>Job</code></li>
<li>监控 <code>Job</code> 的运行和状态信息</li>
</ul>
<h3 id="Hadoop-启动"><a href="#Hadoop-启动" class="headerlink" title="Hadoop 启动"></a><code>Hadoop</code> 启动</h3><p>修改三个配置文件:</p>
<p>(1) <code>$HADOOP/etc/hadoop/mapred-site.xml</code></p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></div><div class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapred.job.tracker<span class="tag">&lt;/<span class="name">name</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>localhost:54311<span class="tag">&lt;/<span class="name">value</span>&gt;</span></div><div class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></div><div class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></div></pre></td></tr></table></figure>
<p>(2) <code>$HADOOP/etc/core-site.xml</code></p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></div><div class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></div><div class="line">	<span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.tmp.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></div><div class="line">	<span class="tag">&lt;<span class="name">value</span>&gt;</span>/home/zk/Documents/hadoop-hdfs<span class="tag">&lt;/<span class="name">value</span>&gt;</span></div><div class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></div><div class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></div><div class="line">	<span class="tag">&lt;<span class="name">name</span>&gt;</span>fs.default.name<span class="tag">&lt;/<span class="name">name</span>&gt;</span></div><div class="line">	<span class="tag">&lt;<span class="name">value</span>&gt;</span>hdfs://localhost:54310<span class="tag">&lt;/<span class="name">value</span>&gt;</span></div><div class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></div><div class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></div></pre></td></tr></table></figure>
<p>(3) <code>$HADOOP/etc/hdfs-site.xml</code></p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></div><div class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.replication<span class="tag">&lt;/<span class="name">name</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>1<span class="tag">&lt;/<span class="name">value</span>&gt;</span></div><div class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></div><div class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></div><div class="line">	<span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.permissions<span class="tag">&lt;/<span class="name">name</span>&gt;</span></div><div class="line">	<span class="tag">&lt;<span class="name">value</span>&gt;</span>false<span class="tag">&lt;/<span class="name">value</span>&gt;</span></div><div class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></div><div class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></div></pre></td></tr></table></figure>
<p><code>Hadoop</code> 启动/停止脚本时需要通过 <code>SSH</code> 发送命令启动相关守护进程,为了避免每次启动/停止 <code>Hadoop</code> 输入密码进行验证,需要设置免密码登录:拷贝本机的 <code>./ssh/id_rsa.pub</code> 到 <code>authorized_keys</code> 中.</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 格式化文件系统</span></div><div class="line">hadoop namenode -format</div><div class="line"><span class="comment"># 启动 Hadoop</span></div><div class="line"><span class="variable">$HADOOP</span>/sbin/start-all.sh</div></pre></td></tr></table></figure>
<p>启动之后可以使用 <code>$HADOOP/bin/hadoop</code> 来输入命令,完成各种操作,支持的命令请参考: <a href="https://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-common/CommandsManual.html" target="_blank" rel="external">Commands Guide</a></p>
<h3 id="序列化"><a href="#序列化" class="headerlink" title="序列化"></a>序列化</h3><p>在 <code>Hadoop MapReduce</code> 中， 序列化的主要作用有两个： <strong>永久存储和进程间通信</strong>。在 <code>Hadoop MapReduce</code> 中， 使一个 Java 对象可序列化的方法是让其对应的类实现 <code>Writable</code> 接口。 但对于 <code>key</code> 而言， 由于它是<strong>数据排序</strong>的关键字， 因此还需要提供比较两个 <code>key</code> 对象的方法。 为此， <code>key</code> 对应类需实现 <code>WritableComparable</code> 接口。</p>
<p><img src="2017_10_31_16_37_07.png" alt=""></p>
<h3 id="报告进度"><a href="#报告进度" class="headerlink" title="报告进度"></a>报告进度</h3><p><code>Reporter</code> 是 <code>MapReduce</code> 提供给应用程序的工具。 如图 3-4 所示， 应用程序可使用 <code>Reporter</code> 中的方法报告完成进度（ progress）、 设定状态消息（ setStatus） 以及更新计数器<br>（ incrCounter）。</p>
<h3 id="InputFormat"><a href="#InputFormat" class="headerlink" title="InputFormat"></a><code>InputFormat</code></h3><p><img src="2017_10_31_17_56_09.png" alt=""></p>
<h3 id="必读"><a href="#必读" class="headerlink" title="必读"></a>必读</h3><ul>
<li><a href="https://www.zhihu.com/question/19795366" target="_blank" rel="external">知乎-零基础学习 Hadoop 该如何下手？</a></li>
<li><a href="https://wiki.apache.org/hadoop#Setting_up_a_Hadoop_Cluster" target="_blank" rel="external">配置 <code>Hadoop</code> 集群教程</a><ul>
<li><a href="http://www.michael-noll.com/tutorials/running-hadoop-on-ubuntu-linux-single-node-cluster/" target="_blank" rel="external">Running Hadoop on Ubuntu Linux (Single-Node Cluster)</a></li>
</ul>
</li>
</ul>






<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script>
<script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><!-- hexo-inject:begin --><!-- hexo-inject:end -->
</body>
</html>
